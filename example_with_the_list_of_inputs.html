

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Example : k times repetition with the list of k input files &mdash; deepbiome 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example : k fold cross-validation with an input file" href="example_with_one_input_file.html" />
    <link rel="prev" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deepbiome
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example : k times repetition with the list of k input files</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#1.-Load-library">1. Load library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Prepare-the-dataset">2. Prepare the dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-tree-information">Example of the tree information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-list-of-the-name-of-input-files">Example of the list of the name of input files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-lists-of-the-input-files">Example of the lists of the input files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(regression)">Example of the Y (regression)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(classification)">Example of the Y (classification)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exmple-of-the-training-index-file-for-repetition">Exmple of the training index file for repetition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#3.-Prepare-the-configuration">3. Prepare the configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-network-information-(network_info)">For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-path-information-(path_info)">For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#4.-Deepbiome-Training">4. Deepbiome Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5.-Load-the-pre-trained-network-for-training">5. Load the pre-trained network for training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#6.-Load-the-pre-trained-network-for-testing">6. Load the pre-trained network for testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#7.-Load-the-pre-trained-network-for-prediction">7. Load the pre-trained network for prediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_with_one_input_file.html">Example : k fold cross-validation with an input file</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-history.html">Release History</a></li>
<li class="toctree-l1"><a class="reference internal" href="min_versions.html">Minimum Version of Python and NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepbiome</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Example : k times repetition with the list of k input files</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/example_with_the_list_of_inputs.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Example-:-k-times-repetition-with-the-list-of-k-input-files">
<h1>Example : k times repetition with the list of k input files<a class="headerlink" href="#Example-:-k-times-repetition-with-the-list-of-k-input-files" title="Permalink to this headline">¶</a></h1>
<p>Deepbiome packages takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.</p>
<p>To use deepbiome, you can experiment (1) <strong>k times repeatition</strong> or (2) <strong>k fold cross-validation</strong>. For each experiment, we asuume that the dataset is given by - <strong>A list of k input files for k times repeatition.</strong> - <strong>One input file for k fold cross-validation.</strong></p>
<p>This notebook contains an example of (1) <strong>k times repeatition</strong> for the deep neural netowrk using deepbiome.</p>
<div class="section" id="1.-Load-library">
<h2>1. Load library<a class="headerlink" href="#1.-Load-library" title="Permalink to this headline">¶</a></h2>
<p>First, we have to load deepbiome package. The deepbiome package is build on the tensorflow and keras library</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">resource_filename</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">deepbiome</span> <span class="kn">import</span> <span class="n">deepbiome</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
</pre></div></div>
</div>
</div>
<div class="section" id="2.-Prepare-the-dataset">
<h2>2. Prepare the dataset<a class="headerlink" href="#2.-Prepare-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this example, we assume that we have <strong>a list of k input files for k times repeatition.</strong></p>
<p>Deepbiome needs 4 data as follow: 1. <strong>the tree information</strong> 1. <strong>the lists of the input files</strong> (each file has all sample’s information for one repeatition) 1. <strong>the list of the name of input files</strong> 1. <strong>y</strong></p>
<p>In addition, we can set <strong>the training index for each repeatition</strong>. If we set the index file, deepbiome build the training set for each repeatition based on each fold index in the index file. If not, deepbiome will generate the index file locally.</p>
<p>Eath data should have the csv format. Below is the example of each file.</p>
<div class="section" id="Example-of-the-tree-information">
<h3>Example of the tree information<a class="headerlink" href="#Example-of-the-tree-information" title="Permalink to this headline">¶</a></h3>
<p>First we need a file about the phylogenetic tree information. This tree information file should have the format below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tree_information</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">))</span>
<span class="n">tree_information</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genus</th>
      <th>Family</th>
      <th>Order</th>
      <th>Class</th>
      <th>Phylum</th>
      <th>Domain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Streptococcus</td>
      <td>Streptococcaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tropheryma</td>
      <td>Cellulomonadaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Veillonella</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Actinomyces</td>
      <td>Actinomycetaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Flavobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Prevotella</td>
      <td>Prevotellaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Porphyromonas</td>
      <td>Porphyromonadaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Parvimonas</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Fusobacterium</td>
      <td>Fusobacteriaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Propionibacterium</td>
      <td>Propionibacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Gemella</td>
      <td>Bacillales_Incertae_Sedis_XI</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Rothia</td>
      <td>Micrococcaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Granulicatella</td>
      <td>Carnobacteriaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Neisseria</td>
      <td>Neisseriaceae</td>
      <td>Neisseriales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Lactobacillus</td>
      <td>Lactobacillaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Megasphaera</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Catonella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Atopobium</td>
      <td>Coriobacteriaceae</td>
      <td>Coriobacteriales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Campylobacter</td>
      <td>Campylobacteraceae</td>
      <td>Campylobacterales</td>
      <td>Epsilonproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Capnocytophaga</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Solobacterium</td>
      <td>Erysipelotrichaceae</td>
      <td>Erysipelotrichales</td>
      <td>Erysipelotrichia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Moryella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>22</th>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Staphylococcus</td>
      <td>Staphylococcaceae</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Filifactor</td>
      <td>Peptostreptococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Oribacterium</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Burkholderia</td>
      <td>Burkholderiaceae</td>
      <td>Burkholderiales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Sneathia</td>
      <td>Leptotrichiaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Treponema</td>
      <td>Spirochaetaceae</td>
      <td>Spirochaetales</td>
      <td>Spirochaetes</td>
      <td>Spirochaetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Moraxella</td>
      <td>Moraxellaceae</td>
      <td>Pseudomonadales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Haemophilus</td>
      <td>Pasteurellaceae</td>
      <td>Pasteurellales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Selenomonas</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Corynebacterium</td>
      <td>Corynebacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Rhizobium</td>
      <td>Rhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Bradyrhizobium</td>
      <td>Bradyrhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Methylobacterium</td>
      <td>Methylobacteriaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>36</th>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Finegoldia</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Microbacterium</td>
      <td>Microbacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Sphingomonas</td>
      <td>Sphingomonadaceae</td>
      <td>Sphingomonadales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Chryseobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Bacteroides</td>
      <td>Bacteroidaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Bdellovibrio</td>
      <td>Bdellovibrionaceae</td>
      <td>Bdellovibrionales</td>
      <td>Deltaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Streptophyta</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Cyanobacteria_Chloroplast</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Lachnospiracea_incertae_sedis</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Paracoccus</td>
      <td>Rhodobacteraceae</td>
      <td>Rhodobacterales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Fastidiosipila</td>
      <td>Ruminococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Pseudonocardia</td>
      <td>Pseudonocardiaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-list-of-the-name-of-input-files">
<h3>Example of the list of the name of input files<a class="headerlink" href="#Example-of-the-list-of-the-name-of-input-files" title="Permalink to this headline">¶</a></h3>
<p>In this example. we assume that input is given by the lists of files. Each file has all sample’s information for one repeatition. If we want to use the list of the input files, we need the make a list of the name of each input file. Below is an example file for <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repeatition.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">list_of_input_files</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">list_of_input_files</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>gcount_0001.csv</td>
    </tr>
    <tr>
      <th>1</th>
      <td>gcount_0002.csv</td>
    </tr>
    <tr>
      <th>2</th>
      <td>gcount_0003.csv</td>
    </tr>
    <tr>
      <th>3</th>
      <td>gcount_0004.csv</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gcount_0005.csv</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">list_of_input_files</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>gcount_0996.csv</td>
    </tr>
    <tr>
      <th>996</th>
      <td>gcount_0997.csv</td>
    </tr>
    <tr>
      <th>997</th>
      <td>gcount_0998.csv</td>
    </tr>
    <tr>
      <th>998</th>
      <td>gcount_0999.csv</td>
    </tr>
    <tr>
      <th>999</th>
      <td>gcount_1000.csv</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-lists-of-the-input-files">
<h3>Example of the lists of the input files<a class="headerlink" href="#Example-of-the-lists-of-the-input-files" title="Permalink to this headline">¶</a></h3>
<p>Below is an example of the each input file. This example has 1000 samples for each row, and abandunt of each microbiome for each column. Below is an example file for <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repeatition. This example is <code class="docutils literal notranslate"><span class="pre">gcount_0001.csv</span></code> for the first repeatition in the list of the names of input files above. This file has the 4 samples’ microbiome abandunce.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">list_of_input_files</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">x_1</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>841</td>
      <td>0</td>
      <td>813</td>
      <td>505</td>
      <td>5</td>
      <td>3224</td>
      <td>0</td>
      <td>362</td>
      <td>11</td>
      <td>65</td>
      <td>...</td>
      <td>0</td>
      <td>87</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2133</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1445</td>
      <td>0</td>
      <td>1</td>
      <td>573</td>
      <td>0</td>
      <td>1278</td>
      <td>82</td>
      <td>85</td>
      <td>69</td>
      <td>154</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3638</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1259</td>
      <td>0</td>
      <td>805</td>
      <td>650</td>
      <td>0</td>
      <td>1088</td>
      <td>0</td>
      <td>0</td>
      <td>74</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3445</td>
    </tr>
    <tr>
      <th>3</th>
      <td>982</td>
      <td>0</td>
      <td>327</td>
      <td>594</td>
      <td>0</td>
      <td>960</td>
      <td>81</td>
      <td>19</td>
      <td>9</td>
      <td>0</td>
      <td>...</td>
      <td>157</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3507</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1162</td>
      <td>0</td>
      <td>130</td>
      <td>969</td>
      <td>163</td>
      <td>1515</td>
      <td>167</td>
      <td>4</td>
      <td>162</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>3945</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x_1</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1401</td>
      <td>4</td>
      <td>30</td>
      <td>526</td>
      <td>0</td>
      <td>923</td>
      <td>25</td>
      <td>0</td>
      <td>127</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4470</td>
    </tr>
    <tr>
      <th>996</th>
      <td>2655</td>
      <td>6</td>
      <td>106</td>
      <td>74</td>
      <td>0</td>
      <td>952</td>
      <td>76</td>
      <td>13</td>
      <td>158</td>
      <td>125</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2826</td>
    </tr>
    <tr>
      <th>997</th>
      <td>335</td>
      <td>0</td>
      <td>71</td>
      <td>259</td>
      <td>67</td>
      <td>718</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>167</td>
      <td>...</td>
      <td>0</td>
      <td>246</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6527</td>
    </tr>
    <tr>
      <th>998</th>
      <td>649</td>
      <td>69</td>
      <td>966</td>
      <td>1227</td>
      <td>0</td>
      <td>508</td>
      <td>2</td>
      <td>30</td>
      <td>550</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4402</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1258</td>
      <td>0</td>
      <td>0</td>
      <td>1119</td>
      <td>0</td>
      <td>2348</td>
      <td>25</td>
      <td>0</td>
      <td>137</td>
      <td>176</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2585</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(regression)">
<h3>Example of the Y (regression)<a class="headerlink" href="#Example-of-the-Y-(regression)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for regression problem. One column contains y samples for one repeatition. For each repeatition (column) has outputs of 4 samples for each repeatition. Below example file has 1000 samples in row, <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repeatition in column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/regression_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>x3</th>
      <th>x4</th>
      <th>x5</th>
      <th>x6</th>
      <th>x7</th>
      <th>x8</th>
      <th>x9</th>
      <th>x10</th>
      <th>...</th>
      <th>x991</th>
      <th>x992</th>
      <th>x993</th>
      <th>x994</th>
      <th>x995</th>
      <th>x996</th>
      <th>x997</th>
      <th>x998</th>
      <th>x999</th>
      <th>x1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.997270</td>
      <td>5.492354</td>
      <td>5.473725</td>
      <td>1.759484</td>
      <td>5.313252</td>
      <td>1.500044</td>
      <td>4.949712</td>
      <td>5.493533</td>
      <td>3.743509</td>
      <td>5.492373</td>
      <td>...</td>
      <td>2.793883</td>
      <td>1.500004</td>
      <td>5.487526</td>
      <td>5.493518</td>
      <td>3.599047</td>
      <td>5.491461</td>
      <td>5.486244</td>
      <td>5.487390</td>
      <td>5.493492</td>
      <td>3.762523</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.004092</td>
      <td>1.500002</td>
      <td>4.640348</td>
      <td>1.538071</td>
      <td>5.491065</td>
      <td>5.481009</td>
      <td>5.492323</td>
      <td>2.968531</td>
      <td>3.576358</td>
      <td>5.491456</td>
      <td>...</td>
      <td>1.500033</td>
      <td>3.369529</td>
      <td>1.500016</td>
      <td>3.103297</td>
      <td>5.493214</td>
      <td>3.831125</td>
      <td>5.492104</td>
      <td>5.474811</td>
      <td>5.492416</td>
      <td>3.268805</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.485126</td>
      <td>4.187426</td>
      <td>5.491340</td>
      <td>5.469662</td>
      <td>5.490478</td>
      <td>1.953375</td>
      <td>5.494656</td>
      <td>3.741680</td>
      <td>4.862400</td>
      <td>5.490701</td>
      <td>...</td>
      <td>5.491728</td>
      <td>2.459981</td>
      <td>5.475697</td>
      <td>3.114158</td>
      <td>1.500004</td>
      <td>1.500019</td>
      <td>4.113815</td>
      <td>5.470539</td>
      <td>5.494373</td>
      <td>5.481754</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.489590</td>
      <td>4.863187</td>
      <td>1.500003</td>
      <td>5.484699</td>
      <td>5.492657</td>
      <td>5.491270</td>
      <td>4.091023</td>
      <td>5.495239</td>
      <td>5.492804</td>
      <td>1.500046</td>
      <td>...</td>
      <td>1.500034</td>
      <td>1.500012</td>
      <td>5.483070</td>
      <td>2.475049</td>
      <td>5.493846</td>
      <td>3.287076</td>
      <td>3.696412</td>
      <td>5.487583</td>
      <td>1.500044</td>
      <td>2.760404</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.500001</td>
      <td>5.480769</td>
      <td>5.489725</td>
      <td>1.500044</td>
      <td>2.695212</td>
      <td>5.492262</td>
      <td>3.381424</td>
      <td>4.805420</td>
      <td>1.500047</td>
      <td>5.474376</td>
      <td>...</td>
      <td>1.500046</td>
      <td>2.586990</td>
      <td>5.440610</td>
      <td>4.376103</td>
      <td>1.500030</td>
      <td>4.713223</td>
      <td>5.491059</td>
      <td>3.230658</td>
      <td>1.500045</td>
      <td>5.488727</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>x3</th>
      <th>x4</th>
      <th>x5</th>
      <th>x6</th>
      <th>x7</th>
      <th>x8</th>
      <th>x9</th>
      <th>x10</th>
      <th>...</th>
      <th>x991</th>
      <th>x992</th>
      <th>x993</th>
      <th>x994</th>
      <th>x995</th>
      <th>x996</th>
      <th>x997</th>
      <th>x998</th>
      <th>x999</th>
      <th>x1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>2.609926</td>
      <td>5.491258</td>
      <td>3.318610</td>
      <td>5.444070</td>
      <td>2.884154</td>
      <td>5.486857</td>
      <td>5.496554</td>
      <td>1.500019</td>
      <td>5.482893</td>
      <td>1.824835</td>
      <td>...</td>
      <td>4.478641</td>
      <td>5.485122</td>
      <td>4.915985</td>
      <td>4.073239</td>
      <td>1.500019</td>
      <td>5.492295</td>
      <td>1.500005</td>
      <td>1.559586</td>
      <td>5.496415</td>
      <td>4.171127</td>
    </tr>
    <tr>
      <th>996</th>
      <td>5.488959</td>
      <td>3.739806</td>
      <td>5.489474</td>
      <td>1.500021</td>
      <td>5.492632</td>
      <td>1.500019</td>
      <td>5.484813</td>
      <td>5.467055</td>
      <td>5.491282</td>
      <td>1.874777</td>
      <td>...</td>
      <td>5.498820</td>
      <td>5.493926</td>
      <td>5.487404</td>
      <td>3.162812</td>
      <td>1.846298</td>
      <td>5.492417</td>
      <td>1.919107</td>
      <td>5.480324</td>
      <td>5.467765</td>
      <td>5.457627</td>
    </tr>
    <tr>
      <th>997</th>
      <td>3.498418</td>
      <td>4.250451</td>
      <td>5.488116</td>
      <td>4.162031</td>
      <td>5.494052</td>
      <td>5.472900</td>
      <td>1.500057</td>
      <td>5.491497</td>
      <td>5.491935</td>
      <td>1.500033</td>
      <td>...</td>
      <td>1.966474</td>
      <td>5.475258</td>
      <td>3.848034</td>
      <td>2.863883</td>
      <td>4.370685</td>
      <td>5.494647</td>
      <td>5.478855</td>
      <td>2.465739</td>
      <td>1.500018</td>
      <td>5.486403</td>
    </tr>
    <tr>
      <th>998</th>
      <td>5.486107</td>
      <td>1.917414</td>
      <td>5.414975</td>
      <td>5.492364</td>
      <td>2.027914</td>
      <td>5.491349</td>
      <td>5.494135</td>
      <td>5.491245</td>
      <td>1.500039</td>
      <td>1.500019</td>
      <td>...</td>
      <td>4.556995</td>
      <td>5.457072</td>
      <td>2.071106</td>
      <td>5.417333</td>
      <td>5.491818</td>
      <td>5.473390</td>
      <td>4.374154</td>
      <td>5.489109</td>
      <td>4.515340</td>
      <td>1.500020</td>
    </tr>
    <tr>
      <th>999</th>
      <td>5.319623</td>
      <td>5.482776</td>
      <td>1.500035</td>
      <td>5.485141</td>
      <td>5.491019</td>
      <td>3.733982</td>
      <td>5.494374</td>
      <td>3.077159</td>
      <td>5.493188</td>
      <td>1.500001</td>
      <td>...</td>
      <td>5.485356</td>
      <td>1.500059</td>
      <td>5.400762</td>
      <td>5.489606</td>
      <td>5.494583</td>
      <td>5.490943</td>
      <td>5.123794</td>
      <td>5.473465</td>
      <td>3.274979</td>
      <td>3.700653</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>For one repeatition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    4.997270
1    5.004092
2    5.485126
3    5.489590
4    1.500001
Name: x1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    2.609926
996    5.488959
997    3.498418
998    5.486107
999    5.319623
Name: x1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(classification)">
<h3>Example of the Y (classification)<a class="headerlink" href="#Example-of-the-Y-(classification)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for classification problem. Below example file has 1000 samples in row, 1000 repeatition in column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>997</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>For one repeatition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    1.0
1    1.0
2    0.0
3    0.0
4    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    1.0
996    0.0
997    1.0
998    0.0
999    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Exmple-of-the-training-index-file-for-repetition">
<h3>Exmple of the training index file for repetition<a class="headerlink" href="#Exmple-of-the-training-index-file-for-repetition" title="Permalink to this headline">¶</a></h3>
<p>For each repeatition, we have to set the training and test set. If the index file is given, the deepbiome library set the training set and test set based on the index file. Below is the example of the index file. Each column has the training indexs for each repeatition. The deepbiome will only use the samples in this index set for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/regression_idx.csv&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">idxs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>490</td>
      <td>690</td>
      <td>62</td>
      <td>703</td>
      <td>690</td>
      <td>845</td>
      <td>150</td>
      <td>268</td>
      <td>488</td>
      <td>179</td>
      <td>...</td>
      <td>675</td>
      <td>886</td>
      <td>225</td>
      <td>222</td>
      <td>781</td>
      <td>778</td>
      <td>603</td>
      <td>222</td>
      <td>254</td>
      <td>407</td>
    </tr>
    <tr>
      <th>1</th>
      <td>498</td>
      <td>968</td>
      <td>123</td>
      <td>913</td>
      <td>348</td>
      <td>262</td>
      <td>705</td>
      <td>239</td>
      <td>632</td>
      <td>44</td>
      <td>...</td>
      <td>636</td>
      <td>216</td>
      <td>495</td>
      <td>557</td>
      <td>196</td>
      <td>516</td>
      <td>23</td>
      <td>351</td>
      <td>472</td>
      <td>945</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389</td>
      <td>999</td>
      <td>335</td>
      <td>947</td>
      <td>215</td>
      <td>696</td>
      <td>793</td>
      <td>349</td>
      <td>734</td>
      <td>624</td>
      <td>...</td>
      <td>626</td>
      <td>230</td>
      <td>26</td>
      <td>330</td>
      <td>470</td>
      <td>992</td>
      <td>329</td>
      <td>532</td>
      <td>655</td>
      <td>426</td>
    </tr>
    <tr>
      <th>3</th>
      <td>51</td>
      <td>139</td>
      <td>843</td>
      <td>491</td>
      <td>47</td>
      <td>421</td>
      <td>892</td>
      <td>32</td>
      <td>438</td>
      <td>996</td>
      <td>...</td>
      <td>956</td>
      <td>706</td>
      <td>836</td>
      <td>151</td>
      <td>80</td>
      <td>409</td>
      <td>671</td>
      <td>772</td>
      <td>882</td>
      <td>181</td>
    </tr>
    <tr>
      <th>4</th>
      <td>592</td>
      <td>83</td>
      <td>204</td>
      <td>810</td>
      <td>198</td>
      <td>955</td>
      <td>357</td>
      <td>125</td>
      <td>190</td>
      <td>162</td>
      <td>...</td>
      <td>542</td>
      <td>108</td>
      <td>959</td>
      <td>311</td>
      <td>771</td>
      <td>902</td>
      <td>986</td>
      <td>481</td>
      <td>922</td>
      <td>305</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>745</th>
      <td>599</td>
      <td>824</td>
      <td>997</td>
      <td>216</td>
      <td>586</td>
      <td>796</td>
      <td>806</td>
      <td>39</td>
      <td>483</td>
      <td>518</td>
      <td>...</td>
      <td>573</td>
      <td>861</td>
      <td>366</td>
      <td>374</td>
      <td>585</td>
      <td>871</td>
      <td>140</td>
      <td>597</td>
      <td>795</td>
      <td>743</td>
    </tr>
    <tr>
      <th>746</th>
      <td>720</td>
      <td>633</td>
      <td>821</td>
      <td>149</td>
      <td>339</td>
      <td>461</td>
      <td>750</td>
      <td>194</td>
      <td>769</td>
      <td>699</td>
      <td>...</td>
      <td>913</td>
      <td>570</td>
      <td>670</td>
      <td>249</td>
      <td>840</td>
      <td>889</td>
      <td>242</td>
      <td>959</td>
      <td>791</td>
      <td>954</td>
    </tr>
    <tr>
      <th>747</th>
      <td>80</td>
      <td>268</td>
      <td>661</td>
      <td>187</td>
      <td>929</td>
      <td>469</td>
      <td>481</td>
      <td>332</td>
      <td>781</td>
      <td>615</td>
      <td>...</td>
      <td>985</td>
      <td>459</td>
      <td>965</td>
      <td>888</td>
      <td>461</td>
      <td>551</td>
      <td>465</td>
      <td>827</td>
      <td>557</td>
      <td>662</td>
    </tr>
    <tr>
      <th>748</th>
      <td>570</td>
      <td>32</td>
      <td>750</td>
      <td>332</td>
      <td>902</td>
      <td>107</td>
      <td>281</td>
      <td>667</td>
      <td>917</td>
      <td>793</td>
      <td>...</td>
      <td>924</td>
      <td>662</td>
      <td>975</td>
      <td>199</td>
      <td>32</td>
      <td>715</td>
      <td>668</td>
      <td>241</td>
      <td>299</td>
      <td>518</td>
    </tr>
    <tr>
      <th>749</th>
      <td>440</td>
      <td>589</td>
      <td>607</td>
      <td>597</td>
      <td>380</td>
      <td>961</td>
      <td>747</td>
      <td>396</td>
      <td>649</td>
      <td>974</td>
      <td>...</td>
      <td>867</td>
      <td>839</td>
      <td>234</td>
      <td>99</td>
      <td>901</td>
      <td>19</td>
      <td>821</td>
      <td>450</td>
      <td>780</td>
      <td>326</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>Below is the index set for 1st repeatition. From 1000 samples above, it uses 750 samples for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    490
1    498
2    389
3     51
4    592
Name: V1, dtype: int64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>745    599
746    720
747     80
748    570
749    440
Name: V1, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="3.-Prepare-the-configuration">
<h2>3. Prepare the configuration<a class="headerlink" href="#3.-Prepare-the-configuration" title="Permalink to this headline">¶</a></h2>
<p>For detailed configuration, we used python dictionary as inputs for the main training function. You can build the configuration information for the network training by: 1. the python dictionary format 1. the configufation file (.cfg).</p>
<p>In this notebook, we showed the dictionary python dictionary format configuration.</p>
<p>Please check the detailed information about each options in the <a class="reference external" href="https://young-won.github.io/deepbiome/prerequisites.html#configuration">documantation</a></p>
<div class="section" id="For-preparing-the-configuration-about-the-network-information-(network_info)">
<h3>For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-network-information-(network_info)" title="Permalink to this headline">¶</a></h3>
<p>For giving the information about the training hyper-parameter, you have to provide the dictionary for configuration to netowrk_info field. Your configuration for the network training should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;50&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="For-preparing-the-configuration-about-the-path-information-(path_info)">
<h3>For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-path-information-(path_info)" title="Permalink to this headline">¶</a></h3>
<p>For giving the information about the path of dataset, paths for saving the trained weight and the evaluation results, you have to provide the dictionary for configuration to path_info feild. Your configuration for the path information should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;hist.json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="4.-Deepbiome-Training">
<h2>4. Deepbiome Training<a class="headerlink" href="#4.-Deepbiome-Training" title="Permalink to this headline">¶</a></h2>
<p>Now we can train the deepbiome network base on the configurations.</p>
<p>For logging, we used the python logging library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;[</span><span class="si">%(name)-8s</span><span class="s1">|</span><span class="si">%(levelname)s</span><span class="s1">|</span><span class="si">%(filename)s</span><span class="s1">:</span><span class="si">%(lineno)s</span><span class="s1">] </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.</p>
<p>If we set <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code>, then the deepbiome package do the cross-validation based on that value. If not, the deepbiome package do the cross-validation based on the index file. If both <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> option and the index file is not given, then the library do leave-one-out-cross-validation (LOOCV).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 1ms/step - loss: 0.6651 - binary_accuracy: 0.6617 - sensitivity: 0.9192 - specificity: 0.0784 - gmeasure: 0.0141 - auc: 0.4752 - val_loss: 0.6395 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4818
Epoch 2/100
600/600 [==============================] - 0s 226us/step - loss: 0.6291 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5025 - val_loss: 0.6128 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5015
Epoch 3/100
600/600 [==============================] - 0s 206us/step - loss: 0.6227 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5128 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5415
Epoch 4/100
600/600 [==============================] - 0s 197us/step - loss: 0.6216 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5220 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5661
Epoch 5/100
600/600 [==============================] - 0s 212us/step - loss: 0.6216 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5483 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5894
Epoch 6/100
600/600 [==============================] - 0s 228us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5746 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6174
Epoch 7/100
600/600 [==============================] - 0s 238us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6052 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6448
Epoch 8/100
600/600 [==============================] - 0s 223us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6142 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6593
Epoch 9/100
600/600 [==============================] - 0s 218us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6346 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6821
Epoch 10/100
600/600 [==============================] - 0s 221us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6439 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7055
Epoch 11/100
600/600 [==============================] - 0s 202us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6662 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7214
Epoch 12/100
600/600 [==============================] - 0s 207us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6774 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7362
Epoch 13/100
600/600 [==============================] - 0s 213us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6829 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7487
Epoch 14/100
600/600 [==============================] - 0s 198us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6943 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7565
Epoch 15/100
600/600 [==============================] - 0s 212us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7138 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7634
Epoch 16/100
600/600 [==============================] - 0s 222us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7195 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7681
Epoch 17/100
600/600 [==============================] - 0s 229us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7319 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7685
Epoch 18/100
600/600 [==============================] - 0s 218us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7329 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7716
Epoch 19/100
600/600 [==============================] - 0s 218us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7373 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7727
Epoch 20/100
600/600 [==============================] - 0s 206us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7478 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7709
Epoch 21/100
600/600 [==============================] - 0s 207us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7451 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7621
Epoch 22/100
600/600 [==============================] - 0s 203us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7507 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7556
Epoch 23/100
600/600 [==============================] - 0s 206us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7601 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525
Epoch 24/100
600/600 [==============================] - 0s 204us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7520 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7502
Epoch 25/100
600/600 [==============================] - 0s 192us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7581 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7484
Epoch 26/100
600/600 [==============================] - 0s 176us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7647 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7440
Epoch 27/100
600/600 [==============================] - 0s 195us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7671 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7442
Epoch 28/100
600/600 [==============================] - 0s 218us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7668 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7400
Epoch 29/100
600/600 [==============================] - 0s 213us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7615 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7387
Epoch 30/100
600/600 [==============================] - 0s 216us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7537 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7358
Epoch 31/100
600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7663 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7344
Epoch 32/100
600/600 [==============================] - 0s 220us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7767 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7319
Epoch 33/100
600/600 [==============================] - 0s 221us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7689 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7283
Epoch 34/100
600/600 [==============================] - 0s 230us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7673 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7254
Epoch 35/100
600/600 [==============================] - 0s 225us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7756 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7245
Epoch 36/100
600/600 [==============================] - 0s 235us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7764 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7260
Epoch 37/100
600/600 [==============================] - 0s 207us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7665 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7280
Epoch 38/100
600/600 [==============================] - 0s 232us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7737 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7314
Epoch 39/100
600/600 [==============================] - 0s 219us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7811 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7323
Epoch 40/100
600/600 [==============================] - 0s 212us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7879 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7316
Epoch 41/100
600/600 [==============================] - 0s 200us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7809 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7329
Epoch 42/100
600/600 [==============================] - 0s 207us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7814 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7353
Epoch 43/100
600/600 [==============================] - 0s 207us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7867 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7351
Epoch 44/100
600/600 [==============================] - 0s 214us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7899 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 45/100
600/600 [==============================] - 0s 211us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7958 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7413
Epoch 46/100
600/600 [==============================] - 0s 191us/step - loss: 0.6201 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7932 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7418
Epoch 47/100
600/600 [==============================] - 0s 209us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8006 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7466
Epoch 48/100
600/600 [==============================] - 0s 187us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8017 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7472
Epoch 49/100
600/600 [==============================] - 0s 207us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8020 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525
Epoch 50/100
600/600 [==============================] - 0s 211us/step - loss: 0.6198 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8096 - val_loss: 0.6108 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7549
Epoch 51/100
600/600 [==============================] - 0s 202us/step - loss: 0.6192 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8026 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7569
Epoch 52/100
600/600 [==============================] - 0s 188us/step - loss: 0.6191 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8086 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7581
Epoch 53/100
600/600 [==============================] - 0s 210us/step - loss: 0.6186 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8008 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7589
Epoch 54/100
600/600 [==============================] - 0s 224us/step - loss: 0.6184 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8034 - val_loss: 0.6106 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7607
Epoch 55/100
600/600 [==============================] - 0s 222us/step - loss: 0.6177 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8122 - val_loss: 0.6103 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7627
Epoch 56/100
600/600 [==============================] - 0s 226us/step - loss: 0.6169 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8069 - val_loss: 0.6099 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7640
Epoch 57/100
600/600 [==============================] - 0s 213us/step - loss: 0.6163 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8155 - val_loss: 0.6097 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7635
Epoch 58/100
600/600 [==============================] - 0s 218us/step - loss: 0.6156 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8180 - val_loss: 0.6096 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7668
Epoch 59/100
600/600 [==============================] - 0s 200us/step - loss: 0.6146 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8081 - val_loss: 0.6090 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7674
Epoch 60/100
600/600 [==============================] - 0s 219us/step - loss: 0.6134 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8184 - val_loss: 0.6086 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7700
Epoch 61/100
600/600 [==============================] - 0s 219us/step - loss: 0.6124 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8119 - val_loss: 0.6082 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7725
Epoch 62/100
600/600 [==============================] - 0s 215us/step - loss: 0.6114 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8207 - val_loss: 0.6077 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7779
Epoch 63/100
600/600 [==============================] - 0s 226us/step - loss: 0.6100 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8239 - val_loss: 0.6066 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7808
Epoch 64/100
600/600 [==============================] - 0s 214us/step - loss: 0.6101 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8216 - val_loss: 0.6055 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7805
Epoch 65/100
600/600 [==============================] - 0s 218us/step - loss: 0.6067 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8326 - val_loss: 0.6057 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7850
Epoch 66/100
600/600 [==============================] - 0s 215us/step - loss: 0.6050 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8201 - val_loss: 0.6035 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7851
Epoch 67/100
600/600 [==============================] - 0s 217us/step - loss: 0.6029 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8177 - val_loss: 0.6019 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7874
Epoch 68/100
600/600 [==============================] - 0s 210us/step - loss: 0.6003 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8281 - val_loss: 0.6013 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7898
Epoch 69/100
600/600 [==============================] - 0s 200us/step - loss: 0.5976 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8286 - val_loss: 0.5983 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7905
Epoch 70/100
600/600 [==============================] - 0s 206us/step - loss: 0.5969 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8185 - val_loss: 0.5965 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7936
Epoch 71/100
600/600 [==============================] - 0s 216us/step - loss: 0.5943 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8229 - val_loss: 0.5936 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7962
Epoch 72/100
600/600 [==============================] - 0s 197us/step - loss: 0.5883 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8342 - val_loss: 0.5939 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7975
Epoch 73/100
600/600 [==============================] - 0s 219us/step - loss: 0.5852 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.5879 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7988
Epoch 74/100
600/600 [==============================] - 0s 230us/step - loss: 0.5805 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8295 - val_loss: 0.5846 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8012
Epoch 75/100
600/600 [==============================] - 0s 217us/step - loss: 0.5761 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.5810 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7992
Epoch 76/100
600/600 [==============================] - 0s 204us/step - loss: 0.5697 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8335 - val_loss: 0.5751 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8016
Epoch 77/100
600/600 [==============================] - 0s 215us/step - loss: 0.5642 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8394 - val_loss: 0.5694 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8011
Epoch 78/100
600/600 [==============================] - 0s 224us/step - loss: 0.5574 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.5642 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8017
Epoch 79/100
600/600 [==============================] - 0s 223us/step - loss: 0.5510 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8491 - val_loss: 0.5573 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8024
Epoch 80/100
600/600 [==============================] - 0s 214us/step - loss: 0.5421 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8387 - val_loss: 0.5508 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8030
Epoch 81/100
600/600 [==============================] - 0s 213us/step - loss: 0.5345 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8400 - val_loss: 0.5443 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8057
Epoch 82/100
600/600 [==============================] - 0s 216us/step - loss: 0.5306 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8428 - val_loss: 0.5440 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8117
Epoch 83/100
600/600 [==============================] - 0s 213us/step - loss: 0.5232 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8464 - val_loss: 0.5315 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8161
Epoch 84/100
600/600 [==============================] - 0s 200us/step - loss: 0.5131 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8504 - val_loss: 0.5254 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8177
Epoch 85/100
600/600 [==============================] - 0s 207us/step - loss: 0.5048 - binary_accuracy: 0.7200 - sensitivity: 0.9955 - specificity: 0.1057 - gmeasure: 0.2500 - auc: 0.8515 - val_loss: 0.5186 - val_binary_accuracy: 0.7333 - val_sensitivity: 1.0000 - val_specificity: 0.0976 - val_gmeasure: 0.2551 - val_auc: 0.8242
Epoch 86/100
600/600 [==============================] - 0s 194us/step - loss: 0.5012 - binary_accuracy: 0.7517 - sensitivity: 0.9910 - specificity: 0.2461 - gmeasure: 0.4659 - auc: 0.8606 - val_loss: 0.5135 - val_binary_accuracy: 0.7333 - val_sensitivity: 1.0000 - val_specificity: 0.0976 - val_gmeasure: 0.2551 - val_auc: 0.8284
Epoch 87/100
600/600 [==============================] - 0s 181us/step - loss: 0.4956 - binary_accuracy: 0.7400 - sensitivity: 0.9918 - specificity: 0.2088 - gmeasure: 0.4155 - auc: 0.8671 - val_loss: 0.5054 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.9822 - val_specificity: 0.1279 - val_gmeasure: 0.3525 - val_auc: 0.8312
Epoch 88/100
600/600 [==============================] - 0s 193us/step - loss: 0.4871 - binary_accuracy: 0.7683 - sensitivity: 0.9899 - specificity: 0.2817 - gmeasure: 0.5075 - auc: 0.8613 - val_loss: 0.5031 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9822 - val_specificity: 0.0976 - val_gmeasure: 0.2533 - val_auc: 0.8366
Epoch 89/100
600/600 [==============================] - 0s 236us/step - loss: 0.4839 - binary_accuracy: 0.7933 - sensitivity: 0.9806 - specificity: 0.3988 - gmeasure: 0.6113 - auc: 0.8724 - val_loss: 0.4977 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9822 - val_specificity: 0.0976 - val_gmeasure: 0.2533 - val_auc: 0.8415
Epoch 90/100
600/600 [==============================] - 0s 215us/step - loss: 0.4783 - binary_accuracy: 0.7567 - sensitivity: 0.9851 - specificity: 0.2609 - gmeasure: 0.4939 - auc: 0.8695 - val_loss: 0.4901 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9540 - val_specificity: 0.3736 - val_gmeasure: 0.5968 - val_auc: 0.8483
Epoch 91/100
600/600 [==============================] - 0s 199us/step - loss: 0.4704 - binary_accuracy: 0.7817 - sensitivity: 0.9783 - specificity: 0.3452 - gmeasure: 0.5624 - auc: 0.8748 - val_loss: 0.4802 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9822 - val_specificity: 0.1517 - val_gmeasure: 0.3805 - val_auc: 0.8510
Epoch 92/100
600/600 [==============================] - 0s 183us/step - loss: 0.4698 - binary_accuracy: 0.7783 - sensitivity: 0.9721 - specificity: 0.3707 - gmeasure: 0.5897 - auc: 0.8821 - val_loss: 0.4745 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9822 - val_specificity: 0.1517 - val_gmeasure: 0.3805 - val_auc: 0.8580
Epoch 93/100
600/600 [==============================] - 0s 193us/step - loss: 0.4562 - binary_accuracy: 0.8033 - sensitivity: 0.9812 - specificity: 0.4105 - gmeasure: 0.6272 - auc: 0.8825 - val_loss: 0.4647 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8628
Epoch 94/100
600/600 [==============================] - 0s 201us/step - loss: 0.4508 - binary_accuracy: 0.7933 - sensitivity: 0.9812 - specificity: 0.3669 - gmeasure: 0.5877 - auc: 0.8836 - val_loss: 0.4619 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9822 - val_specificity: 0.1684 - val_gmeasure: 0.4004 - val_auc: 0.8656
Epoch 95/100
600/600 [==============================] - 0s 210us/step - loss: 0.4452 - binary_accuracy: 0.8017 - sensitivity: 0.9701 - specificity: 0.4256 - gmeasure: 0.6353 - auc: 0.8864 - val_loss: 0.4534 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9822 - val_specificity: 0.2558 - val_gmeasure: 0.4986 - val_auc: 0.8711
Epoch 96/100
600/600 [==============================] - 0s 187us/step - loss: 0.4410 - binary_accuracy: 0.7983 - sensitivity: 0.9789 - specificity: 0.3986 - gmeasure: 0.6091 - auc: 0.8902 - val_loss: 0.4662 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.8631 - val_specificity: 0.7543 - val_gmeasure: 0.8065 - val_auc: 0.8705
Epoch 97/100
600/600 [==============================] - 0s 195us/step - loss: 0.4399 - binary_accuracy: 0.8133 - sensitivity: 0.9500 - specificity: 0.5210 - gmeasure: 0.6972 - auc: 0.8834 - val_loss: 0.4409 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8828
Epoch 98/100
600/600 [==============================] - 0s 192us/step - loss: 0.4285 - binary_accuracy: 0.8067 - sensitivity: 0.9689 - specificity: 0.4458 - gmeasure: 0.6529 - auc: 0.8951 - val_loss: 0.4333 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8860
Epoch 99/100
600/600 [==============================] - 0s 206us/step - loss: 0.4228 - binary_accuracy: 0.8167 - sensitivity: 0.9685 - specificity: 0.4798 - gmeasure: 0.6778 - auc: 0.8987 - val_loss: 0.4275 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9822 - val_specificity: 0.3266 - val_gmeasure: 0.5655 - val_auc: 0.8932
Epoch 100/100
600/600 [==============================] - 0s 218us/step - loss: 0.4198 - binary_accuracy: 0.8200 - sensitivity: 0.9723 - specificity: 0.4830 - gmeasure: 0.6754 - auc: 0.8974 - val_loss: 0.4197 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9343 - val_specificity: 0.4645 - val_gmeasure: 0.6520 - val_auc: 0.8957
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 15.849582433700562!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.014268636703491211!
[root    |INFO|build_network.py:183] Evaluation: [0.41470539569854736, 0.8173333406448364, 0.9498069286346436, 0.5215517282485962, 0.7038277387619019, 0.8984614014625549]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 24us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.013792037963867188!
[root    |INFO|build_network.py:183] Evaluation: [0.42274555563926697, 0.8399999737739563, 0.9822485446929932, 0.5432098507881165, 0.7304567694664001, 0.9060559868812561]
[root    |INFO|deepbiome.py:179] Compute time : 19.22468662261963
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 996us/step - loss: 0.6800 - binary_accuracy: 0.6850 - sensitivity: 0.9167 - specificity: 0.0833 - gmeasure: 0.0000e+00 - auc: 0.4414 - val_loss: 0.6638 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4313
Epoch 2/100
600/600 [==============================] - 0s 221us/step - loss: 0.6502 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3866 - val_loss: 0.6346 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3529
Epoch 3/100
600/600 [==============================] - 0s 202us/step - loss: 0.6238 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3297 - val_loss: 0.6102 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3699
Epoch 4/100
600/600 [==============================] - 0s 212us/step - loss: 0.6043 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3850 - val_loss: 0.5935 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4587
Epoch 5/100
600/600 [==============================] - 0s 209us/step - loss: 0.5887 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4778 - val_loss: 0.5874 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5618
Epoch 6/100
600/600 [==============================] - 0s 220us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6223 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6338
Epoch 7/100
600/600 [==============================] - 0s 204us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6806 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6594
Epoch 8/100
600/600 [==============================] - 0s 211us/step - loss: 0.5852 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7092 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6800
Epoch 9/100
600/600 [==============================] - 0s 208us/step - loss: 0.5852 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7232 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6816
Epoch 10/100
600/600 [==============================] - 0s 202us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7266 - val_loss: 0.5865 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6797
Epoch 11/100
600/600 [==============================] - 0s 212us/step - loss: 0.5851 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7252 - val_loss: 0.5865 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6735
Epoch 12/100
600/600 [==============================] - 0s 203us/step - loss: 0.5849 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7290 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6697
Epoch 13/100
600/600 [==============================] - 0s 214us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7145 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6695
Epoch 14/100
600/600 [==============================] - 0s 221us/step - loss: 0.5851 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7051 - val_loss: 0.5863 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6605
Epoch 15/100
600/600 [==============================] - 0s 191us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7161 - val_loss: 0.5861 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6626
Epoch 16/100
600/600 [==============================] - 0s 201us/step - loss: 0.5843 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7168 - val_loss: 0.5859 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6634
Epoch 17/100
600/600 [==============================] - 0s 203us/step - loss: 0.5842 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7188 - val_loss: 0.5857 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6643
Epoch 18/100
600/600 [==============================] - 0s 198us/step - loss: 0.5838 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7278 - val_loss: 0.5854 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6659
Epoch 19/100
600/600 [==============================] - 0s 223us/step - loss: 0.5833 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7203 - val_loss: 0.5850 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6673
Epoch 20/100
600/600 [==============================] - 0s 208us/step - loss: 0.5827 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7212 - val_loss: 0.5845 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6701
Epoch 21/100
600/600 [==============================] - 0s 203us/step - loss: 0.5821 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7270 - val_loss: 0.5839 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6713
Epoch 22/100
600/600 [==============================] - 0s 210us/step - loss: 0.5818 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7361 - val_loss: 0.5831 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6709
Epoch 23/100
600/600 [==============================] - 0s 208us/step - loss: 0.5798 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7321 - val_loss: 0.5823 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6763
Epoch 24/100
600/600 [==============================] - 0s 209us/step - loss: 0.5790 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7289 - val_loss: 0.5813 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6806
Epoch 25/100
600/600 [==============================] - 0s 207us/step - loss: 0.5767 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7407 - val_loss: 0.5795 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6837
Epoch 26/100
600/600 [==============================] - 0s 198us/step - loss: 0.5747 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7296 - val_loss: 0.5776 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6879
Epoch 27/100
600/600 [==============================] - 0s 210us/step - loss: 0.5718 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7269 - val_loss: 0.5752 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6905
Epoch 28/100
600/600 [==============================] - 0s 199us/step - loss: 0.5683 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7446 - val_loss: 0.5722 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6933
Epoch 29/100
600/600 [==============================] - 0s 210us/step - loss: 0.5643 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7355 - val_loss: 0.5688 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6948
Epoch 30/100
600/600 [==============================] - 0s 208us/step - loss: 0.5592 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7442 - val_loss: 0.5646 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6978
Epoch 31/100
600/600 [==============================] - 0s 183us/step - loss: 0.5536 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7566 - val_loss: 0.5598 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7029
Epoch 32/100
600/600 [==============================] - 0s 160us/step - loss: 0.5470 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7420 - val_loss: 0.5547 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7070
Epoch 33/100
600/600 [==============================] - 0s 207us/step - loss: 0.5421 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7593 - val_loss: 0.5502 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7056
Epoch 34/100
600/600 [==============================] - 0s 191us/step - loss: 0.5356 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7634 - val_loss: 0.5441 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7141
Epoch 35/100
600/600 [==============================] - 0s 210us/step - loss: 0.5295 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7597 - val_loss: 0.5386 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7244
Epoch 36/100
600/600 [==============================] - 0s 209us/step - loss: 0.5201 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7683 - val_loss: 0.5314 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7302
Epoch 37/100
600/600 [==============================] - 0s 220us/step - loss: 0.5113 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7817 - val_loss: 0.5232 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7599
Epoch 38/100
600/600 [==============================] - 0s 224us/step - loss: 0.5026 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8343 - val_loss: 0.5139 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7776
Epoch 39/100
600/600 [==============================] - 0s 224us/step - loss: 0.4929 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8272 - val_loss: 0.5056 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7736
Epoch 40/100
600/600 [==============================] - 0s 212us/step - loss: 0.4808 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8253 - val_loss: 0.4942 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7869
Epoch 41/100
600/600 [==============================] - 0s 186us/step - loss: 0.4700 - binary_accuracy: 0.7633 - sensitivity: 1.0000 - specificity: 0.1461 - gmeasure: 0.2394 - auc: 0.8511 - val_loss: 0.4897 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8059
Epoch 42/100
600/600 [==============================] - 0s 199us/step - loss: 0.4687 - binary_accuracy: 0.7533 - sensitivity: 0.9779 - specificity: 0.1591 - gmeasure: 0.2528 - auc: 0.8636 - val_loss: 0.4786 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9632 - val_specificity: 0.5037 - val_gmeasure: 0.6888 - val_auc: 0.8257
Epoch 43/100
600/600 [==============================] - 0s 213us/step - loss: 0.4476 - binary_accuracy: 0.7900 - sensitivity: 0.9893 - specificity: 0.2573 - gmeasure: 0.4202 - auc: 0.8729 - val_loss: 0.4647 - val_binary_accuracy: 0.7667 - val_sensitivity: 1.0000 - val_specificity: 0.1533 - val_gmeasure: 0.3795 - val_auc: 0.8285
Epoch 44/100
600/600 [==============================] - 0s 222us/step - loss: 0.4331 - binary_accuracy: 0.7817 - sensitivity: 1.0000 - specificity: 0.1890 - gmeasure: 0.4234 - auc: 0.8709 - val_loss: 0.4532 - val_binary_accuracy: 0.7867 - val_sensitivity: 1.0000 - val_specificity: 0.2324 - val_gmeasure: 0.4567 - val_auc: 0.8344
Epoch 45/100
600/600 [==============================] - 0s 213us/step - loss: 0.4226 - binary_accuracy: 0.8133 - sensitivity: 1.0000 - specificity: 0.3156 - gmeasure: 0.5398 - auc: 0.8873 - val_loss: 0.4420 - val_binary_accuracy: 0.8267 - val_sensitivity: 1.0000 - val_specificity: 0.3739 - val_gmeasure: 0.6037 - val_auc: 0.8440
Epoch 46/100
600/600 [==============================] - 0s 205us/step - loss: 0.4124 - binary_accuracy: 0.8183 - sensitivity: 1.0000 - specificity: 0.3367 - gmeasure: 0.5687 - auc: 0.8872 - val_loss: 0.4326 - val_binary_accuracy: 0.8200 - val_sensitivity: 1.0000 - val_specificity: 0.3462 - val_gmeasure: 0.5779 - val_auc: 0.8499
Epoch 47/100
600/600 [==============================] - 0s 203us/step - loss: 0.4019 - binary_accuracy: 0.8350 - sensitivity: 1.0000 - specificity: 0.3918 - gmeasure: 0.6093 - auc: 0.8899 - val_loss: 0.4152 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9910 - val_specificity: 0.4712 - val_gmeasure: 0.6811 - val_auc: 0.8710
Epoch 48/100
600/600 [==============================] - 0s 206us/step - loss: 0.3869 - binary_accuracy: 0.8400 - sensitivity: 0.9978 - specificity: 0.4293 - gmeasure: 0.6445 - auc: 0.9162 - val_loss: 0.3956 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.4017 - val_gmeasure: 0.6264 - val_auc: 0.8849
Epoch 49/100
600/600 [==============================] - 0s 201us/step - loss: 0.3745 - binary_accuracy: 0.8250 - sensitivity: 0.9835 - specificity: 0.4014 - gmeasure: 0.6069 - auc: 0.9236 - val_loss: 0.3891 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9714 - val_specificity: 0.6474 - val_gmeasure: 0.7909 - val_auc: 0.8963
Epoch 50/100
600/600 [==============================] - 0s 205us/step - loss: 0.3602 - binary_accuracy: 0.8483 - sensitivity: 0.9831 - specificity: 0.4749 - gmeasure: 0.6686 - auc: 0.9335 - val_loss: 0.3733 - val_binary_accuracy: 0.8467 - val_sensitivity: 1.0000 - val_specificity: 0.4503 - val_gmeasure: 0.6666 - val_auc: 0.9017
Epoch 51/100
600/600 [==============================] - 0s 174us/step - loss: 0.3492 - binary_accuracy: 0.8717 - sensitivity: 0.9841 - specificity: 0.5543 - gmeasure: 0.7121 - auc: 0.9450 - val_loss: 0.3963 - val_binary_accuracy: 0.8000 - val_sensitivity: 1.0000 - val_specificity: 0.2740 - val_gmeasure: 0.5177 - val_auc: 0.9097
Epoch 52/100
600/600 [==============================] - 0s 200us/step - loss: 0.3446 - binary_accuracy: 0.8600 - sensitivity: 0.9853 - specificity: 0.5315 - gmeasure: 0.7115 - auc: 0.9448 - val_loss: 0.3628 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.4017 - val_gmeasure: 0.6264 - val_auc: 0.9110
Epoch 53/100
600/600 [==============================] - 0s 188us/step - loss: 0.3262 - binary_accuracy: 0.8733 - sensitivity: 0.9975 - specificity: 0.5399 - gmeasure: 0.7287 - auc: 0.9520 - val_loss: 0.3569 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.3948 - val_gmeasure: 0.6234 - val_auc: 0.9143
Epoch 54/100
600/600 [==============================] - 0s 201us/step - loss: 0.3158 - binary_accuracy: 0.8700 - sensitivity: 0.9929 - specificity: 0.5319 - gmeasure: 0.7217 - auc: 0.9472 - val_loss: 0.3380 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9722 - val_specificity: 0.5871 - val_gmeasure: 0.7552 - val_auc: 0.9163
Epoch 55/100
600/600 [==============================] - 0s 210us/step - loss: 0.3113 - binary_accuracy: 0.8967 - sensitivity: 0.9777 - specificity: 0.6923 - gmeasure: 0.8123 - auc: 0.9572 - val_loss: 0.3967 - val_binary_accuracy: 0.8067 - val_sensitivity: 1.0000 - val_specificity: 0.3018 - val_gmeasure: 0.5435 - val_auc: 0.9169
Epoch 56/100
600/600 [==============================] - 0s 197us/step - loss: 0.3352 - binary_accuracy: 0.8400 - sensitivity: 0.9349 - specificity: 0.6039 - gmeasure: 0.7207 - auc: 0.9520 - val_loss: 0.3468 - val_binary_accuracy: 0.8600 - val_sensitivity: 1.0000 - val_specificity: 0.4968 - val_gmeasure: 0.7013 - val_auc: 0.9182
Epoch 57/100
600/600 [==============================] - 0s 204us/step - loss: 0.3088 - binary_accuracy: 0.8850 - sensitivity: 0.9917 - specificity: 0.6003 - gmeasure: 0.7578 - auc: 0.9563 - val_loss: 0.3274 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9722 - val_specificity: 0.5871 - val_gmeasure: 0.7552 - val_auc: 0.9188
Epoch 58/100
600/600 [==============================] - 0s 202us/step - loss: 0.2893 - binary_accuracy: 0.8900 - sensitivity: 0.9978 - specificity: 0.6112 - gmeasure: 0.7722 - auc: 0.9558 - val_loss: 0.3283 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9910 - val_specificity: 0.5662 - val_gmeasure: 0.7482 - val_auc: 0.9235
Epoch 59/100
600/600 [==============================] - 0s 214us/step - loss: 0.2923 - binary_accuracy: 0.8850 - sensitivity: 0.9712 - specificity: 0.6592 - gmeasure: 0.7927 - auc: 0.9545 - val_loss: 0.3471 - val_binary_accuracy: 0.8600 - val_sensitivity: 1.0000 - val_specificity: 0.4968 - val_gmeasure: 0.7013 - val_auc: 0.9234
Epoch 60/100
600/600 [==============================] - 0s 209us/step - loss: 0.2891 - binary_accuracy: 0.8850 - sensitivity: 0.9567 - specificity: 0.6734 - gmeasure: 0.7887 - auc: 0.9566 - val_loss: 0.3720 - val_binary_accuracy: 0.8467 - val_sensitivity: 1.0000 - val_specificity: 0.4482 - val_gmeasure: 0.6630 - val_auc: 0.9234
Epoch 61/100
600/600 [==============================] - 0s 215us/step - loss: 0.2888 - binary_accuracy: 0.8767 - sensitivity: 0.9589 - specificity: 0.6550 - gmeasure: 0.7766 - auc: 0.9568 - val_loss: 0.3311 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9820 - val_specificity: 0.5454 - val_gmeasure: 0.7294 - val_auc: 0.9241
Epoch 62/100
600/600 [==============================] - 0s 202us/step - loss: 0.2723 - binary_accuracy: 0.8933 - sensitivity: 0.9815 - specificity: 0.6355 - gmeasure: 0.7818 - auc: 0.9627 - val_loss: 0.3156 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6939 - val_gmeasure: 0.8152 - val_auc: 0.9240
Epoch 63/100
600/600 [==============================] - 0s 210us/step - loss: 0.2663 - binary_accuracy: 0.9017 - sensitivity: 0.9909 - specificity: 0.6554 - gmeasure: 0.7987 - auc: 0.9660 - val_loss: 0.3139 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9246
Epoch 64/100
600/600 [==============================] - 0s 205us/step - loss: 0.2582 - binary_accuracy: 0.9033 - sensitivity: 0.9864 - specificity: 0.6921 - gmeasure: 0.8226 - auc: 0.9662 - val_loss: 0.3262 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9820 - val_specificity: 0.5454 - val_gmeasure: 0.7294 - val_auc: 0.9233
Epoch 65/100
600/600 [==============================] - 0s 194us/step - loss: 0.2573 - binary_accuracy: 0.9017 - sensitivity: 0.9827 - specificity: 0.6990 - gmeasure: 0.8247 - auc: 0.9674 - val_loss: 0.3178 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9730 - val_specificity: 0.5871 - val_gmeasure: 0.7553 - val_auc: 0.9228
Epoch 66/100
600/600 [==============================] - 0s 224us/step - loss: 0.2540 - binary_accuracy: 0.9017 - sensitivity: 0.9849 - specificity: 0.6823 - gmeasure: 0.8133 - auc: 0.9620 - val_loss: 0.3109 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9227
Epoch 67/100
600/600 [==============================] - 0s 232us/step - loss: 0.2496 - binary_accuracy: 0.9167 - sensitivity: 0.9713 - specificity: 0.7572 - gmeasure: 0.8510 - auc: 0.9637 - val_loss: 0.3269 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9240
Epoch 68/100
600/600 [==============================] - 0s 200us/step - loss: 0.2458 - binary_accuracy: 0.9000 - sensitivity: 0.9775 - specificity: 0.6943 - gmeasure: 0.8152 - auc: 0.9692 - val_loss: 0.3173 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9730 - val_specificity: 0.5871 - val_gmeasure: 0.7553 - val_auc: 0.9240
Epoch 69/100
600/600 [==============================] - 0s 186us/step - loss: 0.2404 - binary_accuracy: 0.9167 - sensitivity: 0.9775 - specificity: 0.7612 - gmeasure: 0.8609 - auc: 0.9626 - val_loss: 0.3271 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9253
Epoch 70/100
600/600 [==============================] - 0s 228us/step - loss: 0.2414 - binary_accuracy: 0.9083 - sensitivity: 0.9778 - specificity: 0.7196 - gmeasure: 0.8349 - auc: 0.9642 - val_loss: 0.3292 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9241
Epoch 71/100
600/600 [==============================] - 0s 212us/step - loss: 0.2414 - binary_accuracy: 0.9067 - sensitivity: 0.9802 - specificity: 0.7183 - gmeasure: 0.8319 - auc: 0.9715 - val_loss: 0.3149 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9632 - val_specificity: 0.6127 - val_gmeasure: 0.7668 - val_auc: 0.9254
Epoch 72/100
600/600 [==============================] - 0s 226us/step - loss: 0.2352 - binary_accuracy: 0.9100 - sensitivity: 0.9861 - specificity: 0.7078 - gmeasure: 0.8312 - auc: 0.9655 - val_loss: 0.3100 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9534 - val_specificity: 0.7473 - val_gmeasure: 0.8408 - val_auc: 0.9292
Epoch 73/100
600/600 [==============================] - 0s 225us/step - loss: 0.2409 - binary_accuracy: 0.9067 - sensitivity: 0.9778 - specificity: 0.7117 - gmeasure: 0.8264 - auc: 0.9673 - val_loss: 0.3042 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9285
Epoch 74/100
600/600 [==============================] - 0s 228us/step - loss: 0.2274 - binary_accuracy: 0.9167 - sensitivity: 0.9799 - specificity: 0.7378 - gmeasure: 0.8462 - auc: 0.9676 - val_loss: 0.3146 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9632 - val_specificity: 0.6127 - val_gmeasure: 0.7668 - val_auc: 0.9266
Epoch 75/100
600/600 [==============================] - 0s 221us/step - loss: 0.2225 - binary_accuracy: 0.9200 - sensitivity: 0.9817 - specificity: 0.7530 - gmeasure: 0.8537 - auc: 0.9670 - val_loss: 0.3159 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9284
Epoch 76/100
600/600 [==============================] - 0s 193us/step - loss: 0.2263 - binary_accuracy: 0.9050 - sensitivity: 0.9849 - specificity: 0.7036 - gmeasure: 0.8293 - auc: 0.9697 - val_loss: 0.3039 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9304
Epoch 77/100
600/600 [==============================] - 0s 211us/step - loss: 0.2231 - binary_accuracy: 0.9100 - sensitivity: 0.9797 - specificity: 0.7370 - gmeasure: 0.8444 - auc: 0.9698 - val_loss: 0.3005 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9310
Epoch 78/100
600/600 [==============================] - 0s 211us/step - loss: 0.2290 - binary_accuracy: 0.9133 - sensitivity: 0.9757 - specificity: 0.7577 - gmeasure: 0.8511 - auc: 0.9735 - val_loss: 0.3003 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9297
Epoch 79/100
600/600 [==============================] - 0s 200us/step - loss: 0.2234 - binary_accuracy: 0.9100 - sensitivity: 0.9796 - specificity: 0.7292 - gmeasure: 0.8409 - auc: 0.9724 - val_loss: 0.2980 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9311
Epoch 80/100
600/600 [==============================] - 0s 187us/step - loss: 0.2217 - binary_accuracy: 0.9217 - sensitivity: 0.9716 - specificity: 0.8000 - gmeasure: 0.8789 - auc: 0.9727 - val_loss: 0.3101 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9317
Epoch 81/100
600/600 [==============================] - 0s 211us/step - loss: 0.2111 - binary_accuracy: 0.9300 - sensitivity: 0.9736 - specificity: 0.8183 - gmeasure: 0.8901 - auc: 0.9760 - val_loss: 0.3228 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9820 - val_specificity: 0.6127 - val_gmeasure: 0.7743 - val_auc: 0.9317
Epoch 82/100
600/600 [==============================] - 0s 209us/step - loss: 0.2172 - binary_accuracy: 0.9150 - sensitivity: 0.9801 - specificity: 0.7462 - gmeasure: 0.8497 - auc: 0.9725 - val_loss: 0.2996 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9337
Epoch 83/100
600/600 [==============================] - 0s 202us/step - loss: 0.2088 - binary_accuracy: 0.9200 - sensitivity: 0.9800 - specificity: 0.7658 - gmeasure: 0.8632 - auc: 0.9727 - val_loss: 0.3098 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9337
Epoch 84/100
600/600 [==============================] - 0s 199us/step - loss: 0.2046 - binary_accuracy: 0.9167 - sensitivity: 0.9813 - specificity: 0.7344 - gmeasure: 0.8473 - auc: 0.9734 - val_loss: 0.2930 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9632 - val_specificity: 0.7473 - val_gmeasure: 0.8445 - val_auc: 0.9364
Epoch 85/100
600/600 [==============================] - 0s 199us/step - loss: 0.2099 - binary_accuracy: 0.9250 - sensitivity: 0.9781 - specificity: 0.7824 - gmeasure: 0.8680 - auc: 0.9744 - val_loss: 0.3045 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9351
Epoch 86/100
600/600 [==============================] - 0s 207us/step - loss: 0.2035 - binary_accuracy: 0.9367 - sensitivity: 0.9786 - specificity: 0.8270 - gmeasure: 0.8971 - auc: 0.9740 - val_loss: 0.3237 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9820 - val_specificity: 0.6384 - val_gmeasure: 0.7889 - val_auc: 0.9338
Epoch 87/100
600/600 [==============================] - 0s 210us/step - loss: 0.2094 - binary_accuracy: 0.9300 - sensitivity: 0.9801 - specificity: 0.8021 - gmeasure: 0.8829 - auc: 0.9753 - val_loss: 0.3018 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9370
Epoch 88/100
600/600 [==============================] - 0s 212us/step - loss: 0.2025 - binary_accuracy: 0.9217 - sensitivity: 0.9890 - specificity: 0.7374 - gmeasure: 0.8492 - auc: 0.9730 - val_loss: 0.2899 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9365
Epoch 89/100
600/600 [==============================] - 0s 214us/step - loss: 0.1975 - binary_accuracy: 0.9283 - sensitivity: 0.9846 - specificity: 0.7858 - gmeasure: 0.8780 - auc: 0.9758 - val_loss: 0.3224 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9820 - val_specificity: 0.6384 - val_gmeasure: 0.7889 - val_auc: 0.9377
Epoch 90/100
600/600 [==============================] - 0s 216us/step - loss: 0.1968 - binary_accuracy: 0.9367 - sensitivity: 0.9816 - specificity: 0.8091 - gmeasure: 0.8862 - auc: 0.9790 - val_loss: 0.2986 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9390
Epoch 91/100
600/600 [==============================] - 0s 189us/step - loss: 0.1943 - binary_accuracy: 0.9333 - sensitivity: 0.9812 - specificity: 0.8027 - gmeasure: 0.8832 - auc: 0.9786 - val_loss: 0.2893 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9390
Epoch 92/100
600/600 [==============================] - 0s 211us/step - loss: 0.1987 - binary_accuracy: 0.9133 - sensitivity: 0.9755 - specificity: 0.7540 - gmeasure: 0.8546 - auc: 0.9755 - val_loss: 0.2846 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9416
Epoch 93/100
600/600 [==============================] - 0s 208us/step - loss: 0.1963 - binary_accuracy: 0.9250 - sensitivity: 0.9677 - specificity: 0.8048 - gmeasure: 0.8785 - auc: 0.9762 - val_loss: 0.2889 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9409
Epoch 94/100
600/600 [==============================] - 0s 209us/step - loss: 0.1976 - binary_accuracy: 0.9233 - sensitivity: 0.9775 - specificity: 0.7753 - gmeasure: 0.8645 - auc: 0.9777 - val_loss: 0.3090 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9722 - val_specificity: 0.6640 - val_gmeasure: 0.7991 - val_auc: 0.9409
Epoch 95/100
600/600 [==============================] - 0s 212us/step - loss: 0.1925 - binary_accuracy: 0.9283 - sensitivity: 0.9749 - specificity: 0.8072 - gmeasure: 0.8846 - auc: 0.9781 - val_loss: 0.2945 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9430
Epoch 96/100
600/600 [==============================] - 0s 194us/step - loss: 0.1872 - binary_accuracy: 0.9433 - sensitivity: 0.9792 - specificity: 0.8467 - gmeasure: 0.9082 - auc: 0.9787 - val_loss: 0.3010 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9423
Epoch 97/100
600/600 [==============================] - 0s 194us/step - loss: 0.1848 - binary_accuracy: 0.9367 - sensitivity: 0.9773 - specificity: 0.8238 - gmeasure: 0.8965 - auc: 0.9767 - val_loss: 0.2921 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9423
Epoch 98/100
600/600 [==============================] - 0s 209us/step - loss: 0.1854 - binary_accuracy: 0.9333 - sensitivity: 0.9844 - specificity: 0.7979 - gmeasure: 0.8833 - auc: 0.9833 - val_loss: 0.2809 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9449
Epoch 99/100
600/600 [==============================] - 0s 205us/step - loss: 0.1956 - binary_accuracy: 0.9183 - sensitivity: 0.9730 - specificity: 0.7771 - gmeasure: 0.8631 - auc: 0.9801 - val_loss: 0.2804 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9436
Epoch 100/100
600/600 [==============================] - 0s 188us/step - loss: 0.1999 - binary_accuracy: 0.9083 - sensitivity: 0.9625 - specificity: 0.7556 - gmeasure: 0.8467 - auc: 0.9830 - val_loss: 0.2903 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9449
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 14.82160210609436!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 6us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.01217961311340332!
[root    |INFO|build_network.py:183] Evaluation: [0.2018193006515503, 0.9279999732971191, 0.976190447807312, 0.7990196347236633, 0.8831734657287598, 0.9702919721603394]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 21us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.012906551361083984!
[root    |INFO|build_network.py:183] Evaluation: [0.3040628135204315, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.932773768901825]
[root    |INFO|deepbiome.py:179] Compute time : 16.38786482810974
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 1ms/step - loss: 0.6701 - binary_accuracy: 0.6700 - sensitivity: 0.9495 - specificity: 0.0441 - gmeasure: 0.0381 - auc: 0.5415 - val_loss: 0.6565 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5673
Epoch 2/100
600/600 [==============================] - 0s 236us/step - loss: 0.6304 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6214 - val_loss: 0.6471 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6013
Epoch 3/100
600/600 [==============================] - 0s 253us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6069 - val_loss: 0.6543 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5432
Epoch 4/100
600/600 [==============================] - 0s 220us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6443 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5826
Epoch 5/100
600/600 [==============================] - 0s 207us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6426 - val_loss: 0.6463 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6066
Epoch 6/100
600/600 [==============================] - 0s 218us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6942 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6527
Epoch 7/100
600/600 [==============================] - 0s 217us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7211 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6842
Epoch 8/100
600/600 [==============================] - 0s 227us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7423 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7172
Epoch 9/100
600/600 [==============================] - 0s 222us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7710 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7442
Epoch 10/100
600/600 [==============================] - 0s 211us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7863 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7656
Epoch 11/100
600/600 [==============================] - 0s 190us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8093 - val_loss: 0.6454 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7805
Epoch 12/100
600/600 [==============================] - 0s 217us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8163 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7938
Epoch 13/100
600/600 [==============================] - 0s 248us/step - loss: 0.6185 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8233 - val_loss: 0.6459 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8113
Epoch 14/100
600/600 [==============================] - 0s 215us/step - loss: 0.6168 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8323 - val_loss: 0.6444 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8237
Epoch 15/100
600/600 [==============================] - 0s 215us/step - loss: 0.6145 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.6417 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8353
Epoch 16/100
600/600 [==============================] - 0s 211us/step - loss: 0.6113 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8398 - val_loss: 0.6408 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8447
Epoch 17/100
600/600 [==============================] - 0s 217us/step - loss: 0.6073 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8547 - val_loss: 0.6327 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8544
Epoch 18/100
600/600 [==============================] - 0s 233us/step - loss: 0.6007 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8553 - val_loss: 0.6230 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8644
Epoch 19/100
600/600 [==============================] - 0s 209us/step - loss: 0.5920 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8570 - val_loss: 0.6164 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8659
Epoch 20/100
600/600 [==============================] - 0s 212us/step - loss: 0.5805 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8598 - val_loss: 0.6035 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8777
Epoch 21/100
600/600 [==============================] - 0s 222us/step - loss: 0.5662 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8644 - val_loss: 0.5845 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8895
Epoch 22/100
600/600 [==============================] - 0s 209us/step - loss: 0.5501 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8627 - val_loss: 0.5640 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8969
Epoch 23/100
600/600 [==============================] - 0s 222us/step - loss: 0.5308 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8761 - val_loss: 0.5423 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8942
Epoch 24/100
600/600 [==============================] - 0s 214us/step - loss: 0.5121 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8786 - val_loss: 0.5288 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8845
Epoch 25/100
600/600 [==============================] - 0s 221us/step - loss: 0.4999 - binary_accuracy: 0.7183 - sensitivity: 0.9690 - specificity: 0.1727 - gmeasure: 0.3474 - auc: 0.8792 - val_loss: 0.5249 - val_binary_accuracy: 0.6800 - val_sensitivity: 1.0000 - val_specificity: 0.0657 - val_gmeasure: 0.2065 - val_auc: 0.8963
Epoch 26/100
600/600 [==============================] - 0s 214us/step - loss: 0.5027 - binary_accuracy: 0.7400 - sensitivity: 0.9573 - specificity: 0.2724 - gmeasure: 0.4810 - auc: 0.8869 - val_loss: 0.4997 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9691 - val_specificity: 0.4433 - val_gmeasure: 0.6555 - val_auc: 0.9087
Epoch 27/100
600/600 [==============================] - 0s 222us/step - loss: 0.4697 - binary_accuracy: 0.7450 - sensitivity: 0.9427 - specificity: 0.3038 - gmeasure: 0.5255 - auc: 0.8864 - val_loss: 0.4848 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9907 - val_specificity: 0.3171 - val_gmeasure: 0.5591 - val_auc: 0.9104
Epoch 28/100
600/600 [==============================] - 0s 212us/step - loss: 0.4539 - binary_accuracy: 0.7683 - sensitivity: 0.9320 - specificity: 0.4046 - gmeasure: 0.5962 - auc: 0.8952 - val_loss: 0.4677 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9691 - val_specificity: 0.3776 - val_gmeasure: 0.6033 - val_auc: 0.9136
Epoch 29/100
600/600 [==============================] - 0s 227us/step - loss: 0.4388 - binary_accuracy: 0.7617 - sensitivity: 0.9292 - specificity: 0.4119 - gmeasure: 0.6088 - auc: 0.9041 - val_loss: 0.4554 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9473 - val_specificity: 0.5329 - val_gmeasure: 0.7101 - val_auc: 0.9117
Epoch 30/100
600/600 [==============================] - 0s 218us/step - loss: 0.4269 - binary_accuracy: 0.7867 - sensitivity: 0.9190 - specificity: 0.4834 - gmeasure: 0.6559 - auc: 0.8998 - val_loss: 0.4438 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9691 - val_specificity: 0.4894 - val_gmeasure: 0.6882 - val_auc: 0.9141
Epoch 31/100
600/600 [==============================] - 0s 214us/step - loss: 0.4131 - binary_accuracy: 0.8100 - sensitivity: 0.9051 - specificity: 0.5909 - gmeasure: 0.7257 - auc: 0.9041 - val_loss: 0.4461 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9691 - val_specificity: 0.4433 - val_gmeasure: 0.6555 - val_auc: 0.9139
Epoch 32/100
600/600 [==============================] - 0s 202us/step - loss: 0.4061 - binary_accuracy: 0.8083 - sensitivity: 0.9184 - specificity: 0.5890 - gmeasure: 0.7278 - auc: 0.9089 - val_loss: 0.4207 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9380 - val_specificity: 0.5329 - val_gmeasure: 0.7067 - val_auc: 0.9126
Epoch 33/100
600/600 [==============================] - 0s 201us/step - loss: 0.3921 - binary_accuracy: 0.8150 - sensitivity: 0.9053 - specificity: 0.6055 - gmeasure: 0.7370 - auc: 0.9094 - val_loss: 0.4071 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9190 - val_specificity: 0.6156 - val_gmeasure: 0.7517 - val_auc: 0.9197
Epoch 34/100
600/600 [==============================] - 0s 211us/step - loss: 0.3812 - binary_accuracy: 0.8183 - sensitivity: 0.9027 - specificity: 0.6327 - gmeasure: 0.7534 - auc: 0.9110 - val_loss: 0.4077 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9285 - val_specificity: 0.5329 - val_gmeasure: 0.7032 - val_auc: 0.9167
Epoch 35/100
600/600 [==============================] - 0s 222us/step - loss: 0.3754 - binary_accuracy: 0.8183 - sensitivity: 0.8997 - specificity: 0.6469 - gmeasure: 0.7545 - auc: 0.9180 - val_loss: 0.3946 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9097 - val_specificity: 0.6922 - val_gmeasure: 0.7934 - val_auc: 0.9145
Epoch 36/100
600/600 [==============================] - 0s 217us/step - loss: 0.3668 - binary_accuracy: 0.8283 - sensitivity: 0.8920 - specificity: 0.6817 - gmeasure: 0.7747 - auc: 0.9159 - val_loss: 0.4043 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9190 - val_specificity: 0.5551 - val_gmeasure: 0.7137 - val_auc: 0.9198
Epoch 37/100
600/600 [==============================] - 0s 195us/step - loss: 0.3599 - binary_accuracy: 0.8233 - sensitivity: 0.8896 - specificity: 0.6792 - gmeasure: 0.7724 - auc: 0.9155 - val_loss: 0.3774 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9097 - val_specificity: 0.7305 - val_gmeasure: 0.8146 - val_auc: 0.9179
Epoch 38/100
600/600 [==============================] - 0s 203us/step - loss: 0.3557 - binary_accuracy: 0.8267 - sensitivity: 0.8895 - specificity: 0.7094 - gmeasure: 0.7903 - auc: 0.9217 - val_loss: 0.3706 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9004 - val_specificity: 0.7833 - val_gmeasure: 0.8381 - val_auc: 0.9193
Epoch 39/100
600/600 [==============================] - 0s 200us/step - loss: 0.3477 - binary_accuracy: 0.8283 - sensitivity: 0.8791 - specificity: 0.7152 - gmeasure: 0.7905 - auc: 0.9178 - val_loss: 0.3719 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9097 - val_specificity: 0.6156 - val_gmeasure: 0.7481 - val_auc: 0.9252
Epoch 40/100
600/600 [==============================] - 0s 222us/step - loss: 0.3415 - binary_accuracy: 0.8383 - sensitivity: 0.8777 - specificity: 0.7366 - gmeasure: 0.7999 - auc: 0.9179 - val_loss: 0.3649 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7253 - val_gmeasure: 0.8102 - val_auc: 0.9182
Epoch 41/100
600/600 [==============================] - 0s 217us/step - loss: 0.3369 - binary_accuracy: 0.8300 - sensitivity: 0.8762 - specificity: 0.7304 - gmeasure: 0.7961 - auc: 0.9216 - val_loss: 0.3613 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9097 - val_specificity: 0.6777 - val_gmeasure: 0.7849 - val_auc: 0.9258
Epoch 42/100
600/600 [==============================] - 0s 212us/step - loss: 0.3296 - binary_accuracy: 0.8450 - sensitivity: 0.8733 - specificity: 0.7717 - gmeasure: 0.8170 - auc: 0.9249 - val_loss: 0.3625 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9097 - val_specificity: 0.6777 - val_gmeasure: 0.7849 - val_auc: 0.9237
Epoch 43/100
600/600 [==============================] - 0s 204us/step - loss: 0.3266 - binary_accuracy: 0.8500 - sensitivity: 0.8731 - specificity: 0.8126 - gmeasure: 0.8390 - auc: 0.9258 - val_loss: 0.3535 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7160 - val_gmeasure: 0.8063 - val_auc: 0.9243
Epoch 44/100
600/600 [==============================] - 0s 215us/step - loss: 0.3228 - binary_accuracy: 0.8350 - sensitivity: 0.8720 - specificity: 0.7586 - gmeasure: 0.8098 - auc: 0.9277 - val_loss: 0.3432 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9097 - val_specificity: 0.7305 - val_gmeasure: 0.8146 - val_auc: 0.9267
Epoch 45/100
600/600 [==============================] - 0s 230us/step - loss: 0.3150 - binary_accuracy: 0.8583 - sensitivity: 0.8722 - specificity: 0.8242 - gmeasure: 0.8468 - auc: 0.9259 - val_loss: 0.3399 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9097 - val_specificity: 0.7672 - val_gmeasure: 0.8353 - val_auc: 0.9283
Epoch 46/100
600/600 [==============================] - 0s 240us/step - loss: 0.3135 - binary_accuracy: 0.8517 - sensitivity: 0.8662 - specificity: 0.8167 - gmeasure: 0.8393 - auc: 0.9261 - val_loss: 0.3463 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7160 - val_gmeasure: 0.8063 - val_auc: 0.9256
Epoch 47/100
600/600 [==============================] - 0s 221us/step - loss: 0.3125 - binary_accuracy: 0.8567 - sensitivity: 0.8712 - specificity: 0.8223 - gmeasure: 0.8416 - auc: 0.9270 - val_loss: 0.3345 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9192 - val_specificity: 0.7894 - val_gmeasure: 0.8518 - val_auc: 0.9316
Epoch 48/100
600/600 [==============================] - 0s 223us/step - loss: 0.3065 - binary_accuracy: 0.8600 - sensitivity: 0.8706 - specificity: 0.8456 - gmeasure: 0.8560 - auc: 0.9297 - val_loss: 0.3223 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9284
Epoch 49/100
600/600 [==============================] - 0s 216us/step - loss: 0.2978 - binary_accuracy: 0.8650 - sensitivity: 0.8809 - specificity: 0.8216 - gmeasure: 0.8496 - auc: 0.9276 - val_loss: 0.3177 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9294
Epoch 50/100
600/600 [==============================] - 0s 214us/step - loss: 0.3007 - binary_accuracy: 0.8617 - sensitivity: 0.8717 - specificity: 0.8372 - gmeasure: 0.8495 - auc: 0.9353 - val_loss: 0.3245 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9192 - val_specificity: 0.7817 - val_gmeasure: 0.8473 - val_auc: 0.9382
Epoch 51/100
600/600 [==============================] - 0s 226us/step - loss: 0.2933 - binary_accuracy: 0.8750 - sensitivity: 0.8851 - specificity: 0.8515 - gmeasure: 0.8658 - auc: 0.9370 - val_loss: 0.3136 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9402
Epoch 52/100
600/600 [==============================] - 0s 218us/step - loss: 0.2896 - binary_accuracy: 0.8767 - sensitivity: 0.8792 - specificity: 0.8750 - gmeasure: 0.8737 - auc: 0.9423 - val_loss: 0.3202 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9445
Epoch 53/100
600/600 [==============================] - 0s 202us/step - loss: 0.2837 - binary_accuracy: 0.8800 - sensitivity: 0.8857 - specificity: 0.8656 - gmeasure: 0.8745 - auc: 0.9385 - val_loss: 0.3095 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9423
Epoch 54/100
600/600 [==============================] - 0s 209us/step - loss: 0.2833 - binary_accuracy: 0.8733 - sensitivity: 0.8803 - specificity: 0.8519 - gmeasure: 0.8630 - auc: 0.9424 - val_loss: 0.3113 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9398
Epoch 55/100
600/600 [==============================] - 0s 237us/step - loss: 0.2769 - binary_accuracy: 0.8817 - sensitivity: 0.8846 - specificity: 0.8789 - gmeasure: 0.8804 - auc: 0.9426 - val_loss: 0.3131 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9409
Epoch 56/100
600/600 [==============================] - 0s 224us/step - loss: 0.2786 - binary_accuracy: 0.8833 - sensitivity: 0.8956 - specificity: 0.8649 - gmeasure: 0.8785 - auc: 0.9446 - val_loss: 0.3170 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9192 - val_specificity: 0.7341 - val_gmeasure: 0.8207 - val_auc: 0.9469
Epoch 57/100
600/600 [==============================] - 0s 208us/step - loss: 0.2759 - binary_accuracy: 0.8833 - sensitivity: 0.8916 - specificity: 0.8775 - gmeasure: 0.8825 - auc: 0.9458 - val_loss: 0.3046 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9454
Epoch 58/100
600/600 [==============================] - 0s 219us/step - loss: 0.2705 - binary_accuracy: 0.8900 - sensitivity: 0.8913 - specificity: 0.8877 - gmeasure: 0.8882 - auc: 0.9437 - val_loss: 0.3028 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9457
Epoch 59/100
600/600 [==============================] - 0s 223us/step - loss: 0.2653 - binary_accuracy: 0.8867 - sensitivity: 0.8887 - specificity: 0.8785 - gmeasure: 0.8818 - auc: 0.9444 - val_loss: 0.2939 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8912 - val_specificity: 0.8422 - val_gmeasure: 0.8659 - val_auc: 0.9431
Epoch 60/100
600/600 [==============================] - 0s 219us/step - loss: 0.2648 - binary_accuracy: 0.8833 - sensitivity: 0.8982 - specificity: 0.8460 - gmeasure: 0.8701 - auc: 0.9441 - val_loss: 0.2960 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8631 - val_specificity: 0.9028 - val_gmeasure: 0.8818 - val_auc: 0.9437
Epoch 61/100
600/600 [==============================] - 0s 211us/step - loss: 0.2670 - binary_accuracy: 0.8883 - sensitivity: 0.8859 - specificity: 0.8975 - gmeasure: 0.8905 - auc: 0.9464 - val_loss: 0.2929 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9007 - val_specificity: 0.8422 - val_gmeasure: 0.8703 - val_auc: 0.9458
Epoch 62/100
600/600 [==============================] - 0s 205us/step - loss: 0.2566 - binary_accuracy: 0.8967 - sensitivity: 0.8962 - specificity: 0.8939 - gmeasure: 0.8937 - auc: 0.9507 - val_loss: 0.3089 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9192 - val_specificity: 0.7511 - val_gmeasure: 0.8309 - val_auc: 0.9483
Epoch 63/100
600/600 [==============================] - 0s 223us/step - loss: 0.2572 - binary_accuracy: 0.8950 - sensitivity: 0.8952 - specificity: 0.8985 - gmeasure: 0.8959 - auc: 0.9494 - val_loss: 0.3095 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9445
Epoch 64/100
600/600 [==============================] - 0s 226us/step - loss: 0.2560 - binary_accuracy: 0.8900 - sensitivity: 0.8951 - specificity: 0.8849 - gmeasure: 0.8891 - auc: 0.9517 - val_loss: 0.3284 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9285 - val_specificity: 0.6455 - val_gmeasure: 0.7719 - val_auc: 0.9490
Epoch 65/100
600/600 [==============================] - 0s 235us/step - loss: 0.2533 - binary_accuracy: 0.8983 - sensitivity: 0.8990 - specificity: 0.8894 - gmeasure: 0.8920 - auc: 0.9495 - val_loss: 0.2952 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9492
Epoch 66/100
600/600 [==============================] - 0s 219us/step - loss: 0.2478 - binary_accuracy: 0.8967 - sensitivity: 0.8986 - specificity: 0.8976 - gmeasure: 0.8973 - auc: 0.9538 - val_loss: 0.3252 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9408 - val_specificity: 0.6600 - val_gmeasure: 0.7859 - val_auc: 0.9502
Epoch 67/100
600/600 [==============================] - 0s 205us/step - loss: 0.2529 - binary_accuracy: 0.9017 - sensitivity: 0.8891 - specificity: 0.9315 - gmeasure: 0.9089 - auc: 0.9456 - val_loss: 0.3004 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9464
Epoch 68/100
600/600 [==============================] - 0s 223us/step - loss: 0.2529 - binary_accuracy: 0.8900 - sensitivity: 0.8878 - specificity: 0.8942 - gmeasure: 0.8897 - auc: 0.9472 - val_loss: 0.2792 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9489
Epoch 69/100
600/600 [==============================] - 0s 246us/step - loss: 0.2446 - binary_accuracy: 0.8933 - sensitivity: 0.8974 - specificity: 0.8813 - gmeasure: 0.8875 - auc: 0.9480 - val_loss: 0.2867 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9007 - val_specificity: 0.8422 - val_gmeasure: 0.8703 - val_auc: 0.9460
Epoch 70/100
600/600 [==============================] - 0s 230us/step - loss: 0.2402 - binary_accuracy: 0.9017 - sensitivity: 0.9114 - specificity: 0.8733 - gmeasure: 0.8906 - auc: 0.9491 - val_loss: 0.2779 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9426
Epoch 71/100
600/600 [==============================] - 0s 207us/step - loss: 0.2409 - binary_accuracy: 0.8983 - sensitivity: 0.9116 - specificity: 0.8835 - gmeasure: 0.8952 - auc: 0.9552 - val_loss: 0.2793 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8727 - val_specificity: 0.8883 - val_gmeasure: 0.8791 - val_auc: 0.9407
Epoch 72/100
600/600 [==============================] - 0s 226us/step - loss: 0.2780 - binary_accuracy: 0.8783 - sensitivity: 0.8735 - specificity: 0.8927 - gmeasure: 0.8789 - auc: 0.9448 - val_loss: 0.3059 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9285 - val_specificity: 0.8039 - val_gmeasure: 0.8639 - val_auc: 0.9535
Epoch 73/100
600/600 [==============================] - 0s 212us/step - loss: 0.2394 - binary_accuracy: 0.9083 - sensitivity: 0.8950 - specificity: 0.9323 - gmeasure: 0.9130 - auc: 0.9485 - val_loss: 0.2898 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9192 - val_specificity: 0.7656 - val_gmeasure: 0.8389 - val_auc: 0.9507
Epoch 74/100
600/600 [==============================] - 0s 218us/step - loss: 0.2373 - binary_accuracy: 0.8933 - sensitivity: 0.9025 - specificity: 0.8828 - gmeasure: 0.8894 - auc: 0.9553 - val_loss: 0.2881 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9100 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9513
Epoch 75/100
600/600 [==============================] - 0s 214us/step - loss: 0.2320 - binary_accuracy: 0.9117 - sensitivity: 0.9049 - specificity: 0.9278 - gmeasure: 0.9150 - auc: 0.9587 - val_loss: 0.2748 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9007 - val_specificity: 0.8883 - val_gmeasure: 0.8936 - val_auc: 0.9517
Epoch 76/100
600/600 [==============================] - 0s 224us/step - loss: 0.2293 - binary_accuracy: 0.9133 - sensitivity: 0.9057 - specificity: 0.9343 - gmeasure: 0.9186 - auc: 0.9591 - val_loss: 0.2913 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9192 - val_specificity: 0.7656 - val_gmeasure: 0.8389 - val_auc: 0.9549
Epoch 77/100
600/600 [==============================] - 0s 210us/step - loss: 0.2241 - binary_accuracy: 0.9067 - sensitivity: 0.9132 - specificity: 0.8917 - gmeasure: 0.9019 - auc: 0.9577 - val_loss: 0.2697 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8822 - val_specificity: 0.8883 - val_gmeasure: 0.8837 - val_auc: 0.9494
Epoch 78/100
600/600 [==============================] - 0s 197us/step - loss: 0.2401 - binary_accuracy: 0.8850 - sensitivity: 0.8974 - specificity: 0.8656 - gmeasure: 0.8787 - auc: 0.9588 - val_loss: 0.2753 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9547
Epoch 79/100
600/600 [==============================] - 0s 201us/step - loss: 0.2431 - binary_accuracy: 0.9000 - sensitivity: 0.8981 - specificity: 0.9177 - gmeasure: 0.9051 - auc: 0.9580 - val_loss: 0.3159 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9285 - val_specificity: 0.6983 - val_gmeasure: 0.8044 - val_auc: 0.9533
Epoch 80/100
600/600 [==============================] - 0s 236us/step - loss: 0.2325 - binary_accuracy: 0.9050 - sensitivity: 0.8899 - specificity: 0.9272 - gmeasure: 0.9072 - auc: 0.9538 - val_loss: 0.3196 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9408 - val_specificity: 0.6839 - val_gmeasure: 0.8006 - val_auc: 0.9551
Epoch 81/100
600/600 [==============================] - 0s 223us/step - loss: 0.2267 - binary_accuracy: 0.9100 - sensitivity: 0.9068 - specificity: 0.9092 - gmeasure: 0.9065 - auc: 0.9582 - val_loss: 0.2697 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9531
Epoch 82/100
600/600 [==============================] - 0s 216us/step - loss: 0.2243 - binary_accuracy: 0.9100 - sensitivity: 0.9190 - specificity: 0.8964 - gmeasure: 0.9063 - auc: 0.9593 - val_loss: 0.2639 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8914 - val_specificity: 0.8883 - val_gmeasure: 0.8887 - val_auc: 0.9471
Epoch 83/100
600/600 [==============================] - 0s 193us/step - loss: 0.2349 - binary_accuracy: 0.9017 - sensitivity: 0.8999 - specificity: 0.9122 - gmeasure: 0.9041 - auc: 0.9591 - val_loss: 0.2732 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9100 - val_specificity: 0.8660 - val_gmeasure: 0.8867 - val_auc: 0.9561
Epoch 84/100
600/600 [==============================] - 0s 213us/step - loss: 0.2246 - binary_accuracy: 0.9100 - sensitivity: 0.9094 - specificity: 0.9203 - gmeasure: 0.9136 - auc: 0.9596 - val_loss: 0.2673 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9100 - val_specificity: 0.8500 - val_gmeasure: 0.8792 - val_auc: 0.9554
Epoch 85/100
600/600 [==============================] - 0s 235us/step - loss: 0.2260 - binary_accuracy: 0.9100 - sensitivity: 0.9048 - specificity: 0.9342 - gmeasure: 0.9176 - auc: 0.9638 - val_loss: 0.2687 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9100 - val_specificity: 0.8660 - val_gmeasure: 0.8867 - val_auc: 0.9534
Epoch 86/100
600/600 [==============================] - 0s 201us/step - loss: 0.2201 - binary_accuracy: 0.9083 - sensitivity: 0.9108 - specificity: 0.9022 - gmeasure: 0.9054 - auc: 0.9577 - val_loss: 0.2584 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9498
Epoch 87/100
600/600 [==============================] - 0s 212us/step - loss: 0.2229 - binary_accuracy: 0.9117 - sensitivity: 0.9106 - specificity: 0.9263 - gmeasure: 0.9169 - auc: 0.9641 - val_loss: 0.2670 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9100 - val_specificity: 0.8500 - val_gmeasure: 0.8792 - val_auc: 0.9554
Epoch 88/100
600/600 [==============================] - 0s 210us/step - loss: 0.2152 - binary_accuracy: 0.9150 - sensitivity: 0.9132 - specificity: 0.9190 - gmeasure: 0.9155 - auc: 0.9590 - val_loss: 0.2587 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9584
Epoch 89/100
600/600 [==============================] - 0s 204us/step - loss: 0.2217 - binary_accuracy: 0.9067 - sensitivity: 0.9008 - specificity: 0.9284 - gmeasure: 0.9123 - auc: 0.9606 - val_loss: 0.2658 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8262 - val_gmeasure: 0.8714 - val_auc: 0.9566
Epoch 90/100
600/600 [==============================] - 0s 196us/step - loss: 0.2152 - binary_accuracy: 0.9117 - sensitivity: 0.9161 - specificity: 0.9073 - gmeasure: 0.9097 - auc: 0.9676 - val_loss: 0.2587 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9575
Epoch 91/100
600/600 [==============================] - 0s 210us/step - loss: 0.2103 - binary_accuracy: 0.9083 - sensitivity: 0.9105 - specificity: 0.9023 - gmeasure: 0.9053 - auc: 0.9627 - val_loss: 0.2939 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9408 - val_specificity: 0.7128 - val_gmeasure: 0.8182 - val_auc: 0.9624
Epoch 92/100
600/600 [==============================] - 0s 215us/step - loss: 0.2201 - binary_accuracy: 0.9033 - sensitivity: 0.9075 - specificity: 0.9065 - gmeasure: 0.9049 - auc: 0.9657 - val_loss: 0.2851 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9408 - val_specificity: 0.7366 - val_gmeasure: 0.8320 - val_auc: 0.9630
Epoch 93/100
600/600 [==============================] - 0s 197us/step - loss: 0.2105 - binary_accuracy: 0.9217 - sensitivity: 0.9101 - specificity: 0.9412 - gmeasure: 0.9250 - auc: 0.9638 - val_loss: 0.2887 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9408 - val_specificity: 0.7128 - val_gmeasure: 0.8182 - val_auc: 0.9630
Epoch 94/100
600/600 [==============================] - 0s 210us/step - loss: 0.2089 - binary_accuracy: 0.9100 - sensitivity: 0.9064 - specificity: 0.9211 - gmeasure: 0.9131 - auc: 0.9641 - val_loss: 0.2924 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9408 - val_specificity: 0.6983 - val_gmeasure: 0.8095 - val_auc: 0.9642
Epoch 95/100
600/600 [==============================] - 0s 205us/step - loss: 0.2072 - binary_accuracy: 0.9167 - sensitivity: 0.9177 - specificity: 0.9190 - gmeasure: 0.9178 - auc: 0.9640 - val_loss: 0.2752 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9408 - val_specificity: 0.7827 - val_gmeasure: 0.8570 - val_auc: 0.9635
Epoch 96/100
600/600 [==============================] - 0s 199us/step - loss: 0.2045 - binary_accuracy: 0.9200 - sensitivity: 0.9161 - specificity: 0.9293 - gmeasure: 0.9213 - auc: 0.9645 - val_loss: 0.2603 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8500 - val_gmeasure: 0.8838 - val_auc: 0.9642
Epoch 97/100
600/600 [==============================] - 0s 214us/step - loss: 0.2021 - binary_accuracy: 0.9233 - sensitivity: 0.9114 - specificity: 0.9502 - gmeasure: 0.9299 - auc: 0.9651 - val_loss: 0.2660 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9408 - val_specificity: 0.8039 - val_gmeasure: 0.8697 - val_auc: 0.9642
Epoch 98/100
600/600 [==============================] - 0s 205us/step - loss: 0.1998 - binary_accuracy: 0.9200 - sensitivity: 0.9186 - specificity: 0.9269 - gmeasure: 0.9214 - auc: 0.9701 - val_loss: 0.2627 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9316 - val_specificity: 0.8117 - val_gmeasure: 0.8693 - val_auc: 0.9654
Epoch 99/100
600/600 [==============================] - 0s 208us/step - loss: 0.2021 - binary_accuracy: 0.9183 - sensitivity: 0.9061 - specificity: 0.9396 - gmeasure: 0.9218 - auc: 0.9621 - val_loss: 0.2604 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9192 - val_specificity: 0.8660 - val_gmeasure: 0.8914 - val_auc: 0.9652
Epoch 100/100
600/600 [==============================] - 0s 218us/step - loss: 0.2014 - binary_accuracy: 0.9267 - sensitivity: 0.9228 - specificity: 0.9360 - gmeasure: 0.9292 - auc: 0.9649 - val_loss: 0.2488 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9316 - val_specificity: 0.8738 - val_gmeasure: 0.9015 - val_auc: 0.9640
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 15.262919902801514!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.014128923416137695!
[root    |INFO|build_network.py:183] Evaluation: [0.2123630940914154, 0.9173333048820496, 0.9041095972061157, 0.9456067085266113, 0.9246253967285156, 0.967468798160553]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 21us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.012145757675170898!
[root    |INFO|build_network.py:183] Evaluation: [0.24281755089759827, 0.9039999842643738, 0.9269663095474243, 0.8472222089767456, 0.8861977458000183, 0.9503355026245117]
[root    |INFO|deepbiome.py:179] Compute time : 16.86178183555603
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.27629593 0.88755554 0.94336899 0.75539269 0.83720887 0.94540739]
[root    |INFO|deepbiome.py:189]        std : [0.09796488 0.04984518 0.02977692 0.17584679 0.09582087 0.03321583]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.32320864 0.87733332 0.95441262 0.70909139 0.8183614  0.92972175]
[root    |INFO|deepbiome.py:196]        std : [0.07469245 0.02719478 0.02257056 0.12565417 0.0651453  0.0182054 ]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">deepbiome_train</span></code> save the trained model weights, evaluation results and history based on the path information from the configuration.</p>
<p>From the example above, we can check that <code class="docutils literal notranslate"><span class="pre">hist_*.json</span></code>, <code class="docutils literal notranslate"><span class="pre">weight_*.h5</span></code>, <code class="docutils literal notranslate"><span class="pre">test_eval.npy</span></code>, <code class="docutils literal notranslate"><span class="pre">train_eval.npy</span></code> files were saved.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[&#39;hist_0.json&#39;,
 &#39;weight_2.h5&#39;,
 &#39;test_eval.npy&#39;,
 &#39;weight_0.h5&#39;,
 &#39;train_eval.npy&#39;,
 &#39;hist_2.json&#39;,
 &#39;weight_1.h5&#39;,
 &#39;hist_1.json&#39;]
</pre></div>
</div>
</div>
<p>Lets check the history files.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_the_list_of_inputs_43_0.png" src="_images/example_with_the_list_of_inputs_43_0.png" />
</div>
</div>
<p>Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.42274556, 0.83999997, 0.98224854, 0.54320985, 0.73045677,
        0.90605599],
       [0.30406281, 0.88800001, 0.954023  , 0.7368421 , 0.83842969,
        0.93277377],
       [0.24281755, 0.90399998, 0.92696631, 0.84722221, 0.88619775,
        0.9503355 ]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.4147054 , 0.81733334, 0.94980693, 0.52155173, 0.70382774,
        0.8984614 ],
       [0.2018193 , 0.92799997, 0.97619045, 0.79901963, 0.88317347,
        0.97029197],
       [0.21236309, 0.9173333 , 0.9041096 , 0.94560671, 0.9246254 ,
        0.9674688 ]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="5.-Load-the-pre-trained-network-for-training">
<h2>5. Load the pre-trained network for training<a class="headerlink" href="#5.-Load-the-pre-trained-network-for-training" title="Permalink to this headline">¶</a></h2>
<p>If you have pre-trianed model, you can use the pre-trained weight for next training. For using pre-trained weights, you have to use <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> option in <code class="docutils literal notranslate"><span class="pre">training_inro</span></code> with addding the file path of the pre-trained weights in the <code class="docutils literal notranslate"><span class="pre">warm_start_model</span></code> option. Below is the example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">warm_start_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span><span class="s1">&#39;True&#39;</span><span class="p">,</span>
        <span class="s1">&#39;warm_start_model&#39;</span><span class="p">:</span><span class="s1">&#39;./example_result/weight.h5&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;200&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">warm_start_network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span>
                                                                       <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 798us/step - loss: 0.4161 - binary_accuracy: 0.8133 - sensitivity: 0.9660 - specificity: 0.4726 - gmeasure: 0.6735 - auc: 0.9011 - val_loss: 0.4189 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9333 - val_specificity: 0.5333 - val_gmeasure: 0.7055 - val_auc: 0.8899
Epoch 2/100
600/600 [==============================] - 0s 60us/step - loss: 0.4156 - binary_accuracy: 0.8400 - sensitivity: 0.9351 - specificity: 0.6339 - gmeasure: 0.7691 - auc: 0.9019 - val_loss: 0.4145 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9333 - val_specificity: 0.4444 - val_gmeasure: 0.6441 - val_auc: 0.8912
Epoch 3/100
600/600 [==============================] - 0s 65us/step - loss: 0.4073 - binary_accuracy: 0.8133 - sensitivity: 0.9659 - specificity: 0.4756 - gmeasure: 0.6775 - auc: 0.9035 - val_loss: 0.4166 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9714 - val_specificity: 0.3333 - val_gmeasure: 0.5690 - val_auc: 0.8912
Epoch 4/100
600/600 [==============================] - 0s 65us/step - loss: 0.4078 - binary_accuracy: 0.8133 - sensitivity: 0.9642 - specificity: 0.4830 - gmeasure: 0.6788 - auc: 0.9045 - val_loss: 0.4088 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9333 - val_specificity: 0.4667 - val_gmeasure: 0.6600 - val_auc: 0.8931
Epoch 5/100
600/600 [==============================] - 0s 68us/step - loss: 0.4031 - binary_accuracy: 0.8350 - sensitivity: 0.9490 - specificity: 0.5833 - gmeasure: 0.7434 - auc: 0.9039 - val_loss: 0.4063 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.8954
Epoch 6/100
600/600 [==============================] - 0s 64us/step - loss: 0.4008 - binary_accuracy: 0.8267 - sensitivity: 0.9541 - specificity: 0.5476 - gmeasure: 0.7209 - auc: 0.9049 - val_loss: 0.4048 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9714 - val_specificity: 0.4000 - val_gmeasure: 0.6234 - val_auc: 0.8963
Epoch 7/100
600/600 [==============================] - 0s 69us/step - loss: 0.3978 - binary_accuracy: 0.8233 - sensitivity: 0.9637 - specificity: 0.5146 - gmeasure: 0.7036 - auc: 0.9061 - val_loss: 0.4002 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9429 - val_specificity: 0.4444 - val_gmeasure: 0.6473 - val_auc: 0.8984
Epoch 8/100
600/600 [==============================] - 0s 63us/step - loss: 0.3939 - binary_accuracy: 0.8400 - sensitivity: 0.9520 - specificity: 0.5880 - gmeasure: 0.7470 - auc: 0.9066 - val_loss: 0.3985 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9048 - val_specificity: 0.6222 - val_gmeasure: 0.7503 - val_auc: 0.9005
Epoch 9/100
600/600 [==============================] - 0s 69us/step - loss: 0.3922 - binary_accuracy: 0.8433 - sensitivity: 0.9468 - specificity: 0.6178 - gmeasure: 0.7635 - auc: 0.9069 - val_loss: 0.3941 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9333 - val_specificity: 0.4889 - val_gmeasure: 0.6755 - val_auc: 0.9018
Epoch 10/100
600/600 [==============================] - 0s 62us/step - loss: 0.3886 - binary_accuracy: 0.8350 - sensitivity: 0.9561 - specificity: 0.5646 - gmeasure: 0.7345 - auc: 0.9071 - val_loss: 0.3918 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9429 - val_specificity: 0.4444 - val_gmeasure: 0.6473 - val_auc: 0.9035
Epoch 11/100
600/600 [==============================] - 0s 61us/step - loss: 0.3860 - binary_accuracy: 0.8350 - sensitivity: 0.9587 - specificity: 0.5593 - gmeasure: 0.7312 - auc: 0.9108 - val_loss: 0.3882 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.9048
Epoch 12/100
600/600 [==============================] - 0s 69us/step - loss: 0.3840 - binary_accuracy: 0.8483 - sensitivity: 0.9522 - specificity: 0.6200 - gmeasure: 0.7680 - auc: 0.9108 - val_loss: 0.3857 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9060
Epoch 13/100
600/600 [==============================] - 0s 68us/step - loss: 0.3804 - binary_accuracy: 0.8450 - sensitivity: 0.9515 - specificity: 0.6083 - gmeasure: 0.7599 - auc: 0.9101 - val_loss: 0.3827 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9333 - val_specificity: 0.4889 - val_gmeasure: 0.6755 - val_auc: 0.9067
Epoch 14/100
600/600 [==============================] - 0s 65us/step - loss: 0.3786 - binary_accuracy: 0.8433 - sensitivity: 0.9567 - specificity: 0.5939 - gmeasure: 0.7535 - auc: 0.9127 - val_loss: 0.3799 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.9073
Epoch 15/100
600/600 [==============================] - 0s 63us/step - loss: 0.3750 - binary_accuracy: 0.8450 - sensitivity: 0.9491 - specificity: 0.6152 - gmeasure: 0.7630 - auc: 0.9127 - val_loss: 0.3778 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9143 - val_specificity: 0.6444 - val_gmeasure: 0.7676 - val_auc: 0.9090
Epoch 16/100
600/600 [==============================] - 0s 66us/step - loss: 0.3732 - binary_accuracy: 0.8433 - sensitivity: 0.9417 - specificity: 0.6266 - gmeasure: 0.7680 - auc: 0.9141 - val_loss: 0.3744 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9096
Epoch 17/100
600/600 [==============================] - 0s 63us/step - loss: 0.3714 - binary_accuracy: 0.8467 - sensitivity: 0.9565 - specificity: 0.6010 - gmeasure: 0.7564 - auc: 0.9176 - val_loss: 0.3719 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9109
Epoch 18/100
600/600 [==============================] - 0s 62us/step - loss: 0.3680 - binary_accuracy: 0.8433 - sensitivity: 0.9486 - specificity: 0.6070 - gmeasure: 0.7577 - auc: 0.9152 - val_loss: 0.3699 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9143 - val_specificity: 0.6444 - val_gmeasure: 0.7676 - val_auc: 0.9117
Epoch 19/100
600/600 [==============================] - 0s 68us/step - loss: 0.3673 - binary_accuracy: 0.8483 - sensitivity: 0.9442 - specificity: 0.6390 - gmeasure: 0.7746 - auc: 0.9177 - val_loss: 0.3670 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9128
Epoch 20/100
600/600 [==============================] - 0s 68us/step - loss: 0.3632 - binary_accuracy: 0.8483 - sensitivity: 0.9446 - specificity: 0.6366 - gmeasure: 0.7753 - auc: 0.9174 - val_loss: 0.3654 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9143
Epoch 21/100
600/600 [==============================] - 0s 66us/step - loss: 0.3615 - binary_accuracy: 0.8467 - sensitivity: 0.9397 - specificity: 0.6420 - gmeasure: 0.7761 - auc: 0.9191 - val_loss: 0.3627 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9048 - val_specificity: 0.6444 - val_gmeasure: 0.7636 - val_auc: 0.9147
Epoch 22/100
600/600 [==============================] - 0s 64us/step - loss: 0.3587 - binary_accuracy: 0.8483 - sensitivity: 0.9424 - specificity: 0.6433 - gmeasure: 0.7781 - auc: 0.9205 - val_loss: 0.3609 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9151
Epoch 23/100
600/600 [==============================] - 0s 66us/step - loss: 0.3565 - binary_accuracy: 0.8483 - sensitivity: 0.9394 - specificity: 0.6471 - gmeasure: 0.7796 - auc: 0.9198 - val_loss: 0.3587 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9156
Epoch 24/100
600/600 [==============================] - 0s 70us/step - loss: 0.3542 - binary_accuracy: 0.8467 - sensitivity: 0.9420 - specificity: 0.6307 - gmeasure: 0.7692 - auc: 0.9204 - val_loss: 0.3567 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9158
Epoch 25/100
600/600 [==============================] - 0s 70us/step - loss: 0.3526 - binary_accuracy: 0.8483 - sensitivity: 0.9395 - specificity: 0.6460 - gmeasure: 0.7790 - auc: 0.9211 - val_loss: 0.3547 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9164
Epoch 26/100
600/600 [==============================] - 0s 71us/step - loss: 0.3506 - binary_accuracy: 0.8467 - sensitivity: 0.9449 - specificity: 0.6263 - gmeasure: 0.7678 - auc: 0.9208 - val_loss: 0.3533 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9048 - val_specificity: 0.7333 - val_gmeasure: 0.8146 - val_auc: 0.9157
Epoch 27/100
600/600 [==============================] - 0s 67us/step - loss: 0.3492 - binary_accuracy: 0.8500 - sensitivity: 0.9352 - specificity: 0.6637 - gmeasure: 0.7876 - auc: 0.9225 - val_loss: 0.3508 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9048 - val_specificity: 0.6889 - val_gmeasure: 0.7895 - val_auc: 0.9168
Epoch 28/100
600/600 [==============================] - 0s 61us/step - loss: 0.3482 - binary_accuracy: 0.8533 - sensitivity: 0.9469 - specificity: 0.6480 - gmeasure: 0.7831 - auc: 0.9234 - val_loss: 0.3490 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9048 - val_specificity: 0.6889 - val_gmeasure: 0.7895 - val_auc: 0.9178
Epoch 29/100
600/600 [==============================] - 0s 68us/step - loss: 0.3470 - binary_accuracy: 0.8533 - sensitivity: 0.9282 - specificity: 0.6864 - gmeasure: 0.7970 - auc: 0.9226 - val_loss: 0.3525 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8667 - val_specificity: 0.8222 - val_gmeasure: 0.8442 - val_auc: 0.9184
Epoch 30/100
600/600 [==============================] - 0s 70us/step - loss: 0.3440 - binary_accuracy: 0.8600 - sensitivity: 0.9371 - specificity: 0.6873 - gmeasure: 0.8018 - auc: 0.9253 - val_loss: 0.3479 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9333 - val_specificity: 0.6000 - val_gmeasure: 0.7483 - val_auc: 0.9189
Epoch 31/100
600/600 [==============================] - 0s 66us/step - loss: 0.3448 - binary_accuracy: 0.8433 - sensitivity: 0.9405 - specificity: 0.6322 - gmeasure: 0.7699 - auc: 0.9287 - val_loss: 0.3460 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8762 - val_specificity: 0.7778 - val_gmeasure: 0.8255 - val_auc: 0.9186
Epoch 32/100
600/600 [==============================] - 0s 68us/step - loss: 0.3418 - binary_accuracy: 0.8567 - sensitivity: 0.9365 - specificity: 0.6803 - gmeasure: 0.7969 - auc: 0.9259 - val_loss: 0.3430 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9048 - val_specificity: 0.7111 - val_gmeasure: 0.8021 - val_auc: 0.9188
Epoch 33/100
600/600 [==============================] - 0s 68us/step - loss: 0.3399 - binary_accuracy: 0.8550 - sensitivity: 0.9272 - specificity: 0.7004 - gmeasure: 0.8045 - auc: 0.9258 - val_loss: 0.3453 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9203
Epoch 34/100
600/600 [==============================] - 0s 68us/step - loss: 0.3345 - binary_accuracy: 0.8600 - sensitivity: 0.9322 - specificity: 0.7052 - gmeasure: 0.8106 - auc: 0.9277 - val_loss: 0.3405 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9238 - val_specificity: 0.7111 - val_gmeasure: 0.8105 - val_auc: 0.9194
Epoch 35/100
600/600 [==============================] - 0s 67us/step - loss: 0.3343 - binary_accuracy: 0.8533 - sensitivity: 0.9487 - specificity: 0.6406 - gmeasure: 0.7793 - auc: 0.9256 - val_loss: 0.3387 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9048 - val_specificity: 0.7111 - val_gmeasure: 0.8021 - val_auc: 0.9212
Epoch 36/100
600/600 [==============================] - 0s 65us/step - loss: 0.3308 - binary_accuracy: 0.8650 - sensitivity: 0.9400 - specificity: 0.6971 - gmeasure: 0.8086 - auc: 0.9273 - val_loss: 0.3402 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8667 - val_specificity: 0.8222 - val_gmeasure: 0.8442 - val_auc: 0.9224
Epoch 37/100
600/600 [==============================] - 0s 67us/step - loss: 0.3308 - binary_accuracy: 0.8550 - sensitivity: 0.9254 - specificity: 0.6997 - gmeasure: 0.8046 - auc: 0.9280 - val_loss: 0.3364 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9226
Epoch 38/100
600/600 [==============================] - 0s 69us/step - loss: 0.3282 - binary_accuracy: 0.8600 - sensitivity: 0.9336 - specificity: 0.6934 - gmeasure: 0.8035 - auc: 0.9294 - val_loss: 0.3353 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9233
Epoch 39/100
600/600 [==============================] - 0s 71us/step - loss: 0.3267 - binary_accuracy: 0.8617 - sensitivity: 0.9374 - specificity: 0.6917 - gmeasure: 0.8046 - auc: 0.9300 - val_loss: 0.3340 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9230
Epoch 40/100
600/600 [==============================] - 0s 67us/step - loss: 0.3254 - binary_accuracy: 0.8600 - sensitivity: 0.9352 - specificity: 0.6952 - gmeasure: 0.8055 - auc: 0.9323 - val_loss: 0.3325 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8952 - val_specificity: 0.7333 - val_gmeasure: 0.8103 - val_auc: 0.9222
Epoch 41/100
600/600 [==============================] - 0s 70us/step - loss: 0.3238 - binary_accuracy: 0.8583 - sensitivity: 0.9396 - specificity: 0.6814 - gmeasure: 0.8000 - auc: 0.9297 - val_loss: 0.3318 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9221
Epoch 42/100
600/600 [==============================] - 0s 74us/step - loss: 0.3228 - binary_accuracy: 0.8617 - sensitivity: 0.9225 - specificity: 0.7277 - gmeasure: 0.8191 - auc: 0.9316 - val_loss: 0.3324 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9238
Epoch 43/100
600/600 [==============================] - 0s 72us/step - loss: 0.3210 - binary_accuracy: 0.8633 - sensitivity: 0.9321 - specificity: 0.7130 - gmeasure: 0.8145 - auc: 0.9321 - val_loss: 0.3296 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9333 - val_specificity: 0.7111 - val_gmeasure: 0.8147 - val_auc: 0.9243
Epoch 44/100
600/600 [==============================] - 0s 64us/step - loss: 0.3210 - binary_accuracy: 0.8583 - sensitivity: 0.9488 - specificity: 0.6593 - gmeasure: 0.7908 - auc: 0.9303 - val_loss: 0.3281 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8857 - val_specificity: 0.8222 - val_gmeasure: 0.8534 - val_auc: 0.9244
Epoch 45/100
600/600 [==============================] - 0s 72us/step - loss: 0.3197 - binary_accuracy: 0.8650 - sensitivity: 0.9181 - specificity: 0.7495 - gmeasure: 0.8293 - auc: 0.9322 - val_loss: 0.3280 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8571 - val_specificity: 0.8222 - val_gmeasure: 0.8395 - val_auc: 0.9255
Epoch 46/100
600/600 [==============================] - 0s 69us/step - loss: 0.3195 - binary_accuracy: 0.8583 - sensitivity: 0.9356 - specificity: 0.6931 - gmeasure: 0.8041 - auc: 0.9326 - val_loss: 0.3255 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9333 - val_specificity: 0.7556 - val_gmeasure: 0.8398 - val_auc: 0.9244
Epoch 47/100
600/600 [==============================] - 0s 69us/step - loss: 0.3187 - binary_accuracy: 0.8650 - sensitivity: 0.9283 - specificity: 0.7343 - gmeasure: 0.8244 - auc: 0.9355 - val_loss: 0.3271 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8571 - val_specificity: 0.8444 - val_gmeasure: 0.8508 - val_auc: 0.9259
Epoch 48/100
600/600 [==============================] - 0s 71us/step - loss: 0.3133 - binary_accuracy: 0.8683 - sensitivity: 0.9177 - specificity: 0.7593 - gmeasure: 0.8345 - auc: 0.9339 - val_loss: 0.3224 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8952 - val_specificity: 0.7556 - val_gmeasure: 0.8224 - val_auc: 0.9268
Epoch 49/100
600/600 [==============================] - 0s 69us/step - loss: 0.3132 - binary_accuracy: 0.8617 - sensitivity: 0.9438 - specificity: 0.6811 - gmeasure: 0.8014 - auc: 0.9345 - val_loss: 0.3214 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9270
Epoch 50/100
600/600 [==============================] - 0s 69us/step - loss: 0.3117 - binary_accuracy: 0.8667 - sensitivity: 0.9269 - specificity: 0.7361 - gmeasure: 0.8257 - auc: 0.9343 - val_loss: 0.3223 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9263
Epoch 51/100
600/600 [==============================] - 0s 70us/step - loss: 0.3110 - binary_accuracy: 0.8600 - sensitivity: 0.9298 - specificity: 0.7065 - gmeasure: 0.8084 - auc: 0.9351 - val_loss: 0.3193 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9266
Epoch 52/100
600/600 [==============================] - 0s 71us/step - loss: 0.3082 - binary_accuracy: 0.8683 - sensitivity: 0.9323 - specificity: 0.7269 - gmeasure: 0.8225 - auc: 0.9360 - val_loss: 0.3195 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9268
Epoch 53/100
600/600 [==============================] - 0s 70us/step - loss: 0.3065 - binary_accuracy: 0.8667 - sensitivity: 0.9199 - specificity: 0.7479 - gmeasure: 0.8290 - auc: 0.9370 - val_loss: 0.3173 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9261
Epoch 54/100
600/600 [==============================] - 0s 72us/step - loss: 0.3071 - binary_accuracy: 0.8667 - sensitivity: 0.9444 - specificity: 0.6953 - gmeasure: 0.8091 - auc: 0.9370 - val_loss: 0.3166 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9272
Epoch 55/100
600/600 [==============================] - 0s 72us/step - loss: 0.3039 - binary_accuracy: 0.8650 - sensitivity: 0.9321 - specificity: 0.7202 - gmeasure: 0.8189 - auc: 0.9384 - val_loss: 0.3185 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8571 - val_specificity: 0.8444 - val_gmeasure: 0.8508 - val_auc: 0.9278
Epoch 56/100
600/600 [==============================] - 0s 70us/step - loss: 0.3042 - binary_accuracy: 0.8650 - sensitivity: 0.9130 - specificity: 0.7628 - gmeasure: 0.8334 - auc: 0.9397 - val_loss: 0.3165 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9266
Epoch 57/100
600/600 [==============================] - 0s 69us/step - loss: 0.3019 - binary_accuracy: 0.8633 - sensitivity: 0.9082 - specificity: 0.7643 - gmeasure: 0.8331 - auc: 0.9363 - val_loss: 0.3146 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9268
Epoch 58/100
600/600 [==============================] - 0s 69us/step - loss: 0.3006 - binary_accuracy: 0.8650 - sensitivity: 0.9275 - specificity: 0.7269 - gmeasure: 0.8204 - auc: 0.9363 - val_loss: 0.3129 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9048 - val_specificity: 0.7778 - val_gmeasure: 0.8389 - val_auc: 0.9270
Epoch 59/100
600/600 [==============================] - 0s 68us/step - loss: 0.2992 - binary_accuracy: 0.8633 - sensitivity: 0.9317 - specificity: 0.7089 - gmeasure: 0.8126 - auc: 0.9389 - val_loss: 0.3142 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9270
Epoch 60/100
600/600 [==============================] - 0s 66us/step - loss: 0.2981 - binary_accuracy: 0.8700 - sensitivity: 0.9178 - specificity: 0.7649 - gmeasure: 0.8377 - auc: 0.9384 - val_loss: 0.3117 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9280
Epoch 61/100
600/600 [==============================] - 0s 62us/step - loss: 0.2988 - binary_accuracy: 0.8683 - sensitivity: 0.9350 - specificity: 0.7239 - gmeasure: 0.8219 - auc: 0.9397 - val_loss: 0.3106 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9283
Epoch 62/100
600/600 [==============================] - 0s 68us/step - loss: 0.2950 - binary_accuracy: 0.8733 - sensitivity: 0.9276 - specificity: 0.7534 - gmeasure: 0.8358 - auc: 0.9394 - val_loss: 0.3132 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8476 - val_specificity: 0.8444 - val_gmeasure: 0.8460 - val_auc: 0.9291
Epoch 63/100
600/600 [==============================] - 0s 65us/step - loss: 0.2954 - binary_accuracy: 0.8717 - sensitivity: 0.9079 - specificity: 0.7937 - gmeasure: 0.8485 - auc: 0.9404 - val_loss: 0.3086 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9285
Epoch 64/100
600/600 [==============================] - 0s 67us/step - loss: 0.2935 - binary_accuracy: 0.8700 - sensitivity: 0.9350 - specificity: 0.7286 - gmeasure: 0.8245 - auc: 0.9413 - val_loss: 0.3075 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9048 - val_specificity: 0.8000 - val_gmeasure: 0.8508 - val_auc: 0.9280
Epoch 65/100
600/600 [==============================] - 0s 66us/step - loss: 0.2932 - binary_accuracy: 0.8750 - sensitivity: 0.9318 - specificity: 0.7448 - gmeasure: 0.8317 - auc: 0.9392 - val_loss: 0.3090 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9283
Epoch 66/100
600/600 [==============================] - 0s 71us/step - loss: 0.2913 - binary_accuracy: 0.8717 - sensitivity: 0.9225 - specificity: 0.7579 - gmeasure: 0.8356 - auc: 0.9425 - val_loss: 0.3060 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9295
Epoch 67/100
600/600 [==============================] - 0s 70us/step - loss: 0.2899 - binary_accuracy: 0.8750 - sensitivity: 0.9277 - specificity: 0.7580 - gmeasure: 0.8385 - auc: 0.9418 - val_loss: 0.3071 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9287
Epoch 68/100
600/600 [==============================] - 0s 70us/step - loss: 0.2891 - binary_accuracy: 0.8733 - sensitivity: 0.9225 - specificity: 0.7648 - gmeasure: 0.8399 - auc: 0.9423 - val_loss: 0.3047 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9291
Epoch 69/100
600/600 [==============================] - 0s 70us/step - loss: 0.2880 - binary_accuracy: 0.8750 - sensitivity: 0.9322 - specificity: 0.7482 - gmeasure: 0.8350 - auc: 0.9443 - val_loss: 0.3054 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9297
Epoch 70/100
600/600 [==============================] - 0s 67us/step - loss: 0.2877 - binary_accuracy: 0.8717 - sensitivity: 0.9153 - specificity: 0.7777 - gmeasure: 0.8427 - auc: 0.9446 - val_loss: 0.3048 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9306
Epoch 71/100
600/600 [==============================] - 0s 70us/step - loss: 0.2868 - binary_accuracy: 0.8800 - sensitivity: 0.9354 - specificity: 0.7615 - gmeasure: 0.8436 - auc: 0.9440 - val_loss: 0.3021 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9299
Epoch 72/100
600/600 [==============================] - 0s 67us/step - loss: 0.2847 - binary_accuracy: 0.8733 - sensitivity: 0.9226 - specificity: 0.7643 - gmeasure: 0.8397 - auc: 0.9430 - val_loss: 0.3027 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9308
Epoch 73/100
600/600 [==============================] - 0s 67us/step - loss: 0.2845 - binary_accuracy: 0.8767 - sensitivity: 0.9273 - specificity: 0.7601 - gmeasure: 0.8384 - auc: 0.9444 - val_loss: 0.3006 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9299
Epoch 74/100
600/600 [==============================] - 0s 63us/step - loss: 0.2828 - binary_accuracy: 0.8767 - sensitivity: 0.9175 - specificity: 0.7855 - gmeasure: 0.8488 - auc: 0.9452 - val_loss: 0.3015 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9310
Epoch 75/100
600/600 [==============================] - 0s 70us/step - loss: 0.2840 - binary_accuracy: 0.8733 - sensitivity: 0.9297 - specificity: 0.7499 - gmeasure: 0.8334 - auc: 0.9449 - val_loss: 0.2998 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9310
Epoch 76/100
600/600 [==============================] - 0s 68us/step - loss: 0.2849 - binary_accuracy: 0.8683 - sensitivity: 0.9091 - specificity: 0.7837 - gmeasure: 0.8437 - auc: 0.9462 - val_loss: 0.3021 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9319
Epoch 77/100
600/600 [==============================] - 0s 73us/step - loss: 0.2785 - binary_accuracy: 0.8800 - sensitivity: 0.9294 - specificity: 0.7682 - gmeasure: 0.8449 - auc: 0.9456 - val_loss: 0.2988 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9238 - val_specificity: 0.8222 - val_gmeasure: 0.8715 - val_auc: 0.9319
Epoch 78/100
600/600 [==============================] - 0s 70us/step - loss: 0.2814 - binary_accuracy: 0.8717 - sensitivity: 0.9419 - specificity: 0.7165 - gmeasure: 0.8215 - auc: 0.9460 - val_loss: 0.3012 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9321
Epoch 79/100
600/600 [==============================] - 0s 70us/step - loss: 0.2821 - binary_accuracy: 0.8783 - sensitivity: 0.9042 - specificity: 0.8226 - gmeasure: 0.8623 - auc: 0.9457 - val_loss: 0.2994 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9312
Epoch 80/100
600/600 [==============================] - 0s 70us/step - loss: 0.2787 - binary_accuracy: 0.8700 - sensitivity: 0.9222 - specificity: 0.7523 - gmeasure: 0.8321 - auc: 0.9463 - val_loss: 0.2957 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9048 - val_specificity: 0.8222 - val_gmeasure: 0.8625 - val_auc: 0.9319
Epoch 81/100
600/600 [==============================] - 0s 67us/step - loss: 0.2862 - binary_accuracy: 0.8783 - sensitivity: 0.9164 - specificity: 0.7968 - gmeasure: 0.8518 - auc: 0.9494 - val_loss: 0.3032 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9325
Epoch 82/100
600/600 [==============================] - 0s 66us/step - loss: 0.2783 - binary_accuracy: 0.8733 - sensitivity: 0.9301 - specificity: 0.7477 - gmeasure: 0.8331 - auc: 0.9480 - val_loss: 0.2971 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9238 - val_specificity: 0.7333 - val_gmeasure: 0.8231 - val_auc: 0.9314
Epoch 83/100
600/600 [==============================] - 0s 72us/step - loss: 0.2755 - binary_accuracy: 0.8783 - sensitivity: 0.9371 - specificity: 0.7480 - gmeasure: 0.8367 - auc: 0.9468 - val_loss: 0.3026 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9325
Epoch 84/100
600/600 [==============================] - 0s 70us/step - loss: 0.2768 - binary_accuracy: 0.8850 - sensitivity: 0.9068 - specificity: 0.8349 - gmeasure: 0.8695 - auc: 0.9464 - val_loss: 0.2946 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9325
Epoch 85/100
600/600 [==============================] - 0s 72us/step - loss: 0.2758 - binary_accuracy: 0.8750 - sensitivity: 0.9324 - specificity: 0.7502 - gmeasure: 0.8353 - auc: 0.9469 - val_loss: 0.2930 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9048 - val_specificity: 0.8444 - val_gmeasure: 0.8741 - val_auc: 0.9319
Epoch 86/100
600/600 [==============================] - 0s 61us/step - loss: 0.2721 - binary_accuracy: 0.8850 - sensitivity: 0.9255 - specificity: 0.7976 - gmeasure: 0.8590 - auc: 0.9491 - val_loss: 0.3022 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9335
Epoch 87/100
600/600 [==============================] - 0s 70us/step - loss: 0.2725 - binary_accuracy: 0.8850 - sensitivity: 0.9152 - specificity: 0.8171 - gmeasure: 0.8636 - auc: 0.9490 - val_loss: 0.2924 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9143 - val_specificity: 0.8444 - val_gmeasure: 0.8787 - val_auc: 0.9323
Epoch 88/100
600/600 [==============================] - 0s 69us/step - loss: 0.2722 - binary_accuracy: 0.8850 - sensitivity: 0.9342 - specificity: 0.7765 - gmeasure: 0.8509 - auc: 0.9490 - val_loss: 0.2938 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9331
Epoch 89/100
600/600 [==============================] - 0s 69us/step - loss: 0.2690 - binary_accuracy: 0.8850 - sensitivity: 0.9225 - specificity: 0.8002 - gmeasure: 0.8583 - auc: 0.9486 - val_loss: 0.2916 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9333
Epoch 90/100
600/600 [==============================] - 0s 65us/step - loss: 0.2696 - binary_accuracy: 0.8833 - sensitivity: 0.9325 - specificity: 0.7728 - gmeasure: 0.8472 - auc: 0.9525 - val_loss: 0.2914 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9340
Epoch 91/100
600/600 [==============================] - 0s 63us/step - loss: 0.2668 - binary_accuracy: 0.8867 - sensitivity: 0.9347 - specificity: 0.7823 - gmeasure: 0.8548 - auc: 0.9502 - val_loss: 0.2902 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9329
Epoch 92/100
600/600 [==============================] - 0s 68us/step - loss: 0.2662 - binary_accuracy: 0.8850 - sensitivity: 0.9324 - specificity: 0.7790 - gmeasure: 0.8519 - auc: 0.9494 - val_loss: 0.2932 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9327
Epoch 93/100
600/600 [==============================] - 0s 71us/step - loss: 0.2661 - binary_accuracy: 0.8850 - sensitivity: 0.9273 - specificity: 0.7941 - gmeasure: 0.8573 - auc: 0.9490 - val_loss: 0.2917 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8952 - val_specificity: 0.8667 - val_gmeasure: 0.8808 - val_auc: 0.9333
Epoch 94/100
600/600 [==============================] - 0s 68us/step - loss: 0.2650 - binary_accuracy: 0.8867 - sensitivity: 0.9211 - specificity: 0.8122 - gmeasure: 0.8649 - auc: 0.9512 - val_loss: 0.2894 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9335
Epoch 95/100
600/600 [==============================] - 0s 70us/step - loss: 0.2657 - binary_accuracy: 0.8850 - sensitivity: 0.9362 - specificity: 0.7670 - gmeasure: 0.8470 - auc: 0.9516 - val_loss: 0.2879 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9338
Epoch 96/100
600/600 [==============================] - 0s 77us/step - loss: 0.2621 - binary_accuracy: 0.8900 - sensitivity: 0.9274 - specificity: 0.8024 - gmeasure: 0.8621 - auc: 0.9504 - val_loss: 0.2961 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8667 - val_specificity: 0.8889 - val_gmeasure: 0.8777 - val_auc: 0.9335
Epoch 97/100
600/600 [==============================] - 0s 68us/step - loss: 0.2632 - binary_accuracy: 0.8867 - sensitivity: 0.9177 - specificity: 0.8184 - gmeasure: 0.8666 - auc: 0.9510 - val_loss: 0.2869 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9344
Epoch 98/100
600/600 [==============================] - 0s 67us/step - loss: 0.2661 - binary_accuracy: 0.8817 - sensitivity: 0.9368 - specificity: 0.7626 - gmeasure: 0.8450 - auc: 0.9505 - val_loss: 0.2898 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9348
Epoch 99/100
600/600 [==============================] - ETA: 0s - loss: 0.2269 - binary_accuracy: 0.9200 - sensitivity: 0.9424 - specificity: 0.8689 - gmeasure: 0.9049 - auc: 0.96 - 0s 68us/step - loss: 0.2658 - binary_accuracy: 0.8967 - sensitivity: 0.9005 - specificity: 0.8876 - gmeasure: 0.8937 - auc: 0.9522 - val_loss: 0.2922 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9337
Epoch 100/100
600/600 [==============================] - 0s 62us/step - loss: 0.2647 - binary_accuracy: 0.8850 - sensitivity: 0.9303 - specificity: 0.7891 - gmeasure: 0.8550 - auc: 0.9525 - val_loss: 0.2868 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9143 - val_specificity: 0.8000 - val_gmeasure: 0.8552 - val_auc: 0.9346
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 6.324186563491821!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.014736413955688477!
[root    |INFO|build_network.py:183] Evaluation: [0.2681126594543457, 0.8786666393280029, 0.9343629479408264, 0.7543103694915771, 0.8395234942436218, 0.9488583207130432]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 20us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.012296676635742188!
[root    |INFO|build_network.py:183] Evaluation: [0.2787688076496124, 0.8759999871253967, 0.9585798978805542, 0.7037037014961243, 0.8213136792182922, 0.9507268667221069]
[root    |INFO|deepbiome.py:179] Compute time : 8.100970029830933
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 776us/step - loss: 0.1934 - binary_accuracy: 0.9283 - sensitivity: 0.9886 - specificity: 0.7692 - gmeasure: 0.8714 - auc: 0.9791 - val_loss: 0.2795 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9541 - val_specificity: 0.7561 - val_gmeasure: 0.8494 - val_auc: 0.9403
Epoch 2/100
600/600 [==============================] - 0s 67us/step - loss: 0.1960 - binary_accuracy: 0.9350 - sensitivity: 0.9378 - specificity: 0.9263 - gmeasure: 0.9319 - auc: 0.9784 - val_loss: 0.2953 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9389
Epoch 3/100
600/600 [==============================] - 0s 59us/step - loss: 0.1838 - binary_accuracy: 0.9200 - sensitivity: 0.9860 - specificity: 0.7399 - gmeasure: 0.8531 - auc: 0.9789 - val_loss: 0.3213 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9817 - val_specificity: 0.6341 - val_gmeasure: 0.7890 - val_auc: 0.9387
Epoch 4/100
600/600 [==============================] - 0s 59us/step - loss: 0.1841 - binary_accuracy: 0.9267 - sensitivity: 0.9886 - specificity: 0.7627 - gmeasure: 0.8669 - auc: 0.9789 - val_loss: 0.2810 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9403
Epoch 5/100
600/600 [==============================] - 0s 64us/step - loss: 0.1819 - binary_accuracy: 0.9483 - sensitivity: 0.9725 - specificity: 0.8844 - gmeasure: 0.9274 - auc: 0.9807 - val_loss: 0.2850 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9403
Epoch 6/100
600/600 [==============================] - 0s 61us/step - loss: 0.1795 - binary_accuracy: 0.9350 - sensitivity: 0.9772 - specificity: 0.8229 - gmeasure: 0.8958 - auc: 0.9794 - val_loss: 0.3089 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9725 - val_specificity: 0.6585 - val_gmeasure: 0.8003 - val_auc: 0.9403
Epoch 7/100
600/600 [==============================] - 0s 59us/step - loss: 0.1787 - binary_accuracy: 0.9217 - sensitivity: 0.9840 - specificity: 0.7521 - gmeasure: 0.8591 - auc: 0.9803 - val_loss: 0.2835 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9414
Epoch 8/100
600/600 [==============================] - 0s 65us/step - loss: 0.1755 - binary_accuracy: 0.9433 - sensitivity: 0.9749 - specificity: 0.8587 - gmeasure: 0.9148 - auc: 0.9814 - val_loss: 0.2803 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9414
Epoch 9/100
600/600 [==============================] - 0s 62us/step - loss: 0.1752 - binary_accuracy: 0.9367 - sensitivity: 0.9746 - specificity: 0.8369 - gmeasure: 0.9030 - auc: 0.9815 - val_loss: 0.2911 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9633 - val_specificity: 0.6829 - val_gmeasure: 0.8111 - val_auc: 0.9420
Epoch 10/100
600/600 [==============================] - 0s 69us/step - loss: 0.1764 - binary_accuracy: 0.9300 - sensitivity: 0.9842 - specificity: 0.7870 - gmeasure: 0.8799 - auc: 0.9819 - val_loss: 0.2892 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9423
Epoch 11/100
600/600 [==============================] - 0s 68us/step - loss: 0.1720 - binary_accuracy: 0.9417 - sensitivity: 0.9765 - specificity: 0.8434 - gmeasure: 0.9071 - auc: 0.9810 - val_loss: 0.2762 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9434
Epoch 12/100
600/600 [==============================] - 0s 69us/step - loss: 0.1735 - binary_accuracy: 0.9450 - sensitivity: 0.9749 - specificity: 0.8623 - gmeasure: 0.9164 - auc: 0.9786 - val_loss: 0.2845 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9436
Epoch 13/100
600/600 [==============================] - 0s 68us/step - loss: 0.1712 - binary_accuracy: 0.9400 - sensitivity: 0.9817 - specificity: 0.8289 - gmeasure: 0.9020 - auc: 0.9825 - val_loss: 0.2879 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9633 - val_specificity: 0.6829 - val_gmeasure: 0.8111 - val_auc: 0.9438
Epoch 14/100
600/600 [==============================] - 0s 70us/step - loss: 0.1703 - binary_accuracy: 0.9400 - sensitivity: 0.9819 - specificity: 0.8273 - gmeasure: 0.9013 - auc: 0.9825 - val_loss: 0.2827 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438
Epoch 15/100
600/600 [==============================] - 0s 71us/step - loss: 0.1698 - binary_accuracy: 0.9367 - sensitivity: 0.9748 - specificity: 0.8359 - gmeasure: 0.9026 - auc: 0.9825 - val_loss: 0.2786 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438
Epoch 16/100
600/600 [==============================] - 0s 70us/step - loss: 0.1699 - binary_accuracy: 0.9350 - sensitivity: 0.9772 - specificity: 0.8221 - gmeasure: 0.8958 - auc: 0.9826 - val_loss: 0.2841 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438
Epoch 17/100
600/600 [==============================] - 0s 72us/step - loss: 0.1669 - binary_accuracy: 0.9367 - sensitivity: 0.9772 - specificity: 0.8261 - gmeasure: 0.8983 - auc: 0.9818 - val_loss: 0.2766 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9454
Epoch 18/100
600/600 [==============================] - 0s 68us/step - loss: 0.1666 - binary_accuracy: 0.9417 - sensitivity: 0.9749 - specificity: 0.8496 - gmeasure: 0.9099 - auc: 0.9821 - val_loss: 0.2791 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9463
Epoch 19/100
600/600 [==============================] - 0s 75us/step - loss: 0.1671 - binary_accuracy: 0.9400 - sensitivity: 0.9778 - specificity: 0.8432 - gmeasure: 0.9079 - auc: 0.9838 - val_loss: 0.2791 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9467
Epoch 20/100
600/600 [==============================] - 0s 72us/step - loss: 0.1645 - binary_accuracy: 0.9383 - sensitivity: 0.9772 - specificity: 0.8347 - gmeasure: 0.9031 - auc: 0.9821 - val_loss: 0.2854 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9458
Epoch 21/100
600/600 [==============================] - 0s 69us/step - loss: 0.1662 - binary_accuracy: 0.9383 - sensitivity: 0.9801 - specificity: 0.8293 - gmeasure: 0.9015 - auc: 0.9824 - val_loss: 0.2750 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9465
Epoch 22/100
600/600 [==============================] - 0s 67us/step - loss: 0.1630 - binary_accuracy: 0.9500 - sensitivity: 0.9747 - specificity: 0.8788 - gmeasure: 0.9253 - auc: 0.9833 - val_loss: 0.2795 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9467
Epoch 23/100
600/600 [==============================] - 0s 66us/step - loss: 0.1622 - binary_accuracy: 0.9417 - sensitivity: 0.9818 - specificity: 0.8271 - gmeasure: 0.9003 - auc: 0.9820 - val_loss: 0.2842 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9474
Epoch 24/100
600/600 [==============================] - 0s 69us/step - loss: 0.1609 - binary_accuracy: 0.9467 - sensitivity: 0.9789 - specificity: 0.8614 - gmeasure: 0.9183 - auc: 0.9843 - val_loss: 0.2722 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9483
Epoch 25/100
600/600 [==============================] - 0s 73us/step - loss: 0.1607 - binary_accuracy: 0.9467 - sensitivity: 0.9774 - specificity: 0.8655 - gmeasure: 0.9196 - auc: 0.9841 - val_loss: 0.2813 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9479
Epoch 26/100
600/600 [==============================] - 0s 83us/step - loss: 0.1597 - binary_accuracy: 0.9400 - sensitivity: 0.9770 - specificity: 0.8413 - gmeasure: 0.9062 - auc: 0.9837 - val_loss: 0.2759 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9488
Epoch 27/100
600/600 [==============================] - 0s 71us/step - loss: 0.1594 - binary_accuracy: 0.9450 - sensitivity: 0.9748 - specificity: 0.8652 - gmeasure: 0.9182 - auc: 0.9841 - val_loss: 0.2703 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9497
Epoch 28/100
600/600 [==============================] - 0s 62us/step - loss: 0.1582 - binary_accuracy: 0.9450 - sensitivity: 0.9749 - specificity: 0.8696 - gmeasure: 0.9204 - auc: 0.9853 - val_loss: 0.2787 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9499
Epoch 29/100
600/600 [==============================] - 0s 61us/step - loss: 0.1568 - binary_accuracy: 0.9417 - sensitivity: 0.9795 - specificity: 0.8393 - gmeasure: 0.9065 - auc: 0.9839 - val_loss: 0.2750 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9497
Epoch 30/100
600/600 [==============================] - 0s 71us/step - loss: 0.1551 - binary_accuracy: 0.9467 - sensitivity: 0.9757 - specificity: 0.8648 - gmeasure: 0.9185 - auc: 0.9862 - val_loss: 0.2679 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9505
Epoch 31/100
600/600 [==============================] - 0s 74us/step - loss: 0.1549 - binary_accuracy: 0.9517 - sensitivity: 0.9726 - specificity: 0.8931 - gmeasure: 0.9318 - auc: 0.9846 - val_loss: 0.2760 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9503
Epoch 32/100
600/600 [==============================] - 0s 66us/step - loss: 0.1536 - binary_accuracy: 0.9433 - sensitivity: 0.9796 - specificity: 0.8452 - gmeasure: 0.9099 - auc: 0.9850 - val_loss: 0.2781 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9508
Epoch 33/100
600/600 [==============================] - 0s 65us/step - loss: 0.1546 - binary_accuracy: 0.9467 - sensitivity: 0.9772 - specificity: 0.8660 - gmeasure: 0.9198 - auc: 0.9845 - val_loss: 0.2668 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9517
Epoch 34/100
600/600 [==============================] - 0s 65us/step - loss: 0.1516 - binary_accuracy: 0.9550 - sensitivity: 0.9794 - specificity: 0.8846 - gmeasure: 0.9302 - auc: 0.9869 - val_loss: 0.2767 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9510
Epoch 35/100
600/600 [==============================] - 0s 68us/step - loss: 0.1543 - binary_accuracy: 0.9433 - sensitivity: 0.9814 - specificity: 0.8438 - gmeasure: 0.9097 - auc: 0.9865 - val_loss: 0.2711 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9521
Epoch 36/100
600/600 [==============================] - 0s 67us/step - loss: 0.1502 - binary_accuracy: 0.9517 - sensitivity: 0.9770 - specificity: 0.8874 - gmeasure: 0.9309 - auc: 0.9855 - val_loss: 0.2612 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9535
Epoch 37/100
600/600 [==============================] - 0s 74us/step - loss: 0.1496 - binary_accuracy: 0.9567 - sensitivity: 0.9796 - specificity: 0.8870 - gmeasure: 0.9317 - auc: 0.9855 - val_loss: 0.2788 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9725 - val_specificity: 0.7073 - val_gmeasure: 0.8294 - val_auc: 0.9526
Epoch 38/100
600/600 [==============================] - 0s 74us/step - loss: 0.1503 - binary_accuracy: 0.9450 - sensitivity: 0.9822 - specificity: 0.8434 - gmeasure: 0.9101 - auc: 0.9854 - val_loss: 0.2736 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9532
Epoch 39/100
600/600 [==============================] - 0s 70us/step - loss: 0.1473 - binary_accuracy: 0.9550 - sensitivity: 0.9814 - specificity: 0.8816 - gmeasure: 0.9296 - auc: 0.9852 - val_loss: 0.2570 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9633 - val_specificity: 0.7561 - val_gmeasure: 0.8534 - val_auc: 0.9535
Epoch 40/100
600/600 [==============================] - 0s 63us/step - loss: 0.1531 - binary_accuracy: 0.9467 - sensitivity: 0.9791 - specificity: 0.8593 - gmeasure: 0.9160 - auc: 0.9874 - val_loss: 0.2768 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9523
Epoch 41/100
600/600 [==============================] - 0s 67us/step - loss: 0.1487 - binary_accuracy: 0.9467 - sensitivity: 0.9723 - specificity: 0.8782 - gmeasure: 0.9237 - auc: 0.9879 - val_loss: 0.2581 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9539
Epoch 42/100
600/600 [==============================] - 0s 67us/step - loss: 0.1512 - binary_accuracy: 0.9467 - sensitivity: 0.9749 - specificity: 0.8771 - gmeasure: 0.9244 - auc: 0.9881 - val_loss: 0.2732 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9530
Epoch 43/100
600/600 [==============================] - 0s 69us/step - loss: 0.1427 - binary_accuracy: 0.9467 - sensitivity: 0.9763 - specificity: 0.8665 - gmeasure: 0.9197 - auc: 0.9859 - val_loss: 0.2518 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9550
Epoch 44/100
600/600 [==============================] - 0s 66us/step - loss: 0.1461 - binary_accuracy: 0.9533 - sensitivity: 0.9678 - specificity: 0.9129 - gmeasure: 0.9398 - auc: 0.9874 - val_loss: 0.2635 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9546
Epoch 45/100
600/600 [==============================] - 0s 66us/step - loss: 0.1467 - binary_accuracy: 0.9500 - sensitivity: 0.9856 - specificity: 0.8507 - gmeasure: 0.9144 - auc: 0.9858 - val_loss: 0.2750 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9817 - val_specificity: 0.7073 - val_gmeasure: 0.8333 - val_auc: 0.9537
Epoch 46/100
600/600 [==============================] - 0s 68us/step - loss: 0.1435 - binary_accuracy: 0.9517 - sensitivity: 0.9796 - specificity: 0.8668 - gmeasure: 0.9206 - auc: 0.9856 - val_loss: 0.2456 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9561
Epoch 47/100
600/600 [==============================] - 0s 69us/step - loss: 0.1449 - binary_accuracy: 0.9500 - sensitivity: 0.9625 - specificity: 0.9125 - gmeasure: 0.9370 - auc: 0.9878 - val_loss: 0.2740 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9817 - val_specificity: 0.7073 - val_gmeasure: 0.8333 - val_auc: 0.9544
Epoch 48/100
600/600 [==============================] - 0s 65us/step - loss: 0.1426 - binary_accuracy: 0.9450 - sensitivity: 0.9862 - specificity: 0.8330 - gmeasure: 0.9061 - auc: 0.9869 - val_loss: 0.2589 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9559
Epoch 49/100
600/600 [==============================] - 0s 66us/step - loss: 0.1390 - binary_accuracy: 0.9600 - sensitivity: 0.9781 - specificity: 0.9164 - gmeasure: 0.9464 - auc: 0.9880 - val_loss: 0.2492 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9570
Epoch 50/100
600/600 [==============================] - 0s 67us/step - loss: 0.1401 - binary_accuracy: 0.9483 - sensitivity: 0.9793 - specificity: 0.8655 - gmeasure: 0.9206 - auc: 0.9870 - val_loss: 0.2672 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9561
Epoch 51/100
600/600 [==============================] - 0s 70us/step - loss: 0.1361 - binary_accuracy: 0.9550 - sensitivity: 0.9841 - specificity: 0.8817 - gmeasure: 0.9309 - auc: 0.9883 - val_loss: 0.2478 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9575
Epoch 52/100
600/600 [==============================] - 0s 68us/step - loss: 0.1368 - binary_accuracy: 0.9600 - sensitivity: 0.9746 - specificity: 0.9152 - gmeasure: 0.9442 - auc: 0.9895 - val_loss: 0.2476 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9579
Epoch 53/100
600/600 [==============================] - 0s 72us/step - loss: 0.1363 - binary_accuracy: 0.9583 - sensitivity: 0.9864 - specificity: 0.8849 - gmeasure: 0.9340 - auc: 0.9876 - val_loss: 0.2665 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9573
Epoch 54/100
600/600 [==============================] - 0s 72us/step - loss: 0.1336 - binary_accuracy: 0.9550 - sensitivity: 0.9863 - specificity: 0.8702 - gmeasure: 0.9263 - auc: 0.9877 - val_loss: 0.2429 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586
Epoch 55/100
600/600 [==============================] - 0s 71us/step - loss: 0.1346 - binary_accuracy: 0.9633 - sensitivity: 0.9722 - specificity: 0.9385 - gmeasure: 0.9551 - auc: 0.9883 - val_loss: 0.2508 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586
Epoch 56/100
600/600 [==============================] - 0s 72us/step - loss: 0.1339 - binary_accuracy: 0.9550 - sensitivity: 0.9864 - specificity: 0.8719 - gmeasure: 0.9269 - auc: 0.9889 - val_loss: 0.2592 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9575
Epoch 57/100
600/600 [==============================] - 0s 70us/step - loss: 0.1304 - binary_accuracy: 0.9600 - sensitivity: 0.9864 - specificity: 0.8903 - gmeasure: 0.9367 - auc: 0.9894 - val_loss: 0.2392 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9584
Epoch 58/100
600/600 [==============================] - 0s 69us/step - loss: 0.1315 - binary_accuracy: 0.9633 - sensitivity: 0.9748 - specificity: 0.9333 - gmeasure: 0.9537 - auc: 0.9893 - val_loss: 0.2513 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9582
Epoch 59/100
600/600 [==============================] - 0s 70us/step - loss: 0.1319 - binary_accuracy: 0.9583 - sensitivity: 0.9863 - specificity: 0.8844 - gmeasure: 0.9338 - auc: 0.9891 - val_loss: 0.2540 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9579
Epoch 60/100
600/600 [==============================] - 0s 71us/step - loss: 0.1273 - binary_accuracy: 0.9600 - sensitivity: 0.9814 - specificity: 0.9007 - gmeasure: 0.9401 - auc: 0.9895 - val_loss: 0.2390 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586
Epoch 61/100
600/600 [==============================] - 0s 67us/step - loss: 0.1295 - binary_accuracy: 0.9617 - sensitivity: 0.9819 - specificity: 0.9118 - gmeasure: 0.9450 - auc: 0.9893 - val_loss: 0.2518 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9584
Epoch 62/100
600/600 [==============================] - 0s 68us/step - loss: 0.1268 - binary_accuracy: 0.9600 - sensitivity: 0.9840 - specificity: 0.8955 - gmeasure: 0.9384 - auc: 0.9889 - val_loss: 0.2437 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586
Epoch 63/100
600/600 [==============================] - 0s 68us/step - loss: 0.1260 - binary_accuracy: 0.9633 - sensitivity: 0.9840 - specificity: 0.9072 - gmeasure: 0.9445 - auc: 0.9891 - val_loss: 0.2449 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9588
Epoch 64/100
600/600 [==============================] - 0s 63us/step - loss: 0.1256 - binary_accuracy: 0.9600 - sensitivity: 0.9839 - specificity: 0.9024 - gmeasure: 0.9418 - auc: 0.9894 - val_loss: 0.2421 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9591
Epoch 65/100
600/600 [==============================] - 0s 58us/step - loss: 0.1254 - binary_accuracy: 0.9617 - sensitivity: 0.9864 - specificity: 0.8983 - gmeasure: 0.9409 - auc: 0.9901 - val_loss: 0.2447 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9591
Epoch 66/100
600/600 [==============================] - 0s 69us/step - loss: 0.1229 - binary_accuracy: 0.9600 - sensitivity: 0.9793 - specificity: 0.9110 - gmeasure: 0.9444 - auc: 0.9898 - val_loss: 0.2375 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9593
Epoch 67/100
600/600 [==============================] - 0s 68us/step - loss: 0.1227 - binary_accuracy: 0.9683 - sensitivity: 0.9794 - specificity: 0.9377 - gmeasure: 0.9583 - auc: 0.9897 - val_loss: 0.2462 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9593
Epoch 68/100
600/600 [==============================] - 0s 62us/step - loss: 0.1240 - binary_accuracy: 0.9600 - sensitivity: 0.9865 - specificity: 0.8930 - gmeasure: 0.9382 - auc: 0.9899 - val_loss: 0.2423 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9593
Epoch 69/100
600/600 [==============================] - 0s 67us/step - loss: 0.1206 - binary_accuracy: 0.9667 - sensitivity: 0.9816 - specificity: 0.9274 - gmeasure: 0.9540 - auc: 0.9897 - val_loss: 0.2347 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9599
Epoch 70/100
600/600 [==============================] - 0s 71us/step - loss: 0.1208 - binary_accuracy: 0.9683 - sensitivity: 0.9795 - specificity: 0.9417 - gmeasure: 0.9603 - auc: 0.9897 - val_loss: 0.2439 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9599
Epoch 71/100
600/600 [==============================] - 0s 69us/step - loss: 0.1252 - binary_accuracy: 0.9550 - sensitivity: 0.9865 - specificity: 0.8785 - gmeasure: 0.9304 - auc: 0.9907 - val_loss: 0.2431 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9599
Epoch 72/100
600/600 [==============================] - 0s 67us/step - loss: 0.1220 - binary_accuracy: 0.9633 - sensitivity: 0.9749 - specificity: 0.9338 - gmeasure: 0.9540 - auc: 0.9905 - val_loss: 0.2312 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9602
Epoch 73/100
600/600 [==============================] - 0s 62us/step - loss: 0.1204 - binary_accuracy: 0.9617 - sensitivity: 0.9794 - specificity: 0.9148 - gmeasure: 0.9462 - auc: 0.9903 - val_loss: 0.2503 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9597
Epoch 74/100
600/600 [==============================] - 0s 69us/step - loss: 0.1176 - binary_accuracy: 0.9650 - sensitivity: 0.9885 - specificity: 0.9019 - gmeasure: 0.9441 - auc: 0.9900 - val_loss: 0.2335 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9599
Epoch 75/100
600/600 [==============================] - 0s 68us/step - loss: 0.1202 - binary_accuracy: 0.9650 - sensitivity: 0.9746 - specificity: 0.9387 - gmeasure: 0.9565 - auc: 0.9900 - val_loss: 0.2382 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602
Epoch 76/100
600/600 [==============================] - 0s 68us/step - loss: 0.1248 - binary_accuracy: 0.9617 - sensitivity: 0.9909 - specificity: 0.8839 - gmeasure: 0.9355 - auc: 0.9907 - val_loss: 0.2476 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602
Epoch 77/100
600/600 [==============================] - 0s 68us/step - loss: 0.1237 - binary_accuracy: 0.9617 - sensitivity: 0.9710 - specificity: 0.9383 - gmeasure: 0.9539 - auc: 0.9908 - val_loss: 0.2245 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9611
Epoch 78/100
600/600 [==============================] - 0s 65us/step - loss: 0.1163 - binary_accuracy: 0.9683 - sensitivity: 0.9822 - specificity: 0.9322 - gmeasure: 0.9568 - auc: 0.9903 - val_loss: 0.2657 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9595
Epoch 79/100
600/600 [==============================] - 0s 68us/step - loss: 0.1260 - binary_accuracy: 0.9583 - sensitivity: 0.9953 - specificity: 0.8647 - gmeasure: 0.9266 - auc: 0.9915 - val_loss: 0.2325 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602
Epoch 80/100
600/600 [==============================] - 0s 70us/step - loss: 0.1280 - binary_accuracy: 0.9567 - sensitivity: 0.9587 - specificity: 0.9502 - gmeasure: 0.9542 - auc: 0.9904 - val_loss: 0.2232 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9613
Epoch 81/100
600/600 [==============================] - 0s 69us/step - loss: 0.1224 - binary_accuracy: 0.9583 - sensitivity: 0.9841 - specificity: 0.8913 - gmeasure: 0.9362 - auc: 0.9908 - val_loss: 0.2714 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9595
Epoch 82/100
600/600 [==============================] - 0s 65us/step - loss: 0.1171 - binary_accuracy: 0.9683 - sensitivity: 0.9933 - specificity: 0.9041 - gmeasure: 0.9475 - auc: 0.9917 - val_loss: 0.2228 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9725 - val_specificity: 0.8293 - val_gmeasure: 0.8980 - val_auc: 0.9620
Epoch 83/100
600/600 [==============================] - 0s 70us/step - loss: 0.1203 - binary_accuracy: 0.9633 - sensitivity: 0.9634 - specificity: 0.9622 - gmeasure: 0.9628 - auc: 0.9909 - val_loss: 0.2275 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9617
Epoch 84/100
600/600 [==============================] - 0s 70us/step - loss: 0.1166 - binary_accuracy: 0.9617 - sensitivity: 0.9886 - specificity: 0.8876 - gmeasure: 0.9360 - auc: 0.9914 - val_loss: 0.2597 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9613
Epoch 85/100
600/600 [==============================] - 0s 71us/step - loss: 0.1147 - binary_accuracy: 0.9683 - sensitivity: 0.9886 - specificity: 0.9138 - gmeasure: 0.9502 - auc: 0.9910 - val_loss: 0.2221 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9725 - val_specificity: 0.8293 - val_gmeasure: 0.8980 - val_auc: 0.9622
Epoch 86/100
600/600 [==============================] - 0s 68us/step - loss: 0.1145 - binary_accuracy: 0.9717 - sensitivity: 0.9817 - specificity: 0.9455 - gmeasure: 0.9632 - auc: 0.9910 - val_loss: 0.2378 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9617
Epoch 87/100
600/600 [==============================] - 0s 70us/step - loss: 0.1100 - binary_accuracy: 0.9683 - sensitivity: 0.9887 - specificity: 0.9168 - gmeasure: 0.9520 - auc: 0.9901 - val_loss: 0.2325 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620
Epoch 88/100
600/600 [==============================] - 0s 69us/step - loss: 0.1092 - binary_accuracy: 0.9700 - sensitivity: 0.9793 - specificity: 0.9458 - gmeasure: 0.9624 - auc: 0.9914 - val_loss: 0.2246 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9626
Epoch 89/100
600/600 [==============================] - 0s 69us/step - loss: 0.1085 - binary_accuracy: 0.9750 - sensitivity: 0.9861 - specificity: 0.9445 - gmeasure: 0.9651 - auc: 0.9914 - val_loss: 0.2365 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9622
Epoch 90/100
600/600 [==============================] - 0s 69us/step - loss: 0.1081 - binary_accuracy: 0.9750 - sensitivity: 0.9919 - specificity: 0.9301 - gmeasure: 0.9605 - auc: 0.9920 - val_loss: 0.2343 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620
Epoch 91/100
600/600 [==============================] - 0s 63us/step - loss: 0.1070 - binary_accuracy: 0.9733 - sensitivity: 0.9886 - specificity: 0.9319 - gmeasure: 0.9598 - auc: 0.9914 - val_loss: 0.2317 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620
Epoch 92/100
600/600 [==============================] - 0s 69us/step - loss: 0.1066 - binary_accuracy: 0.9717 - sensitivity: 0.9857 - specificity: 0.9397 - gmeasure: 0.9623 - auc: 0.9910 - val_loss: 0.2289 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9624
Epoch 93/100
600/600 [==============================] - 0s 58us/step - loss: 0.1057 - binary_accuracy: 0.9717 - sensitivity: 0.9865 - specificity: 0.9304 - gmeasure: 0.9578 - auc: 0.9914 - val_loss: 0.2312 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9622
Epoch 94/100
600/600 [==============================] - 0s 66us/step - loss: 0.1056 - binary_accuracy: 0.9717 - sensitivity: 0.9863 - specificity: 0.9336 - gmeasure: 0.9594 - auc: 0.9925 - val_loss: 0.2324 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9629
Epoch 95/100
600/600 [==============================] - 0s 67us/step - loss: 0.1069 - binary_accuracy: 0.9683 - sensitivity: 0.9909 - specificity: 0.9101 - gmeasure: 0.9493 - auc: 0.9916 - val_loss: 0.2317 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9626
Epoch 96/100
600/600 [==============================] - 0s 68us/step - loss: 0.1040 - binary_accuracy: 0.9733 - sensitivity: 0.9864 - specificity: 0.9402 - gmeasure: 0.9628 - auc: 0.9921 - val_loss: 0.2238 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9631
Epoch 97/100
600/600 [==============================] - 0s 61us/step - loss: 0.1049 - binary_accuracy: 0.9733 - sensitivity: 0.9862 - specificity: 0.9389 - gmeasure: 0.9623 - auc: 0.9915 - val_loss: 0.2334 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9629
Epoch 98/100
600/600 [==============================] - 0s 67us/step - loss: 0.1039 - binary_accuracy: 0.9700 - sensitivity: 0.9840 - specificity: 0.9327 - gmeasure: 0.9579 - auc: 0.9923 - val_loss: 0.2266 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9633
Epoch 99/100
600/600 [==============================] - 0s 65us/step - loss: 0.1027 - binary_accuracy: 0.9717 - sensitivity: 0.9863 - specificity: 0.9302 - gmeasure: 0.9577 - auc: 0.9919 - val_loss: 0.2338 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9633
Epoch 100/100
600/600 [==============================] - 0s 66us/step - loss: 0.1036 - binary_accuracy: 0.9750 - sensitivity: 0.9862 - specificity: 0.9423 - gmeasure: 0.9636 - auc: 0.9921 - val_loss: 0.2230 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9635
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 6.270015716552734!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.014514684677124023!
[root    |INFO|build_network.py:183] Evaluation: [0.12617357075214386, 0.9653333425521851, 0.9853479862213135, 0.9117646813392639, 0.947842538356781, 0.985859751701355]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 23us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.012951135635375977!
[root    |INFO|build_network.py:183] Evaluation: [0.2848759889602661, 0.9079999923706055, 0.959770143032074, 0.7894737124443054, 0.8704673051834106, 0.9521324634552002]
[root    |INFO|deepbiome.py:179] Compute time : 8.087581872940063
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 760us/step - loss: 0.2191 - binary_accuracy: 0.9033 - sensitivity: 0.9142 - specificity: 0.8903 - gmeasure: 0.9003 - auc: 0.9679 - val_loss: 0.2551 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9286 - val_specificity: 0.8462 - val_gmeasure: 0.8864 - val_auc: 0.9628
Epoch 2/100
600/600 [==============================] - 0s 66us/step - loss: 0.2087 - binary_accuracy: 0.9217 - sensitivity: 0.9017 - specificity: 0.9673 - gmeasure: 0.9334 - auc: 0.9702 - val_loss: 0.2460 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9082 - val_specificity: 0.8846 - val_gmeasure: 0.8963 - val_auc: 0.9625
Epoch 3/100
600/600 [==============================] - 0s 66us/step - loss: 0.2047 - binary_accuracy: 0.9183 - sensitivity: 0.9121 - specificity: 0.9312 - gmeasure: 0.9212 - auc: 0.9650 - val_loss: 0.2914 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9623
Epoch 4/100
600/600 [==============================] - 0s 68us/step - loss: 0.1999 - binary_accuracy: 0.9133 - sensitivity: 0.9199 - specificity: 0.8990 - gmeasure: 0.9094 - auc: 0.9646 - val_loss: 0.2553 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9657
Epoch 5/100
600/600 [==============================] - 0s 80us/step - loss: 0.1950 - binary_accuracy: 0.9217 - sensitivity: 0.9132 - specificity: 0.9387 - gmeasure: 0.9258 - auc: 0.9690 - val_loss: 0.2467 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9286 - val_specificity: 0.8462 - val_gmeasure: 0.8864 - val_auc: 0.9657
Epoch 6/100
600/600 [==============================] - 0s 67us/step - loss: 0.2000 - binary_accuracy: 0.9183 - sensitivity: 0.9081 - specificity: 0.9430 - gmeasure: 0.9247 - auc: 0.9706 - val_loss: 0.2754 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9388 - val_specificity: 0.7115 - val_gmeasure: 0.8173 - val_auc: 0.9645
Epoch 7/100
600/600 [==============================] - 0s 66us/step - loss: 0.1930 - binary_accuracy: 0.9250 - sensitivity: 0.9326 - specificity: 0.9080 - gmeasure: 0.9202 - auc: 0.9669 - val_loss: 0.2578 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9659
Epoch 8/100
600/600 [==============================] - 0s 70us/step - loss: 0.1955 - binary_accuracy: 0.9233 - sensitivity: 0.9110 - specificity: 0.9523 - gmeasure: 0.9312 - auc: 0.9704 - val_loss: 0.2451 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9184 - val_specificity: 0.8846 - val_gmeasure: 0.9013 - val_auc: 0.9645
Epoch 9/100
600/600 [==============================] - 0s 70us/step - loss: 0.1921 - binary_accuracy: 0.9250 - sensitivity: 0.9156 - specificity: 0.9460 - gmeasure: 0.9306 - auc: 0.9675 - val_loss: 0.2712 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9657
Epoch 10/100
600/600 [==============================] - 0s 69us/step - loss: 0.1911 - binary_accuracy: 0.9200 - sensitivity: 0.9178 - specificity: 0.9244 - gmeasure: 0.9210 - auc: 0.9680 - val_loss: 0.2588 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9661
Epoch 11/100
600/600 [==============================] - 0s 64us/step - loss: 0.1886 - binary_accuracy: 0.9233 - sensitivity: 0.9139 - specificity: 0.9465 - gmeasure: 0.9300 - auc: 0.9712 - val_loss: 0.2521 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9664
Epoch 12/100
600/600 [==============================] - 0s 72us/step - loss: 0.1869 - binary_accuracy: 0.9250 - sensitivity: 0.9225 - specificity: 0.9301 - gmeasure: 0.9263 - auc: 0.9698 - val_loss: 0.2663 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9661
Epoch 13/100
600/600 [==============================] - 0s 70us/step - loss: 0.1878 - binary_accuracy: 0.9267 - sensitivity: 0.9275 - specificity: 0.9262 - gmeasure: 0.9262 - auc: 0.9685 - val_loss: 0.2536 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9666
Epoch 14/100
600/600 [==============================] - 0s 72us/step - loss: 0.1862 - binary_accuracy: 0.9250 - sensitivity: 0.9139 - specificity: 0.9527 - gmeasure: 0.9330 - auc: 0.9720 - val_loss: 0.2521 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9670
Epoch 15/100
600/600 [==============================] - 0s 67us/step - loss: 0.1843 - binary_accuracy: 0.9233 - sensitivity: 0.9152 - specificity: 0.9422 - gmeasure: 0.9285 - auc: 0.9705 - val_loss: 0.2632 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9388 - val_specificity: 0.7692 - val_gmeasure: 0.8498 - val_auc: 0.9670
Epoch 16/100
600/600 [==============================] - 0s 67us/step - loss: 0.1847 - binary_accuracy: 0.9250 - sensitivity: 0.9205 - specificity: 0.9346 - gmeasure: 0.9274 - auc: 0.9698 - val_loss: 0.2559 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9670
Epoch 17/100
600/600 [==============================] - 0s 66us/step - loss: 0.1826 - binary_accuracy: 0.9300 - sensitivity: 0.9226 - specificity: 0.9441 - gmeasure: 0.9331 - auc: 0.9709 - val_loss: 0.2539 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9672
Epoch 18/100
600/600 [==============================] - 0s 66us/step - loss: 0.1824 - binary_accuracy: 0.9267 - sensitivity: 0.9157 - specificity: 0.9522 - gmeasure: 0.9336 - auc: 0.9713 - val_loss: 0.2603 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9676
Epoch 19/100
600/600 [==============================] - 0s 61us/step - loss: 0.1813 - binary_accuracy: 0.9300 - sensitivity: 0.9281 - specificity: 0.9345 - gmeasure: 0.9310 - auc: 0.9706 - val_loss: 0.2541 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9676
Epoch 20/100
600/600 [==============================] - 0s 59us/step - loss: 0.1799 - binary_accuracy: 0.9233 - sensitivity: 0.9160 - specificity: 0.9399 - gmeasure: 0.9279 - auc: 0.9717 - val_loss: 0.2505 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9388 - val_specificity: 0.8269 - val_gmeasure: 0.8811 - val_auc: 0.9680
Epoch 21/100
600/600 [==============================] - 0s 60us/step - loss: 0.1796 - binary_accuracy: 0.9250 - sensitivity: 0.9157 - specificity: 0.9488 - gmeasure: 0.9320 - auc: 0.9719 - val_loss: 0.2576 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9678
Epoch 22/100
600/600 [==============================] - 0s 67us/step - loss: 0.1794 - binary_accuracy: 0.9250 - sensitivity: 0.9186 - specificity: 0.9465 - gmeasure: 0.9320 - auc: 0.9732 - val_loss: 0.2644 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9674
Epoch 23/100
600/600 [==============================] - 0s 64us/step - loss: 0.1796 - binary_accuracy: 0.9300 - sensitivity: 0.9346 - specificity: 0.9199 - gmeasure: 0.9271 - auc: 0.9708 - val_loss: 0.2565 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9680
Epoch 24/100
600/600 [==============================] - 0s 61us/step - loss: 0.1758 - binary_accuracy: 0.9317 - sensitivity: 0.9220 - specificity: 0.9509 - gmeasure: 0.9362 - auc: 0.9719 - val_loss: 0.2386 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9667
Epoch 25/100
600/600 [==============================] - 0s 68us/step - loss: 0.1769 - binary_accuracy: 0.9250 - sensitivity: 0.9152 - specificity: 0.9456 - gmeasure: 0.9302 - auc: 0.9719 - val_loss: 0.2634 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9388 - val_specificity: 0.7692 - val_gmeasure: 0.8498 - val_auc: 0.9682
Epoch 26/100
600/600 [==============================] - 0s 66us/step - loss: 0.1759 - binary_accuracy: 0.9300 - sensitivity: 0.9270 - specificity: 0.9341 - gmeasure: 0.9303 - auc: 0.9714 - val_loss: 0.2445 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9670
Epoch 27/100
600/600 [==============================] - 0s 67us/step - loss: 0.1741 - binary_accuracy: 0.9333 - sensitivity: 0.9265 - specificity: 0.9453 - gmeasure: 0.9358 - auc: 0.9728 - val_loss: 0.2512 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9694
Epoch 28/100
600/600 [==============================] - 0s 64us/step - loss: 0.1734 - binary_accuracy: 0.9333 - sensitivity: 0.9297 - specificity: 0.9420 - gmeasure: 0.9358 - auc: 0.9727 - val_loss: 0.2545 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9690
Epoch 29/100
600/600 [==============================] - 0s 62us/step - loss: 0.1728 - binary_accuracy: 0.9300 - sensitivity: 0.9185 - specificity: 0.9581 - gmeasure: 0.9379 - auc: 0.9737 - val_loss: 0.2424 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9698
Epoch 30/100
600/600 [==============================] - 0s 67us/step - loss: 0.1721 - binary_accuracy: 0.9283 - sensitivity: 0.9258 - specificity: 0.9371 - gmeasure: 0.9312 - auc: 0.9737 - val_loss: 0.2650 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9696
Epoch 31/100
600/600 [==============================] - 0s 65us/step - loss: 0.1735 - binary_accuracy: 0.9250 - sensitivity: 0.9234 - specificity: 0.9339 - gmeasure: 0.9281 - auc: 0.9741 - val_loss: 0.2468 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9676
Epoch 32/100
600/600 [==============================] - 0s 69us/step - loss: 0.1703 - binary_accuracy: 0.9317 - sensitivity: 0.9273 - specificity: 0.9422 - gmeasure: 0.9345 - auc: 0.9737 - val_loss: 0.2521 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9677
Epoch 33/100
600/600 [==============================] - 0s 67us/step - loss: 0.1682 - binary_accuracy: 0.9333 - sensitivity: 0.9273 - specificity: 0.9467 - gmeasure: 0.9369 - auc: 0.9754 - val_loss: 0.2436 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9710
Epoch 34/100
600/600 [==============================] - 0s 67us/step - loss: 0.1703 - binary_accuracy: 0.9300 - sensitivity: 0.9157 - specificity: 0.9640 - gmeasure: 0.9394 - auc: 0.9752 - val_loss: 0.2475 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9712
Epoch 35/100
600/600 [==============================] - 0s 64us/step - loss: 0.1687 - binary_accuracy: 0.9283 - sensitivity: 0.9348 - specificity: 0.9120 - gmeasure: 0.9232 - auc: 0.9733 - val_loss: 0.2618 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9704
Epoch 36/100
600/600 [==============================] - 0s 67us/step - loss: 0.1657 - binary_accuracy: 0.9300 - sensitivity: 0.9201 - specificity: 0.9517 - gmeasure: 0.9357 - auc: 0.9753 - val_loss: 0.2276 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9688
Epoch 37/100
600/600 [==============================] - 0s 63us/step - loss: 0.1665 - binary_accuracy: 0.9350 - sensitivity: 0.9154 - specificity: 0.9786 - gmeasure: 0.9464 - auc: 0.9751 - val_loss: 0.2744 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9490 - val_specificity: 0.7500 - val_gmeasure: 0.8436 - val_auc: 0.9698
Epoch 38/100
600/600 [==============================] - 0s 55us/step - loss: 0.1656 - binary_accuracy: 0.9283 - sensitivity: 0.9323 - specificity: 0.9196 - gmeasure: 0.9259 - auc: 0.9741 - val_loss: 0.2280 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9692
Epoch 39/100
600/600 [==============================] - 0s 58us/step - loss: 0.1662 - binary_accuracy: 0.9333 - sensitivity: 0.9125 - specificity: 0.9782 - gmeasure: 0.9447 - auc: 0.9746 - val_loss: 0.2442 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9717
Epoch 40/100
600/600 [==============================] - 0s 62us/step - loss: 0.1662 - binary_accuracy: 0.9383 - sensitivity: 0.9435 - specificity: 0.9303 - gmeasure: 0.9368 - auc: 0.9737 - val_loss: 0.2510 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9714
Epoch 41/100
600/600 [==============================] - 0s 61us/step - loss: 0.1630 - binary_accuracy: 0.9317 - sensitivity: 0.9206 - specificity: 0.9574 - gmeasure: 0.9388 - auc: 0.9750 - val_loss: 0.2245 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9707
Epoch 42/100
600/600 [==============================] - 0s 65us/step - loss: 0.1644 - binary_accuracy: 0.9317 - sensitivity: 0.9249 - specificity: 0.9570 - gmeasure: 0.9405 - auc: 0.9771 - val_loss: 0.2589 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9714
Epoch 43/100
600/600 [==============================] - 0s 65us/step - loss: 0.1601 - binary_accuracy: 0.9350 - sensitivity: 0.9354 - specificity: 0.9316 - gmeasure: 0.9335 - auc: 0.9772 - val_loss: 0.2366 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9731
Epoch 44/100
600/600 [==============================] - 0s 61us/step - loss: 0.1587 - binary_accuracy: 0.9383 - sensitivity: 0.9298 - specificity: 0.9570 - gmeasure: 0.9433 - auc: 0.9770 - val_loss: 0.2455 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9731
Epoch 45/100
600/600 [==============================] - 0s 64us/step - loss: 0.1607 - binary_accuracy: 0.9383 - sensitivity: 0.9429 - specificity: 0.9346 - gmeasure: 0.9384 - auc: 0.9769 - val_loss: 0.2512 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9731
Epoch 46/100
600/600 [==============================] - 0s 64us/step - loss: 0.1592 - binary_accuracy: 0.9400 - sensitivity: 0.9300 - specificity: 0.9628 - gmeasure: 0.9462 - auc: 0.9783 - val_loss: 0.2226 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9723
Epoch 47/100
600/600 [==============================] - 0s 59us/step - loss: 0.1615 - binary_accuracy: 0.9367 - sensitivity: 0.9328 - specificity: 0.9475 - gmeasure: 0.9396 - auc: 0.9774 - val_loss: 0.2606 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9490 - val_specificity: 0.7500 - val_gmeasure: 0.8436 - val_auc: 0.9725
Epoch 48/100
600/600 [==============================] - 0s 61us/step - loss: 0.1563 - binary_accuracy: 0.9433 - sensitivity: 0.9395 - specificity: 0.9493 - gmeasure: 0.9442 - auc: 0.9773 - val_loss: 0.2242 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9717
Epoch 49/100
600/600 [==============================] - 0s 64us/step - loss: 0.1582 - binary_accuracy: 0.9417 - sensitivity: 0.9391 - specificity: 0.9455 - gmeasure: 0.9417 - auc: 0.9773 - val_loss: 0.2562 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9727
Epoch 50/100
600/600 [==============================] - 0s 67us/step - loss: 0.1526 - binary_accuracy: 0.9433 - sensitivity: 0.9395 - specificity: 0.9508 - gmeasure: 0.9451 - auc: 0.9774 - val_loss: 0.2265 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9728
Epoch 51/100
600/600 [==============================] - 0s 64us/step - loss: 0.1534 - binary_accuracy: 0.9400 - sensitivity: 0.9274 - specificity: 0.9671 - gmeasure: 0.9470 - auc: 0.9785 - val_loss: 0.2547 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9739
Epoch 52/100
600/600 [==============================] - 0s 66us/step - loss: 0.1522 - binary_accuracy: 0.9467 - sensitivity: 0.9491 - specificity: 0.9395 - gmeasure: 0.9442 - auc: 0.9767 - val_loss: 0.2427 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9741
Epoch 53/100
600/600 [==============================] - 0s 54us/step - loss: 0.1525 - binary_accuracy: 0.9467 - sensitivity: 0.9419 - specificity: 0.9586 - gmeasure: 0.9500 - auc: 0.9779 - val_loss: 0.2353 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9749
Epoch 54/100
600/600 [==============================] - 0s 55us/step - loss: 0.1504 - binary_accuracy: 0.9467 - sensitivity: 0.9492 - specificity: 0.9413 - gmeasure: 0.9453 - auc: 0.9776 - val_loss: 0.2477 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9735
Epoch 55/100
600/600 [==============================] - 0s 50us/step - loss: 0.1486 - binary_accuracy: 0.9467 - sensitivity: 0.9421 - specificity: 0.9565 - gmeasure: 0.9492 - auc: 0.9787 - val_loss: 0.2328 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9721
Epoch 56/100
600/600 [==============================] - 0s 66us/step - loss: 0.1481 - binary_accuracy: 0.9483 - sensitivity: 0.9393 - specificity: 0.9649 - gmeasure: 0.9520 - auc: 0.9779 - val_loss: 0.2497 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9745
Epoch 57/100
600/600 [==============================] - 0s 61us/step - loss: 0.1466 - binary_accuracy: 0.9483 - sensitivity: 0.9489 - specificity: 0.9437 - gmeasure: 0.9460 - auc: 0.9781 - val_loss: 0.2311 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9490 - val_specificity: 0.8269 - val_gmeasure: 0.8859 - val_auc: 0.9728
Epoch 58/100
600/600 [==============================] - 0s 63us/step - loss: 0.1510 - binary_accuracy: 0.9417 - sensitivity: 0.9306 - specificity: 0.9703 - gmeasure: 0.9499 - auc: 0.9802 - val_loss: 0.2373 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9753
Epoch 59/100
600/600 [==============================] - 0s 65us/step - loss: 0.1472 - binary_accuracy: 0.9483 - sensitivity: 0.9513 - specificity: 0.9409 - gmeasure: 0.9460 - auc: 0.9778 - val_loss: 0.2657 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9796 - val_specificity: 0.7500 - val_gmeasure: 0.8571 - val_auc: 0.9751
Epoch 60/100
600/600 [==============================] - 0s 67us/step - loss: 0.1428 - binary_accuracy: 0.9500 - sensitivity: 0.9493 - specificity: 0.9524 - gmeasure: 0.9508 - auc: 0.9791 - val_loss: 0.2131 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9746
Epoch 61/100
600/600 [==============================] - 0s 72us/step - loss: 0.1442 - binary_accuracy: 0.9517 - sensitivity: 0.9419 - specificity: 0.9727 - gmeasure: 0.9571 - auc: 0.9799 - val_loss: 0.2418 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9490 - val_specificity: 0.8269 - val_gmeasure: 0.8859 - val_auc: 0.9755
Epoch 62/100
600/600 [==============================] - 0s 60us/step - loss: 0.1439 - binary_accuracy: 0.9483 - sensitivity: 0.9538 - specificity: 0.9364 - gmeasure: 0.9450 - auc: 0.9782 - val_loss: 0.2295 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9774
Epoch 63/100
600/600 [==============================] - 0s 62us/step - loss: 0.1414 - binary_accuracy: 0.9550 - sensitivity: 0.9470 - specificity: 0.9741 - gmeasure: 0.9604 - auc: 0.9803 - val_loss: 0.2280 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9490 - val_specificity: 0.8462 - val_gmeasure: 0.8961 - val_auc: 0.9772
Epoch 64/100
600/600 [==============================] - 0s 64us/step - loss: 0.1432 - binary_accuracy: 0.9533 - sensitivity: 0.9561 - specificity: 0.9445 - gmeasure: 0.9494 - auc: 0.9788 - val_loss: 0.2273 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9772
Epoch 65/100
600/600 [==============================] - 0s 53us/step - loss: 0.1446 - binary_accuracy: 0.9483 - sensitivity: 0.9353 - specificity: 0.9807 - gmeasure: 0.9576 - auc: 0.9806 - val_loss: 0.2212 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9764
Epoch 66/100
600/600 [==============================] - 0s 64us/step - loss: 0.1390 - binary_accuracy: 0.9517 - sensitivity: 0.9492 - specificity: 0.9565 - gmeasure: 0.9528 - auc: 0.9797 - val_loss: 0.2647 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9788
Epoch 67/100
600/600 [==============================] - 0s 57us/step - loss: 0.1379 - binary_accuracy: 0.9567 - sensitivity: 0.9535 - specificity: 0.9622 - gmeasure: 0.9578 - auc: 0.9800 - val_loss: 0.1952 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9723
Epoch 68/100
600/600 [==============================] - 0s 68us/step - loss: 0.1423 - binary_accuracy: 0.9500 - sensitivity: 0.9394 - specificity: 0.9736 - gmeasure: 0.9561 - auc: 0.9812 - val_loss: 0.2752 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9796 - val_specificity: 0.7308 - val_gmeasure: 0.8461 - val_auc: 0.9788
Epoch 69/100
600/600 [==============================] - 0s 70us/step - loss: 0.1424 - binary_accuracy: 0.9500 - sensitivity: 0.9637 - specificity: 0.9203 - gmeasure: 0.9417 - auc: 0.9796 - val_loss: 0.2077 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9775
Epoch 70/100
600/600 [==============================] - 0s 67us/step - loss: 0.1422 - binary_accuracy: 0.9500 - sensitivity: 0.9349 - specificity: 0.9844 - gmeasure: 0.9592 - auc: 0.9820 - val_loss: 0.2318 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9763
Epoch 71/100
600/600 [==============================] - 0s 66us/step - loss: 0.1495 - binary_accuracy: 0.9450 - sensitivity: 0.9599 - specificity: 0.9210 - gmeasure: 0.9395 - auc: 0.9810 - val_loss: 0.2199 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9766
Epoch 72/100
600/600 [==============================] - 0s 56us/step - loss: 0.1467 - binary_accuracy: 0.9450 - sensitivity: 0.9302 - specificity: 0.9788 - gmeasure: 0.9541 - auc: 0.9820 - val_loss: 0.2181 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9592 - val_specificity: 0.8654 - val_gmeasure: 0.9111 - val_auc: 0.9769
Epoch 73/100
600/600 [==============================] - 0s 60us/step - loss: 0.1377 - binary_accuracy: 0.9550 - sensitivity: 0.9617 - specificity: 0.9391 - gmeasure: 0.9503 - auc: 0.9804 - val_loss: 0.2586 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9794
Epoch 74/100
600/600 [==============================] - 0s 58us/step - loss: 0.1377 - binary_accuracy: 0.9583 - sensitivity: 0.9495 - specificity: 0.9800 - gmeasure: 0.9645 - auc: 0.9813 - val_loss: 0.2009 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9388 - val_specificity: 0.9038 - val_gmeasure: 0.9211 - val_auc: 0.9755
Epoch 75/100
600/600 [==============================] - 0s 59us/step - loss: 0.1337 - binary_accuracy: 0.9517 - sensitivity: 0.9442 - specificity: 0.9688 - gmeasure: 0.9562 - auc: 0.9819 - val_loss: 0.2704 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9794
Epoch 76/100
600/600 [==============================] - 0s 57us/step - loss: 0.1328 - binary_accuracy: 0.9583 - sensitivity: 0.9659 - specificity: 0.9407 - gmeasure: 0.9532 - auc: 0.9808 - val_loss: 0.2123 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9592 - val_specificity: 0.8654 - val_gmeasure: 0.9111 - val_auc: 0.9778
Epoch 77/100
600/600 [==============================] - 0s 64us/step - loss: 0.1314 - binary_accuracy: 0.9600 - sensitivity: 0.9515 - specificity: 0.9780 - gmeasure: 0.9646 - auc: 0.9838 - val_loss: 0.2120 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9694 - val_specificity: 0.8654 - val_gmeasure: 0.9159 - val_auc: 0.9810
Epoch 78/100
600/600 [==============================] - 0s 64us/step - loss: 0.1295 - binary_accuracy: 0.9600 - sensitivity: 0.9637 - specificity: 0.9522 - gmeasure: 0.9577 - auc: 0.9819 - val_loss: 0.2566 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9796 - val_specificity: 0.8077 - val_gmeasure: 0.8895 - val_auc: 0.9798
Epoch 79/100
600/600 [==============================] - 0s 70us/step - loss: 0.1270 - binary_accuracy: 0.9567 - sensitivity: 0.9589 - specificity: 0.9520 - gmeasure: 0.9553 - auc: 0.9823 - val_loss: 0.2073 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9789
Epoch 80/100
600/600 [==============================] - 0s 70us/step - loss: 0.1283 - binary_accuracy: 0.9617 - sensitivity: 0.9487 - specificity: 0.9883 - gmeasure: 0.9681 - auc: 0.9830 - val_loss: 0.2412 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9804
Epoch 81/100
600/600 [==============================] - 0s 67us/step - loss: 0.1255 - binary_accuracy: 0.9600 - sensitivity: 0.9637 - specificity: 0.9533 - gmeasure: 0.9584 - auc: 0.9827 - val_loss: 0.2322 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9806
Epoch 82/100
600/600 [==============================] - 0s 68us/step - loss: 0.1243 - binary_accuracy: 0.9667 - sensitivity: 0.9664 - specificity: 0.9686 - gmeasure: 0.9673 - auc: 0.9831 - val_loss: 0.2003 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9818
Epoch 83/100
600/600 [==============================] - 0s 70us/step - loss: 0.1244 - binary_accuracy: 0.9650 - sensitivity: 0.9564 - specificity: 0.9840 - gmeasure: 0.9701 - auc: 0.9841 - val_loss: 0.2379 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9808
Epoch 84/100
600/600 [==============================] - 0s 70us/step - loss: 0.1233 - binary_accuracy: 0.9617 - sensitivity: 0.9610 - specificity: 0.9635 - gmeasure: 0.9622 - auc: 0.9832 - val_loss: 0.2172 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9814
Epoch 85/100
600/600 [==============================] - 0s 71us/step - loss: 0.1230 - binary_accuracy: 0.9650 - sensitivity: 0.9537 - specificity: 0.9887 - gmeasure: 0.9710 - auc: 0.9848 - val_loss: 0.2331 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9796 - val_specificity: 0.8462 - val_gmeasure: 0.9104 - val_auc: 0.9810
Epoch 86/100
600/600 [==============================] - 0s 70us/step - loss: 0.1231 - binary_accuracy: 0.9600 - sensitivity: 0.9662 - specificity: 0.9492 - gmeasure: 0.9576 - auc: 0.9842 - val_loss: 0.2140 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9812
Epoch 87/100
600/600 [==============================] - 0s 62us/step - loss: 0.1200 - binary_accuracy: 0.9650 - sensitivity: 0.9567 - specificity: 0.9839 - gmeasure: 0.9702 - auc: 0.9845 - val_loss: 0.2099 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9816
Epoch 88/100
600/600 [==============================] - 0s 59us/step - loss: 0.1175 - binary_accuracy: 0.9650 - sensitivity: 0.9611 - specificity: 0.9728 - gmeasure: 0.9669 - auc: 0.9836 - val_loss: 0.2519 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9796 - val_specificity: 0.8077 - val_gmeasure: 0.8895 - val_auc: 0.9804
Epoch 89/100
600/600 [==============================] - 0s 58us/step - loss: 0.1189 - binary_accuracy: 0.9617 - sensitivity: 0.9637 - specificity: 0.9587 - gmeasure: 0.9611 - auc: 0.9845 - val_loss: 0.1993 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9785
Epoch 90/100
600/600 [==============================] - 0s 64us/step - loss: 0.1196 - binary_accuracy: 0.9650 - sensitivity: 0.9593 - specificity: 0.9799 - gmeasure: 0.9694 - auc: 0.9849 - val_loss: 0.2416 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9810
Epoch 91/100
600/600 [==============================] - 0s 62us/step - loss: 0.1166 - binary_accuracy: 0.9650 - sensitivity: 0.9690 - specificity: 0.9601 - gmeasure: 0.9644 - auc: 0.9853 - val_loss: 0.2114 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812
Epoch 92/100
600/600 [==============================] - 0s 58us/step - loss: 0.1191 - binary_accuracy: 0.9617 - sensitivity: 0.9545 - specificity: 0.9797 - gmeasure: 0.9669 - auc: 0.9853 - val_loss: 0.2206 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9812
Epoch 93/100
600/600 [==============================] - 0s 65us/step - loss: 0.1150 - binary_accuracy: 0.9667 - sensitivity: 0.9659 - specificity: 0.9638 - gmeasure: 0.9644 - auc: 0.9862 - val_loss: 0.2429 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9796 - val_specificity: 0.8462 - val_gmeasure: 0.9104 - val_auc: 0.9808
Epoch 94/100
600/600 [==============================] - 0s 67us/step - loss: 0.1138 - binary_accuracy: 0.9683 - sensitivity: 0.9668 - specificity: 0.9752 - gmeasure: 0.9708 - auc: 0.9872 - val_loss: 0.1867 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9816
Epoch 95/100
600/600 [==============================] - 0s 67us/step - loss: 0.1158 - binary_accuracy: 0.9700 - sensitivity: 0.9613 - specificity: 0.9896 - gmeasure: 0.9753 - auc: 0.9857 - val_loss: 0.2352 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9806
Epoch 96/100
600/600 [==============================] - 0s 63us/step - loss: 0.1157 - binary_accuracy: 0.9617 - sensitivity: 0.9685 - specificity: 0.9459 - gmeasure: 0.9570 - auc: 0.9865 - val_loss: 0.2102 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812
Epoch 97/100
600/600 [==============================] - 0s 67us/step - loss: 0.1193 - binary_accuracy: 0.9617 - sensitivity: 0.9490 - specificity: 0.9894 - gmeasure: 0.9689 - auc: 0.9860 - val_loss: 0.2064 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812
Epoch 98/100
600/600 [==============================] - 0s 68us/step - loss: 0.1119 - binary_accuracy: 0.9683 - sensitivity: 0.9683 - specificity: 0.9671 - gmeasure: 0.9675 - auc: 0.9878 - val_loss: 0.2911 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9796 - val_specificity: 0.7115 - val_gmeasure: 0.8349 - val_auc: 0.9808
Epoch 99/100
600/600 [==============================] - 0s 63us/step - loss: 0.1097 - binary_accuracy: 0.9633 - sensitivity: 0.9678 - specificity: 0.9515 - gmeasure: 0.9596 - auc: 0.9888 - val_loss: 0.1809 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9592 - val_specificity: 0.9038 - val_gmeasure: 0.9311 - val_auc: 0.9831
Epoch 100/100
600/600 [==============================] - 0s 60us/step - loss: 0.1148 - binary_accuracy: 0.9650 - sensitivity: 0.9540 - specificity: 0.9896 - gmeasure: 0.9716 - auc: 0.9877 - val_loss: 0.2218 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9819
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 6.227388858795166!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 6us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.011963129043579102!
[root    |INFO|build_network.py:183] Evaluation: [0.13018378615379333, 0.9639999866485596, 0.9686888456344604, 0.9539749026298523, 0.9613037109375, 0.9872716665267944]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 18us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.011726856231689453!
[root    |INFO|build_network.py:183] Evaluation: [0.2259432077407837, 0.9279999732971191, 0.9606741666793823, 0.8472222089767456, 0.9021665453910828, 0.9655118584632874]
[root    |INFO|deepbiome.py:179] Compute time : 8.126851081848145
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.17482334 0.93599999 0.96279993 0.87334998 0.91622325 0.97399658]
[root    |INFO|deepbiome.py:189]        std : [0.06598582 0.04054445 0.021227   0.08591953 0.05451263 0.01778478]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.263196   0.90399998 0.95967474 0.78013321 0.86464918 0.95612373]
[root    |INFO|deepbiome.py:196]        std : [0.02645943 0.0214165  0.00085764 0.05896227 0.03326344 0.00666316]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>Let’s check the history plot again.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_the_list_of_inputs_51_0.png" src="_images/example_with_the_list_of_inputs_51_0.png" />
</div>
</div>
</div>
<div class="section" id="6.-Load-the-pre-trained-network-for-testing">
<h2>6. Load the pre-trained network for testing<a class="headerlink" href="#6.-Load-the-pre-trained-network-for-testing" title="Permalink to this headline">¶</a></h2>
<p>If you want to test the trained model, you can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_test</span></code> function. If you use the index file, this function provide the evaluation using test index (index set not included in the index file) for each fold. If not, this function provide the evaluation using the whole samples. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is setted as <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will test the model only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_test</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">test_network_info</span><span class="p">,</span> <span class="n">test_path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:294] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 1 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 283us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.22127509117126465!
[root    |INFO|build_network.py:183] Evaluation: [0.2787688076496124, 0.8759999871253967, 0.9585798978805542, 0.7037037014961243, 0.8213136792182922, 0.9507268667221069]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.6310412883758545
[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 2 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 457us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.31082844734191895!
[root    |INFO|build_network.py:183] Evaluation: [0.2848759889602661, 0.9079999923706055, 0.959770143032074, 0.7894737124443054, 0.8704673051834106, 0.9521324634552002]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.7521309852600098
[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 3 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 336us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.26335835456848145!
[root    |INFO|build_network.py:183] Evaluation: [0.2259432077407837, 0.9279999732971191, 0.9606741666793823, 0.8472222089767456, 0.9021665453910828, 0.9655118584632874]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.9530818462371826
[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:328] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:331]       mean : [0.263196   0.90399998 0.95967474 0.78013321 0.86464918 0.95612373]
[root    |INFO|deepbiome.py:332]        std : [0.02645943 0.0214165  0.00085764 0.05896227 0.03326344 0.00666316]
[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:336] Total Computing Ended
[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>This function provide the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">+</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">s</span>.strip() for s in network_info[&#39;model_info&#39;][&#39;metrics&#39;].split(&#39;,&#39;)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.mean(evaluation, axis=0)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Std : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.std(evaluation, axis=0)]))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc
Mean:           0.2632          0.9040          0.9597          0.7801          0.8646          0.9561
Std :           0.0265          0.0214          0.0009          0.0590          0.0333          0.0067
</pre></div></div>
</div>
</div>
<div class="section" id="7.-Load-the-pre-trained-network-for-prediction">
<h2>7. Load the pre-trained network for prediction<a class="headerlink" href="#7.-Load-the-pre-trained-network-for-prediction" title="Permalink to this headline">¶</a></h2>
<p>If you want to predict using the pre-trained model, you can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_prediction</span></code> function. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is setted as <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will predict only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds sample’s outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight_0.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_prediction</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">prediction_network_info</span><span class="p">,</span> <span class="n">prediction_path_info</span><span class="p">,</span>
                                            <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 1 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 47us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.050612688064575195!
[root    |INFO|deepbiome.py:444] Compute time : 1.2163026332855225
[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 2 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 47us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.050907135009765625!
[root    |INFO|deepbiome.py:444] Compute time : 1.1867918968200684
[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 3 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 26us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.02785348892211914!
[root    |INFO|deepbiome.py:444] Compute time : 1.1357481479644775
[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:449] Total Computing Ended
[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(3, 1000, 1)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.78799784],
       [0.9245996 ],
       [0.1545347 ],
       [0.14412734],
       [0.9911699 ],
       [0.98303807],
       [0.1934169 ],
       [0.14412734],
       [0.979736  ],
       [0.9812544 ]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="example_with_one_input_file.html" class="btn btn-neutral float-right" title="Example : k fold cross-validation with an input file" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="usage.html" class="btn btn-neutral float-left" title="Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Youngwon Choi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>