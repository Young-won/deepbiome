

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Example : k times repetition with the list of k input files &mdash; deepbiome 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example : k fold cross-validation with an input file" href="example_with_one_input_file.html" />
    <link rel="prev" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deepbiome
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example : k times repetition with the list of k input files</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#1.-Load-library">1. Load library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Prepare-the-dataset">2. Prepare the dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-tree-information">Example of the tree information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-list-of-the-name-of-input-files">Example of the list of the name of input files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-lists-of-the-input-files">Example of the lists of the input files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(regression)">Example of the Y (regression)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(classification)">Example of the Y (classification)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exmple-of-the-training-index-file-for-repetition">Exmple of the training index file for repetition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#3.-Prepare-the-configuration">3. Prepare the configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-network-information-(network_info)">For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-path-information-(path_info)">For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#4.-DeepBiome-Training">4. DeepBiome Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5.-Load-the-pre-trained-network-for-training">5. Load the pre-trained network for training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#6.-Load-the-pre-trained-network-for-testing">6. Load the pre-trained network for testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#7.-Load-the-pre-trained-network-for-prediction">7. Load the pre-trained network for prediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_with_one_input_file.html">Example : k fold cross-validation with an input file</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-history.html">Release History</a></li>
<li class="toctree-l1"><a class="reference internal" href="min_versions.html">Minimum Version of Python and NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepbiome</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Example : k times repetition with the list of k input files</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/example_with_the_list_of_inputs.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Example-:-k-times-repetition-with-the-list-of-k-input-files">
<h1>Example : k times repetition with the list of k input files<a class="headerlink" href="#Example-:-k-times-repetition-with-the-list-of-k-input-files" title="Permalink to this headline">¶</a></h1>
<p>DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.</p>
<p>To use DeepBiome, you can experiment (1) <strong>k times repetition</strong> or (2) <strong>k fold cross-validation</strong>. For each experiment, we asuume that the dataset is given by - <strong>A list of k input files for k times repetition.</strong> - <strong>One input file for k fold cross-validation.</strong></p>
<p>This notebook contains an example of (1) <strong>k times repetition</strong> for the deep neural netowrk using deepbiome.</p>
<div class="section" id="1.-Load-library">
<h2>1. Load library<a class="headerlink" href="#1.-Load-library" title="Permalink to this headline">¶</a></h2>
<p>First, we have to load deepbiome package. The deepbiome package is build on the tensorflow and keras library</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">resource_filename</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">deepbiome</span> <span class="kn">import</span> <span class="n">deepbiome</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
</pre></div></div>
</div>
</div>
<div class="section" id="2.-Prepare-the-dataset">
<h2>2. Prepare the dataset<a class="headerlink" href="#2.-Prepare-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this example, we assume that we have <strong>a list of k input files for k times repetition.</strong></p>
<p>DeepBiome needs 4 data files as follows: 1. <strong>the tree information</strong> 1. <strong>the lists of the input files</strong> (each file has all sample’s information for one repetition) 1. <strong>the list of the names of input files</strong> 1. <strong>y</strong></p>
<p>In addition, we can set <strong>the training index for each repetition</strong>. If we set the index file, DeepBiome builds the training set for each repetition based on each fold index in the index file. If not, DeepBiome will generate the index file locally.</p>
<p>Eath data should have the csv format. Below is the example of each file.</p>
<div class="section" id="Example-of-the-tree-information">
<h3>Example of the tree information<a class="headerlink" href="#Example-of-the-tree-information" title="Permalink to this headline">¶</a></h3>
<p>First we need a file about the phylogenetic tree information. This tree information file should have the format below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tree_information</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">))</span>
<span class="n">tree_information</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genus</th>
      <th>Family</th>
      <th>Order</th>
      <th>Class</th>
      <th>Phylum</th>
      <th>Domain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Streptococcus</td>
      <td>Streptococcaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tropheryma</td>
      <td>Cellulomonadaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Veillonella</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Actinomyces</td>
      <td>Actinomycetaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Flavobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Prevotella</td>
      <td>Prevotellaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Porphyromonas</td>
      <td>Porphyromonadaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Parvimonas</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Fusobacterium</td>
      <td>Fusobacteriaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Propionibacterium</td>
      <td>Propionibacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Gemella</td>
      <td>Bacillales_Incertae_Sedis_XI</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Rothia</td>
      <td>Micrococcaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Granulicatella</td>
      <td>Carnobacteriaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Neisseria</td>
      <td>Neisseriaceae</td>
      <td>Neisseriales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Lactobacillus</td>
      <td>Lactobacillaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Megasphaera</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Catonella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Atopobium</td>
      <td>Coriobacteriaceae</td>
      <td>Coriobacteriales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Campylobacter</td>
      <td>Campylobacteraceae</td>
      <td>Campylobacterales</td>
      <td>Epsilonproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Capnocytophaga</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Solobacterium</td>
      <td>Erysipelotrichaceae</td>
      <td>Erysipelotrichales</td>
      <td>Erysipelotrichia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Moryella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>22</th>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Staphylococcus</td>
      <td>Staphylococcaceae</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Filifactor</td>
      <td>Peptostreptococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Oribacterium</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Burkholderia</td>
      <td>Burkholderiaceae</td>
      <td>Burkholderiales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Sneathia</td>
      <td>Leptotrichiaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Treponema</td>
      <td>Spirochaetaceae</td>
      <td>Spirochaetales</td>
      <td>Spirochaetes</td>
      <td>Spirochaetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Moraxella</td>
      <td>Moraxellaceae</td>
      <td>Pseudomonadales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Haemophilus</td>
      <td>Pasteurellaceae</td>
      <td>Pasteurellales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Selenomonas</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Corynebacterium</td>
      <td>Corynebacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Rhizobium</td>
      <td>Rhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Bradyrhizobium</td>
      <td>Bradyrhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Methylobacterium</td>
      <td>Methylobacteriaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>36</th>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Finegoldia</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Microbacterium</td>
      <td>Microbacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Sphingomonas</td>
      <td>Sphingomonadaceae</td>
      <td>Sphingomonadales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Chryseobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Bacteroides</td>
      <td>Bacteroidaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Bdellovibrio</td>
      <td>Bdellovibrionaceae</td>
      <td>Bdellovibrionales</td>
      <td>Deltaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Streptophyta</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Cyanobacteria_Chloroplast</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Lachnospiracea_incertae_sedis</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Paracoccus</td>
      <td>Rhodobacteraceae</td>
      <td>Rhodobacterales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Fastidiosipila</td>
      <td>Ruminococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Pseudonocardia</td>
      <td>Pseudonocardiaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-list-of-the-name-of-input-files">
<h3>Example of the list of the name of input files<a class="headerlink" href="#Example-of-the-list-of-the-name-of-input-files" title="Permalink to this headline">¶</a></h3>
<p>In this example. we assume that input is given by the lists of files. Each file has all sample’s information for one repeatition. If we want to use the list of the input files, we need to make a list of the names of each input file. Below is an example file for <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repetition.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">list_of_input_files</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">list_of_input_files</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>gcount_0001.csv</td>
    </tr>
    <tr>
      <th>1</th>
      <td>gcount_0002.csv</td>
    </tr>
    <tr>
      <th>2</th>
      <td>gcount_0003.csv</td>
    </tr>
    <tr>
      <th>3</th>
      <td>gcount_0004.csv</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gcount_0005.csv</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">list_of_input_files</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>gcount_0996.csv</td>
    </tr>
    <tr>
      <th>996</th>
      <td>gcount_0997.csv</td>
    </tr>
    <tr>
      <th>997</th>
      <td>gcount_0998.csv</td>
    </tr>
    <tr>
      <th>998</th>
      <td>gcount_0999.csv</td>
    </tr>
    <tr>
      <th>999</th>
      <td>gcount_1000.csv</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-lists-of-the-input-files">
<h3>Example of the lists of the input files<a class="headerlink" href="#Example-of-the-lists-of-the-input-files" title="Permalink to this headline">¶</a></h3>
<p>Below is an example of each input file. This example has 1000 samples as rows, and the abandunce of each microbiome as columns. Below is an example file for <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repetition. This example is <code class="docutils literal notranslate"><span class="pre">gcount_0001.csv</span></code> for the first repetition in the list of the names of input files above. This file has the 4 samples’ microbiome abandunce.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">list_of_input_files</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">x_1</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>841</td>
      <td>0</td>
      <td>813</td>
      <td>505</td>
      <td>5</td>
      <td>3224</td>
      <td>0</td>
      <td>362</td>
      <td>11</td>
      <td>65</td>
      <td>...</td>
      <td>0</td>
      <td>87</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2133</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1445</td>
      <td>0</td>
      <td>1</td>
      <td>573</td>
      <td>0</td>
      <td>1278</td>
      <td>82</td>
      <td>85</td>
      <td>69</td>
      <td>154</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3638</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1259</td>
      <td>0</td>
      <td>805</td>
      <td>650</td>
      <td>0</td>
      <td>1088</td>
      <td>0</td>
      <td>0</td>
      <td>74</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3445</td>
    </tr>
    <tr>
      <th>3</th>
      <td>982</td>
      <td>0</td>
      <td>327</td>
      <td>594</td>
      <td>0</td>
      <td>960</td>
      <td>81</td>
      <td>19</td>
      <td>9</td>
      <td>0</td>
      <td>...</td>
      <td>157</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3507</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1162</td>
      <td>0</td>
      <td>130</td>
      <td>969</td>
      <td>163</td>
      <td>1515</td>
      <td>167</td>
      <td>4</td>
      <td>162</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>3945</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x_1</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1401</td>
      <td>4</td>
      <td>30</td>
      <td>526</td>
      <td>0</td>
      <td>923</td>
      <td>25</td>
      <td>0</td>
      <td>127</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4470</td>
    </tr>
    <tr>
      <th>996</th>
      <td>2655</td>
      <td>6</td>
      <td>106</td>
      <td>74</td>
      <td>0</td>
      <td>952</td>
      <td>76</td>
      <td>13</td>
      <td>158</td>
      <td>125</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2826</td>
    </tr>
    <tr>
      <th>997</th>
      <td>335</td>
      <td>0</td>
      <td>71</td>
      <td>259</td>
      <td>67</td>
      <td>718</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>167</td>
      <td>...</td>
      <td>0</td>
      <td>246</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6527</td>
    </tr>
    <tr>
      <th>998</th>
      <td>649</td>
      <td>69</td>
      <td>966</td>
      <td>1227</td>
      <td>0</td>
      <td>508</td>
      <td>2</td>
      <td>30</td>
      <td>550</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4402</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1258</td>
      <td>0</td>
      <td>0</td>
      <td>1119</td>
      <td>0</td>
      <td>2348</td>
      <td>25</td>
      <td>0</td>
      <td>137</td>
      <td>176</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2585</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(regression)">
<h3>Example of the Y (regression)<a class="headerlink" href="#Example-of-the-Y-(regression)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for regression problem. One column contains y samples for one repeatition. For each repeatition (column) has outputs of 4 samples for each repeatition. Below example file has 1000 samples in row, <code class="docutils literal notranslate"><span class="pre">k=1000</span></code> repetition in column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/regression_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>x3</th>
      <th>x4</th>
      <th>x5</th>
      <th>x6</th>
      <th>x7</th>
      <th>x8</th>
      <th>x9</th>
      <th>x10</th>
      <th>...</th>
      <th>x991</th>
      <th>x992</th>
      <th>x993</th>
      <th>x994</th>
      <th>x995</th>
      <th>x996</th>
      <th>x997</th>
      <th>x998</th>
      <th>x999</th>
      <th>x1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.997270</td>
      <td>5.492354</td>
      <td>5.473725</td>
      <td>1.759484</td>
      <td>5.313252</td>
      <td>1.500044</td>
      <td>4.949712</td>
      <td>5.493533</td>
      <td>3.743509</td>
      <td>5.492373</td>
      <td>...</td>
      <td>2.793883</td>
      <td>1.500004</td>
      <td>5.487526</td>
      <td>5.493518</td>
      <td>3.599047</td>
      <td>5.491461</td>
      <td>5.486244</td>
      <td>5.487390</td>
      <td>5.493492</td>
      <td>3.762523</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.004092</td>
      <td>1.500002</td>
      <td>4.640348</td>
      <td>1.538071</td>
      <td>5.491065</td>
      <td>5.481009</td>
      <td>5.492323</td>
      <td>2.968531</td>
      <td>3.576358</td>
      <td>5.491456</td>
      <td>...</td>
      <td>1.500033</td>
      <td>3.369529</td>
      <td>1.500016</td>
      <td>3.103297</td>
      <td>5.493214</td>
      <td>3.831125</td>
      <td>5.492104</td>
      <td>5.474811</td>
      <td>5.492416</td>
      <td>3.268805</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.485126</td>
      <td>4.187426</td>
      <td>5.491340</td>
      <td>5.469662</td>
      <td>5.490478</td>
      <td>1.953375</td>
      <td>5.494656</td>
      <td>3.741680</td>
      <td>4.862400</td>
      <td>5.490701</td>
      <td>...</td>
      <td>5.491728</td>
      <td>2.459981</td>
      <td>5.475697</td>
      <td>3.114158</td>
      <td>1.500004</td>
      <td>1.500019</td>
      <td>4.113815</td>
      <td>5.470539</td>
      <td>5.494373</td>
      <td>5.481754</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.489590</td>
      <td>4.863187</td>
      <td>1.500003</td>
      <td>5.484699</td>
      <td>5.492657</td>
      <td>5.491270</td>
      <td>4.091023</td>
      <td>5.495239</td>
      <td>5.492804</td>
      <td>1.500046</td>
      <td>...</td>
      <td>1.500034</td>
      <td>1.500012</td>
      <td>5.483070</td>
      <td>2.475049</td>
      <td>5.493846</td>
      <td>3.287076</td>
      <td>3.696412</td>
      <td>5.487583</td>
      <td>1.500044</td>
      <td>2.760404</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.500001</td>
      <td>5.480769</td>
      <td>5.489725</td>
      <td>1.500044</td>
      <td>2.695212</td>
      <td>5.492262</td>
      <td>3.381424</td>
      <td>4.805420</td>
      <td>1.500047</td>
      <td>5.474376</td>
      <td>...</td>
      <td>1.500046</td>
      <td>2.586990</td>
      <td>5.440610</td>
      <td>4.376103</td>
      <td>1.500030</td>
      <td>4.713223</td>
      <td>5.491059</td>
      <td>3.230658</td>
      <td>1.500045</td>
      <td>5.488727</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>x3</th>
      <th>x4</th>
      <th>x5</th>
      <th>x6</th>
      <th>x7</th>
      <th>x8</th>
      <th>x9</th>
      <th>x10</th>
      <th>...</th>
      <th>x991</th>
      <th>x992</th>
      <th>x993</th>
      <th>x994</th>
      <th>x995</th>
      <th>x996</th>
      <th>x997</th>
      <th>x998</th>
      <th>x999</th>
      <th>x1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>2.609926</td>
      <td>5.491258</td>
      <td>3.318610</td>
      <td>5.444070</td>
      <td>2.884154</td>
      <td>5.486857</td>
      <td>5.496554</td>
      <td>1.500019</td>
      <td>5.482893</td>
      <td>1.824835</td>
      <td>...</td>
      <td>4.478641</td>
      <td>5.485122</td>
      <td>4.915985</td>
      <td>4.073239</td>
      <td>1.500019</td>
      <td>5.492295</td>
      <td>1.500005</td>
      <td>1.559586</td>
      <td>5.496415</td>
      <td>4.171127</td>
    </tr>
    <tr>
      <th>996</th>
      <td>5.488959</td>
      <td>3.739806</td>
      <td>5.489474</td>
      <td>1.500021</td>
      <td>5.492632</td>
      <td>1.500019</td>
      <td>5.484813</td>
      <td>5.467055</td>
      <td>5.491282</td>
      <td>1.874777</td>
      <td>...</td>
      <td>5.498820</td>
      <td>5.493926</td>
      <td>5.487404</td>
      <td>3.162812</td>
      <td>1.846298</td>
      <td>5.492417</td>
      <td>1.919107</td>
      <td>5.480324</td>
      <td>5.467765</td>
      <td>5.457627</td>
    </tr>
    <tr>
      <th>997</th>
      <td>3.498418</td>
      <td>4.250451</td>
      <td>5.488116</td>
      <td>4.162031</td>
      <td>5.494052</td>
      <td>5.472900</td>
      <td>1.500057</td>
      <td>5.491497</td>
      <td>5.491935</td>
      <td>1.500033</td>
      <td>...</td>
      <td>1.966474</td>
      <td>5.475258</td>
      <td>3.848034</td>
      <td>2.863883</td>
      <td>4.370685</td>
      <td>5.494647</td>
      <td>5.478855</td>
      <td>2.465739</td>
      <td>1.500018</td>
      <td>5.486403</td>
    </tr>
    <tr>
      <th>998</th>
      <td>5.486107</td>
      <td>1.917414</td>
      <td>5.414975</td>
      <td>5.492364</td>
      <td>2.027914</td>
      <td>5.491349</td>
      <td>5.494135</td>
      <td>5.491245</td>
      <td>1.500039</td>
      <td>1.500019</td>
      <td>...</td>
      <td>4.556995</td>
      <td>5.457072</td>
      <td>2.071106</td>
      <td>5.417333</td>
      <td>5.491818</td>
      <td>5.473390</td>
      <td>4.374154</td>
      <td>5.489109</td>
      <td>4.515340</td>
      <td>1.500020</td>
    </tr>
    <tr>
      <th>999</th>
      <td>5.319623</td>
      <td>5.482776</td>
      <td>1.500035</td>
      <td>5.485141</td>
      <td>5.491019</td>
      <td>3.733982</td>
      <td>5.494374</td>
      <td>3.077159</td>
      <td>5.493188</td>
      <td>1.500001</td>
      <td>...</td>
      <td>5.485356</td>
      <td>1.500059</td>
      <td>5.400762</td>
      <td>5.489606</td>
      <td>5.494583</td>
      <td>5.490943</td>
      <td>5.123794</td>
      <td>5.473465</td>
      <td>3.274979</td>
      <td>3.700653</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>For one repeatition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    4.997270
1    5.004092
2    5.485126
3    5.489590
4    1.500001
Name: x1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    2.609926
996    5.488959
997    3.498418
998    5.486107
999    5.319623
Name: x1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(classification)">
<h3>Example of the Y (classification)<a class="headerlink" href="#Example-of-the-Y-(classification)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetitions in columns.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>997</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>For one repeatition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    1.0
1    1.0
2    0.0
3    0.0
4    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    1.0
996    0.0
997    1.0
998    0.0
999    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Exmple-of-the-training-index-file-for-repetition">
<h3>Exmple of the training index file for repetition<a class="headerlink" href="#Exmple-of-the-training-index-file-for-repetition" title="Permalink to this headline">¶</a></h3>
<p>For each repeatition, we have to set the training and test set. If the index file is given, the deepbiome library set the training set and test set based on the index file. Below is the example of the index file. Each column has the training indexs for each repeatition. The deepbiome will only use the samples in this index set for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/regression_idx.csv&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">idxs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>490</td>
      <td>690</td>
      <td>62</td>
      <td>703</td>
      <td>690</td>
      <td>845</td>
      <td>150</td>
      <td>268</td>
      <td>488</td>
      <td>179</td>
      <td>...</td>
      <td>675</td>
      <td>886</td>
      <td>225</td>
      <td>222</td>
      <td>781</td>
      <td>778</td>
      <td>603</td>
      <td>222</td>
      <td>254</td>
      <td>407</td>
    </tr>
    <tr>
      <th>1</th>
      <td>498</td>
      <td>968</td>
      <td>123</td>
      <td>913</td>
      <td>348</td>
      <td>262</td>
      <td>705</td>
      <td>239</td>
      <td>632</td>
      <td>44</td>
      <td>...</td>
      <td>636</td>
      <td>216</td>
      <td>495</td>
      <td>557</td>
      <td>196</td>
      <td>516</td>
      <td>23</td>
      <td>351</td>
      <td>472</td>
      <td>945</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389</td>
      <td>999</td>
      <td>335</td>
      <td>947</td>
      <td>215</td>
      <td>696</td>
      <td>793</td>
      <td>349</td>
      <td>734</td>
      <td>624</td>
      <td>...</td>
      <td>626</td>
      <td>230</td>
      <td>26</td>
      <td>330</td>
      <td>470</td>
      <td>992</td>
      <td>329</td>
      <td>532</td>
      <td>655</td>
      <td>426</td>
    </tr>
    <tr>
      <th>3</th>
      <td>51</td>
      <td>139</td>
      <td>843</td>
      <td>491</td>
      <td>47</td>
      <td>421</td>
      <td>892</td>
      <td>32</td>
      <td>438</td>
      <td>996</td>
      <td>...</td>
      <td>956</td>
      <td>706</td>
      <td>836</td>
      <td>151</td>
      <td>80</td>
      <td>409</td>
      <td>671</td>
      <td>772</td>
      <td>882</td>
      <td>181</td>
    </tr>
    <tr>
      <th>4</th>
      <td>592</td>
      <td>83</td>
      <td>204</td>
      <td>810</td>
      <td>198</td>
      <td>955</td>
      <td>357</td>
      <td>125</td>
      <td>190</td>
      <td>162</td>
      <td>...</td>
      <td>542</td>
      <td>108</td>
      <td>959</td>
      <td>311</td>
      <td>771</td>
      <td>902</td>
      <td>986</td>
      <td>481</td>
      <td>922</td>
      <td>305</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V991</th>
      <th>V992</th>
      <th>V993</th>
      <th>V994</th>
      <th>V995</th>
      <th>V996</th>
      <th>V997</th>
      <th>V998</th>
      <th>V999</th>
      <th>V1000</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>745</th>
      <td>599</td>
      <td>824</td>
      <td>997</td>
      <td>216</td>
      <td>586</td>
      <td>796</td>
      <td>806</td>
      <td>39</td>
      <td>483</td>
      <td>518</td>
      <td>...</td>
      <td>573</td>
      <td>861</td>
      <td>366</td>
      <td>374</td>
      <td>585</td>
      <td>871</td>
      <td>140</td>
      <td>597</td>
      <td>795</td>
      <td>743</td>
    </tr>
    <tr>
      <th>746</th>
      <td>720</td>
      <td>633</td>
      <td>821</td>
      <td>149</td>
      <td>339</td>
      <td>461</td>
      <td>750</td>
      <td>194</td>
      <td>769</td>
      <td>699</td>
      <td>...</td>
      <td>913</td>
      <td>570</td>
      <td>670</td>
      <td>249</td>
      <td>840</td>
      <td>889</td>
      <td>242</td>
      <td>959</td>
      <td>791</td>
      <td>954</td>
    </tr>
    <tr>
      <th>747</th>
      <td>80</td>
      <td>268</td>
      <td>661</td>
      <td>187</td>
      <td>929</td>
      <td>469</td>
      <td>481</td>
      <td>332</td>
      <td>781</td>
      <td>615</td>
      <td>...</td>
      <td>985</td>
      <td>459</td>
      <td>965</td>
      <td>888</td>
      <td>461</td>
      <td>551</td>
      <td>465</td>
      <td>827</td>
      <td>557</td>
      <td>662</td>
    </tr>
    <tr>
      <th>748</th>
      <td>570</td>
      <td>32</td>
      <td>750</td>
      <td>332</td>
      <td>902</td>
      <td>107</td>
      <td>281</td>
      <td>667</td>
      <td>917</td>
      <td>793</td>
      <td>...</td>
      <td>924</td>
      <td>662</td>
      <td>975</td>
      <td>199</td>
      <td>32</td>
      <td>715</td>
      <td>668</td>
      <td>241</td>
      <td>299</td>
      <td>518</td>
    </tr>
    <tr>
      <th>749</th>
      <td>440</td>
      <td>589</td>
      <td>607</td>
      <td>597</td>
      <td>380</td>
      <td>961</td>
      <td>747</td>
      <td>396</td>
      <td>649</td>
      <td>974</td>
      <td>...</td>
      <td>867</td>
      <td>839</td>
      <td>234</td>
      <td>99</td>
      <td>901</td>
      <td>19</td>
      <td>821</td>
      <td>450</td>
      <td>780</td>
      <td>326</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1000 columns</p>
</div></div>
</div>
<p>Below is the index set for 1st repetition. From 1000 samples above, it uses 750 samples for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    490
1    498
2    389
3     51
4    592
Name: V1, dtype: int64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>745    599
746    720
747     80
748    570
749    440
Name: V1, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="3.-Prepare-the-configuration">
<h2>3. Prepare the configuration<a class="headerlink" href="#3.-Prepare-the-configuration" title="Permalink to this headline">¶</a></h2>
<p>For detailed configuration, we used python dictionary as inputs for the main training function. You can build the configuration information for the network training by: 1. the python dictionary format 1. the configufation file (.cfg).</p>
<p>In this notebook, we showed the dictionary python dictionary format configuration.</p>
<p>Please check the detailed information about each options in the <a class="reference external" href="https://young-won.github.io/deepbiome/prerequisites.html#configuration">documantation</a></p>
<div class="section" id="For-preparing-the-configuration-about-the-network-information-(network_info)">
<h3>For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-network-information-(network_info)" title="Permalink to this headline">¶</a></h3>
<p>For giving the information about the training hyper-parameter, you have to provide the dictionary for configuration to the <code class="docutils literal notranslate"><span class="pre">netowrk_info</span></code> field. Your configuration for the network training should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;taxa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;50&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="For-preparing-the-configuration-about-the-path-information-(path_info)">
<h3>For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-path-information-(path_info)" title="Permalink to this headline">¶</a></h3>
<p>To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, we provide the dictionary for configuration to the <code class="docutils literal notranslate"><span class="pre">path_info</span></code> feild. Your configuration for the path information should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;hist.json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="4.-DeepBiome-Training">
<h2>4. DeepBiome Training<a class="headerlink" href="#4.-DeepBiome-Training" title="Permalink to this headline">¶</a></h2>
<p>Now we can train the DeepBiome network based on the configurations.</p>
<p>For logging, we use the python logging library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;[</span><span class="si">%(name)-8s</span><span class="s1">|</span><span class="si">%(levelname)s</span><span class="s1">|</span><span class="si">%(filename)s</span><span class="s1">:</span><span class="si">%(lineno)s</span><span class="s1">] </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.</p>
<p>If we set <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code>, then the deepbiome package do the cross-validation based on that value. If not, the deepbiome package do the cross-validation based on the index file. If both <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> option and the index file is not given, then the library do leave-one-out-cross-validation (LOOCV).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 1ms/step - loss: 0.6690 - binary_accuracy: 0.6883 - sensitivity: 0.9944 - specificity: 0.0083 - gmeasure: 0.0255 - auc: 0.5398 - val_loss: 0.6384 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6168
Epoch 2/100
600/600 [==============================] - 0s 213us/step - loss: 0.6296 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5535 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5639
Epoch 3/100
600/600 [==============================] - 0s 224us/step - loss: 0.6222 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5930 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7221
Epoch 4/100
600/600 [==============================] - 0s 199us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7564 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7981
Epoch 5/100
600/600 [==============================] - 0s 200us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7830 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8111
Epoch 6/100
600/600 [==============================] - 0s 173us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7904 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8117
Epoch 7/100
600/600 [==============================] - 0s 224us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7970 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8141
Epoch 8/100
600/600 [==============================] - 0s 215us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8025 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8189
Epoch 9/100
600/600 [==============================] - 0s 208us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8005 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8233
Epoch 10/100
600/600 [==============================] - 0s 214us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8094 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8259
Epoch 11/100
600/600 [==============================] - 0s 221us/step - loss: 0.6215 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8090 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8284
Epoch 12/100
600/600 [==============================] - 0s 214us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8157 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8383
Epoch 13/100
600/600 [==============================] - 0s 207us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8202 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8426
Epoch 14/100
600/600 [==============================] - 0s 211us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8218 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8465
Epoch 15/100
600/600 [==============================] - 0s 217us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8177 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8472
Epoch 16/100
600/600 [==============================] - 0s 215us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8265 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8513
Epoch 17/100
600/600 [==============================] - 0s 210us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8190 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8527
Epoch 18/100
600/600 [==============================] - 0s 208us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8286 - val_loss: 0.6103 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8588
Epoch 19/100
600/600 [==============================] - 0s 194us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8334 - val_loss: 0.6102 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8592
Epoch 20/100
600/600 [==============================] - 0s 210us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8350 - val_loss: 0.6108 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613
Epoch 21/100
600/600 [==============================] - 0s 210us/step - loss: 0.6198 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8393 - val_loss: 0.6100 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8579
Epoch 22/100
600/600 [==============================] - 0s 219us/step - loss: 0.6197 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8338 - val_loss: 0.6101 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8595
Epoch 23/100
600/600 [==============================] - 0s 236us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8329 - val_loss: 0.6093 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8575
Epoch 24/100
600/600 [==============================] - 0s 222us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8333 - val_loss: 0.6096 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8583
Epoch 25/100
600/600 [==============================] - 0s 219us/step - loss: 0.6201 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8283 - val_loss: 0.6086 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8542
Epoch 26/100
600/600 [==============================] - 0s 217us/step - loss: 0.6193 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8290 - val_loss: 0.6099 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8578
Epoch 27/100
600/600 [==============================] - 0s 211us/step - loss: 0.6182 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8333 - val_loss: 0.6082 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8608
Epoch 28/100
600/600 [==============================] - 0s 208us/step - loss: 0.6177 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.6069 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8562
Epoch 29/100
600/600 [==============================] - 0s 219us/step - loss: 0.6174 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8424 - val_loss: 0.6068 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8598
Epoch 30/100
600/600 [==============================] - 0s 209us/step - loss: 0.6152 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8353 - val_loss: 0.6050 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8592
Epoch 31/100
600/600 [==============================] - 0s 214us/step - loss: 0.6140 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8374 - val_loss: 0.6031 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8598
Epoch 32/100
600/600 [==============================] - 0s 227us/step - loss: 0.6125 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8450 - val_loss: 0.6020 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613
Epoch 33/100
600/600 [==============================] - 0s 234us/step - loss: 0.6088 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8366 - val_loss: 0.5978 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8516
Epoch 34/100
600/600 [==============================] - 0s 209us/step - loss: 0.6056 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.5936 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8537
Epoch 35/100
600/600 [==============================] - 0s 226us/step - loss: 0.6006 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8433 - val_loss: 0.5878 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8544
Epoch 36/100
600/600 [==============================] - 0s 217us/step - loss: 0.5929 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8420 - val_loss: 0.5805 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8525
Epoch 37/100
600/600 [==============================] - 0s 213us/step - loss: 0.5854 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8549 - val_loss: 0.5720 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8538
Epoch 38/100
600/600 [==============================] - 0s 214us/step - loss: 0.5723 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8486 - val_loss: 0.5572 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8516
Epoch 39/100
600/600 [==============================] - 0s 222us/step - loss: 0.5568 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8527 - val_loss: 0.5427 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8558
Epoch 40/100
600/600 [==============================] - 0s 215us/step - loss: 0.5398 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8574 - val_loss: 0.5257 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8622
Epoch 41/100
600/600 [==============================] - 0s 219us/step - loss: 0.5238 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8752 - val_loss: 0.5061 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8698
Epoch 42/100
600/600 [==============================] - 0s 215us/step - loss: 0.5123 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8802 - val_loss: 0.5066 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8825
Epoch 43/100
600/600 [==============================] - 0s 207us/step - loss: 0.4857 - binary_accuracy: 0.7233 - sensitivity: 0.9881 - specificity: 0.1467 - gmeasure: 0.3425 - auc: 0.8856 - val_loss: 0.4752 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9907 - val_specificity: 0.2058 - val_gmeasure: 0.4469 - val_auc: 0.8808
Epoch 44/100
600/600 [==============================] - 0s 206us/step - loss: 0.4675 - binary_accuracy: 0.7633 - sensitivity: 0.9811 - specificity: 0.2881 - gmeasure: 0.5206 - auc: 0.8939 - val_loss: 0.4615 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9907 - val_specificity: 0.3028 - val_gmeasure: 0.5470 - val_auc: 0.8886
Epoch 45/100
600/600 [==============================] - 0s 198us/step - loss: 0.4524 - binary_accuracy: 0.7817 - sensitivity: 0.9762 - specificity: 0.3274 - gmeasure: 0.5289 - auc: 0.8992 - val_loss: 0.4666 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9140 - val_specificity: 0.6335 - val_gmeasure: 0.7602 - val_auc: 0.9020
Epoch 46/100
600/600 [==============================] - 0s 213us/step - loss: 0.4537 - binary_accuracy: 0.8117 - sensitivity: 0.9724 - specificity: 0.4768 - gmeasure: 0.6650 - auc: 0.9045 - val_loss: 0.4372 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9422 - val_specificity: 0.4812 - val_gmeasure: 0.6686 - val_auc: 0.9004
Epoch 47/100
600/600 [==============================] - 0s 211us/step - loss: 0.4255 - binary_accuracy: 0.8017 - sensitivity: 0.9714 - specificity: 0.4250 - gmeasure: 0.6320 - auc: 0.9064 - val_loss: 0.4220 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9729 - val_specificity: 0.3634 - val_gmeasure: 0.5922 - val_auc: 0.9039
Epoch 48/100
600/600 [==============================] - 0s 215us/step - loss: 0.4167 - binary_accuracy: 0.8250 - sensitivity: 0.9583 - specificity: 0.5348 - gmeasure: 0.7123 - auc: 0.9173 - val_loss: 0.4102 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9729 - val_specificity: 0.3801 - val_gmeasure: 0.6058 - val_auc: 0.9103
Epoch 49/100
600/600 [==============================] - 0s 209us/step - loss: 0.4021 - binary_accuracy: 0.8267 - sensitivity: 0.9449 - specificity: 0.5452 - gmeasure: 0.7072 - auc: 0.9163 - val_loss: 0.4010 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9251 - val_specificity: 0.5931 - val_gmeasure: 0.7393 - val_auc: 0.9137
Epoch 50/100
600/600 [==============================] - 0s 205us/step - loss: 0.3993 - binary_accuracy: 0.8383 - sensitivity: 0.9508 - specificity: 0.5871 - gmeasure: 0.7392 - auc: 0.9160 - val_loss: 0.3943 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.8969 - val_specificity: 0.6574 - val_gmeasure: 0.7663 - val_auc: 0.9192
Epoch 51/100
600/600 [==============================] - 0s 209us/step - loss: 0.3871 - binary_accuracy: 0.8333 - sensitivity: 0.9415 - specificity: 0.5890 - gmeasure: 0.7390 - auc: 0.9276 - val_loss: 0.3815 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9251 - val_specificity: 0.6169 - val_gmeasure: 0.7534 - val_auc: 0.9172
Epoch 52/100
600/600 [==============================] - 0s 216us/step - loss: 0.3787 - binary_accuracy: 0.8483 - sensitivity: 0.9401 - specificity: 0.6394 - gmeasure: 0.7676 - auc: 0.9261 - val_loss: 0.3747 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9080 - val_specificity: 0.6907 - val_gmeasure: 0.7914 - val_auc: 0.9251
Epoch 53/100
600/600 [==============================] - 0s 214us/step - loss: 0.3687 - binary_accuracy: 0.8367 - sensitivity: 0.9290 - specificity: 0.6507 - gmeasure: 0.7732 - auc: 0.9314 - val_loss: 0.3767 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9251 - val_specificity: 0.4574 - val_gmeasure: 0.6411 - val_auc: 0.9241
Epoch 54/100
600/600 [==============================] - 0s 197us/step - loss: 0.3592 - binary_accuracy: 0.8400 - sensitivity: 0.9273 - specificity: 0.6327 - gmeasure: 0.7581 - auc: 0.9300 - val_loss: 0.3608 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.8772 - val_specificity: 0.7145 - val_gmeasure: 0.7910 - val_auc: 0.9264
Epoch 55/100
600/600 [==============================] - 0s 188us/step - loss: 0.3492 - binary_accuracy: 0.8483 - sensitivity: 0.9290 - specificity: 0.6599 - gmeasure: 0.7753 - auc: 0.9391 - val_loss: 0.3479 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9165 - val_specificity: 0.6574 - val_gmeasure: 0.7742 - val_auc: 0.9321
Epoch 56/100
600/600 [==============================] - 0s 221us/step - loss: 0.3443 - binary_accuracy: 0.8567 - sensitivity: 0.9227 - specificity: 0.7173 - gmeasure: 0.8090 - auc: 0.9401 - val_loss: 0.3430 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9165 - val_specificity: 0.6574 - val_gmeasure: 0.7742 - val_auc: 0.9290
Epoch 57/100
600/600 [==============================] - 0s 215us/step - loss: 0.3318 - binary_accuracy: 0.8633 - sensitivity: 0.9154 - specificity: 0.7479 - gmeasure: 0.8226 - auc: 0.9430 - val_loss: 0.3373 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9165 - val_specificity: 0.6097 - val_gmeasure: 0.7468 - val_auc: 0.9342
Epoch 58/100
600/600 [==============================] - 0s 209us/step - loss: 0.3279 - binary_accuracy: 0.8483 - sensitivity: 0.9173 - specificity: 0.7085 - gmeasure: 0.8023 - auc: 0.9483 - val_loss: 0.3280 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9080 - val_specificity: 0.7383 - val_gmeasure: 0.8164 - val_auc: 0.9307
Epoch 59/100
600/600 [==============================] - 0s 206us/step - loss: 0.3254 - binary_accuracy: 0.8550 - sensitivity: 0.9039 - specificity: 0.7533 - gmeasure: 0.8220 - auc: 0.9454 - val_loss: 0.3389 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8594 - val_specificity: 0.8758 - val_gmeasure: 0.8670 - val_auc: 0.9371
Epoch 60/100
600/600 [==============================] - 0s 200us/step - loss: 0.3154 - binary_accuracy: 0.8667 - sensitivity: 0.8992 - specificity: 0.7986 - gmeasure: 0.8431 - auc: 0.9520 - val_loss: 0.3167 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8772 - val_specificity: 0.8424 - val_gmeasure: 0.8590 - val_auc: 0.9374
Epoch 61/100
600/600 [==============================] - 0s 212us/step - loss: 0.3051 - binary_accuracy: 0.8733 - sensitivity: 0.9270 - specificity: 0.7445 - gmeasure: 0.8243 - auc: 0.9523 - val_loss: 0.3434 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8409 - val_specificity: 0.9061 - val_gmeasure: 0.8725 - val_auc: 0.9419
Epoch 62/100
600/600 [==============================] - 0s 218us/step - loss: 0.2966 - binary_accuracy: 0.8817 - sensitivity: 0.9148 - specificity: 0.7833 - gmeasure: 0.8423 - auc: 0.9521 - val_loss: 0.3157 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9336 - val_specificity: 0.6812 - val_gmeasure: 0.7942 - val_auc: 0.9416
Epoch 63/100
600/600 [==============================] - 0s 213us/step - loss: 0.2981 - binary_accuracy: 0.8683 - sensitivity: 0.9152 - specificity: 0.7672 - gmeasure: 0.8341 - auc: 0.9581 - val_loss: 0.3033 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9165 - val_specificity: 0.7686 - val_gmeasure: 0.8372 - val_auc: 0.9443
Epoch 64/100
600/600 [==============================] - 0s 219us/step - loss: 0.2839 - binary_accuracy: 0.8800 - sensitivity: 0.9119 - specificity: 0.8002 - gmeasure: 0.8515 - auc: 0.9546 - val_loss: 0.3109 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8765 - val_specificity: 0.9061 - val_gmeasure: 0.8909 - val_auc: 0.9440
Epoch 65/100
600/600 [==============================] - 0s 218us/step - loss: 0.2814 - binary_accuracy: 0.8800 - sensitivity: 0.9116 - specificity: 0.8054 - gmeasure: 0.8546 - auc: 0.9603 - val_loss: 0.2953 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8772 - val_specificity: 0.8591 - val_gmeasure: 0.8675 - val_auc: 0.9439
Epoch 66/100
600/600 [==============================] - 0s 192us/step - loss: 0.2728 - binary_accuracy: 0.8883 - sensitivity: 0.9136 - specificity: 0.8277 - gmeasure: 0.8679 - auc: 0.9611 - val_loss: 0.2916 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9336 - val_specificity: 0.7686 - val_gmeasure: 0.8449 - val_auc: 0.9451
Epoch 67/100
600/600 [==============================] - 0s 204us/step - loss: 0.2692 - binary_accuracy: 0.8900 - sensitivity: 0.9139 - specificity: 0.8264 - gmeasure: 0.8674 - auc: 0.9658 - val_loss: 0.2837 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9251 - val_specificity: 0.8091 - val_gmeasure: 0.8627 - val_auc: 0.9461
Epoch 68/100
600/600 [==============================] - 0s 211us/step - loss: 0.2741 - binary_accuracy: 0.8867 - sensitivity: 0.9255 - specificity: 0.8027 - gmeasure: 0.8578 - auc: 0.9586 - val_loss: 0.2824 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9336 - val_specificity: 0.7853 - val_gmeasure: 0.8547 - val_auc: 0.9463
Epoch 69/100
600/600 [==============================] - 0s 214us/step - loss: 0.2578 - binary_accuracy: 0.8933 - sensitivity: 0.9090 - specificity: 0.8492 - gmeasure: 0.8759 - auc: 0.9650 - val_loss: 0.2818 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9165 - val_specificity: 0.8758 - val_gmeasure: 0.8949 - val_auc: 0.9478
Epoch 70/100
600/600 [==============================] - 0s 217us/step - loss: 0.2569 - binary_accuracy: 0.9017 - sensitivity: 0.9233 - specificity: 0.8562 - gmeasure: 0.8878 - auc: 0.9638 - val_loss: 0.2839 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8765 - val_specificity: 0.9061 - val_gmeasure: 0.8909 - val_auc: 0.9433
Epoch 71/100
600/600 [==============================] - 0s 207us/step - loss: 0.2619 - binary_accuracy: 0.8967 - sensitivity: 0.9278 - specificity: 0.8326 - gmeasure: 0.8744 - auc: 0.9655 - val_loss: 0.2741 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9336 - val_specificity: 0.8424 - val_gmeasure: 0.8851 - val_auc: 0.9456
Epoch 72/100
600/600 [==============================] - 0s 215us/step - loss: 0.2480 - binary_accuracy: 0.9100 - sensitivity: 0.9171 - specificity: 0.8901 - gmeasure: 0.9018 - auc: 0.9674 - val_loss: 0.2709 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9165 - val_specificity: 0.8758 - val_gmeasure: 0.8949 - val_auc: 0.9468
Epoch 73/100
600/600 [==============================] - 0s 219us/step - loss: 0.2455 - binary_accuracy: 0.9083 - sensitivity: 0.9275 - specificity: 0.8660 - gmeasure: 0.8940 - auc: 0.9667 - val_loss: 0.2845 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8672 - val_specificity: 0.9061 - val_gmeasure: 0.8860 - val_auc: 0.9445
Epoch 74/100
600/600 [==============================] - 0s 202us/step - loss: 0.2418 - binary_accuracy: 0.9100 - sensitivity: 0.9232 - specificity: 0.8816 - gmeasure: 0.9004 - auc: 0.9693 - val_loss: 0.2713 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9422 - val_specificity: 0.8258 - val_gmeasure: 0.8797 - val_auc: 0.9471
Epoch 75/100
600/600 [==============================] - 0s 208us/step - loss: 0.2432 - binary_accuracy: 0.9000 - sensitivity: 0.9340 - specificity: 0.8299 - gmeasure: 0.8760 - auc: 0.9685 - val_loss: 0.2996 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8309 - val_specificity: 0.9364 - val_gmeasure: 0.8815 - val_auc: 0.9515
Epoch 76/100
600/600 [==============================] - 0s 209us/step - loss: 0.2546 - binary_accuracy: 0.9000 - sensitivity: 0.9151 - specificity: 0.8703 - gmeasure: 0.8897 - auc: 0.9670 - val_loss: 0.2830 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9061 - val_gmeasure: 0.8958 - val_auc: 0.9477
Epoch 77/100
600/600 [==============================] - 0s 203us/step - loss: 0.2350 - binary_accuracy: 0.9133 - sensitivity: 0.9206 - specificity: 0.8857 - gmeasure: 0.9004 - auc: 0.9686 - val_loss: 0.2633 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9336 - val_specificity: 0.8591 - val_gmeasure: 0.8940 - val_auc: 0.9501
Epoch 78/100
600/600 [==============================] - 0s 214us/step - loss: 0.2271 - binary_accuracy: 0.9150 - sensitivity: 0.9284 - specificity: 0.8901 - gmeasure: 0.9077 - auc: 0.9731 - val_loss: 0.2613 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9251 - val_specificity: 0.8591 - val_gmeasure: 0.8901 - val_auc: 0.9461
Epoch 79/100
600/600 [==============================] - 0s 211us/step - loss: 0.2299 - binary_accuracy: 0.9083 - sensitivity: 0.9304 - specificity: 0.8700 - gmeasure: 0.8986 - auc: 0.9708 - val_loss: 0.2588 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9336 - val_specificity: 0.8591 - val_gmeasure: 0.8940 - val_auc: 0.9524
Epoch 80/100
600/600 [==============================] - 0s 212us/step - loss: 0.2303 - binary_accuracy: 0.9133 - sensitivity: 0.9205 - specificity: 0.8981 - gmeasure: 0.9080 - auc: 0.9691 - val_loss: 0.2665 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9422 - val_specificity: 0.8258 - val_gmeasure: 0.8797 - val_auc: 0.9460
Epoch 81/100
600/600 [==============================] - 0s 219us/step - loss: 0.2187 - binary_accuracy: 0.9167 - sensitivity: 0.9238 - specificity: 0.9055 - gmeasure: 0.9131 - auc: 0.9747 - val_loss: 0.2605 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9251 - val_specificity: 0.8591 - val_gmeasure: 0.8901 - val_auc: 0.9510
Epoch 82/100
600/600 [==============================] - 0s 212us/step - loss: 0.2190 - binary_accuracy: 0.9250 - sensitivity: 0.9284 - specificity: 0.9189 - gmeasure: 0.9222 - auc: 0.9756 - val_loss: 0.2642 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9514 - val_specificity: 0.8424 - val_gmeasure: 0.8936 - val_auc: 0.9480
Epoch 83/100
600/600 [==============================] - 0s 206us/step - loss: 0.2197 - binary_accuracy: 0.9183 - sensitivity: 0.9275 - specificity: 0.9022 - gmeasure: 0.9138 - auc: 0.9721 - val_loss: 0.2615 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9499
Epoch 84/100
600/600 [==============================] - 0s 209us/step - loss: 0.2264 - binary_accuracy: 0.9233 - sensitivity: 0.9312 - specificity: 0.9095 - gmeasure: 0.9183 - auc: 0.9719 - val_loss: 0.2785 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9514 - val_specificity: 0.8091 - val_gmeasure: 0.8750 - val_auc: 0.9472
Epoch 85/100
600/600 [==============================] - 0s 199us/step - loss: 0.2255 - binary_accuracy: 0.9133 - sensitivity: 0.9326 - specificity: 0.8735 - gmeasure: 0.8988 - auc: 0.9727 - val_loss: 0.2548 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9140 - val_specificity: 0.8591 - val_gmeasure: 0.8848 - val_auc: 0.9537
Epoch 86/100
600/600 [==============================] - 0s 208us/step - loss: 0.2069 - binary_accuracy: 0.9200 - sensitivity: 0.9316 - specificity: 0.9040 - gmeasure: 0.9165 - auc: 0.9761 - val_loss: 0.2567 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8591 - val_gmeasure: 0.8987 - val_auc: 0.9522
Epoch 87/100
600/600 [==============================] - 0s 207us/step - loss: 0.2065 - binary_accuracy: 0.9233 - sensitivity: 0.9314 - specificity: 0.9094 - gmeasure: 0.9196 - auc: 0.9704 - val_loss: 0.2651 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9514 - val_specificity: 0.8424 - val_gmeasure: 0.8936 - val_auc: 0.9485
Epoch 88/100
600/600 [==============================] - 0s 216us/step - loss: 0.2069 - binary_accuracy: 0.9317 - sensitivity: 0.9397 - specificity: 0.9171 - gmeasure: 0.9267 - auc: 0.9754 - val_loss: 0.2620 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9514 - val_specificity: 0.8258 - val_gmeasure: 0.8844 - val_auc: 0.9506
Epoch 89/100
600/600 [==============================] - 0s 193us/step - loss: 0.2055 - binary_accuracy: 0.9283 - sensitivity: 0.9325 - specificity: 0.9242 - gmeasure: 0.9266 - auc: 0.9779 - val_loss: 0.2611 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9486
Epoch 90/100
600/600 [==============================] - 0s 207us/step - loss: 0.2026 - binary_accuracy: 0.9250 - sensitivity: 0.9321 - specificity: 0.9055 - gmeasure: 0.9175 - auc: 0.9689 - val_loss: 0.2526 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8591 - val_gmeasure: 0.8987 - val_auc: 0.9548
Epoch 91/100
600/600 [==============================] - 0s 201us/step - loss: 0.2048 - binary_accuracy: 0.9217 - sensitivity: 0.9197 - specificity: 0.9221 - gmeasure: 0.9197 - auc: 0.9728 - val_loss: 0.2548 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9343 - val_specificity: 0.8591 - val_gmeasure: 0.8949 - val_auc: 0.9497
Epoch 92/100
600/600 [==============================] - 0s 209us/step - loss: 0.1990 - binary_accuracy: 0.9267 - sensitivity: 0.9331 - specificity: 0.9066 - gmeasure: 0.9190 - auc: 0.9719 - val_loss: 0.2576 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8962 - val_specificity: 0.8894 - val_gmeasure: 0.8922 - val_auc: 0.9526
Epoch 93/100
600/600 [==============================] - 0s 213us/step - loss: 0.1944 - binary_accuracy: 0.9300 - sensitivity: 0.9365 - specificity: 0.9213 - gmeasure: 0.9283 - auc: 0.9768 - val_loss: 0.2484 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9336 - val_specificity: 0.8894 - val_gmeasure: 0.9105 - val_auc: 0.9553
Epoch 94/100
600/600 [==============================] - 0s 222us/step - loss: 0.1980 - binary_accuracy: 0.9283 - sensitivity: 0.9348 - specificity: 0.9209 - gmeasure: 0.9264 - auc: 0.9779 - val_loss: 0.2593 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9522
Epoch 95/100
600/600 [==============================] - 0s 216us/step - loss: 0.2210 - binary_accuracy: 0.9267 - sensitivity: 0.9297 - specificity: 0.9257 - gmeasure: 0.9249 - auc: 0.9750 - val_loss: 0.2574 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9505
Epoch 96/100
600/600 [==============================] - 0s 222us/step - loss: 0.2135 - binary_accuracy: 0.9200 - sensitivity: 0.9329 - specificity: 0.8973 - gmeasure: 0.9137 - auc: 0.9736 - val_loss: 0.2521 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9336 - val_specificity: 0.8894 - val_gmeasure: 0.9105 - val_auc: 0.9521
Epoch 97/100
600/600 [==============================] - 0s 212us/step - loss: 0.1901 - binary_accuracy: 0.9300 - sensitivity: 0.9454 - specificity: 0.8897 - gmeasure: 0.9158 - auc: 0.9756 - val_loss: 0.2683 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8776 - val_specificity: 0.9197 - val_gmeasure: 0.8976 - val_auc: 0.9517
Epoch 98/100
600/600 [==============================] - 0s 215us/step - loss: 0.1866 - binary_accuracy: 0.9300 - sensitivity: 0.9390 - specificity: 0.9139 - gmeasure: 0.9258 - auc: 0.9769 - val_loss: 0.2504 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9047 - val_specificity: 0.8894 - val_gmeasure: 0.8963 - val_auc: 0.9532
Epoch 99/100
600/600 [==============================] - 0s 219us/step - loss: 0.1896 - binary_accuracy: 0.9317 - sensitivity: 0.9382 - specificity: 0.9265 - gmeasure: 0.9308 - auc: 0.9765 - val_loss: 0.2567 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9197 - val_gmeasure: 0.9026 - val_auc: 0.9495
Epoch 100/100
600/600 [==============================] - 0s 216us/step - loss: 0.1857 - binary_accuracy: 0.9333 - sensitivity: 0.9434 - specificity: 0.9220 - gmeasure: 0.9315 - auc: 0.9770 - val_loss: 0.2595 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9197 - val_gmeasure: 0.9026 - val_auc: 0.9500
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 15.505073070526123!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.012549400329589844!
[root    |INFO|build_network.py:175] Evaluation: [0.2006135731935501, 0.9306666851043701, 0.9169884324073792, 0.9612069129943848, 0.9388373494148254, 0.9727108478546143]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 26us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.01367950439453125!
[root    |INFO|build_network.py:175] Evaluation: [0.21072882413864136, 0.9359999895095825, 0.9349112510681152, 0.9382715821266174, 0.9365898966789246, 0.9612827897071838]
[root    |INFO|deepbiome.py:179] Compute time : 18.371322631835938
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 890us/step - loss: 0.6784 - binary_accuracy: 0.7050 - sensitivity: 0.9310 - specificity: 0.0833 - gmeasure: 0.0345 - auc: 0.5210 - val_loss: 0.6558 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5565
Epoch 2/100
600/600 [==============================] - 0s 219us/step - loss: 0.6342 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4836 - val_loss: 0.6088 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4704
Epoch 3/100
600/600 [==============================] - 0s 211us/step - loss: 0.5920 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5116 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5116
Epoch 4/100
600/600 [==============================] - 0s 214us/step - loss: 0.5899 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5532 - val_loss: 0.5900 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5864
Epoch 5/100
600/600 [==============================] - 0s 210us/step - loss: 0.5859 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7038 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8023
Epoch 6/100
600/600 [==============================] - 0s 210us/step - loss: 0.5860 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7640 - val_loss: 0.5868 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7640
Epoch 7/100
600/600 [==============================] - 0s 214us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7522 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7517
Epoch 8/100
600/600 [==============================] - 0s 217us/step - loss: 0.5861 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7388 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7498
Epoch 9/100
600/600 [==============================] - 0s 227us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7436 - val_loss: 0.5863 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7520
Epoch 10/100
600/600 [==============================] - 0s 210us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7484 - val_loss: 0.5862 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7565
Epoch 11/100
600/600 [==============================] - 0s 206us/step - loss: 0.5854 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7360 - val_loss: 0.5862 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7638
Epoch 12/100
600/600 [==============================] - 0s 211us/step - loss: 0.5847 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7491 - val_loss: 0.5860 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7739
Epoch 13/100
600/600 [==============================] - 0s 215us/step - loss: 0.5853 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7552 - val_loss: 0.5860 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7820
Epoch 14/100
600/600 [==============================] - 0s 220us/step - loss: 0.5849 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7757 - val_loss: 0.5858 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7952
Epoch 15/100
600/600 [==============================] - 0s 203us/step - loss: 0.5859 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7914 - val_loss: 0.5861 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8043
Epoch 16/100
600/600 [==============================] - 0s 206us/step - loss: 0.5840 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7954 - val_loss: 0.5849 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8113
Epoch 17/100
600/600 [==============================] - 0s 216us/step - loss: 0.5836 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8057 - val_loss: 0.5843 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8360
Epoch 18/100
600/600 [==============================] - 0s 216us/step - loss: 0.5826 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8149 - val_loss: 0.5834 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8452
Epoch 19/100
600/600 [==============================] - 0s 215us/step - loss: 0.5819 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8345 - val_loss: 0.5820 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8507
Epoch 20/100
600/600 [==============================] - 0s 218us/step - loss: 0.5803 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8313 - val_loss: 0.5801 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8609
Epoch 21/100
600/600 [==============================] - 0s 213us/step - loss: 0.5790 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8440 - val_loss: 0.5778 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8605
Epoch 22/100
600/600 [==============================] - 0s 217us/step - loss: 0.5762 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8383 - val_loss: 0.5749 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8575
Epoch 23/100
600/600 [==============================] - 0s 218us/step - loss: 0.5743 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8421 - val_loss: 0.5720 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8615
Epoch 24/100
600/600 [==============================] - 0s 223us/step - loss: 0.5701 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8538 - val_loss: 0.5674 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8604
Epoch 25/100
600/600 [==============================] - 0s 213us/step - loss: 0.5662 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8502 - val_loss: 0.5625 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8615
Epoch 26/100
600/600 [==============================] - 0s 200us/step - loss: 0.5606 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8504 - val_loss: 0.5569 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8600
Epoch 27/100
600/600 [==============================] - 0s 206us/step - loss: 0.5553 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8527 - val_loss: 0.5488 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8614
Epoch 28/100
600/600 [==============================] - 0s 221us/step - loss: 0.5493 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8585 - val_loss: 0.5415 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613
Epoch 29/100
600/600 [==============================] - 0s 219us/step - loss: 0.5396 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8571 - val_loss: 0.5305 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8633
Epoch 30/100
600/600 [==============================] - 0s 211us/step - loss: 0.5312 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8555 - val_loss: 0.5199 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8647
Epoch 31/100
600/600 [==============================] - 0s 224us/step - loss: 0.5195 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8519 - val_loss: 0.5071 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8647
Epoch 32/100
600/600 [==============================] - 0s 221us/step - loss: 0.5081 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8561 - val_loss: 0.4951 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8681
Epoch 33/100
600/600 [==============================] - 0s 212us/step - loss: 0.4969 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8691 - val_loss: 0.4825 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8661
Epoch 34/100
600/600 [==============================] - 0s 219us/step - loss: 0.4887 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8666 - val_loss: 0.4720 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8720
Epoch 35/100
600/600 [==============================] - 0s 216us/step - loss: 0.4804 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8600 - val_loss: 0.4632 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8715
Epoch 36/100
600/600 [==============================] - 0s 224us/step - loss: 0.4750 - binary_accuracy: 0.7317 - sensitivity: 1.0000 - specificity: 0.0185 - gmeasure: 0.0393 - auc: 0.8815 - val_loss: 0.4559 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9642 - val_specificity: 0.3365 - val_gmeasure: 0.5667 - val_auc: 0.8769
Epoch 37/100
600/600 [==============================] - 0s 210us/step - loss: 0.4593 - binary_accuracy: 0.7783 - sensitivity: 0.9423 - specificity: 0.3399 - gmeasure: 0.5567 - auc: 0.8724 - val_loss: 0.4488 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9284 - val_specificity: 0.3365 - val_gmeasure: 0.5556 - val_auc: 0.8765
Epoch 38/100
600/600 [==============================] - 0s 208us/step - loss: 0.4518 - binary_accuracy: 0.7883 - sensitivity: 0.9571 - specificity: 0.3397 - gmeasure: 0.5632 - auc: 0.8839 - val_loss: 0.4387 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9642 - val_specificity: 0.3365 - val_gmeasure: 0.5667 - val_auc: 0.8829
Epoch 39/100
600/600 [==============================] - 0s 214us/step - loss: 0.4393 - binary_accuracy: 0.7917 - sensitivity: 0.9551 - specificity: 0.3521 - gmeasure: 0.5718 - auc: 0.8855 - val_loss: 0.4298 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9732 - val_specificity: 0.3365 - val_gmeasure: 0.5696 - val_auc: 0.8867
Epoch 40/100
600/600 [==============================] - 0s 213us/step - loss: 0.4300 - binary_accuracy: 0.8017 - sensitivity: 0.9641 - specificity: 0.3708 - gmeasure: 0.5853 - auc: 0.8918 - val_loss: 0.4197 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9454 - val_specificity: 0.4177 - val_gmeasure: 0.6273 - val_auc: 0.8909
Epoch 41/100
600/600 [==============================] - 0s 208us/step - loss: 0.4209 - binary_accuracy: 0.7983 - sensitivity: 0.9437 - specificity: 0.4363 - gmeasure: 0.6316 - auc: 0.9023 - val_loss: 0.4108 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9544 - val_specificity: 0.4177 - val_gmeasure: 0.6305 - val_auc: 0.8945
Epoch 42/100
600/600 [==============================] - 0s 209us/step - loss: 0.4084 - binary_accuracy: 0.8150 - sensitivity: 0.9491 - specificity: 0.4591 - gmeasure: 0.6491 - auc: 0.9022 - val_loss: 0.4005 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9544 - val_specificity: 0.4434 - val_gmeasure: 0.6479 - val_auc: 0.9012
Epoch 43/100
600/600 [==============================] - 0s 209us/step - loss: 0.3975 - binary_accuracy: 0.8267 - sensitivity: 0.9400 - specificity: 0.5262 - gmeasure: 0.6990 - auc: 0.8982 - val_loss: 0.3888 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9544 - val_specificity: 0.4434 - val_gmeasure: 0.6479 - val_auc: 0.9124
Epoch 44/100
600/600 [==============================] - 0s 222us/step - loss: 0.3842 - binary_accuracy: 0.8450 - sensitivity: 0.9700 - specificity: 0.5077 - gmeasure: 0.6984 - auc: 0.9144 - val_loss: 0.3768 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9544 - val_specificity: 0.4920 - val_gmeasure: 0.6843 - val_auc: 0.9189
Epoch 45/100
600/600 [==============================] - 0s 215us/step - loss: 0.3744 - binary_accuracy: 0.8450 - sensitivity: 0.9541 - specificity: 0.5337 - gmeasure: 0.7044 - auc: 0.9206 - val_loss: 0.3747 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9724 - val_specificity: 0.3691 - val_gmeasure: 0.5969 - val_auc: 0.9256
Epoch 46/100
600/600 [==============================] - 0s 215us/step - loss: 0.3630 - binary_accuracy: 0.8517 - sensitivity: 0.9611 - specificity: 0.5453 - gmeasure: 0.7203 - auc: 0.9261 - val_loss: 0.3540 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9634 - val_specificity: 0.5176 - val_gmeasure: 0.7041 - val_auc: 0.9374
Epoch 47/100
600/600 [==============================] - 0s 206us/step - loss: 0.3551 - binary_accuracy: 0.8550 - sensitivity: 0.9595 - specificity: 0.5893 - gmeasure: 0.7470 - auc: 0.9405 - val_loss: 0.3461 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9274 - val_specificity: 0.6565 - val_gmeasure: 0.7802 - val_auc: 0.9361
Epoch 48/100
600/600 [==============================] - 0s 214us/step - loss: 0.3448 - binary_accuracy: 0.8583 - sensitivity: 0.9548 - specificity: 0.6041 - gmeasure: 0.7535 - auc: 0.9382 - val_loss: 0.3373 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9634 - val_specificity: 0.5176 - val_gmeasure: 0.7041 - val_auc: 0.9419
Epoch 49/100
600/600 [==============================] - 0s 213us/step - loss: 0.3320 - binary_accuracy: 0.8667 - sensitivity: 0.9519 - specificity: 0.6274 - gmeasure: 0.7663 - auc: 0.9431 - val_loss: 0.3245 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9634 - val_specificity: 0.5662 - val_gmeasure: 0.7377 - val_auc: 0.9469
Epoch 50/100
600/600 [==============================] - 0s 223us/step - loss: 0.3225 - binary_accuracy: 0.8733 - sensitivity: 0.9579 - specificity: 0.6284 - gmeasure: 0.7721 - auc: 0.9475 - val_loss: 0.3174 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9364 - val_specificity: 0.7147 - val_gmeasure: 0.8164 - val_auc: 0.9524
Epoch 51/100
600/600 [==============================] - 0s 214us/step - loss: 0.3205 - binary_accuracy: 0.8783 - sensitivity: 0.9536 - specificity: 0.6726 - gmeasure: 0.7954 - auc: 0.9538 - val_loss: 0.3043 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9552
Epoch 52/100
600/600 [==============================] - 0s 203us/step - loss: 0.3067 - binary_accuracy: 0.8817 - sensitivity: 0.9488 - specificity: 0.7146 - gmeasure: 0.8197 - auc: 0.9527 - val_loss: 0.2988 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9544 - val_specificity: 0.6384 - val_gmeasure: 0.7778 - val_auc: 0.9592
Epoch 53/100
600/600 [==============================] - 0s 216us/step - loss: 0.2995 - binary_accuracy: 0.8850 - sensitivity: 0.9614 - specificity: 0.6787 - gmeasure: 0.8047 - auc: 0.9531 - val_loss: 0.2994 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9544 - val_specificity: 0.5849 - val_gmeasure: 0.7447 - val_auc: 0.9619
Epoch 54/100
600/600 [==============================] - 0s 191us/step - loss: 0.2889 - binary_accuracy: 0.8900 - sensitivity: 0.9617 - specificity: 0.6971 - gmeasure: 0.8166 - auc: 0.9556 - val_loss: 0.2826 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9653
Epoch 55/100
600/600 [==============================] - 0s 194us/step - loss: 0.2883 - binary_accuracy: 0.8850 - sensitivity: 0.9535 - specificity: 0.6918 - gmeasure: 0.8073 - auc: 0.9559 - val_loss: 0.2861 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9364 - val_specificity: 0.8632 - val_gmeasure: 0.8971 - val_auc: 0.9631
Epoch 56/100
600/600 [==============================] - 0s 212us/step - loss: 0.2786 - binary_accuracy: 0.8917 - sensitivity: 0.9550 - specificity: 0.7134 - gmeasure: 0.8214 - auc: 0.9633 - val_loss: 0.2725 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9693
Epoch 57/100
600/600 [==============================] - 0s 210us/step - loss: 0.2812 - binary_accuracy: 0.8933 - sensitivity: 0.9579 - specificity: 0.7148 - gmeasure: 0.8204 - auc: 0.9644 - val_loss: 0.2665 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9544 - val_specificity: 0.7147 - val_gmeasure: 0.8247 - val_auc: 0.9714
Epoch 58/100
600/600 [==============================] - 0s 221us/step - loss: 0.2754 - binary_accuracy: 0.8983 - sensitivity: 0.9388 - specificity: 0.7555 - gmeasure: 0.8243 - auc: 0.9661 - val_loss: 0.3071 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9912 - val_specificity: 0.4738 - val_gmeasure: 0.6760 - val_auc: 0.9713
Epoch 59/100
600/600 [==============================] - 0s 220us/step - loss: 0.2712 - binary_accuracy: 0.8967 - sensitivity: 0.9535 - specificity: 0.7490 - gmeasure: 0.8408 - auc: 0.9665 - val_loss: 0.2582 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9677
Epoch 60/100
600/600 [==============================] - 0s 214us/step - loss: 0.2565 - binary_accuracy: 0.8950 - sensitivity: 0.9620 - specificity: 0.7356 - gmeasure: 0.8383 - auc: 0.9714 - val_loss: 0.2523 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9728
Epoch 61/100
600/600 [==============================] - 0s 206us/step - loss: 0.2530 - binary_accuracy: 0.9050 - sensitivity: 0.9471 - specificity: 0.8068 - gmeasure: 0.8715 - auc: 0.9678 - val_loss: 0.2582 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9544 - val_specificity: 0.6592 - val_gmeasure: 0.7911 - val_auc: 0.9748
Epoch 62/100
600/600 [==============================] - 0s 216us/step - loss: 0.2407 - binary_accuracy: 0.9067 - sensitivity: 0.9567 - specificity: 0.7623 - gmeasure: 0.8522 - auc: 0.9686 - val_loss: 0.2441 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9735
Epoch 63/100
600/600 [==============================] - 0s 211us/step - loss: 0.2347 - binary_accuracy: 0.9117 - sensitivity: 0.9522 - specificity: 0.7948 - gmeasure: 0.8683 - auc: 0.9721 - val_loss: 0.2553 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9732 - val_specificity: 0.6592 - val_gmeasure: 0.7991 - val_auc: 0.9754
Epoch 64/100
600/600 [==============================] - 0s 208us/step - loss: 0.2344 - binary_accuracy: 0.9083 - sensitivity: 0.9587 - specificity: 0.7691 - gmeasure: 0.8535 - auc: 0.9729 - val_loss: 0.2377 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9756
Epoch 65/100
600/600 [==============================] - 0s 213us/step - loss: 0.2251 - binary_accuracy: 0.9200 - sensitivity: 0.9591 - specificity: 0.8128 - gmeasure: 0.8823 - auc: 0.9723 - val_loss: 0.2415 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9642 - val_specificity: 0.7078 - val_gmeasure: 0.8252 - val_auc: 0.9760
Epoch 66/100
600/600 [==============================] - 0s 216us/step - loss: 0.2239 - binary_accuracy: 0.9267 - sensitivity: 0.9547 - specificity: 0.8505 - gmeasure: 0.8991 - auc: 0.9715 - val_loss: 0.2419 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9634 - val_specificity: 0.7682 - val_gmeasure: 0.8581 - val_auc: 0.9761
Epoch 67/100
600/600 [==============================] - 0s 216us/step - loss: 0.2237 - binary_accuracy: 0.9117 - sensitivity: 0.9548 - specificity: 0.8069 - gmeasure: 0.8758 - auc: 0.9726 - val_loss: 0.2329 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9755
Epoch 68/100
600/600 [==============================] - 0s 215us/step - loss: 0.2121 - binary_accuracy: 0.9150 - sensitivity: 0.9636 - specificity: 0.7811 - gmeasure: 0.8658 - auc: 0.9734 - val_loss: 0.2259 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9776
Epoch 69/100
600/600 [==============================] - 0s 209us/step - loss: 0.2106 - binary_accuracy: 0.9250 - sensitivity: 0.9606 - specificity: 0.8123 - gmeasure: 0.8798 - auc: 0.9725 - val_loss: 0.2329 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9788
Epoch 70/100
600/600 [==============================] - 0s 214us/step - loss: 0.2062 - binary_accuracy: 0.9250 - sensitivity: 0.9571 - specificity: 0.8361 - gmeasure: 0.8908 - auc: 0.9756 - val_loss: 0.2299 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9781
Epoch 71/100
600/600 [==============================] - ETA: 0s - loss: 0.2004 - binary_accuracy: 0.9286 - sensitivity: 0.9646 - specificity: 0.8246 - gmeasure: 0.8898 - auc: 0.97 - 0s 207us/step - loss: 0.2043 - binary_accuracy: 0.9200 - sensitivity: 0.9604 - specificity: 0.8132 - gmeasure: 0.8818 - auc: 0.9775 - val_loss: 0.2215 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9776
Epoch 72/100
600/600 [==============================] - 0s 213us/step - loss: 0.1976 - binary_accuracy: 0.9300 - sensitivity: 0.9517 - specificity: 0.8658 - gmeasure: 0.9056 - auc: 0.9744 - val_loss: 0.2192 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9802
Epoch 73/100
600/600 [==============================] - 0s 218us/step - loss: 0.1942 - binary_accuracy: 0.9267 - sensitivity: 0.9627 - specificity: 0.8286 - gmeasure: 0.8900 - auc: 0.9771 - val_loss: 0.2135 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9782
Epoch 74/100
600/600 [==============================] - 0s 206us/step - loss: 0.1919 - binary_accuracy: 0.9233 - sensitivity: 0.9572 - specificity: 0.8431 - gmeasure: 0.8971 - auc: 0.9765 - val_loss: 0.2157 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9795
Epoch 75/100
600/600 [==============================] - 0s 202us/step - loss: 0.1890 - binary_accuracy: 0.9333 - sensitivity: 0.9591 - specificity: 0.8641 - gmeasure: 0.9088 - auc: 0.9762 - val_loss: 0.2095 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9796
Epoch 76/100
600/600 [==============================] - 0s 217us/step - loss: 0.1886 - binary_accuracy: 0.9317 - sensitivity: 0.9607 - specificity: 0.8520 - gmeasure: 0.9031 - auc: 0.9778 - val_loss: 0.2083 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9751
Epoch 77/100
600/600 [==============================] - 0s 214us/step - loss: 0.1816 - binary_accuracy: 0.9383 - sensitivity: 0.9639 - specificity: 0.8655 - gmeasure: 0.9127 - auc: 0.9783 - val_loss: 0.2159 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9809
Epoch 78/100
600/600 [==============================] - 0s 209us/step - loss: 0.1814 - binary_accuracy: 0.9367 - sensitivity: 0.9583 - specificity: 0.8808 - gmeasure: 0.9175 - auc: 0.9791 - val_loss: 0.2080 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9809
Epoch 79/100
600/600 [==============================] - 0s 211us/step - loss: 0.1758 - binary_accuracy: 0.9333 - sensitivity: 0.9632 - specificity: 0.8505 - gmeasure: 0.9032 - auc: 0.9782 - val_loss: 0.2006 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9809
Epoch 80/100
600/600 [==============================] - 0s 224us/step - loss: 0.1780 - binary_accuracy: 0.9317 - sensitivity: 0.9524 - specificity: 0.8614 - gmeasure: 0.9034 - auc: 0.9794 - val_loss: 0.2038 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9816
Epoch 81/100
600/600 [==============================] - 0s 214us/step - loss: 0.1742 - binary_accuracy: 0.9400 - sensitivity: 0.9611 - specificity: 0.8932 - gmeasure: 0.9252 - auc: 0.9790 - val_loss: 0.2008 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816
Epoch 82/100
600/600 [==============================] - 0s 224us/step - loss: 0.1743 - binary_accuracy: 0.9400 - sensitivity: 0.9528 - specificity: 0.9061 - gmeasure: 0.9278 - auc: 0.9806 - val_loss: 0.2081 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9816
Epoch 83/100
600/600 [==============================] - 0s 223us/step - loss: 0.1701 - binary_accuracy: 0.9467 - sensitivity: 0.9610 - specificity: 0.9224 - gmeasure: 0.9405 - auc: 0.9798 - val_loss: 0.1970 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816
Epoch 84/100
600/600 [==============================] - 0s 207us/step - loss: 0.1657 - binary_accuracy: 0.9450 - sensitivity: 0.9634 - specificity: 0.8998 - gmeasure: 0.9306 - auc: 0.9817 - val_loss: 0.1994 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9816
Epoch 85/100
600/600 [==============================] - 0s 225us/step - loss: 0.1684 - binary_accuracy: 0.9433 - sensitivity: 0.9668 - specificity: 0.8942 - gmeasure: 0.9280 - auc: 0.9794 - val_loss: 0.1975 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9274 - val_specificity: 0.9049 - val_gmeasure: 0.9152 - val_auc: 0.9791
Epoch 86/100
600/600 [==============================] - 0s 211us/step - loss: 0.1687 - binary_accuracy: 0.9350 - sensitivity: 0.9511 - specificity: 0.8869 - gmeasure: 0.9165 - auc: 0.9840 - val_loss: 0.1940 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9829
Epoch 87/100
600/600 [==============================] - 0s 226us/step - loss: 0.1598 - binary_accuracy: 0.9467 - sensitivity: 0.9629 - specificity: 0.8897 - gmeasure: 0.9240 - auc: 0.9827 - val_loss: 0.1983 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9816
Epoch 88/100
600/600 [==============================] - 0s 213us/step - loss: 0.1579 - binary_accuracy: 0.9467 - sensitivity: 0.9614 - specificity: 0.9106 - gmeasure: 0.9351 - auc: 0.9804 - val_loss: 0.1955 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9642 - val_specificity: 0.7869 - val_gmeasure: 0.8682 - val_auc: 0.9823
Epoch 89/100
600/600 [==============================] - 0s 220us/step - loss: 0.1561 - binary_accuracy: 0.9500 - sensitivity: 0.9573 - specificity: 0.9251 - gmeasure: 0.9399 - auc: 0.9807 - val_loss: 0.1954 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816
Epoch 90/100
600/600 [==============================] - 0s 209us/step - loss: 0.1611 - binary_accuracy: 0.9383 - sensitivity: 0.9602 - specificity: 0.8868 - gmeasure: 0.9208 - auc: 0.9833 - val_loss: 0.1942 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9364 - val_specificity: 0.9049 - val_gmeasure: 0.9199 - val_auc: 0.9772
Epoch 91/100
600/600 [==============================] - 0s 218us/step - loss: 0.1686 - binary_accuracy: 0.9350 - sensitivity: 0.9574 - specificity: 0.8846 - gmeasure: 0.9180 - auc: 0.9845 - val_loss: 0.1906 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9841
Epoch 92/100
600/600 [==============================] - 0s 216us/step - loss: 0.1538 - binary_accuracy: 0.9533 - sensitivity: 0.9587 - specificity: 0.9311 - gmeasure: 0.9436 - auc: 0.9815 - val_loss: 0.1960 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9835
Epoch 93/100
600/600 [==============================] - 0s 210us/step - loss: 0.1562 - binary_accuracy: 0.9483 - sensitivity: 0.9550 - specificity: 0.9230 - gmeasure: 0.9374 - auc: 0.9827 - val_loss: 0.1932 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9544 - val_specificity: 0.8632 - val_gmeasure: 0.9063 - val_auc: 0.9799
Epoch 94/100
600/600 [==============================] - 0s 208us/step - loss: 0.1580 - binary_accuracy: 0.9467 - sensitivity: 0.9622 - specificity: 0.9221 - gmeasure: 0.9408 - auc: 0.9835 - val_loss: 0.1843 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9840
Epoch 95/100
600/600 [==============================] - 0s 187us/step - loss: 0.1473 - binary_accuracy: 0.9550 - sensitivity: 0.9632 - specificity: 0.9325 - gmeasure: 0.9467 - auc: 0.9861 - val_loss: 0.1987 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9821
Epoch 96/100
600/600 [==============================] - 0s 204us/step - loss: 0.1438 - binary_accuracy: 0.9533 - sensitivity: 0.9642 - specificity: 0.9262 - gmeasure: 0.9440 - auc: 0.9843 - val_loss: 0.1844 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9854
Epoch 97/100
600/600 [==============================] - 0s 208us/step - loss: 0.1456 - binary_accuracy: 0.9567 - sensitivity: 0.9605 - specificity: 0.9458 - gmeasure: 0.9524 - auc: 0.9847 - val_loss: 0.1899 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9642 - val_specificity: 0.7869 - val_gmeasure: 0.8682 - val_auc: 0.9835
Epoch 98/100
600/600 [==============================] - 0s 222us/step - loss: 0.1427 - binary_accuracy: 0.9583 - sensitivity: 0.9561 - specificity: 0.9637 - gmeasure: 0.9595 - auc: 0.9856 - val_loss: 0.2170 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9822 - val_specificity: 0.7334 - val_gmeasure: 0.8474 - val_auc: 0.9841
Epoch 99/100
600/600 [==============================] - 0s 217us/step - loss: 0.1544 - binary_accuracy: 0.9483 - sensitivity: 0.9672 - specificity: 0.8937 - gmeasure: 0.9252 - auc: 0.9817 - val_loss: 0.1880 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9809
Epoch 100/100
600/600 [==============================] - 0s 209us/step - loss: 0.1455 - binary_accuracy: 0.9517 - sensitivity: 0.9697 - specificity: 0.9058 - gmeasure: 0.9361 - auc: 0.9838 - val_loss: 0.1816 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9454 - val_specificity: 0.8632 - val_gmeasure: 0.9018 - val_auc: 0.9854
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 14.831358671188354!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 5us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010845184326171875!
[root    |INFO|build_network.py:175] Evaluation: [0.14836500585079193, 0.9493333101272583, 0.9523809552192688, 0.9411764740943909, 0.9467621445655823, 0.9843155145645142]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 15us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.011316776275634766!
[root    |INFO|build_network.py:175] Evaluation: [0.237688347697258, 0.9039999842643738, 0.9367815852165222, 0.8289473652839661, 0.8812165260314941, 0.9612069129943848]
[root    |INFO|deepbiome.py:179] Compute time : 16.136231422424316
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 1s 925us/step - loss: 0.6698 - binary_accuracy: 0.6583 - sensitivity: 0.9167 - specificity: 0.0833 - gmeasure: 0.0000e+00 - auc: 0.5761 - val_loss: 0.6539 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4036
Epoch 2/100
600/600 [==============================] - 0s 222us/step - loss: 0.6283 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5441 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4674
Epoch 3/100
600/600 [==============================] - 0s 217us/step - loss: 0.6225 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5044 - val_loss: 0.6547 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4405
Epoch 4/100
600/600 [==============================] - 0s 203us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5435 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4083
Epoch 5/100
600/600 [==============================] - 0s 220us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5460 - val_loss: 0.6464 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4065
Epoch 6/100
600/600 [==============================] - 0s 220us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5374 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4117
Epoch 7/100
600/600 [==============================] - 0s 213us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5356 - val_loss: 0.6498 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4140
Epoch 8/100
600/600 [==============================] - 0s 221us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5392 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4191
Epoch 9/100
600/600 [==============================] - 0s 209us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5299 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4216
Epoch 10/100
600/600 [==============================] - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.6850 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.55 - 0s 212us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5508 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4228
Epoch 11/100
600/600 [==============================] - 0s 236us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5435 - val_loss: 0.6486 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4268
Epoch 12/100
600/600 [==============================] - 0s 216us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5415 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4280
Epoch 13/100
600/600 [==============================] - 0s 215us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5551 - val_loss: 0.6467 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4293
Epoch 14/100
600/600 [==============================] - 0s 217us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5551 - val_loss: 0.6505 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4347
Epoch 15/100
600/600 [==============================] - 0s 215us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5472 - val_loss: 0.6484 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4386
Epoch 16/100
600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5582 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4432
Epoch 17/100
600/600 [==============================] - 0s 213us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5471 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4473
Epoch 18/100
600/600 [==============================] - 0s 211us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5511 - val_loss: 0.6487 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4486
Epoch 19/100
600/600 [==============================] - 0s 211us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5573 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4494
Epoch 20/100
600/600 [==============================] - 0s 200us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5540 - val_loss: 0.6489 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4556
Epoch 21/100
600/600 [==============================] - 0s 203us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5704 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4564
Epoch 22/100
600/600 [==============================] - 0s 217us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5600 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4554
Epoch 23/100
600/600 [==============================] - 0s 219us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5534 - val_loss: 0.6474 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4581
Epoch 24/100
600/600 [==============================] - 0s 206us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5562 - val_loss: 0.6493 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4583
Epoch 25/100
600/600 [==============================] - 0s 223us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5574 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4612
Epoch 26/100
600/600 [==============================] - 0s 205us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5583 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4615
Epoch 27/100
600/600 [==============================] - 0s 203us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5605 - val_loss: 0.6471 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4635
Epoch 28/100
600/600 [==============================] - 0s 216us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5645 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4632
Epoch 29/100
600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5570 - val_loss: 0.6493 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4608
Epoch 30/100
600/600 [==============================] - 0s 213us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5682 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4601
Epoch 31/100
600/600 [==============================] - 0s 211us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5725 - val_loss: 0.6474 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4594
Epoch 32/100
600/600 [==============================] - 0s 207us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5701 - val_loss: 0.6488 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4601
Epoch 33/100
600/600 [==============================] - 0s 214us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4590
Epoch 34/100
600/600 [==============================] - 0s 217us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5557 - val_loss: 0.6491 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4597
Epoch 35/100
600/600 [==============================] - 0s 205us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5664 - val_loss: 0.6477 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619
Epoch 36/100
600/600 [==============================] - 0s 220us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5597 - val_loss: 0.6488 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4612
Epoch 37/100
600/600 [==============================] - 0s 219us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5552 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4691
Epoch 38/100
600/600 [==============================] - 0s 214us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5651 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4706
Epoch 39/100
600/600 [==============================] - 0s 212us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5557 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4698
Epoch 40/100
600/600 [==============================] - 0s 211us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5683 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4724
Epoch 41/100
600/600 [==============================] - 0s 219us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6495 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4716
Epoch 42/100
600/600 [==============================] - 0s 215us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5592 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4733
Epoch 43/100
600/600 [==============================] - 0s 197us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5661 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4733
Epoch 44/100
600/600 [==============================] - 0s 198us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5714 - val_loss: 0.6501 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4781
Epoch 45/100
600/600 [==============================] - 0s 215us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5684 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4814
Epoch 46/100
600/600 [==============================] - 0s 221us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5813 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4898
Epoch 47/100
600/600 [==============================] - 0s 210us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5798 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4923
Epoch 48/100
600/600 [==============================] - 0s 210us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5813 - val_loss: 0.6477 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4975
Epoch 49/100
600/600 [==============================] - 0s 216us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5943 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5013
Epoch 50/100
600/600 [==============================] - 0s 218us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6015 - val_loss: 0.6487 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071
Epoch 51/100
600/600 [==============================] - 0s 207us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6032 - val_loss: 0.6484 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5162
Epoch 52/100
600/600 [==============================] - 0s 211us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6064 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5225
Epoch 53/100
600/600 [==============================] - 0s 218us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6145 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5401
Epoch 54/100
600/600 [==============================] - 0s 213us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6160 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5470
Epoch 55/100
600/600 [==============================] - 0s 215us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6190 - val_loss: 0.6496 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5511
Epoch 56/100
600/600 [==============================] - 0s 213us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6239 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5517
Epoch 57/100
600/600 [==============================] - 0s 215us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6265 - val_loss: 0.6478 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5663
Epoch 58/100
600/600 [==============================] - 0s 216us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6190 - val_loss: 0.6462 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6322
Epoch 59/100
600/600 [==============================] - 0s 210us/step - loss: 0.6194 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6412 - val_loss: 0.6466 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6460
Epoch 60/100
600/600 [==============================] - 0s 200us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6387 - val_loss: 0.6423 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6767
Epoch 61/100
600/600 [==============================] - 0s 216us/step - loss: 0.6178 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6503 - val_loss: 0.6448 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6759
Epoch 62/100
600/600 [==============================] - 0s 228us/step - loss: 0.6172 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6484 - val_loss: 0.6422 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6861
Epoch 63/100
600/600 [==============================] - 0s 221us/step - loss: 0.6156 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6472 - val_loss: 0.6419 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6909
Epoch 64/100
600/600 [==============================] - 0s 213us/step - loss: 0.6145 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6513 - val_loss: 0.6413 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6939
Epoch 65/100
600/600 [==============================] - 0s 215us/step - loss: 0.6134 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6631 - val_loss: 0.6389 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6981
Epoch 66/100
600/600 [==============================] - 0s 207us/step - loss: 0.6119 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6561 - val_loss: 0.6378 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7019
Epoch 67/100
600/600 [==============================] - 0s 208us/step - loss: 0.6099 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6691 - val_loss: 0.6355 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7045
Epoch 68/100
600/600 [==============================] - 0s 213us/step - loss: 0.6086 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6771 - val_loss: 0.6342 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7069
Epoch 69/100
600/600 [==============================] - 0s 206us/step - loss: 0.6057 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6794 - val_loss: 0.6307 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7103
Epoch 70/100
600/600 [==============================] - 0s 215us/step - loss: 0.6047 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6741 - val_loss: 0.6297 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7118
Epoch 71/100
600/600 [==============================] - 0s 211us/step - loss: 0.6019 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6856 - val_loss: 0.6285 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7153
Epoch 72/100
600/600 [==============================] - 0s 214us/step - loss: 0.6016 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6877 - val_loss: 0.6238 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7195
Epoch 73/100
600/600 [==============================] - 0s 217us/step - loss: 0.5968 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6837 - val_loss: 0.6208 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7211
Epoch 74/100
600/600 [==============================] - 0s 213us/step - loss: 0.5933 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7010 - val_loss: 0.6199 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7235
Epoch 75/100
600/600 [==============================] - 0s 225us/step - loss: 0.5893 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6947 - val_loss: 0.6174 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7270
Epoch 76/100
600/600 [==============================] - 0s 213us/step - loss: 0.5894 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6959 - val_loss: 0.6171 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7286
Epoch 77/100
600/600 [==============================] - 0s 198us/step - loss: 0.5873 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6991 - val_loss: 0.6151 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7312
Epoch 78/100
600/600 [==============================] - 0s 214us/step - loss: 0.5842 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7068 - val_loss: 0.6123 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7351
Epoch 79/100
600/600 [==============================] - 0s 222us/step - loss: 0.5811 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7115 - val_loss: 0.6102 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7355
Epoch 80/100
600/600 [==============================] - 0s 209us/step - loss: 0.5784 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7141 - val_loss: 0.6092 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7380
Epoch 81/100
600/600 [==============================] - 0s 197us/step - loss: 0.5749 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7121 - val_loss: 0.6073 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7369
Epoch 82/100
600/600 [==============================] - 0s 210us/step - loss: 0.5725 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7088 - val_loss: 0.6071 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7395
Epoch 83/100
600/600 [==============================] - 0s 211us/step - loss: 0.5760 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7255 - val_loss: 0.6142 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7375
Epoch 84/100
600/600 [==============================] - 0s 214us/step - loss: 0.5702 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7281 - val_loss: 0.6060 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 85/100
600/600 [==============================] - 0s 222us/step - loss: 0.5687 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7210 - val_loss: 0.6184 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7405
Epoch 86/100
600/600 [==============================] - 0s 215us/step - loss: 0.5736 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7281 - val_loss: 0.6034 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7440
Epoch 87/100
600/600 [==============================] - 0s 203us/step - loss: 0.5697 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7393 - val_loss: 0.5962 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7473
Epoch 88/100
600/600 [==============================] - 0s 216us/step - loss: 0.5611 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7375 - val_loss: 0.5966 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7506
Epoch 89/100
600/600 [==============================] - 0s 216us/step - loss: 0.5611 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7351 - val_loss: 0.6019 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7540
Epoch 90/100
600/600 [==============================] - 0s 210us/step - loss: 0.5567 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7457 - val_loss: 0.6048 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525
Epoch 91/100
600/600 [==============================] - 0s 211us/step - loss: 0.5600 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7501 - val_loss: 0.5962 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7545
Epoch 92/100
600/600 [==============================] - 0s 203us/step - loss: 0.5507 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7463 - val_loss: 0.5961 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7549
Epoch 93/100
600/600 [==============================] - 0s 203us/step - loss: 0.5566 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7539 - val_loss: 0.5958 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7600
Epoch 94/100
600/600 [==============================] - 0s 208us/step - loss: 0.5517 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7537 - val_loss: 0.5895 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7589
Epoch 95/100
600/600 [==============================] - 0s 217us/step - loss: 0.5493 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7574 - val_loss: 0.5879 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7643
Epoch 96/100
600/600 [==============================] - 0s 218us/step - loss: 0.5472 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7599 - val_loss: 0.5946 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7620
Epoch 97/100
600/600 [==============================] - 0s 217us/step - loss: 0.5456 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7624 - val_loss: 0.5869 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7642
Epoch 98/100
600/600 [==============================] - 0s 207us/step - loss: 0.5414 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7601 - val_loss: 0.5879 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7710
Epoch 99/100
600/600 [==============================] - 0s 219us/step - loss: 0.5477 - binary_accuracy: 0.6967 - sensitivity: 0.9892 - specificity: 0.0711 - gmeasure: 0.1628 - auc: 0.7583 - val_loss: 0.5924 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7671
Epoch 100/100
600/600 [==============================] - 0s 209us/step - loss: 0.5445 - binary_accuracy: 0.7150 - sensitivity: 0.9787 - specificity: 0.1429 - gmeasure: 0.2987 - auc: 0.7673 - val_loss: 0.5860 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9408 - val_specificity: 0.4144 - val_gmeasure: 0.6230 - val_auc: 0.7797
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 14.849649667739868!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.013460636138916016!
[root    |INFO|build_network.py:175] Evaluation: [0.5479835867881775, 0.7480000257492065, 0.9412915706634521, 0.33472803235054016, 0.5613169074058533, 0.7735673189163208]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 19us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.011509180068969727!
[root    |INFO|build_network.py:175] Evaluation: [0.5602806210517883, 0.6959999799728394, 0.9044944047927856, 0.1805555522441864, 0.404118150472641, 0.6734550595283508]
[root    |INFO|deepbiome.py:179] Compute time : 16.241212129592896
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.29898739 0.87600001 0.93688699 0.74570381 0.8156388  0.91019789]
[root    |INFO|deepbiome.py:189]        std : [0.17735427 0.0908299  0.0147808  0.29071879 0.17986184 0.09672849]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.3362326  0.84533332 0.92539575 0.64925817 0.74064152 0.86531492]
[root    |INFO|deepbiome.py:196]        std : [0.15880773 0.10639967 0.01479919 0.33441446 0.23902934 0.13566541]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">deepbiome_train</span></code> saves the trained model weights, evaluation results and history based on the path information from the configuration.</p>
<p>From the example above, we can check that <code class="docutils literal notranslate"><span class="pre">hist_*.json</span></code>, <code class="docutils literal notranslate"><span class="pre">weight_*.h5</span></code>, <code class="docutils literal notranslate"><span class="pre">test_eval.npy</span></code>, <code class="docutils literal notranslate"><span class="pre">train_eval.npy</span></code> files were saved.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[&#39;hist_0.json&#39;,
 &#39;weight_2.h5&#39;,
 &#39;test_eval.npy&#39;,
 &#39;weight_0.h5&#39;,
 &#39;train_eval.npy&#39;,
 &#39;hist_2.json&#39;,
 &#39;weight_1.h5&#39;,
 &#39;hist_1.json&#39;]
</pre></div>
</div>
</div>
<p>Lets check the history files.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_the_list_of_inputs_43_0.png" src="_images/example_with_the_list_of_inputs_43_0.png" />
</div>
</div>
<p>Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.21072882, 0.93599999, 0.93491125, 0.93827158, 0.9365899 ,
        0.96128279],
       [0.23768835, 0.90399998, 0.93678159, 0.82894737, 0.88121653,
        0.96120691],
       [0.56028062, 0.69599998, 0.9044944 , 0.18055555, 0.40411815,
        0.67345506]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.20061357, 0.93066669, 0.91698843, 0.96120691, 0.93883735,
        0.97271085],
       [0.14836501, 0.94933331, 0.95238096, 0.94117647, 0.94676214,
        0.98431551],
       [0.54798359, 0.74800003, 0.94129157, 0.33472803, 0.56131691,
        0.77356732]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="5.-Load-the-pre-trained-network-for-training">
<h2>5. Load the pre-trained network for training<a class="headerlink" href="#5.-Load-the-pre-trained-network-for-training" title="Permalink to this headline">¶</a></h2>
<p>If you have pre-trianed model, you can use the pre-trained weight for next training. For using pre-trained weights, you have to use <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> option in <code class="docutils literal notranslate"><span class="pre">training_inro</span></code> with addding the file path of the pre-trained weights in the <code class="docutils literal notranslate"><span class="pre">warm_start_model</span></code> option. Below is the example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">warm_start_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;taxa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span><span class="s1">&#39;True&#39;</span><span class="p">,</span>
        <span class="s1">&#39;warm_start_model&#39;</span><span class="p">:</span><span class="s1">&#39;./example_result/weight.h5&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;200&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">warm_start_network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span>
                                                                       <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 686us/step - loss: 0.2182 - binary_accuracy: 0.9167 - sensitivity: 0.9518 - specificity: 0.8445 - gmeasure: 0.8930 - auc: 0.9733 - val_loss: 0.2641 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8667 - val_specificity: 0.9111 - val_gmeasure: 0.8886 - val_auc: 0.9512
Epoch 2/100
600/600 [==============================] - 0s 65us/step - loss: 0.1991 - binary_accuracy: 0.9300 - sensitivity: 0.9032 - specificity: 0.9898 - gmeasure: 0.9455 - auc: 0.9791 - val_loss: 0.2558 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8762 - val_specificity: 0.9111 - val_gmeasure: 0.8935 - val_auc: 0.9491
Epoch 3/100
600/600 [==============================] - 0s 66us/step - loss: 0.1879 - binary_accuracy: 0.9267 - sensitivity: 0.9347 - specificity: 0.9099 - gmeasure: 0.9214 - auc: 0.9772 - val_loss: 0.2728 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9475
Epoch 4/100
600/600 [==============================] - 0s 64us/step - loss: 0.1875 - binary_accuracy: 0.9267 - sensitivity: 0.9593 - specificity: 0.8507 - gmeasure: 0.9023 - auc: 0.9768 - val_loss: 0.2501 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9496
Epoch 5/100
600/600 [==============================] - 0s 66us/step - loss: 0.1804 - binary_accuracy: 0.9433 - sensitivity: 0.9378 - specificity: 0.9559 - gmeasure: 0.9467 - auc: 0.9784 - val_loss: 0.2614 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8857 - val_specificity: 0.9111 - val_gmeasure: 0.8983 - val_auc: 0.9492
Epoch 6/100
600/600 [==============================] - 0s 69us/step - loss: 0.1827 - binary_accuracy: 0.9400 - sensitivity: 0.9346 - specificity: 0.9552 - gmeasure: 0.9446 - auc: 0.9780 - val_loss: 0.2519 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9496
Epoch 7/100
600/600 [==============================] - 0s 66us/step - loss: 0.1749 - binary_accuracy: 0.9300 - sensitivity: 0.9470 - specificity: 0.8934 - gmeasure: 0.9195 - auc: 0.9784 - val_loss: 0.2526 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9510
Epoch 8/100
600/600 [==============================] - 0s 64us/step - loss: 0.1725 - binary_accuracy: 0.9333 - sensitivity: 0.9442 - specificity: 0.9090 - gmeasure: 0.9264 - auc: 0.9771 - val_loss: 0.2503 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9475
Epoch 9/100
600/600 [==============================] - 0s 64us/step - loss: 0.1715 - binary_accuracy: 0.9367 - sensitivity: 0.9390 - specificity: 0.9296 - gmeasure: 0.9341 - auc: 0.9772 - val_loss: 0.2494 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9512
Epoch 10/100
600/600 [==============================] - 0s 68us/step - loss: 0.1700 - binary_accuracy: 0.9383 - sensitivity: 0.9442 - specificity: 0.9246 - gmeasure: 0.9343 - auc: 0.9804 - val_loss: 0.2497 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9333 - val_specificity: 0.8667 - val_gmeasure: 0.8994 - val_auc: 0.9490
Epoch 11/100
600/600 [==============================] - 0s 64us/step - loss: 0.1701 - binary_accuracy: 0.9350 - sensitivity: 0.9477 - specificity: 0.9105 - gmeasure: 0.9282 - auc: 0.9794 - val_loss: 0.2475 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9505
Epoch 12/100
600/600 [==============================] - 0s 66us/step - loss: 0.1679 - binary_accuracy: 0.9400 - sensitivity: 0.9439 - specificity: 0.9300 - gmeasure: 0.9369 - auc: 0.9779 - val_loss: 0.2474 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9496
Epoch 13/100
600/600 [==============================] - 0s 67us/step - loss: 0.1672 - binary_accuracy: 0.9383 - sensitivity: 0.9448 - specificity: 0.9232 - gmeasure: 0.9339 - auc: 0.9763 - val_loss: 0.2475 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9490
Epoch 14/100
600/600 [==============================] - 0s 66us/step - loss: 0.1658 - binary_accuracy: 0.9383 - sensitivity: 0.9443 - specificity: 0.9212 - gmeasure: 0.9324 - auc: 0.9776 - val_loss: 0.2474 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9492
Epoch 15/100
600/600 [==============================] - 0s 64us/step - loss: 0.1657 - binary_accuracy: 0.9400 - sensitivity: 0.9471 - specificity: 0.9268 - gmeasure: 0.9365 - auc: 0.9790 - val_loss: 0.2480 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9513
Epoch 16/100
600/600 [==============================] - 0s 67us/step - loss: 0.1635 - binary_accuracy: 0.9383 - sensitivity: 0.9441 - specificity: 0.9243 - gmeasure: 0.9341 - auc: 0.9784 - val_loss: 0.2480 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9503
Epoch 17/100
600/600 [==============================] - 0s 64us/step - loss: 0.1637 - binary_accuracy: 0.9383 - sensitivity: 0.9492 - specificity: 0.9151 - gmeasure: 0.9320 - auc: 0.9800 - val_loss: 0.2478 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9519
Epoch 18/100
600/600 [==============================] - 0s 75us/step - loss: 0.1615 - binary_accuracy: 0.9367 - sensitivity: 0.9386 - specificity: 0.9289 - gmeasure: 0.9335 - auc: 0.9787 - val_loss: 0.2480 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9492
Epoch 19/100
600/600 [==============================] - 0s 67us/step - loss: 0.1609 - binary_accuracy: 0.9417 - sensitivity: 0.9421 - specificity: 0.9413 - gmeasure: 0.9417 - auc: 0.9798 - val_loss: 0.2482 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9492
Epoch 20/100
600/600 [==============================] - 0s 66us/step - loss: 0.1664 - binary_accuracy: 0.9383 - sensitivity: 0.9568 - specificity: 0.9006 - gmeasure: 0.9278 - auc: 0.9786 - val_loss: 0.2489 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9512
Epoch 21/100
600/600 [==============================] - 0s 63us/step - loss: 0.1634 - binary_accuracy: 0.9433 - sensitivity: 0.9362 - specificity: 0.9644 - gmeasure: 0.9500 - auc: 0.9795 - val_loss: 0.2520 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9501
Epoch 22/100
600/600 [==============================] - 0s 69us/step - loss: 0.1594 - binary_accuracy: 0.9467 - sensitivity: 0.9418 - specificity: 0.9570 - gmeasure: 0.9493 - auc: 0.9788 - val_loss: 0.2552 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9506
Epoch 23/100
600/600 [==============================] - 0s 62us/step - loss: 0.1625 - binary_accuracy: 0.9367 - sensitivity: 0.9612 - specificity: 0.8812 - gmeasure: 0.9203 - auc: 0.9791 - val_loss: 0.2500 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9525
Epoch 24/100
600/600 [==============================] - 0s 66us/step - loss: 0.1600 - binary_accuracy: 0.9417 - sensitivity: 0.9328 - specificity: 0.9640 - gmeasure: 0.9481 - auc: 0.9788 - val_loss: 0.2512 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9503
Epoch 25/100
600/600 [==============================] - 0s 68us/step - loss: 0.1579 - binary_accuracy: 0.9400 - sensitivity: 0.9454 - specificity: 0.9327 - gmeasure: 0.9386 - auc: 0.9804 - val_loss: 0.2573 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9505
Epoch 26/100
600/600 [==============================] - 0s 64us/step - loss: 0.1563 - binary_accuracy: 0.9383 - sensitivity: 0.9536 - specificity: 0.9064 - gmeasure: 0.9293 - auc: 0.9798 - val_loss: 0.2502 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9520
Epoch 27/100
600/600 [==============================] - 0s 66us/step - loss: 0.1567 - binary_accuracy: 0.9417 - sensitivity: 0.9460 - specificity: 0.9338 - gmeasure: 0.9396 - auc: 0.9793 - val_loss: 0.2497 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9535
Epoch 28/100
600/600 [==============================] - 0s 60us/step - loss: 0.1527 - binary_accuracy: 0.9467 - sensitivity: 0.9491 - specificity: 0.9423 - gmeasure: 0.9455 - auc: 0.9805 - val_loss: 0.2493 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9535
Epoch 29/100
600/600 [==============================] - 0s 63us/step - loss: 0.1593 - binary_accuracy: 0.9367 - sensitivity: 0.9517 - specificity: 0.9019 - gmeasure: 0.9261 - auc: 0.9802 - val_loss: 0.2506 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9509
Epoch 30/100
600/600 [==============================] - 0s 61us/step - loss: 0.1590 - binary_accuracy: 0.9400 - sensitivity: 0.9299 - specificity: 0.9631 - gmeasure: 0.9457 - auc: 0.9808 - val_loss: 0.2504 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9540
Epoch 31/100
600/600 [==============================] - 0s 67us/step - loss: 0.1518 - binary_accuracy: 0.9400 - sensitivity: 0.9469 - specificity: 0.9238 - gmeasure: 0.9348 - auc: 0.9805 - val_loss: 0.2592 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9509
Epoch 32/100
600/600 [==============================] - 0s 68us/step - loss: 0.1537 - binary_accuracy: 0.9400 - sensitivity: 0.9588 - specificity: 0.9003 - gmeasure: 0.9291 - auc: 0.9798 - val_loss: 0.2540 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9534
Epoch 33/100
600/600 [==============================] - 0s 68us/step - loss: 0.1612 - binary_accuracy: 0.9417 - sensitivity: 0.9251 - specificity: 0.9777 - gmeasure: 0.9509 - auc: 0.9813 - val_loss: 0.2501 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9514
Epoch 34/100
600/600 [==============================] - 0s 68us/step - loss: 0.1517 - binary_accuracy: 0.9450 - sensitivity: 0.9564 - specificity: 0.9172 - gmeasure: 0.9362 - auc: 0.9818 - val_loss: 0.2639 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9524 - val_specificity: 0.8667 - val_gmeasure: 0.9085 - val_auc: 0.9505
Epoch 35/100
600/600 [==============================] - 0s 66us/step - loss: 0.1544 - binary_accuracy: 0.9417 - sensitivity: 0.9540 - specificity: 0.9135 - gmeasure: 0.9331 - auc: 0.9805 - val_loss: 0.2520 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9512
Epoch 36/100
600/600 [==============================] - 0s 67us/step - loss: 0.1503 - binary_accuracy: 0.9467 - sensitivity: 0.9367 - specificity: 0.9648 - gmeasure: 0.9503 - auc: 0.9816 - val_loss: 0.2522 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9532
Epoch 37/100
600/600 [==============================] - 0s 66us/step - loss: 0.1467 - binary_accuracy: 0.9450 - sensitivity: 0.9539 - specificity: 0.9250 - gmeasure: 0.9390 - auc: 0.9811 - val_loss: 0.2537 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9515
Epoch 38/100
600/600 [==============================] - 0s 66us/step - loss: 0.1455 - binary_accuracy: 0.9500 - sensitivity: 0.9586 - specificity: 0.9315 - gmeasure: 0.9449 - auc: 0.9805 - val_loss: 0.2525 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9515
Epoch 39/100
600/600 [==============================] - 0s 68us/step - loss: 0.1463 - binary_accuracy: 0.9517 - sensitivity: 0.9431 - specificity: 0.9683 - gmeasure: 0.9556 - auc: 0.9809 - val_loss: 0.2526 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9509
Epoch 40/100
600/600 [==============================] - 0s 69us/step - loss: 0.1435 - binary_accuracy: 0.9517 - sensitivity: 0.9591 - specificity: 0.9347 - gmeasure: 0.9467 - auc: 0.9812 - val_loss: 0.2583 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9510
Epoch 41/100
600/600 [==============================] - 0s 72us/step - loss: 0.1492 - binary_accuracy: 0.9467 - sensitivity: 0.9514 - specificity: 0.9367 - gmeasure: 0.9437 - auc: 0.9798 - val_loss: 0.2542 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9522
Epoch 42/100
600/600 [==============================] - 0s 67us/step - loss: 0.1432 - binary_accuracy: 0.9550 - sensitivity: 0.9527 - specificity: 0.9631 - gmeasure: 0.9578 - auc: 0.9811 - val_loss: 0.2556 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9515
Epoch 43/100
600/600 [==============================] - 0s 69us/step - loss: 0.1453 - binary_accuracy: 0.9500 - sensitivity: 0.9588 - specificity: 0.9306 - gmeasure: 0.9445 - auc: 0.9817 - val_loss: 0.2536 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9525
Epoch 44/100
600/600 [==============================] - 0s 64us/step - loss: 0.1543 - binary_accuracy: 0.9483 - sensitivity: 0.9372 - specificity: 0.9744 - gmeasure: 0.9556 - auc: 0.9835 - val_loss: 0.2544 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9522
Epoch 45/100
600/600 [==============================] - 0s 67us/step - loss: 0.1415 - binary_accuracy: 0.9500 - sensitivity: 0.9595 - specificity: 0.9304 - gmeasure: 0.9448 - auc: 0.9826 - val_loss: 0.2668 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9429 - val_specificity: 0.8444 - val_gmeasure: 0.8923 - val_auc: 0.9515
Epoch 46/100
600/600 [==============================] - 0s 63us/step - loss: 0.1453 - binary_accuracy: 0.9500 - sensitivity: 0.9569 - specificity: 0.9391 - gmeasure: 0.9470 - auc: 0.9833 - val_loss: 0.2562 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9537
Epoch 47/100
600/600 [==============================] - 0s 61us/step - loss: 0.1423 - binary_accuracy: 0.9533 - sensitivity: 0.9494 - specificity: 0.9634 - gmeasure: 0.9563 - auc: 0.9833 - val_loss: 0.2577 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9515
Epoch 48/100
600/600 [==============================] - 0s 66us/step - loss: 0.1447 - binary_accuracy: 0.9467 - sensitivity: 0.9603 - specificity: 0.9194 - gmeasure: 0.9392 - auc: 0.9801 - val_loss: 0.2578 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9512
Epoch 49/100
600/600 [==============================] - 0s 68us/step - loss: 0.1574 - binary_accuracy: 0.9400 - sensitivity: 0.9335 - specificity: 0.9617 - gmeasure: 0.9469 - auc: 0.9827 - val_loss: 0.2596 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9543
Epoch 50/100
600/600 [==============================] - 0s 65us/step - loss: 0.1471 - binary_accuracy: 0.9483 - sensitivity: 0.9507 - specificity: 0.9521 - gmeasure: 0.9510 - auc: 0.9821 - val_loss: 0.2802 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9509
Epoch 51/100
600/600 [==============================] - 0s 69us/step - loss: 0.1600 - binary_accuracy: 0.9383 - sensitivity: 0.9489 - specificity: 0.9231 - gmeasure: 0.9353 - auc: 0.9810 - val_loss: 0.2695 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8571 - val_specificity: 0.9333 - val_gmeasure: 0.8944 - val_auc: 0.9513
Epoch 52/100
600/600 [==============================] - 0s 64us/step - loss: 0.1451 - binary_accuracy: 0.9533 - sensitivity: 0.9418 - specificity: 0.9793 - gmeasure: 0.9604 - auc: 0.9840 - val_loss: 0.2655 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9517
Epoch 53/100
600/600 [==============================] - 0s 66us/step - loss: 0.1538 - binary_accuracy: 0.9383 - sensitivity: 0.9642 - specificity: 0.8804 - gmeasure: 0.9211 - auc: 0.9818 - val_loss: 0.2655 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9523
Epoch 54/100
600/600 [==============================] - 0s 62us/step - loss: 0.1511 - binary_accuracy: 0.9433 - sensitivity: 0.9425 - specificity: 0.9487 - gmeasure: 0.9449 - auc: 0.9827 - val_loss: 0.2730 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8571 - val_specificity: 0.9333 - val_gmeasure: 0.8944 - val_auc: 0.9502
Epoch 55/100
600/600 [==============================] - 0s 62us/step - loss: 0.1529 - binary_accuracy: 0.9433 - sensitivity: 0.9382 - specificity: 0.9590 - gmeasure: 0.9480 - auc: 0.9829 - val_loss: 0.2771 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9522
Epoch 56/100
600/600 [==============================] - 0s 61us/step - loss: 0.1416 - binary_accuracy: 0.9400 - sensitivity: 0.9614 - specificity: 0.8949 - gmeasure: 0.9270 - auc: 0.9833 - val_loss: 0.2593 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9528
Epoch 57/100
600/600 [==============================] - 0s 66us/step - loss: 0.1432 - binary_accuracy: 0.9483 - sensitivity: 0.9396 - specificity: 0.9687 - gmeasure: 0.9539 - auc: 0.9839 - val_loss: 0.2591 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9535
Epoch 58/100
600/600 [==============================] - 0s 67us/step - loss: 0.1346 - binary_accuracy: 0.9517 - sensitivity: 0.9540 - specificity: 0.9458 - gmeasure: 0.9498 - auc: 0.9834 - val_loss: 0.2720 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9513
Epoch 59/100
600/600 [==============================] - 0s 66us/step - loss: 0.1399 - binary_accuracy: 0.9400 - sensitivity: 0.9610 - specificity: 0.8956 - gmeasure: 0.9277 - auc: 0.9828 - val_loss: 0.2604 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9515
Epoch 60/100
600/600 [==============================] - 0s 66us/step - loss: 0.1374 - binary_accuracy: 0.9550 - sensitivity: 0.9466 - specificity: 0.9728 - gmeasure: 0.9596 - auc: 0.9846 - val_loss: 0.2593 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9532
Epoch 61/100
600/600 [==============================] - 0s 65us/step - loss: 0.1354 - binary_accuracy: 0.9567 - sensitivity: 0.9588 - specificity: 0.9510 - gmeasure: 0.9546 - auc: 0.9837 - val_loss: 0.2642 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9526
Epoch 62/100
600/600 [==============================] - 0s 68us/step - loss: 0.1342 - binary_accuracy: 0.9533 - sensitivity: 0.9565 - specificity: 0.9466 - gmeasure: 0.9513 - auc: 0.9837 - val_loss: 0.2623 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9535
Epoch 63/100
600/600 [==============================] - 0s 64us/step - loss: 0.1356 - binary_accuracy: 0.9517 - sensitivity: 0.9497 - specificity: 0.9562 - gmeasure: 0.9528 - auc: 0.9842 - val_loss: 0.2624 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9532
Epoch 64/100
600/600 [==============================] - 0s 60us/step - loss: 0.1315 - binary_accuracy: 0.9567 - sensitivity: 0.9588 - specificity: 0.9520 - gmeasure: 0.9554 - auc: 0.9843 - val_loss: 0.2614 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9534
Epoch 65/100
600/600 [==============================] - 0s 61us/step - loss: 0.1309 - binary_accuracy: 0.9600 - sensitivity: 0.9586 - specificity: 0.9596 - gmeasure: 0.9590 - auc: 0.9837 - val_loss: 0.2606 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9540
Epoch 66/100
600/600 [==============================] - 0s 65us/step - loss: 0.1312 - binary_accuracy: 0.9567 - sensitivity: 0.9591 - specificity: 0.9545 - gmeasure: 0.9566 - auc: 0.9842 - val_loss: 0.2595 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9559
Epoch 67/100
600/600 [==============================] - 0s 68us/step - loss: 0.1317 - binary_accuracy: 0.9617 - sensitivity: 0.9594 - specificity: 0.9697 - gmeasure: 0.9644 - auc: 0.9856 - val_loss: 0.2589 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9558
Epoch 68/100
600/600 [==============================] - 0s 67us/step - loss: 0.1291 - binary_accuracy: 0.9617 - sensitivity: 0.9576 - specificity: 0.9672 - gmeasure: 0.9623 - auc: 0.9855 - val_loss: 0.2622 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9537
Epoch 69/100
600/600 [==============================] - 0s 70us/step - loss: 0.1296 - binary_accuracy: 0.9567 - sensitivity: 0.9585 - specificity: 0.9518 - gmeasure: 0.9551 - auc: 0.9841 - val_loss: 0.2597 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9549
Epoch 70/100
600/600 [==============================] - 0s 65us/step - loss: 0.1291 - binary_accuracy: 0.9633 - sensitivity: 0.9582 - specificity: 0.9729 - gmeasure: 0.9654 - auc: 0.9845 - val_loss: 0.2596 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9557
Epoch 71/100
600/600 [==============================] - 0s 65us/step - loss: 0.1276 - binary_accuracy: 0.9617 - sensitivity: 0.9588 - specificity: 0.9675 - gmeasure: 0.9632 - auc: 0.9844 - val_loss: 0.2616 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9543
Epoch 72/100
600/600 [==============================] - 0s 67us/step - loss: 0.1276 - binary_accuracy: 0.9617 - sensitivity: 0.9587 - specificity: 0.9681 - gmeasure: 0.9633 - auc: 0.9840 - val_loss: 0.2619 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9534
Epoch 73/100
600/600 [==============================] - 0s 69us/step - loss: 0.1269 - binary_accuracy: 0.9583 - sensitivity: 0.9588 - specificity: 0.9571 - gmeasure: 0.9579 - auc: 0.9843 - val_loss: 0.2623 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9539
Epoch 74/100
600/600 [==============================] - 0s 71us/step - loss: 0.1275 - binary_accuracy: 0.9617 - sensitivity: 0.9593 - specificity: 0.9679 - gmeasure: 0.9635 - auc: 0.9863 - val_loss: 0.2603 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9560
Epoch 75/100
600/600 [==============================] - 0s 68us/step - loss: 0.1261 - binary_accuracy: 0.9583 - sensitivity: 0.9589 - specificity: 0.9574 - gmeasure: 0.9581 - auc: 0.9853 - val_loss: 0.2627 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9547
Epoch 76/100
600/600 [==============================] - 0s 74us/step - loss: 0.1255 - binary_accuracy: 0.9567 - sensitivity: 0.9583 - specificity: 0.9525 - gmeasure: 0.9553 - auc: 0.9851 - val_loss: 0.2601 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9553
Epoch 77/100
600/600 [==============================] - ETA: 0s - loss: 0.1032 - binary_accuracy: 0.9750 - sensitivity: 0.9708 - specificity: 0.9841 - gmeasure: 0.9774 - auc: 0.99 - 0s 66us/step - loss: 0.1254 - binary_accuracy: 0.9600 - sensitivity: 0.9592 - specificity: 0.9637 - gmeasure: 0.9613 - auc: 0.9858 - val_loss: 0.2605 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9549
Epoch 78/100
600/600 [==============================] - 0s 65us/step - loss: 0.1245 - binary_accuracy: 0.9633 - sensitivity: 0.9587 - specificity: 0.9723 - gmeasure: 0.9654 - auc: 0.9863 - val_loss: 0.2613 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9547
Epoch 79/100
600/600 [==============================] - 0s 69us/step - loss: 0.1246 - binary_accuracy: 0.9633 - sensitivity: 0.9585 - specificity: 0.9737 - gmeasure: 0.9661 - auc: 0.9849 - val_loss: 0.2628 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9560
Epoch 80/100
600/600 [==============================] - 0s 68us/step - loss: 0.1233 - binary_accuracy: 0.9600 - sensitivity: 0.9594 - specificity: 0.9608 - gmeasure: 0.9601 - auc: 0.9858 - val_loss: 0.2647 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9537
Epoch 81/100
600/600 [==============================] - 0s 69us/step - loss: 0.1233 - binary_accuracy: 0.9583 - sensitivity: 0.9589 - specificity: 0.9569 - gmeasure: 0.9576 - auc: 0.9865 - val_loss: 0.2630 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9551
Epoch 82/100
600/600 [==============================] - 0s 66us/step - loss: 0.1255 - binary_accuracy: 0.9633 - sensitivity: 0.9594 - specificity: 0.9754 - gmeasure: 0.9672 - auc: 0.9868 - val_loss: 0.2609 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9549
Epoch 83/100
600/600 [==============================] - 0s 65us/step - loss: 0.1241 - binary_accuracy: 0.9583 - sensitivity: 0.9615 - specificity: 0.9554 - gmeasure: 0.9583 - auc: 0.9861 - val_loss: 0.2684 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9549
Epoch 84/100
600/600 [==============================] - 0s 64us/step - loss: 0.1236 - binary_accuracy: 0.9567 - sensitivity: 0.9587 - specificity: 0.9519 - gmeasure: 0.9552 - auc: 0.9849 - val_loss: 0.2607 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9560
Epoch 85/100
600/600 [==============================] - 0s 66us/step - loss: 0.1236 - binary_accuracy: 0.9567 - sensitivity: 0.9537 - specificity: 0.9646 - gmeasure: 0.9590 - auc: 0.9864 - val_loss: 0.2689 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9545
Epoch 86/100
600/600 [==============================] - 0s 66us/step - loss: 0.1225 - binary_accuracy: 0.9583 - sensitivity: 0.9636 - specificity: 0.9460 - gmeasure: 0.9546 - auc: 0.9859 - val_loss: 0.2628 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9562
Epoch 87/100
600/600 [==============================] - 0s 70us/step - loss: 0.1204 - binary_accuracy: 0.9617 - sensitivity: 0.9559 - specificity: 0.9740 - gmeasure: 0.9649 - auc: 0.9874 - val_loss: 0.2636 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9566
Epoch 88/100
600/600 [==============================] - 0s 64us/step - loss: 0.1218 - binary_accuracy: 0.9633 - sensitivity: 0.9602 - specificity: 0.9744 - gmeasure: 0.9671 - auc: 0.9883 - val_loss: 0.2679 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9557
Epoch 89/100
600/600 [==============================] - 0s 71us/step - loss: 0.1206 - binary_accuracy: 0.9583 - sensitivity: 0.9633 - specificity: 0.9456 - gmeasure: 0.9543 - auc: 0.9848 - val_loss: 0.2662 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9553
Epoch 90/100
600/600 [==============================] - 0s 62us/step - loss: 0.1247 - binary_accuracy: 0.9617 - sensitivity: 0.9566 - specificity: 0.9735 - gmeasure: 0.9650 - auc: 0.9873 - val_loss: 0.2639 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9576
Epoch 91/100
600/600 [==============================] - 0s 66us/step - loss: 0.1180 - binary_accuracy: 0.9617 - sensitivity: 0.9613 - specificity: 0.9619 - gmeasure: 0.9616 - auc: 0.9873 - val_loss: 0.2739 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9429 - val_specificity: 0.8444 - val_gmeasure: 0.8923 - val_auc: 0.9547
Epoch 92/100
600/600 [==============================] - 0s 62us/step - loss: 0.1206 - binary_accuracy: 0.9550 - sensitivity: 0.9637 - specificity: 0.9358 - gmeasure: 0.9496 - auc: 0.9861 - val_loss: 0.2615 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9566
Epoch 93/100
600/600 [==============================] - 0s 68us/step - loss: 0.1183 - binary_accuracy: 0.9633 - sensitivity: 0.9563 - specificity: 0.9785 - gmeasure: 0.9673 - auc: 0.9878 - val_loss: 0.2632 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9238 - val_specificity: 0.9111 - val_gmeasure: 0.9174 - val_auc: 0.9558
Epoch 94/100
600/600 [==============================] - 0s 68us/step - loss: 0.1166 - binary_accuracy: 0.9567 - sensitivity: 0.9560 - specificity: 0.9551 - gmeasure: 0.9554 - auc: 0.9870 - val_loss: 0.2676 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9558
Epoch 95/100
600/600 [==============================] - 0s 64us/step - loss: 0.1159 - binary_accuracy: 0.9650 - sensitivity: 0.9610 - specificity: 0.9732 - gmeasure: 0.9669 - auc: 0.9878 - val_loss: 0.2640 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9048 - val_specificity: 0.9333 - val_gmeasure: 0.9189 - val_auc: 0.9564
Epoch 96/100
600/600 [==============================] - 0s 67us/step - loss: 0.1170 - binary_accuracy: 0.9650 - sensitivity: 0.9613 - specificity: 0.9729 - gmeasure: 0.9671 - auc: 0.9869 - val_loss: 0.2667 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9549
Epoch 97/100
600/600 [==============================] - 0s 66us/step - loss: 0.1155 - binary_accuracy: 0.9633 - sensitivity: 0.9638 - specificity: 0.9608 - gmeasure: 0.9623 - auc: 0.9867 - val_loss: 0.2644 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9553
Epoch 98/100
600/600 [==============================] - 0s 71us/step - loss: 0.1183 - binary_accuracy: 0.9617 - sensitivity: 0.9562 - specificity: 0.9737 - gmeasure: 0.9649 - auc: 0.9874 - val_loss: 0.2646 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9549
Epoch 99/100
600/600 [==============================] - 0s 60us/step - loss: 0.1190 - binary_accuracy: 0.9567 - sensitivity: 0.9635 - specificity: 0.9400 - gmeasure: 0.9513 - auc: 0.9871 - val_loss: 0.2673 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9553
Epoch 100/100
600/600 [==============================] - 0s 59us/step - loss: 0.1134 - binary_accuracy: 0.9650 - sensitivity: 0.9638 - specificity: 0.9655 - gmeasure: 0.9643 - auc: 0.9873 - val_loss: 0.2639 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9048 - val_specificity: 0.9333 - val_gmeasure: 0.9189 - val_auc: 0.9560
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 5.950875282287598!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.013648033142089844!
[root    |INFO|build_network.py:175] Evaluation: [0.14493373036384583, 0.9546666741371155, 0.9478764533996582, 0.9698275923728943, 0.9587891697883606, 0.9821844696998596]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 22us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.013254642486572266!
[root    |INFO|build_network.py:175] Evaluation: [0.20152749121189117, 0.9319999814033508, 0.9349112510681152, 0.9259259104728699, 0.930407702922821, 0.966177225112915]
[root    |INFO|deepbiome.py:179] Compute time : 7.348566770553589
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 691us/step - loss: 0.1415 - binary_accuracy: 0.9517 - sensitivity: 0.9675 - specificity: 0.9035 - gmeasure: 0.9339 - auc: 0.9852 - val_loss: 0.1819 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9794
Epoch 2/100
600/600 [==============================] - 0s 68us/step - loss: 0.1382 - binary_accuracy: 0.9583 - sensitivity: 0.9561 - specificity: 0.9630 - gmeasure: 0.9595 - auc: 0.9856 - val_loss: 0.1909 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9783
Epoch 3/100
600/600 [==============================] - 0s 62us/step - loss: 0.1418 - binary_accuracy: 0.9450 - sensitivity: 0.9706 - specificity: 0.8815 - gmeasure: 0.9243 - auc: 0.9863 - val_loss: 0.1910 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9541 - val_specificity: 0.8049 - val_gmeasure: 0.8763 - val_auc: 0.9787
Epoch 4/100
600/600 [==============================] - 0s 62us/step - loss: 0.1403 - binary_accuracy: 0.9550 - sensitivity: 0.9571 - specificity: 0.9561 - gmeasure: 0.9561 - auc: 0.9852 - val_loss: 0.1808 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9450 - val_specificity: 0.9024 - val_gmeasure: 0.9235 - val_auc: 0.9796
Epoch 5/100
600/600 [==============================] - 0s 69us/step - loss: 0.1376 - binary_accuracy: 0.9533 - sensitivity: 0.9590 - specificity: 0.9415 - gmeasure: 0.9494 - auc: 0.9866 - val_loss: 0.1939 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9794
Epoch 6/100
600/600 [==============================] - 0s 69us/step - loss: 0.1362 - binary_accuracy: 0.9500 - sensitivity: 0.9727 - specificity: 0.9000 - gmeasure: 0.9349 - auc: 0.9860 - val_loss: 0.1914 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9794
Epoch 7/100
600/600 [==============================] - 0s 69us/step - loss: 0.1350 - binary_accuracy: 0.9583 - sensitivity: 0.9636 - specificity: 0.9458 - gmeasure: 0.9542 - auc: 0.9866 - val_loss: 0.1799 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9450 - val_specificity: 0.9024 - val_gmeasure: 0.9235 - val_auc: 0.9801
Epoch 8/100
600/600 [==============================] - 0s 66us/step - loss: 0.1326 - binary_accuracy: 0.9583 - sensitivity: 0.9566 - specificity: 0.9639 - gmeasure: 0.9602 - auc: 0.9866 - val_loss: 0.1858 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9790
Epoch 9/100
600/600 [==============================] - 0s 62us/step - loss: 0.1285 - binary_accuracy: 0.9583 - sensitivity: 0.9676 - specificity: 0.9318 - gmeasure: 0.9494 - auc: 0.9859 - val_loss: 0.1967 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9790
Epoch 10/100
600/600 [==============================] - 0s 65us/step - loss: 0.1285 - binary_accuracy: 0.9550 - sensitivity: 0.9701 - specificity: 0.9142 - gmeasure: 0.9417 - auc: 0.9858 - val_loss: 0.1847 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9792
Epoch 11/100
600/600 [==============================] - 0s 62us/step - loss: 0.1278 - binary_accuracy: 0.9550 - sensitivity: 0.9570 - specificity: 0.9484 - gmeasure: 0.9525 - auc: 0.9869 - val_loss: 0.1770 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9805
Epoch 12/100
600/600 [==============================] - 0s 63us/step - loss: 0.1259 - binary_accuracy: 0.9617 - sensitivity: 0.9590 - specificity: 0.9683 - gmeasure: 0.9636 - auc: 0.9865 - val_loss: 0.1879 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796
Epoch 13/100
600/600 [==============================] - 0s 68us/step - loss: 0.1265 - binary_accuracy: 0.9567 - sensitivity: 0.9725 - specificity: 0.9129 - gmeasure: 0.9422 - auc: 0.9855 - val_loss: 0.1901 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9790
Epoch 14/100
600/600 [==============================] - 0s 67us/step - loss: 0.1221 - binary_accuracy: 0.9633 - sensitivity: 0.9697 - specificity: 0.9409 - gmeasure: 0.9549 - auc: 0.9863 - val_loss: 0.1835 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9796
Epoch 15/100
600/600 [==============================] - 0s 67us/step - loss: 0.1241 - binary_accuracy: 0.9600 - sensitivity: 0.9591 - specificity: 0.9660 - gmeasure: 0.9625 - auc: 0.9869 - val_loss: 0.1839 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803
Epoch 16/100
600/600 [==============================] - 0s 65us/step - loss: 0.1220 - binary_accuracy: 0.9617 - sensitivity: 0.9656 - specificity: 0.9518 - gmeasure: 0.9584 - auc: 0.9864 - val_loss: 0.1939 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9794
Epoch 17/100
600/600 [==============================] - 0s 65us/step - loss: 0.1209 - binary_accuracy: 0.9600 - sensitivity: 0.9702 - specificity: 0.9320 - gmeasure: 0.9507 - auc: 0.9862 - val_loss: 0.1829 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9541 - val_specificity: 0.8293 - val_gmeasure: 0.8895 - val_auc: 0.9799
Epoch 18/100
600/600 [==============================] - 0s 63us/step - loss: 0.1194 - binary_accuracy: 0.9700 - sensitivity: 0.9705 - specificity: 0.9719 - gmeasure: 0.9711 - auc: 0.9874 - val_loss: 0.1811 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803
Epoch 19/100
600/600 [==============================] - 0s 65us/step - loss: 0.1202 - binary_accuracy: 0.9650 - sensitivity: 0.9671 - specificity: 0.9629 - gmeasure: 0.9649 - auc: 0.9866 - val_loss: 0.1840 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803
Epoch 20/100
600/600 [==============================] - 0s 64us/step - loss: 0.1176 - binary_accuracy: 0.9717 - sensitivity: 0.9731 - specificity: 0.9700 - gmeasure: 0.9715 - auc: 0.9872 - val_loss: 0.1836 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9801
Epoch 21/100
600/600 [==============================] - 0s 68us/step - loss: 0.1164 - binary_accuracy: 0.9667 - sensitivity: 0.9683 - specificity: 0.9615 - gmeasure: 0.9648 - auc: 0.9872 - val_loss: 0.1918 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796
Epoch 22/100
600/600 [==============================] - 0s 67us/step - loss: 0.1164 - binary_accuracy: 0.9600 - sensitivity: 0.9680 - specificity: 0.9381 - gmeasure: 0.9526 - auc: 0.9872 - val_loss: 0.1888 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799
Epoch 23/100
600/600 [==============================] - 0s 64us/step - loss: 0.1158 - binary_accuracy: 0.9683 - sensitivity: 0.9680 - specificity: 0.9695 - gmeasure: 0.9688 - auc: 0.9873 - val_loss: 0.1853 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9801
Epoch 24/100
600/600 [==============================] - 0s 64us/step - loss: 0.1135 - binary_accuracy: 0.9683 - sensitivity: 0.9680 - specificity: 0.9710 - gmeasure: 0.9694 - auc: 0.9881 - val_loss: 0.1899 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799
Epoch 25/100
600/600 [==============================] - 0s 67us/step - loss: 0.1133 - binary_accuracy: 0.9683 - sensitivity: 0.9723 - specificity: 0.9575 - gmeasure: 0.9648 - auc: 0.9871 - val_loss: 0.1861 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9541 - val_specificity: 0.8293 - val_gmeasure: 0.8895 - val_auc: 0.9803
Epoch 26/100
600/600 [==============================] - 0s 59us/step - loss: 0.1127 - binary_accuracy: 0.9683 - sensitivity: 0.9678 - specificity: 0.9685 - gmeasure: 0.9681 - auc: 0.9878 - val_loss: 0.1854 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9801
Epoch 27/100
600/600 [==============================] - 0s 61us/step - loss: 0.1112 - binary_accuracy: 0.9700 - sensitivity: 0.9702 - specificity: 0.9689 - gmeasure: 0.9695 - auc: 0.9880 - val_loss: 0.1905 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 28/100
600/600 [==============================] - 0s 67us/step - loss: 0.1126 - binary_accuracy: 0.9650 - sensitivity: 0.9725 - specificity: 0.9476 - gmeasure: 0.9597 - auc: 0.9870 - val_loss: 0.1865 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803
Epoch 29/100
600/600 [==============================] - 0s 62us/step - loss: 0.1099 - binary_accuracy: 0.9700 - sensitivity: 0.9704 - specificity: 0.9681 - gmeasure: 0.9692 - auc: 0.9874 - val_loss: 0.1828 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808
Epoch 30/100
600/600 [==============================] - 0s 70us/step - loss: 0.1123 - binary_accuracy: 0.9667 - sensitivity: 0.9703 - specificity: 0.9579 - gmeasure: 0.9637 - auc: 0.9885 - val_loss: 0.1942 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 31/100
600/600 [==============================] - 0s 67us/step - loss: 0.1084 - binary_accuracy: 0.9683 - sensitivity: 0.9725 - specificity: 0.9572 - gmeasure: 0.9648 - auc: 0.9880 - val_loss: 0.1832 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9805
Epoch 32/100
600/600 [==============================] - 0s 69us/step - loss: 0.1111 - binary_accuracy: 0.9667 - sensitivity: 0.9616 - specificity: 0.9806 - gmeasure: 0.9710 - auc: 0.9887 - val_loss: 0.1839 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9810
Epoch 33/100
600/600 [==============================] - 0s 67us/step - loss: 0.1063 - binary_accuracy: 0.9667 - sensitivity: 0.9675 - specificity: 0.9640 - gmeasure: 0.9656 - auc: 0.9887 - val_loss: 0.2031 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 34/100
600/600 [==============================] - 0s 65us/step - loss: 0.1093 - binary_accuracy: 0.9617 - sensitivity: 0.9749 - specificity: 0.9272 - gmeasure: 0.9504 - auc: 0.9881 - val_loss: 0.1875 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9812
Epoch 35/100
600/600 [==============================] - 0s 65us/step - loss: 0.1069 - binary_accuracy: 0.9700 - sensitivity: 0.9681 - specificity: 0.9748 - gmeasure: 0.9713 - auc: 0.9880 - val_loss: 0.1872 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808
Epoch 36/100
600/600 [==============================] - 0s 64us/step - loss: 0.1076 - binary_accuracy: 0.9683 - sensitivity: 0.9681 - specificity: 0.9709 - gmeasure: 0.9694 - auc: 0.9884 - val_loss: 0.1929 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9812
Epoch 37/100
600/600 [==============================] - 0s 68us/step - loss: 0.1057 - binary_accuracy: 0.9683 - sensitivity: 0.9746 - specificity: 0.9494 - gmeasure: 0.9616 - auc: 0.9888 - val_loss: 0.1817 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9814
Epoch 38/100
600/600 [==============================] - 0s 66us/step - loss: 0.1041 - binary_accuracy: 0.9650 - sensitivity: 0.9612 - specificity: 0.9743 - gmeasure: 0.9677 - auc: 0.9893 - val_loss: 0.1890 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9810
Epoch 39/100
600/600 [==============================] - 0s 65us/step - loss: 0.1037 - binary_accuracy: 0.9700 - sensitivity: 0.9752 - specificity: 0.9556 - gmeasure: 0.9651 - auc: 0.9881 - val_loss: 0.1981 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 40/100
600/600 [==============================] - 0s 63us/step - loss: 0.1030 - binary_accuracy: 0.9700 - sensitivity: 0.9748 - specificity: 0.9567 - gmeasure: 0.9657 - auc: 0.9882 - val_loss: 0.1866 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808
Epoch 41/100
600/600 [==============================] - 0s 66us/step - loss: 0.1016 - binary_accuracy: 0.9667 - sensitivity: 0.9633 - specificity: 0.9752 - gmeasure: 0.9692 - auc: 0.9891 - val_loss: 0.1858 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9805
Epoch 42/100
600/600 [==============================] - 0s 68us/step - loss: 0.1009 - binary_accuracy: 0.9717 - sensitivity: 0.9708 - specificity: 0.9761 - gmeasure: 0.9734 - auc: 0.9889 - val_loss: 0.1973 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808
Epoch 43/100
600/600 [==============================] - 0s 67us/step - loss: 0.1003 - binary_accuracy: 0.9700 - sensitivity: 0.9747 - specificity: 0.9557 - gmeasure: 0.9651 - auc: 0.9884 - val_loss: 0.1933 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9810
Epoch 44/100
600/600 [==============================] - 0s 69us/step - loss: 0.1035 - binary_accuracy: 0.9683 - sensitivity: 0.9663 - specificity: 0.9783 - gmeasure: 0.9722 - auc: 0.9895 - val_loss: 0.1898 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9805
Epoch 45/100
600/600 [==============================] - 0s 66us/step - loss: 0.1030 - binary_accuracy: 0.9667 - sensitivity: 0.9749 - specificity: 0.9440 - gmeasure: 0.9589 - auc: 0.9893 - val_loss: 0.1997 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9810
Epoch 46/100
600/600 [==============================] - 0s 67us/step - loss: 0.0997 - binary_accuracy: 0.9717 - sensitivity: 0.9701 - specificity: 0.9743 - gmeasure: 0.9721 - auc: 0.9890 - val_loss: 0.1844 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9778
Epoch 47/100
600/600 [==============================] - 0s 65us/step - loss: 0.1008 - binary_accuracy: 0.9717 - sensitivity: 0.9681 - specificity: 0.9819 - gmeasure: 0.9748 - auc: 0.9894 - val_loss: 0.1959 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 48/100
600/600 [==============================] - 0s 59us/step - loss: 0.0975 - binary_accuracy: 0.9733 - sensitivity: 0.9770 - specificity: 0.9632 - gmeasure: 0.9700 - auc: 0.9890 - val_loss: 0.1965 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 49/100
600/600 [==============================] - 0s 65us/step - loss: 0.0984 - binary_accuracy: 0.9750 - sensitivity: 0.9725 - specificity: 0.9814 - gmeasure: 0.9769 - auc: 0.9883 - val_loss: 0.1957 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9808
Epoch 50/100
600/600 [==============================] - 0s 59us/step - loss: 0.0963 - binary_accuracy: 0.9750 - sensitivity: 0.9728 - specificity: 0.9827 - gmeasure: 0.9777 - auc: 0.9893 - val_loss: 0.1979 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9808
Epoch 51/100
600/600 [==============================] - 0s 66us/step - loss: 0.0958 - binary_accuracy: 0.9717 - sensitivity: 0.9729 - specificity: 0.9722 - gmeasure: 0.9725 - auc: 0.9897 - val_loss: 0.1970 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 52/100
600/600 [==============================] - 0s 66us/step - loss: 0.0966 - binary_accuracy: 0.9700 - sensitivity: 0.9751 - specificity: 0.9623 - gmeasure: 0.9684 - auc: 0.9898 - val_loss: 0.1881 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803
Epoch 53/100
600/600 [==============================] - 0s 64us/step - loss: 0.1003 - binary_accuracy: 0.9683 - sensitivity: 0.9630 - specificity: 0.9820 - gmeasure: 0.9723 - auc: 0.9901 - val_loss: 0.1891 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9776
Epoch 54/100
600/600 [==============================] - 0s 65us/step - loss: 0.1012 - binary_accuracy: 0.9650 - sensitivity: 0.9705 - specificity: 0.9585 - gmeasure: 0.9641 - auc: 0.9900 - val_loss: 0.2116 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803
Epoch 55/100
600/600 [==============================] - 0s 62us/step - loss: 0.0962 - binary_accuracy: 0.9733 - sensitivity: 0.9749 - specificity: 0.9699 - gmeasure: 0.9722 - auc: 0.9899 - val_loss: 0.1863 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9781
Epoch 56/100
600/600 [==============================] - 0s 67us/step - loss: 0.0942 - binary_accuracy: 0.9750 - sensitivity: 0.9704 - specificity: 0.9885 - gmeasure: 0.9793 - auc: 0.9899 - val_loss: 0.1956 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808
Epoch 57/100
600/600 [==============================] - 0s 65us/step - loss: 0.0928 - binary_accuracy: 0.9733 - sensitivity: 0.9748 - specificity: 0.9691 - gmeasure: 0.9719 - auc: 0.9899 - val_loss: 0.2025 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 58/100
600/600 [==============================] - 0s 63us/step - loss: 0.0920 - binary_accuracy: 0.9717 - sensitivity: 0.9745 - specificity: 0.9643 - gmeasure: 0.9694 - auc: 0.9898 - val_loss: 0.1898 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9810
Epoch 59/100
600/600 [==============================] - 0s 62us/step - loss: 0.0919 - binary_accuracy: 0.9767 - sensitivity: 0.9729 - specificity: 0.9880 - gmeasure: 0.9803 - auc: 0.9900 - val_loss: 0.1998 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 60/100
600/600 [==============================] - 0s 61us/step - loss: 0.0910 - binary_accuracy: 0.9767 - sensitivity: 0.9775 - specificity: 0.9733 - gmeasure: 0.9754 - auc: 0.9906 - val_loss: 0.2048 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 61/100
600/600 [==============================] - 0s 58us/step - loss: 0.0907 - binary_accuracy: 0.9767 - sensitivity: 0.9772 - specificity: 0.9753 - gmeasure: 0.9762 - auc: 0.9905 - val_loss: 0.1917 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9810
Epoch 62/100
600/600 [==============================] - 0s 57us/step - loss: 0.0896 - binary_accuracy: 0.9767 - sensitivity: 0.9749 - specificity: 0.9820 - gmeasure: 0.9784 - auc: 0.9906 - val_loss: 0.1968 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808
Epoch 63/100
600/600 [==============================] - 0s 60us/step - loss: 0.0893 - binary_accuracy: 0.9767 - sensitivity: 0.9752 - specificity: 0.9805 - gmeasure: 0.9779 - auc: 0.9908 - val_loss: 0.1991 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9801
Epoch 64/100
600/600 [==============================] - 0s 65us/step - loss: 0.0881 - binary_accuracy: 0.9783 - sensitivity: 0.9771 - specificity: 0.9830 - gmeasure: 0.9801 - auc: 0.9909 - val_loss: 0.2026 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 65/100
600/600 [==============================] - 0s 68us/step - loss: 0.0875 - binary_accuracy: 0.9783 - sensitivity: 0.9772 - specificity: 0.9816 - gmeasure: 0.9794 - auc: 0.9907 - val_loss: 0.2008 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796
Epoch 66/100
600/600 [==============================] - 0s 63us/step - loss: 0.0869 - binary_accuracy: 0.9783 - sensitivity: 0.9746 - specificity: 0.9867 - gmeasure: 0.9806 - auc: 0.9905 - val_loss: 0.1986 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 67/100
600/600 [==============================] - 0s 66us/step - loss: 0.0866 - binary_accuracy: 0.9733 - sensitivity: 0.9748 - specificity: 0.9696 - gmeasure: 0.9721 - auc: 0.9906 - val_loss: 0.1989 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799
Epoch 68/100
600/600 [==============================] - 0s 65us/step - loss: 0.0854 - binary_accuracy: 0.9800 - sensitivity: 0.9751 - specificity: 0.9933 - gmeasure: 0.9842 - auc: 0.9909 - val_loss: 0.2006 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9803
Epoch 69/100
600/600 [==============================] - 0s 69us/step - loss: 0.0858 - binary_accuracy: 0.9800 - sensitivity: 0.9770 - specificity: 0.9872 - gmeasure: 0.9821 - auc: 0.9912 - val_loss: 0.2060 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9799
Epoch 70/100
600/600 [==============================] - 0s 66us/step - loss: 0.0846 - binary_accuracy: 0.9783 - sensitivity: 0.9773 - specificity: 0.9812 - gmeasure: 0.9792 - auc: 0.9907 - val_loss: 0.1975 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 71/100
600/600 [==============================] - 0s 68us/step - loss: 0.0852 - binary_accuracy: 0.9767 - sensitivity: 0.9749 - specificity: 0.9822 - gmeasure: 0.9785 - auc: 0.9911 - val_loss: 0.1964 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803
Epoch 72/100
600/600 [==============================] - 0s 68us/step - loss: 0.0839 - binary_accuracy: 0.9767 - sensitivity: 0.9750 - specificity: 0.9814 - gmeasure: 0.9782 - auc: 0.9911 - val_loss: 0.2061 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9799
Epoch 73/100
600/600 [==============================] - 0s 63us/step - loss: 0.0840 - binary_accuracy: 0.9817 - sensitivity: 0.9796 - specificity: 0.9881 - gmeasure: 0.9838 - auc: 0.9913 - val_loss: 0.2037 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9781
Epoch 74/100
600/600 [==============================] - 0s 64us/step - loss: 0.0841 - binary_accuracy: 0.9817 - sensitivity: 0.9794 - specificity: 0.9883 - gmeasure: 0.9838 - auc: 0.9907 - val_loss: 0.2048 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 75/100
600/600 [==============================] - 0s 67us/step - loss: 0.0823 - binary_accuracy: 0.9800 - sensitivity: 0.9787 - specificity: 0.9811 - gmeasure: 0.9799 - auc: 0.9909 - val_loss: 0.1948 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782
Epoch 76/100
600/600 [==============================] - 0s 59us/step - loss: 0.0831 - binary_accuracy: 0.9767 - sensitivity: 0.9702 - specificity: 0.9943 - gmeasure: 0.9821 - auc: 0.9917 - val_loss: 0.2030 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805
Epoch 77/100
600/600 [==============================] - 0s 59us/step - loss: 0.0816 - binary_accuracy: 0.9750 - sensitivity: 0.9771 - specificity: 0.9713 - gmeasure: 0.9740 - auc: 0.9925 - val_loss: 0.2130 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796
Epoch 78/100
600/600 [==============================] - 0s 61us/step - loss: 0.0813 - binary_accuracy: 0.9767 - sensitivity: 0.9797 - specificity: 0.9676 - gmeasure: 0.9736 - auc: 0.9919 - val_loss: 0.2050 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796
Epoch 79/100
600/600 [==============================] - 0s 66us/step - loss: 0.0805 - binary_accuracy: 0.9817 - sensitivity: 0.9771 - specificity: 0.9947 - gmeasure: 0.9859 - auc: 0.9912 - val_loss: 0.2030 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9781
Epoch 80/100
600/600 [==============================] - 0s 67us/step - loss: 0.0798 - binary_accuracy: 0.9817 - sensitivity: 0.9770 - specificity: 0.9944 - gmeasure: 0.9856 - auc: 0.9916 - val_loss: 0.2043 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801
Epoch 81/100
600/600 [==============================] - 0s 65us/step - loss: 0.0796 - binary_accuracy: 0.9817 - sensitivity: 0.9795 - specificity: 0.9880 - gmeasure: 0.9837 - auc: 0.9926 - val_loss: 0.2062 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799
Epoch 82/100
600/600 [==============================] - 0s 70us/step - loss: 0.0788 - binary_accuracy: 0.9817 - sensitivity: 0.9773 - specificity: 0.9940 - gmeasure: 0.9856 - auc: 0.9924 - val_loss: 0.2033 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796
Epoch 83/100
600/600 [==============================] - 0s 63us/step - loss: 0.0787 - binary_accuracy: 0.9783 - sensitivity: 0.9798 - specificity: 0.9744 - gmeasure: 0.9771 - auc: 0.9922 - val_loss: 0.2111 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9794
Epoch 84/100
600/600 [==============================] - 0s 68us/step - loss: 0.0805 - binary_accuracy: 0.9800 - sensitivity: 0.9746 - specificity: 0.9933 - gmeasure: 0.9839 - auc: 0.9928 - val_loss: 0.2025 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9777
Epoch 85/100
600/600 [==============================] - 0s 62us/step - loss: 0.0790 - binary_accuracy: 0.9767 - sensitivity: 0.9793 - specificity: 0.9695 - gmeasure: 0.9742 - auc: 0.9926 - val_loss: 0.2186 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9790
Epoch 86/100
600/600 [==============================] - 0s 66us/step - loss: 0.0790 - binary_accuracy: 0.9783 - sensitivity: 0.9753 - specificity: 0.9892 - gmeasure: 0.9821 - auc: 0.9926 - val_loss: 0.1964 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782
Epoch 87/100
600/600 [==============================] - 0s 67us/step - loss: 0.0767 - binary_accuracy: 0.9783 - sensitivity: 0.9773 - specificity: 0.9825 - gmeasure: 0.9798 - auc: 0.9928 - val_loss: 0.2171 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9792
Epoch 88/100
600/600 [==============================] - 0s 61us/step - loss: 0.0759 - binary_accuracy: 0.9783 - sensitivity: 0.9816 - specificity: 0.9702 - gmeasure: 0.9757 - auc: 0.9924 - val_loss: 0.2073 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9775
Epoch 89/100
600/600 [==============================] - 0s 66us/step - loss: 0.0747 - binary_accuracy: 0.9833 - sensitivity: 0.9795 - specificity: 0.9933 - gmeasure: 0.9864 - auc: 0.9930 - val_loss: 0.2128 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9762
Epoch 90/100
600/600 [==============================] - 0s 66us/step - loss: 0.0753 - binary_accuracy: 0.9800 - sensitivity: 0.9810 - specificity: 0.9733 - gmeasure: 0.9769 - auc: 0.9926 - val_loss: 0.2163 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9785
Epoch 91/100
600/600 [==============================] - 0s 68us/step - loss: 0.0736 - binary_accuracy: 0.9850 - sensitivity: 0.9813 - specificity: 0.9931 - gmeasure: 0.9871 - auc: 0.9929 - val_loss: 0.2020 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9777
Epoch 92/100
600/600 [==============================] - 0s 64us/step - loss: 0.0734 - binary_accuracy: 0.9817 - sensitivity: 0.9797 - specificity: 0.9883 - gmeasure: 0.9839 - auc: 0.9930 - val_loss: 0.2134 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9794
Epoch 93/100
600/600 [==============================] - 0s 59us/step - loss: 0.0726 - binary_accuracy: 0.9833 - sensitivity: 0.9794 - specificity: 0.9936 - gmeasure: 0.9865 - auc: 0.9925 - val_loss: 0.2117 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9770
Epoch 94/100
600/600 [==============================] - 0s 66us/step - loss: 0.0754 - binary_accuracy: 0.9800 - sensitivity: 0.9750 - specificity: 0.9944 - gmeasure: 0.9846 - auc: 0.9932 - val_loss: 0.2075 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782
Epoch 95/100
600/600 [==============================] - 0s 64us/step - loss: 0.0744 - binary_accuracy: 0.9783 - sensitivity: 0.9794 - specificity: 0.9758 - gmeasure: 0.9773 - auc: 0.9930 - val_loss: 0.2269 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9790
Epoch 96/100
600/600 [==============================] - 0s 64us/step - loss: 0.0725 - binary_accuracy: 0.9800 - sensitivity: 0.9797 - specificity: 0.9822 - gmeasure: 0.9809 - auc: 0.9932 - val_loss: 0.1935 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9633 - val_specificity: 0.8780 - val_gmeasure: 0.9197 - val_auc: 0.9785
Epoch 97/100
600/600 [==============================] - 0s 65us/step - loss: 0.0735 - binary_accuracy: 0.9783 - sensitivity: 0.9725 - specificity: 0.9939 - gmeasure: 0.9831 - auc: 0.9933 - val_loss: 0.2176 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9794
Epoch 98/100
600/600 [==============================] - 0s 67us/step - loss: 0.0719 - binary_accuracy: 0.9800 - sensitivity: 0.9815 - specificity: 0.9772 - gmeasure: 0.9793 - auc: 0.9928 - val_loss: 0.2189 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796
Epoch 99/100
600/600 [==============================] - 0s 66us/step - loss: 0.0697 - binary_accuracy: 0.9833 - sensitivity: 0.9793 - specificity: 0.9936 - gmeasure: 0.9864 - auc: 0.9934 - val_loss: 0.2047 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9786
Epoch 100/100
600/600 [==============================] - 0s 69us/step - loss: 0.0696 - binary_accuracy: 0.9817 - sensitivity: 0.9770 - specificity: 0.9939 - gmeasure: 0.9854 - auc: 0.9935 - val_loss: 0.2214 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9785
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 5.911888599395752!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.012015104293823242!
[root    |INFO|build_network.py:175] Evaluation: [0.09940922260284424, 0.9706666469573975, 0.9798534512519836, 0.9460784196853638, 0.9628178477287292, 0.9906180500984192]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 25us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.013327836990356445!
[root    |INFO|build_network.py:175] Evaluation: [0.32912105321884155, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.9599969983100891]
[root    |INFO|deepbiome.py:179] Compute time : 7.48249077796936
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 600 samples, validate on 150 samples
Epoch 1/100
600/600 [==============================] - 0s 751us/step - loss: 0.5407 - binary_accuracy: 0.7183 - sensitivity: 0.9787 - specificity: 0.1501 - gmeasure: 0.3349 - auc: 0.7700 - val_loss: 0.5851 - val_binary_accuracy: 0.6733 - val_sensitivity: 0.9796 - val_specificity: 0.0962 - val_gmeasure: 0.3069 - val_auc: 0.7597
Epoch 2/100
600/600 [==============================] - 0s 66us/step - loss: 0.5363 - binary_accuracy: 0.7317 - sensitivity: 0.9544 - specificity: 0.2456 - gmeasure: 0.4715 - auc: 0.7742 - val_loss: 0.5865 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9286 - val_specificity: 0.4423 - val_gmeasure: 0.6409 - val_auc: 0.7661
Epoch 3/100
600/600 [==============================] - 0s 65us/step - loss: 0.5347 - binary_accuracy: 0.7550 - sensitivity: 0.9471 - specificity: 0.3336 - gmeasure: 0.5609 - auc: 0.7787 - val_loss: 0.5843 - val_binary_accuracy: 0.6867 - val_sensitivity: 0.9694 - val_specificity: 0.1538 - val_gmeasure: 0.3862 - val_auc: 0.7633
Epoch 4/100
600/600 [==============================] - 0s 64us/step - loss: 0.5342 - binary_accuracy: 0.7317 - sensitivity: 0.9805 - specificity: 0.1848 - gmeasure: 0.4167 - auc: 0.7722 - val_loss: 0.5872 - val_binary_accuracy: 0.6867 - val_sensitivity: 0.9694 - val_specificity: 0.1538 - val_gmeasure: 0.3862 - val_auc: 0.7594
Epoch 5/100
600/600 [==============================] - 0s 68us/step - loss: 0.5316 - binary_accuracy: 0.7300 - sensitivity: 0.9659 - specificity: 0.2071 - gmeasure: 0.4466 - auc: 0.7723 - val_loss: 0.5825 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.9388 - val_specificity: 0.3846 - val_gmeasure: 0.6009 - val_auc: 0.7624
Epoch 6/100
600/600 [==============================] - 0s 66us/step - loss: 0.5307 - binary_accuracy: 0.7467 - sensitivity: 0.9200 - specificity: 0.3658 - gmeasure: 0.5785 - auc: 0.7773 - val_loss: 0.5825 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7691
Epoch 7/100
600/600 [==============================] - 0s 69us/step - loss: 0.5295 - binary_accuracy: 0.7383 - sensitivity: 0.9055 - specificity: 0.3685 - gmeasure: 0.5771 - auc: 0.7779 - val_loss: 0.5809 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9184 - val_specificity: 0.3846 - val_gmeasure: 0.5943 - val_auc: 0.7651
Epoch 8/100
600/600 [==============================] - 0s 66us/step - loss: 0.5294 - binary_accuracy: 0.7367 - sensitivity: 0.9325 - specificity: 0.3068 - gmeasure: 0.5250 - auc: 0.7809 - val_loss: 0.5846 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9490 - val_specificity: 0.2885 - val_gmeasure: 0.5232 - val_auc: 0.7622
Epoch 9/100
600/600 [==============================] - 0s 65us/step - loss: 0.5268 - binary_accuracy: 0.7333 - sensitivity: 0.9274 - specificity: 0.3023 - gmeasure: 0.5256 - auc: 0.7782 - val_loss: 0.5793 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7682
Epoch 10/100
600/600 [==============================] - 0s 69us/step - loss: 0.5265 - binary_accuracy: 0.7383 - sensitivity: 0.8939 - specificity: 0.3946 - gmeasure: 0.5872 - auc: 0.7823 - val_loss: 0.5787 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.7735
Epoch 11/100
600/600 [==============================] - 0s 81us/step - loss: 0.5242 - binary_accuracy: 0.7333 - sensitivity: 0.8957 - specificity: 0.3781 - gmeasure: 0.5789 - auc: 0.7834 - val_loss: 0.5790 - val_binary_accuracy: 0.7067 - val_sensitivity: 0.8980 - val_specificity: 0.3462 - val_gmeasure: 0.5575 - val_auc: 0.7686
Epoch 12/100
600/600 [==============================] - 0s 67us/step - loss: 0.5227 - binary_accuracy: 0.7283 - sensitivity: 0.9099 - specificity: 0.3232 - gmeasure: 0.5403 - auc: 0.7801 - val_loss: 0.5779 - val_binary_accuracy: 0.7067 - val_sensitivity: 0.8980 - val_specificity: 0.3462 - val_gmeasure: 0.5575 - val_auc: 0.7694
Epoch 13/100
600/600 [==============================] - 0s 69us/step - loss: 0.5213 - binary_accuracy: 0.7333 - sensitivity: 0.9013 - specificity: 0.3646 - gmeasure: 0.5702 - auc: 0.7850 - val_loss: 0.5752 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.7714
Epoch 14/100
600/600 [==============================] - 0s 64us/step - loss: 0.5196 - binary_accuracy: 0.7400 - sensitivity: 0.8955 - specificity: 0.3898 - gmeasure: 0.5880 - auc: 0.7859 - val_loss: 0.5750 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7695
Epoch 15/100
600/600 [==============================] - 0s 62us/step - loss: 0.5179 - binary_accuracy: 0.7400 - sensitivity: 0.9007 - specificity: 0.3887 - gmeasure: 0.5900 - auc: 0.7886 - val_loss: 0.5747 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7698
Epoch 16/100
600/600 [==============================] - 0s 57us/step - loss: 0.5174 - binary_accuracy: 0.7383 - sensitivity: 0.9017 - specificity: 0.3815 - gmeasure: 0.5853 - auc: 0.7882 - val_loss: 0.5733 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7712
Epoch 17/100
600/600 [==============================] - 0s 66us/step - loss: 0.5154 - binary_accuracy: 0.7450 - sensitivity: 0.8967 - specificity: 0.3997 - gmeasure: 0.5964 - auc: 0.7912 - val_loss: 0.5716 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8776 - val_specificity: 0.4808 - val_gmeasure: 0.6495 - val_auc: 0.7747
Epoch 18/100
600/600 [==============================] - 0s 70us/step - loss: 0.5144 - binary_accuracy: 0.7383 - sensitivity: 0.9030 - specificity: 0.3764 - gmeasure: 0.5812 - auc: 0.7918 - val_loss: 0.5730 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.9184 - val_specificity: 0.3654 - val_gmeasure: 0.5793 - val_auc: 0.7761
Epoch 19/100
600/600 [==============================] - 0s 68us/step - loss: 0.5126 - binary_accuracy: 0.7433 - sensitivity: 0.9026 - specificity: 0.3905 - gmeasure: 0.5896 - auc: 0.7926 - val_loss: 0.5694 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.7785
Epoch 20/100
600/600 [==============================] - 0s 68us/step - loss: 0.5106 - binary_accuracy: 0.7483 - sensitivity: 0.8957 - specificity: 0.4232 - gmeasure: 0.6151 - auc: 0.7948 - val_loss: 0.5691 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7779
Epoch 21/100
600/600 [==============================] - 0s 66us/step - loss: 0.5099 - binary_accuracy: 0.7500 - sensitivity: 0.9009 - specificity: 0.4219 - gmeasure: 0.6148 - auc: 0.7999 - val_loss: 0.5680 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7794
Epoch 22/100
600/600 [==============================] - 0s 68us/step - loss: 0.5072 - binary_accuracy: 0.7567 - sensitivity: 0.9179 - specificity: 0.4034 - gmeasure: 0.6078 - auc: 0.7979 - val_loss: 0.5708 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9184 - val_specificity: 0.4038 - val_gmeasure: 0.6090 - val_auc: 0.7804
Epoch 23/100
600/600 [==============================] - 0s 68us/step - loss: 0.5070 - binary_accuracy: 0.7600 - sensitivity: 0.9152 - specificity: 0.4173 - gmeasure: 0.6179 - auc: 0.7983 - val_loss: 0.5653 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8776 - val_specificity: 0.4615 - val_gmeasure: 0.6364 - val_auc: 0.7834
Epoch 24/100
600/600 [==============================] - 0s 67us/step - loss: 0.5038 - binary_accuracy: 0.7633 - sensitivity: 0.9057 - specificity: 0.4496 - gmeasure: 0.6367 - auc: 0.8049 - val_loss: 0.5647 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8776 - val_specificity: 0.4423 - val_gmeasure: 0.6230 - val_auc: 0.7841
Epoch 25/100
600/600 [==============================] - 0s 66us/step - loss: 0.5016 - binary_accuracy: 0.7583 - sensitivity: 0.9106 - specificity: 0.4231 - gmeasure: 0.6205 - auc: 0.8020 - val_loss: 0.5659 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.8878 - val_specificity: 0.4038 - val_gmeasure: 0.5988 - val_auc: 0.7849
Epoch 26/100
600/600 [==============================] - 0s 66us/step - loss: 0.5009 - binary_accuracy: 0.7650 - sensitivity: 0.9127 - specificity: 0.4420 - gmeasure: 0.6340 - auc: 0.8004 - val_loss: 0.5629 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7879
Epoch 27/100
600/600 [==============================] - 0s 65us/step - loss: 0.5010 - binary_accuracy: 0.7600 - sensitivity: 0.9131 - specificity: 0.4172 - gmeasure: 0.6162 - auc: 0.8030 - val_loss: 0.5645 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.8878 - val_specificity: 0.4038 - val_gmeasure: 0.5988 - val_auc: 0.7883
Epoch 28/100
600/600 [==============================] - 0s 66us/step - loss: 0.4975 - binary_accuracy: 0.7717 - sensitivity: 0.9105 - specificity: 0.4668 - gmeasure: 0.6505 - auc: 0.8098 - val_loss: 0.5622 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8673 - val_specificity: 0.5000 - val_gmeasure: 0.6585 - val_auc: 0.7891
Epoch 29/100
600/600 [==============================] - 0s 65us/step - loss: 0.4975 - binary_accuracy: 0.7733 - sensitivity: 0.9120 - specificity: 0.4751 - gmeasure: 0.6565 - auc: 0.8101 - val_loss: 0.5625 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7922
Epoch 30/100
600/600 [==============================] - 0s 69us/step - loss: 0.4938 - binary_accuracy: 0.7700 - sensitivity: 0.9295 - specificity: 0.4171 - gmeasure: 0.6217 - auc: 0.8106 - val_loss: 0.5605 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7939
Epoch 31/100
600/600 [==============================] - 0s 67us/step - loss: 0.4970 - binary_accuracy: 0.7750 - sensitivity: 0.8986 - specificity: 0.5135 - gmeasure: 0.6738 - auc: 0.8151 - val_loss: 0.5592 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7947
Epoch 32/100
600/600 [==============================] - 0s 67us/step - loss: 0.4909 - binary_accuracy: 0.7767 - sensitivity: 0.9281 - specificity: 0.4413 - gmeasure: 0.6333 - auc: 0.8127 - val_loss: 0.5669 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8980 - val_specificity: 0.4038 - val_gmeasure: 0.6022 - val_auc: 0.7926
Epoch 33/100
600/600 [==============================] - 0s 66us/step - loss: 0.4896 - binary_accuracy: 0.7733 - sensitivity: 0.9295 - specificity: 0.4308 - gmeasure: 0.6305 - auc: 0.8143 - val_loss: 0.5570 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7975
Epoch 34/100
600/600 [==============================] - 0s 66us/step - loss: 0.4858 - binary_accuracy: 0.7900 - sensitivity: 0.9181 - specificity: 0.5080 - gmeasure: 0.6828 - auc: 0.8205 - val_loss: 0.5569 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7969
Epoch 35/100
600/600 [==============================] - 0s 70us/step - loss: 0.4831 - binary_accuracy: 0.7850 - sensitivity: 0.9263 - specificity: 0.4731 - gmeasure: 0.6610 - auc: 0.8203 - val_loss: 0.5596 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7976
Epoch 36/100
600/600 [==============================] - 0s 70us/step - loss: 0.4811 - binary_accuracy: 0.7833 - sensitivity: 0.9322 - specificity: 0.4553 - gmeasure: 0.6514 - auc: 0.8225 - val_loss: 0.5585 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7967
Epoch 37/100
600/600 [==============================] - 0s 64us/step - loss: 0.4792 - binary_accuracy: 0.7883 - sensitivity: 0.9271 - specificity: 0.4855 - gmeasure: 0.6692 - auc: 0.8251 - val_loss: 0.5574 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7961
Epoch 38/100
600/600 [==============================] - 0s 66us/step - loss: 0.4772 - binary_accuracy: 0.7950 - sensitivity: 0.9281 - specificity: 0.5039 - gmeasure: 0.6833 - auc: 0.8268 - val_loss: 0.5565 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7959
Epoch 39/100
600/600 [==============================] - 0s 65us/step - loss: 0.4745 - binary_accuracy: 0.7933 - sensitivity: 0.9320 - specificity: 0.4866 - gmeasure: 0.6734 - auc: 0.8285 - val_loss: 0.5570 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7960
Epoch 40/100
600/600 [==============================] - 0s 67us/step - loss: 0.4723 - binary_accuracy: 0.8017 - sensitivity: 0.9393 - specificity: 0.4921 - gmeasure: 0.6782 - auc: 0.8308 - val_loss: 0.5555 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7969
Epoch 41/100
600/600 [==============================] - 0s 66us/step - loss: 0.4708 - binary_accuracy: 0.8100 - sensitivity: 0.9374 - specificity: 0.5269 - gmeasure: 0.7027 - auc: 0.8308 - val_loss: 0.5555 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7961
Epoch 42/100
600/600 [==============================] - 0s 69us/step - loss: 0.4693 - binary_accuracy: 0.7983 - sensitivity: 0.9394 - specificity: 0.4922 - gmeasure: 0.6773 - auc: 0.8335 - val_loss: 0.5598 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7982
Epoch 43/100
600/600 [==============================] - 0s 69us/step - loss: 0.4661 - binary_accuracy: 0.8100 - sensitivity: 0.9420 - specificity: 0.5220 - gmeasure: 0.7006 - auc: 0.8358 - val_loss: 0.5556 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8878 - val_specificity: 0.4615 - val_gmeasure: 0.6401 - val_auc: 0.7969
Epoch 44/100
600/600 [==============================] - 0s 66us/step - loss: 0.4635 - binary_accuracy: 0.8117 - sensitivity: 0.9425 - specificity: 0.5284 - gmeasure: 0.7049 - auc: 0.8394 - val_loss: 0.5568 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7965
Epoch 45/100
600/600 [==============================] - 0s 67us/step - loss: 0.4610 - binary_accuracy: 0.8100 - sensitivity: 0.9466 - specificity: 0.5093 - gmeasure: 0.6934 - auc: 0.8410 - val_loss: 0.5550 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8776 - val_specificity: 0.4615 - val_gmeasure: 0.6364 - val_auc: 0.7963
Epoch 46/100
600/600 [==============================] - 0s 63us/step - loss: 0.4595 - binary_accuracy: 0.8150 - sensitivity: 0.9345 - specificity: 0.5520 - gmeasure: 0.7179 - auc: 0.8445 - val_loss: 0.5537 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.7945
Epoch 47/100
600/600 [==============================] - 0s 63us/step - loss: 0.4557 - binary_accuracy: 0.8267 - sensitivity: 0.9445 - specificity: 0.5635 - gmeasure: 0.7270 - auc: 0.8437 - val_loss: 0.5592 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9082 - val_specificity: 0.4038 - val_gmeasure: 0.6056 - val_auc: 0.7982
Epoch 48/100
600/600 [==============================] - 0s 68us/step - loss: 0.4546 - binary_accuracy: 0.8167 - sensitivity: 0.9514 - specificity: 0.5233 - gmeasure: 0.7025 - auc: 0.8474 - val_loss: 0.5545 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.7979
Epoch 49/100
600/600 [==============================] - 0s 66us/step - loss: 0.4511 - binary_accuracy: 0.8250 - sensitivity: 0.9512 - specificity: 0.5476 - gmeasure: 0.7214 - auc: 0.8502 - val_loss: 0.5562 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9082 - val_specificity: 0.4231 - val_gmeasure: 0.6199 - val_auc: 0.7971
Epoch 50/100
600/600 [==============================] - 0s 64us/step - loss: 0.4481 - binary_accuracy: 0.8200 - sensitivity: 0.9538 - specificity: 0.5233 - gmeasure: 0.7064 - auc: 0.8514 - val_loss: 0.5542 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.8980 - val_specificity: 0.5192 - val_gmeasure: 0.6828 - val_auc: 0.7961
Epoch 51/100
600/600 [==============================] - 0s 63us/step - loss: 0.4454 - binary_accuracy: 0.8300 - sensitivity: 0.9549 - specificity: 0.5555 - gmeasure: 0.7280 - auc: 0.8518 - val_loss: 0.5547 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.7977
Epoch 52/100
600/600 [==============================] - 0s 62us/step - loss: 0.4444 - binary_accuracy: 0.8183 - sensitivity: 0.9543 - specificity: 0.5197 - gmeasure: 0.7025 - auc: 0.8566 - val_loss: 0.5569 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7993
Epoch 53/100
600/600 [==============================] - 0s 61us/step - loss: 0.4492 - binary_accuracy: 0.8283 - sensitivity: 0.9327 - specificity: 0.6139 - gmeasure: 0.7542 - auc: 0.8612 - val_loss: 0.5516 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.7987
Epoch 54/100
600/600 [==============================] - 0s 63us/step - loss: 0.4427 - binary_accuracy: 0.8167 - sensitivity: 0.9469 - specificity: 0.5302 - gmeasure: 0.7066 - auc: 0.8613 - val_loss: 0.5752 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.9490 - val_specificity: 0.3654 - val_gmeasure: 0.5888 - val_auc: 0.8031
Epoch 55/100
600/600 [==============================] - 0s 66us/step - loss: 0.4403 - binary_accuracy: 0.8167 - sensitivity: 0.9520 - specificity: 0.5152 - gmeasure: 0.6964 - auc: 0.8636 - val_loss: 0.5503 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8673 - val_specificity: 0.5385 - val_gmeasure: 0.6834 - val_auc: 0.7992
Epoch 56/100
600/600 [==============================] - 0s 72us/step - loss: 0.4386 - binary_accuracy: 0.8200 - sensitivity: 0.9348 - specificity: 0.5707 - gmeasure: 0.7298 - auc: 0.8614 - val_loss: 0.5556 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8042
Epoch 57/100
600/600 [==============================] - 0s 68us/step - loss: 0.4351 - binary_accuracy: 0.8183 - sensitivity: 0.9576 - specificity: 0.5174 - gmeasure: 0.7033 - auc: 0.8704 - val_loss: 0.5534 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8052
Epoch 58/100
600/600 [==============================] - 0s 66us/step - loss: 0.4370 - binary_accuracy: 0.8267 - sensitivity: 0.9265 - specificity: 0.6121 - gmeasure: 0.7515 - auc: 0.8683 - val_loss: 0.5479 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.8070
Epoch 59/100
600/600 [==============================] - 0s 67us/step - loss: 0.4322 - binary_accuracy: 0.8233 - sensitivity: 0.9469 - specificity: 0.5522 - gmeasure: 0.7224 - auc: 0.8655 - val_loss: 0.5667 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9388 - val_specificity: 0.4231 - val_gmeasure: 0.6302 - val_auc: 0.8086
Epoch 60/100
600/600 [==============================] - 0s 66us/step - loss: 0.4328 - binary_accuracy: 0.8233 - sensitivity: 0.9431 - specificity: 0.5715 - gmeasure: 0.7325 - auc: 0.8689 - val_loss: 0.5470 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.8081
Epoch 61/100
600/600 [==============================] - 0s 68us/step - loss: 0.4277 - binary_accuracy: 0.8300 - sensitivity: 0.9469 - specificity: 0.5749 - gmeasure: 0.7375 - auc: 0.8708 - val_loss: 0.5607 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9286 - val_specificity: 0.4615 - val_gmeasure: 0.6547 - val_auc: 0.8090
Epoch 62/100
600/600 [==============================] - 0s 72us/step - loss: 0.4245 - binary_accuracy: 0.8350 - sensitivity: 0.9583 - specificity: 0.5630 - gmeasure: 0.7344 - auc: 0.8711 - val_loss: 0.5475 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8100
Epoch 63/100
600/600 [==============================] - 0s 65us/step - loss: 0.4230 - binary_accuracy: 0.8383 - sensitivity: 0.9396 - specificity: 0.6194 - gmeasure: 0.7617 - auc: 0.8713 - val_loss: 0.5491 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8127
Epoch 64/100
600/600 [==============================] - 0s 68us/step - loss: 0.4216 - binary_accuracy: 0.8300 - sensitivity: 0.9531 - specificity: 0.5536 - gmeasure: 0.7246 - auc: 0.8727 - val_loss: 0.5609 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9184 - val_specificity: 0.4615 - val_gmeasure: 0.6510 - val_auc: 0.8137
Epoch 65/100
600/600 [==============================] - 0s 59us/step - loss: 0.4182 - binary_accuracy: 0.8267 - sensitivity: 0.9510 - specificity: 0.5505 - gmeasure: 0.7234 - auc: 0.8745 - val_loss: 0.5439 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8776 - val_specificity: 0.5385 - val_gmeasure: 0.6874 - val_auc: 0.8120
Epoch 66/100
600/600 [==============================] - 0s 56us/step - loss: 0.4200 - binary_accuracy: 0.8267 - sensitivity: 0.9203 - specificity: 0.6160 - gmeasure: 0.7519 - auc: 0.8721 - val_loss: 0.5553 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8155
Epoch 67/100
600/600 [==============================] - 0s 59us/step - loss: 0.4165 - binary_accuracy: 0.8300 - sensitivity: 0.9601 - specificity: 0.5538 - gmeasure: 0.7271 - auc: 0.8826 - val_loss: 0.5560 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8158
Epoch 68/100
600/600 [==============================] - 0s 69us/step - loss: 0.4127 - binary_accuracy: 0.8367 - sensitivity: 0.9563 - specificity: 0.5711 - gmeasure: 0.7384 - auc: 0.8767 - val_loss: 0.5430 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8673 - val_specificity: 0.5385 - val_gmeasure: 0.6834 - val_auc: 0.8148
Epoch 69/100
600/600 [==============================] - 0s 65us/step - loss: 0.4157 - binary_accuracy: 0.8283 - sensitivity: 0.9180 - specificity: 0.6318 - gmeasure: 0.7611 - auc: 0.8771 - val_loss: 0.5549 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8178
Epoch 70/100
600/600 [==============================] - 0s 71us/step - loss: 0.4122 - binary_accuracy: 0.8283 - sensitivity: 0.9614 - specificity: 0.5333 - gmeasure: 0.7152 - auc: 0.8783 - val_loss: 0.5546 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8190
Epoch 71/100
600/600 [==============================] - 0s 67us/step - loss: 0.4092 - binary_accuracy: 0.8383 - sensitivity: 0.9460 - specificity: 0.6015 - gmeasure: 0.7541 - auc: 0.8802 - val_loss: 0.5462 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8194
Epoch 72/100
600/600 [==============================] - 0s 68us/step - loss: 0.4074 - binary_accuracy: 0.8383 - sensitivity: 0.9343 - specificity: 0.6181 - gmeasure: 0.7575 - auc: 0.8797 - val_loss: 0.5521 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8189
Epoch 73/100
600/600 [==============================] - 0s 67us/step - loss: 0.4061 - binary_accuracy: 0.8400 - sensitivity: 0.9497 - specificity: 0.6001 - gmeasure: 0.7524 - auc: 0.8826 - val_loss: 0.5515 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8197
Epoch 74/100
600/600 [==============================] - 0s 70us/step - loss: 0.4041 - binary_accuracy: 0.8417 - sensitivity: 0.9491 - specificity: 0.6045 - gmeasure: 0.7570 - auc: 0.8822 - val_loss: 0.5483 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8218
Epoch 75/100
600/600 [==============================] - 0s 70us/step - loss: 0.4025 - binary_accuracy: 0.8417 - sensitivity: 0.9443 - specificity: 0.6133 - gmeasure: 0.7606 - auc: 0.8842 - val_loss: 0.5506 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8230
Epoch 76/100
600/600 [==============================] - 0s 66us/step - loss: 0.4024 - binary_accuracy: 0.8367 - sensitivity: 0.9487 - specificity: 0.5913 - gmeasure: 0.7481 - auc: 0.8848 - val_loss: 0.5455 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8244
Epoch 77/100
600/600 [==============================] - 0s 67us/step - loss: 0.3995 - binary_accuracy: 0.8383 - sensitivity: 0.9345 - specificity: 0.6253 - gmeasure: 0.7639 - auc: 0.8861 - val_loss: 0.5539 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8225
Epoch 78/100
600/600 [==============================] - 0s 67us/step - loss: 0.4021 - binary_accuracy: 0.8300 - sensitivity: 0.9546 - specificity: 0.5561 - gmeasure: 0.7284 - auc: 0.8886 - val_loss: 0.5454 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.8216
Epoch 79/100
600/600 [==============================] - 0s 68us/step - loss: 0.4051 - binary_accuracy: 0.8300 - sensitivity: 0.9059 - specificity: 0.6663 - gmeasure: 0.7760 - auc: 0.8858 - val_loss: 0.5465 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8233
Epoch 80/100
600/600 [==============================] - 0s 67us/step - loss: 0.3958 - binary_accuracy: 0.8400 - sensitivity: 0.9613 - specificity: 0.5728 - gmeasure: 0.7418 - auc: 0.8905 - val_loss: 0.5636 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8240
Epoch 81/100
600/600 [==============================] - 0s 68us/step - loss: 0.3950 - binary_accuracy: 0.8400 - sensitivity: 0.9385 - specificity: 0.6181 - gmeasure: 0.7597 - auc: 0.8905 - val_loss: 0.5397 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8571 - val_specificity: 0.5577 - val_gmeasure: 0.6914 - val_auc: 0.8255
Epoch 82/100
600/600 [==============================] - 0s 66us/step - loss: 0.3948 - binary_accuracy: 0.8367 - sensitivity: 0.9191 - specificity: 0.6505 - gmeasure: 0.7728 - auc: 0.8869 - val_loss: 0.5591 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8292
Epoch 83/100
600/600 [==============================] - 0s 64us/step - loss: 0.4004 - binary_accuracy: 0.8267 - sensitivity: 0.9614 - specificity: 0.5312 - gmeasure: 0.7135 - auc: 0.8936 - val_loss: 0.5468 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.8292
Epoch 84/100
600/600 [==============================] - 0s 64us/step - loss: 0.3926 - binary_accuracy: 0.8350 - sensitivity: 0.9119 - specificity: 0.6719 - gmeasure: 0.7812 - auc: 0.8920 - val_loss: 0.5383 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.8571 - val_specificity: 0.6154 - val_gmeasure: 0.7263 - val_auc: 0.8283
Epoch 85/100
600/600 [==============================] - 0s 64us/step - loss: 0.3882 - binary_accuracy: 0.8350 - sensitivity: 0.9297 - specificity: 0.6253 - gmeasure: 0.7622 - auc: 0.8942 - val_loss: 0.5689 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9184 - val_specificity: 0.4423 - val_gmeasure: 0.6373 - val_auc: 0.8250
Epoch 86/100
600/600 [==============================] - 0s 64us/step - loss: 0.3902 - binary_accuracy: 0.8417 - sensitivity: 0.9617 - specificity: 0.5770 - gmeasure: 0.7449 - auc: 0.8950 - val_loss: 0.5371 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.8571 - val_specificity: 0.5962 - val_gmeasure: 0.7148 - val_auc: 0.8289
Epoch 87/100
600/600 [==============================] - 0s 66us/step - loss: 0.3944 - binary_accuracy: 0.8433 - sensitivity: 0.9058 - specificity: 0.7082 - gmeasure: 0.8004 - auc: 0.8937 - val_loss: 0.5485 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8314
Epoch 88/100
600/600 [==============================] - 0s 67us/step - loss: 0.3949 - binary_accuracy: 0.8300 - sensitivity: 0.9567 - specificity: 0.5505 - gmeasure: 0.7257 - auc: 0.8957 - val_loss: 0.5596 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8291
Epoch 89/100
600/600 [==============================] - 0s 66us/step - loss: 0.3935 - binary_accuracy: 0.8350 - sensitivity: 0.9230 - specificity: 0.6444 - gmeasure: 0.7680 - auc: 0.8941 - val_loss: 0.5364 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.8571 - val_specificity: 0.6731 - val_gmeasure: 0.7596 - val_auc: 0.8308
Epoch 90/100
600/600 [==============================] - 0s 64us/step - loss: 0.3858 - binary_accuracy: 0.8367 - sensitivity: 0.9275 - specificity: 0.6401 - gmeasure: 0.7687 - auc: 0.8961 - val_loss: 0.5779 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9286 - val_specificity: 0.4423 - val_gmeasure: 0.6409 - val_auc: 0.8259
Epoch 91/100
600/600 [==============================] - 0s 67us/step - loss: 0.3879 - binary_accuracy: 0.8367 - sensitivity: 0.9613 - specificity: 0.5610 - gmeasure: 0.7324 - auc: 0.8995 - val_loss: 0.5384 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.8571 - val_specificity: 0.6154 - val_gmeasure: 0.7263 - val_auc: 0.8328
Epoch 92/100
600/600 [==============================] - 0s 69us/step - loss: 0.3828 - binary_accuracy: 0.8433 - sensitivity: 0.9176 - specificity: 0.6785 - gmeasure: 0.7886 - auc: 0.8976 - val_loss: 0.5471 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8303
Epoch 93/100
600/600 [==============================] - 0s 64us/step - loss: 0.3813 - binary_accuracy: 0.8483 - sensitivity: 0.9491 - specificity: 0.6263 - gmeasure: 0.7707 - auc: 0.9008 - val_loss: 0.5540 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8318
Epoch 94/100
600/600 [==============================] - 0s 67us/step - loss: 0.3892 - binary_accuracy: 0.8350 - sensitivity: 0.9173 - specificity: 0.6609 - gmeasure: 0.7745 - auc: 0.9004 - val_loss: 0.5370 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.8571 - val_specificity: 0.6346 - val_gmeasure: 0.7375 - val_auc: 0.8340
Epoch 95/100
600/600 [==============================] - 0s 64us/step - loss: 0.3798 - binary_accuracy: 0.8450 - sensitivity: 0.9515 - specificity: 0.6100 - gmeasure: 0.7609 - auc: 0.9003 - val_loss: 0.5702 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9184 - val_specificity: 0.4615 - val_gmeasure: 0.6510 - val_auc: 0.8324
Epoch 96/100
600/600 [==============================] - 0s 58us/step - loss: 0.3782 - binary_accuracy: 0.8383 - sensitivity: 0.9542 - specificity: 0.5771 - gmeasure: 0.7407 - auc: 0.9032 - val_loss: 0.5345 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.8571 - val_specificity: 0.6731 - val_gmeasure: 0.7596 - val_auc: 0.8350
Epoch 97/100
600/600 [==============================] - 0s 61us/step - loss: 0.3792 - binary_accuracy: 0.8483 - sensitivity: 0.9178 - specificity: 0.6917 - gmeasure: 0.7956 - auc: 0.8957 - val_loss: 0.5468 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.8359
Epoch 98/100
600/600 [==============================] - 0s 61us/step - loss: 0.3749 - binary_accuracy: 0.8467 - sensitivity: 0.9468 - specificity: 0.6255 - gmeasure: 0.7677 - auc: 0.9040 - val_loss: 0.5529 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8359
Epoch 99/100
600/600 [==============================] - 0s 62us/step - loss: 0.3713 - binary_accuracy: 0.8467 - sensitivity: 0.9444 - specificity: 0.6312 - gmeasure: 0.7720 - auc: 0.9038 - val_loss: 0.5392 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.8673 - val_specificity: 0.6346 - val_gmeasure: 0.7419 - val_auc: 0.8367
Epoch 100/100
600/600 [==============================] - 0s 66us/step - loss: 0.3717 - binary_accuracy: 0.8483 - sensitivity: 0.9281 - specificity: 0.6763 - gmeasure: 0.7919 - auc: 0.9017 - val_loss: 0.5460 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8373
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 6.008526563644409!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
750/750 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010854005813598633!
[root    |INFO|build_network.py:175] Evaluation: [0.40481051802635193, 0.828000009059906, 0.931506872177124, 0.6066945791244507, 0.7517580389976501, 0.8901817202568054]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 20us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010163545608520508!
[root    |INFO|build_network.py:175] Evaluation: [0.4838153123855591, 0.7680000066757202, 0.8932584524154663, 0.4583333432674408, 0.6398516297340393, 0.8164793848991394]
[root    |INFO|deepbiome.py:179] Compute time : 7.612103700637817
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.21638449 0.91777778 0.95307893 0.84086686 0.89112169 0.95432808]
[root    |INFO|deepbiome.py:189]        std : [0.13452731 0.06381763 0.0200773  0.16586842 0.0985587  0.04548881]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.33815462 0.86266667 0.92739757 0.70703378 0.80289634 0.91421787]
[root    |INFO|deepbiome.py:196]        std : [0.11542041 0.06930768 0.02536959 0.19205399 0.1212509  0.06915758]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>Let’s check the history plot again.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_the_list_of_inputs_51_0.png" src="_images/example_with_the_list_of_inputs_51_0.png" />
</div>
</div>
</div>
<div class="section" id="6.-Load-the-pre-trained-network-for-testing">
<h2>6. Load the pre-trained network for testing<a class="headerlink" href="#6.-Load-the-pre-trained-network-for-testing" title="Permalink to this headline">¶</a></h2>
<p>If you want to test the trained model, you can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_test</span></code> function. If you use the index file, this function provide the evaluation using test index (index set not included in the index file) for each fold. If not, this function provide the evaluation using the whole samples. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is setted as <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will test the model only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/classification_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_test</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">test_network_info</span><span class="p">,</span> <span class="n">test_path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:294] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 1 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 329us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.24315500259399414!
[root    |INFO|build_network.py:175] Evaluation: [0.20152749121189117, 0.9319999814033508, 0.9349112510681152, 0.9259259104728699, 0.930407702922821, 0.966177225112915]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.4478569030761719
[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 2 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 283us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.20883989334106445!
[root    |INFO|build_network.py:175] Evaluation: [0.32912105321884155, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.9599969983100891]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.3928356170654297
[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 3 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
250/250 [==============================] - 0s 282us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.18898677825927734!
[root    |INFO|build_network.py:175] Evaluation: [0.4838153123855591, 0.7680000066757202, 0.8932584524154663, 0.4583333432674408, 0.6398516297340393, 0.8164793848991394]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.4299449920654297
[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:328] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:331]       mean : [0.33815462 0.86266667 0.92739757 0.70703378 0.80289634 0.91421787]
[root    |INFO|deepbiome.py:332]        std : [0.11542041 0.06930768 0.02536959 0.19205399 0.1212509  0.06915758]
[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:336] Total Computing Ended
[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>This function provides the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">+</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">s</span>.strip() for s in network_info[&#39;model_info&#39;][&#39;metrics&#39;].split(&#39;,&#39;)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.mean(evaluation, axis=0)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Std : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.std(evaluation, axis=0)]))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc
Mean:           0.3382          0.8627          0.9274          0.7070          0.8029          0.9142
Std :           0.1154          0.0693          0.0254          0.1921          0.1213          0.0692
</pre></div></div>
</div>
</div>
<div class="section" id="7.-Load-the-pre-trained-network-for-prediction">
<h2>7. Load the pre-trained network for prediction<a class="headerlink" href="#7.-Load-the-pre-trained-network-for-prediction" title="Permalink to this headline">¶</a></h2>
<p>For prediction using the pre-trained model, we can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_prediction</span></code> function. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is set to <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will predict only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds sample’s outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;taxa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;count_list_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/gcount_list.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;count_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/count&#39;</span><span class="p">),</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight_0.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_prediction</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">prediction_network_info</span><span class="p">,</span> <span class="n">prediction_path_info</span><span class="p">,</span>
                                            <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 1 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 26us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.0282289981842041!
[root    |INFO|deepbiome.py:444] Compute time : 0.9565651416778564
[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 2 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 44us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.04712557792663574!
[root    |INFO|deepbiome.py:444] Compute time : 0.9941525459289551
[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 3 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Family&#39;, &#39;Genus&#39;, &#39;Order&#39;, &#39;Number&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 32us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.03409934043884277!
[root    |INFO|deepbiome.py:444] Compute time : 1.0578253269195557
[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:449] Total Computing Ended
[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(3, 1000, 1)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.9551762 ],
       [0.7373678 ],
       [0.07542831],
       [0.07542831],
       [0.9999994 ],
       [0.9921325 ],
       [0.07542831],
       [0.07542831],
       [0.9999854 ],
       [0.9997467 ]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="example_with_one_input_file.html" class="btn btn-neutral float-right" title="Example : k fold cross-validation with an input file" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="usage.html" class="btn btn-neutral float-left" title="Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Youngwon Choi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>