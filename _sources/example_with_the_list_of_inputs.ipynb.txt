{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : k times repetition with the list of k input files \n",
    "\n",
    "DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.\n",
    "\n",
    "To use DeepBiome, you can experiment (1) __k times repetition__ or (2) __k fold cross-validation__.\n",
    "For each experiment, we asuume that the dataset is given by\n",
    "- __A list of k input files for k times repetition.__\n",
    "- __One input file for k fold cross-validation.__\n",
    "\n",
    "This notebook contains an example of (1) __k times repetition__ for the deep neural netowrk using deepbiome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load library\n",
    "\n",
    "First, we have to load deepbiome package. The deepbiome package is build on the tensorflow and keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepbiome import deepbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset\n",
    "\n",
    "In this example, we assume that we have __a list of k input files for k times repetition.__\n",
    "\n",
    "DeepBiome needs 4 data files as follows:\n",
    "1. __the tree information__\n",
    "1. __the lists of the input files__ (each file has all sample's information for one repetition)\n",
    "1. __the list of the names of input files__ \n",
    "1. __y__\n",
    "\n",
    "In addition, we can set __the training index for each repetition__. If we set the index file, DeepBiome builds the training set for each repetition based on each fold index in the index file. If not, DeepBiome will generate the index file locally.\n",
    "\n",
    "\n",
    "Eath data should have the csv format. Below is the example of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the tree information\n",
    "\n",
    "First we need a file about the phylogenetic tree information. This tree information file should have the format below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genus</th>\n",
       "      <th>Family</th>\n",
       "      <th>Order</th>\n",
       "      <th>Class</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Streptococcus</td>\n",
       "      <td>Streptococcaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tropheryma</td>\n",
       "      <td>Cellulomonadaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veillonella</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actinomyces</td>\n",
       "      <td>Actinomycetaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flavobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prevotella</td>\n",
       "      <td>Prevotellaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Porphyromonas</td>\n",
       "      <td>Porphyromonadaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parvimonas</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fusobacterium</td>\n",
       "      <td>Fusobacteriaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Propionibacterium</td>\n",
       "      <td>Propionibacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gemella</td>\n",
       "      <td>Bacillales_Incertae_Sedis_XI</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rothia</td>\n",
       "      <td>Micrococcaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Granulicatella</td>\n",
       "      <td>Carnobacteriaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Neisseria</td>\n",
       "      <td>Neisseriaceae</td>\n",
       "      <td>Neisseriales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lactobacillus</td>\n",
       "      <td>Lactobacillaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Megasphaera</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Catonella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atopobium</td>\n",
       "      <td>Coriobacteriaceae</td>\n",
       "      <td>Coriobacteriales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>Campylobacteraceae</td>\n",
       "      <td>Campylobacterales</td>\n",
       "      <td>Epsilonproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Capnocytophaga</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solobacterium</td>\n",
       "      <td>Erysipelotrichaceae</td>\n",
       "      <td>Erysipelotrichales</td>\n",
       "      <td>Erysipelotrichia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Moryella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Staphylococcus</td>\n",
       "      <td>Staphylococcaceae</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Filifactor</td>\n",
       "      <td>Peptostreptococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oribacterium</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Burkholderia</td>\n",
       "      <td>Burkholderiaceae</td>\n",
       "      <td>Burkholderiales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sneathia</td>\n",
       "      <td>Leptotrichiaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Treponema</td>\n",
       "      <td>Spirochaetaceae</td>\n",
       "      <td>Spirochaetales</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Moraxella</td>\n",
       "      <td>Moraxellaceae</td>\n",
       "      <td>Pseudomonadales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Haemophilus</td>\n",
       "      <td>Pasteurellaceae</td>\n",
       "      <td>Pasteurellales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Selenomonas</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Corynebacterium</td>\n",
       "      <td>Corynebacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rhizobium</td>\n",
       "      <td>Rhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bradyrhizobium</td>\n",
       "      <td>Bradyrhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Methylobacterium</td>\n",
       "      <td>Methylobacteriaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Finegoldia</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Microbacterium</td>\n",
       "      <td>Microbacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sphingomonas</td>\n",
       "      <td>Sphingomonadaceae</td>\n",
       "      <td>Sphingomonadales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Chryseobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bacteroides</td>\n",
       "      <td>Bacteroidaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bdellovibrio</td>\n",
       "      <td>Bdellovibrionaceae</td>\n",
       "      <td>Bdellovibrionales</td>\n",
       "      <td>Deltaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Streptophyta</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Cyanobacteria_Chloroplast</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Lachnospiracea_incertae_sedis</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Paracoccus</td>\n",
       "      <td>Rhodobacteraceae</td>\n",
       "      <td>Rhodobacterales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fastidiosipila</td>\n",
       "      <td>Ruminococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pseudonocardia</td>\n",
       "      <td>Pseudonocardiaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Genus                           Family  \\\n",
       "0                   Streptococcus                 Streptococcaceae   \n",
       "1                      Tropheryma                Cellulomonadaceae   \n",
       "2                     Veillonella                  Veillonellaceae   \n",
       "3                     Actinomyces                 Actinomycetaceae   \n",
       "4                  Flavobacterium                Flavobacteriaceae   \n",
       "5                      Prevotella                   Prevotellaceae   \n",
       "6                   Porphyromonas               Porphyromonadaceae   \n",
       "7                      Parvimonas  Clostridiales_Incertae_Sedis_XI   \n",
       "8                   Fusobacterium                 Fusobacteriaceae   \n",
       "9               Propionibacterium             Propionibacteriaceae   \n",
       "10                        Gemella     Bacillales_Incertae_Sedis_XI   \n",
       "11                         Rothia                   Micrococcaceae   \n",
       "12                 Granulicatella                Carnobacteriaceae   \n",
       "13                      Neisseria                    Neisseriaceae   \n",
       "14                  Lactobacillus                 Lactobacillaceae   \n",
       "15                    Megasphaera                  Veillonellaceae   \n",
       "16                      Catonella                  Lachnospiraceae   \n",
       "17                      Atopobium                Coriobacteriaceae   \n",
       "18                  Campylobacter               Campylobacteraceae   \n",
       "19                 Capnocytophaga                Flavobacteriaceae   \n",
       "20                  Solobacterium              Erysipelotrichaceae   \n",
       "21                       Moryella                  Lachnospiraceae   \n",
       "22      TM7_genera_incertae_sedis        TM7_genera_incertae_sedis   \n",
       "23                 Staphylococcus                Staphylococcaceae   \n",
       "24                     Filifactor            Peptostreptococcaceae   \n",
       "25                   Oribacterium                  Lachnospiraceae   \n",
       "26                   Burkholderia                 Burkholderiaceae   \n",
       "27                       Sneathia                 Leptotrichiaceae   \n",
       "28                      Treponema                  Spirochaetaceae   \n",
       "29                      Moraxella                    Moraxellaceae   \n",
       "30                    Haemophilus                  Pasteurellaceae   \n",
       "31                    Selenomonas                  Veillonellaceae   \n",
       "32                Corynebacterium               Corynebacteriaceae   \n",
       "33                      Rhizobium                     Rhizobiaceae   \n",
       "34                 Bradyrhizobium                Bradyrhizobiaceae   \n",
       "35               Methylobacterium              Methylobacteriaceae   \n",
       "36      OD1_genera_incertae_sedis        OD1_genera_incertae_sedis   \n",
       "37                     Finegoldia  Clostridiales_Incertae_Sedis_XI   \n",
       "38                 Microbacterium                Microbacteriaceae   \n",
       "39                   Sphingomonas                Sphingomonadaceae   \n",
       "40               Chryseobacterium                Flavobacteriaceae   \n",
       "41                    Bacteroides                   Bacteroidaceae   \n",
       "42                   Bdellovibrio               Bdellovibrionaceae   \n",
       "43                   Streptophyta                      Chloroplast   \n",
       "44  Lachnospiracea_incertae_sedis                  Lachnospiraceae   \n",
       "45                     Paracoccus                 Rhodobacteraceae   \n",
       "46                 Fastidiosipila                  Ruminococcaceae   \n",
       "47                 Pseudonocardia               Pseudonocardiaceae   \n",
       "\n",
       "                        Order                      Class  \\\n",
       "0             Lactobacillales                    Bacilli   \n",
       "1             Actinomycetales             Actinobacteria   \n",
       "2             Selenomonadales              Negativicutes   \n",
       "3             Actinomycetales             Actinobacteria   \n",
       "4            Flavobacteriales              Flavobacteria   \n",
       "5               Bacteroidales                Bacteroidia   \n",
       "6               Bacteroidales                Bacteroidia   \n",
       "7               Clostridiales                 Clostridia   \n",
       "8             Fusobacteriales               Fusobacteria   \n",
       "9             Actinomycetales             Actinobacteria   \n",
       "10                 Bacillales                    Bacilli   \n",
       "11            Actinomycetales             Actinobacteria   \n",
       "12            Lactobacillales                    Bacilli   \n",
       "13               Neisseriales         Betaproteobacteria   \n",
       "14            Lactobacillales                    Bacilli   \n",
       "15            Selenomonadales              Negativicutes   \n",
       "16              Clostridiales                 Clostridia   \n",
       "17           Coriobacteriales             Actinobacteria   \n",
       "18          Campylobacterales      Epsilonproteobacteria   \n",
       "19           Flavobacteriales              Flavobacteria   \n",
       "20         Erysipelotrichales           Erysipelotrichia   \n",
       "21              Clostridiales                 Clostridia   \n",
       "22  TM7_genera_incertae_sedis  TM7_genera_incertae_sedis   \n",
       "23                 Bacillales                    Bacilli   \n",
       "24              Clostridiales                 Clostridia   \n",
       "25              Clostridiales                 Clostridia   \n",
       "26            Burkholderiales         Betaproteobacteria   \n",
       "27            Fusobacteriales               Fusobacteria   \n",
       "28             Spirochaetales               Spirochaetes   \n",
       "29            Pseudomonadales        Gammaproteobacteria   \n",
       "30             Pasteurellales        Gammaproteobacteria   \n",
       "31            Selenomonadales              Negativicutes   \n",
       "32            Actinomycetales             Actinobacteria   \n",
       "33                Rhizobiales        Alphaproteobacteria   \n",
       "34                Rhizobiales        Alphaproteobacteria   \n",
       "35                Rhizobiales        Alphaproteobacteria   \n",
       "36  OD1_genera_incertae_sedis  OD1_genera_incertae_sedis   \n",
       "37              Clostridiales                 Clostridia   \n",
       "38            Actinomycetales             Actinobacteria   \n",
       "39           Sphingomonadales        Alphaproteobacteria   \n",
       "40           Flavobacteriales              Flavobacteria   \n",
       "41              Bacteroidales                Bacteroidia   \n",
       "42          Bdellovibrionales        Deltaproteobacteria   \n",
       "43                Chloroplast                Chloroplast   \n",
       "44              Clostridiales                 Clostridia   \n",
       "45            Rhodobacterales        Alphaproteobacteria   \n",
       "46              Clostridiales                 Clostridia   \n",
       "47            Actinomycetales             Actinobacteria   \n",
       "\n",
       "                       Phylum    Domain  \n",
       "0                  Firmicutes  Bacteria  \n",
       "1              Actinobacteria  Bacteria  \n",
       "2                  Firmicutes  Bacteria  \n",
       "3              Actinobacteria  Bacteria  \n",
       "4               Bacteroidetes  Bacteria  \n",
       "5               Bacteroidetes  Bacteria  \n",
       "6               Bacteroidetes  Bacteria  \n",
       "7                  Firmicutes  Bacteria  \n",
       "8                Fusobacteria  Bacteria  \n",
       "9              Actinobacteria  Bacteria  \n",
       "10                 Firmicutes  Bacteria  \n",
       "11             Actinobacteria  Bacteria  \n",
       "12                 Firmicutes  Bacteria  \n",
       "13             Proteobacteria  Bacteria  \n",
       "14                 Firmicutes  Bacteria  \n",
       "15                 Firmicutes  Bacteria  \n",
       "16                 Firmicutes  Bacteria  \n",
       "17             Actinobacteria  Bacteria  \n",
       "18             Proteobacteria  Bacteria  \n",
       "19              Bacteroidetes  Bacteria  \n",
       "20                 Firmicutes  Bacteria  \n",
       "21                 Firmicutes  Bacteria  \n",
       "22                        TM7  Bacteria  \n",
       "23                 Firmicutes  Bacteria  \n",
       "24                 Firmicutes  Bacteria  \n",
       "25                 Firmicutes  Bacteria  \n",
       "26             Proteobacteria  Bacteria  \n",
       "27               Fusobacteria  Bacteria  \n",
       "28               Spirochaetes  Bacteria  \n",
       "29             Proteobacteria  Bacteria  \n",
       "30             Proteobacteria  Bacteria  \n",
       "31                 Firmicutes  Bacteria  \n",
       "32             Actinobacteria  Bacteria  \n",
       "33             Proteobacteria  Bacteria  \n",
       "34             Proteobacteria  Bacteria  \n",
       "35             Proteobacteria  Bacteria  \n",
       "36                        OD1  Bacteria  \n",
       "37                 Firmicutes  Bacteria  \n",
       "38             Actinobacteria  Bacteria  \n",
       "39             Proteobacteria  Bacteria  \n",
       "40              Bacteroidetes  Bacteria  \n",
       "41              Bacteroidetes  Bacteria  \n",
       "42             Proteobacteria  Bacteria  \n",
       "43  Cyanobacteria_Chloroplast  Bacteria  \n",
       "44                 Firmicutes  Bacteria  \n",
       "45             Proteobacteria  Bacteria  \n",
       "46                 Firmicutes  Bacteria  \n",
       "47             Actinobacteria  Bacteria  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_information = pd.read_csv(resource_filename('deepbiome', 'tests/data/genus48_dic.csv'))\n",
    "tree_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the list of the name of input files\n",
    "\n",
    "In this example. we assume that input is given by the lists of files. Each file has all sample's information for one repeatition.\n",
    "If we want to use the list of the input files, we need to make a list of the names of each input file. Below is an example file for `k=1000` repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gcount_0001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gcount_0002.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gcount_0003.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcount_0004.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gcount_0005.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0  gcount_0001.csv\n",
       "1  gcount_0002.csv\n",
       "2  gcount_0003.csv\n",
       "3  gcount_0004.csv\n",
       "4  gcount_0005.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_input_files = pd.read_csv(resource_filename('deepbiome', 'tests/data/gcount_list.csv'), header=None)\n",
    "list_of_input_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>gcount_0996.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gcount_0997.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>gcount_0998.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>gcount_0999.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>gcount_1000.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "995  gcount_0996.csv\n",
       "996  gcount_0997.csv\n",
       "997  gcount_0998.csv\n",
       "998  gcount_0999.csv\n",
       "999  gcount_1000.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_input_files.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the lists of the input files\n",
    "\n",
    "Below is an example of each input file. This example has 1000 samples as rows, and the abandunce of each microbiome as columns. Below is an example file for `k=1000` repetition. This example is `gcount_0001.csv` for the first repetition in the list of the names of input files above. This file has the 4 samples' microbiome abandunce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>3224</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>1278</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1259</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>969</td>\n",
       "      <td>163</td>\n",
       "      <td>1515</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "0            841           0          813          505               5   \n",
       "1           1445           0            1          573               0   \n",
       "2           1259           0          805          650               0   \n",
       "3            982           0          327          594               0   \n",
       "4           1162           0          130          969             163   \n",
       "\n",
       "   Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "0        3224              0         362             11                 65   \n",
       "1        1278             82          85             69                154   \n",
       "2        1088              0           0             74                  0   \n",
       "3         960             81          19              9                  0   \n",
       "4        1515            167           4            162                  3   \n",
       "\n",
       "   ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "0  ...               0            87                 0            0   \n",
       "1  ...               0             1                 2            0   \n",
       "2  ...               0             2                 8            1   \n",
       "3  ...             157             1                 0            4   \n",
       "4  ...               0             9                 0            0   \n",
       "\n",
       "   Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "0             0             0                              0           0   \n",
       "1             0             0                              0           0   \n",
       "2            39             0                              0           0   \n",
       "3            60             0                              0           0   \n",
       "4             0             0                             60           0   \n",
       "\n",
       "   Fastidiosipila  Pseudonocardia  \n",
       "0               0            2133  \n",
       "1               0            3638  \n",
       "2               0            3445  \n",
       "3               0            3507  \n",
       "4               0            3945  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = pd.read_csv(resource_filename('deepbiome', 'tests/data/count/%s' % list_of_input_files.iloc[0,0]))\n",
    "x_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1401</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2655</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>259</td>\n",
       "      <td>67</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>649</td>\n",
       "      <td>69</td>\n",
       "      <td>966</td>\n",
       "      <td>1227</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>2348</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "995           1401           4           30          526               0   \n",
       "996           2655           6          106           74               0   \n",
       "997            335           0           71          259              67   \n",
       "998            649          69          966         1227               0   \n",
       "999           1258           0            0         1119               0   \n",
       "\n",
       "     Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "995         923             25           0            127                  0   \n",
       "996         952             76          13            158                125   \n",
       "997         718              1           4              4                167   \n",
       "998         508              2          30            550                  0   \n",
       "999        2348             25           0            137                176   \n",
       "\n",
       "     ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "995  ...               0             0                 7            0   \n",
       "996  ...               0             2                 0            0   \n",
       "997  ...               0           246                 0            0   \n",
       "998  ...               0             0                 0            0   \n",
       "999  ...               0             2                 0            0   \n",
       "\n",
       "     Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "995             0             0                              0           0   \n",
       "996             0             0                              0           0   \n",
       "997             6             0                              0           0   \n",
       "998             0             6                              0           0   \n",
       "999             0             0                              0           0   \n",
       "\n",
       "     Fastidiosipila  Pseudonocardia  \n",
       "995               0            4470  \n",
       "996               0            2826  \n",
       "997               0            6527  \n",
       "998               0            4402  \n",
       "999               0            2585  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (regression)\n",
    "\n",
    "This is an example of the output file for regression problem. One column contains y samples for one repeatition. \n",
    "For each repeatition (column) has outputs of 4 samples for each repeatition. Below example file has 1000 samples in row, `k=1000` repetition in column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "      <th>x1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.997270</td>\n",
       "      <td>5.492354</td>\n",
       "      <td>5.473725</td>\n",
       "      <td>1.759484</td>\n",
       "      <td>5.313252</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>4.949712</td>\n",
       "      <td>5.493533</td>\n",
       "      <td>3.743509</td>\n",
       "      <td>5.492373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.793883</td>\n",
       "      <td>1.500004</td>\n",
       "      <td>5.487526</td>\n",
       "      <td>5.493518</td>\n",
       "      <td>3.599047</td>\n",
       "      <td>5.491461</td>\n",
       "      <td>5.486244</td>\n",
       "      <td>5.487390</td>\n",
       "      <td>5.493492</td>\n",
       "      <td>3.762523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004092</td>\n",
       "      <td>1.500002</td>\n",
       "      <td>4.640348</td>\n",
       "      <td>1.538071</td>\n",
       "      <td>5.491065</td>\n",
       "      <td>5.481009</td>\n",
       "      <td>5.492323</td>\n",
       "      <td>2.968531</td>\n",
       "      <td>3.576358</td>\n",
       "      <td>5.491456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500033</td>\n",
       "      <td>3.369529</td>\n",
       "      <td>1.500016</td>\n",
       "      <td>3.103297</td>\n",
       "      <td>5.493214</td>\n",
       "      <td>3.831125</td>\n",
       "      <td>5.492104</td>\n",
       "      <td>5.474811</td>\n",
       "      <td>5.492416</td>\n",
       "      <td>3.268805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.485126</td>\n",
       "      <td>4.187426</td>\n",
       "      <td>5.491340</td>\n",
       "      <td>5.469662</td>\n",
       "      <td>5.490478</td>\n",
       "      <td>1.953375</td>\n",
       "      <td>5.494656</td>\n",
       "      <td>3.741680</td>\n",
       "      <td>4.862400</td>\n",
       "      <td>5.490701</td>\n",
       "      <td>...</td>\n",
       "      <td>5.491728</td>\n",
       "      <td>2.459981</td>\n",
       "      <td>5.475697</td>\n",
       "      <td>3.114158</td>\n",
       "      <td>1.500004</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>4.113815</td>\n",
       "      <td>5.470539</td>\n",
       "      <td>5.494373</td>\n",
       "      <td>5.481754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.489590</td>\n",
       "      <td>4.863187</td>\n",
       "      <td>1.500003</td>\n",
       "      <td>5.484699</td>\n",
       "      <td>5.492657</td>\n",
       "      <td>5.491270</td>\n",
       "      <td>4.091023</td>\n",
       "      <td>5.495239</td>\n",
       "      <td>5.492804</td>\n",
       "      <td>1.500046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500034</td>\n",
       "      <td>1.500012</td>\n",
       "      <td>5.483070</td>\n",
       "      <td>2.475049</td>\n",
       "      <td>5.493846</td>\n",
       "      <td>3.287076</td>\n",
       "      <td>3.696412</td>\n",
       "      <td>5.487583</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>2.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500001</td>\n",
       "      <td>5.480769</td>\n",
       "      <td>5.489725</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>2.695212</td>\n",
       "      <td>5.492262</td>\n",
       "      <td>3.381424</td>\n",
       "      <td>4.805420</td>\n",
       "      <td>1.500047</td>\n",
       "      <td>5.474376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500046</td>\n",
       "      <td>2.586990</td>\n",
       "      <td>5.440610</td>\n",
       "      <td>4.376103</td>\n",
       "      <td>1.500030</td>\n",
       "      <td>4.713223</td>\n",
       "      <td>5.491059</td>\n",
       "      <td>3.230658</td>\n",
       "      <td>1.500045</td>\n",
       "      <td>5.488727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  4.997270  5.492354  5.473725  1.759484  5.313252  1.500044  4.949712   \n",
       "1  5.004092  1.500002  4.640348  1.538071  5.491065  5.481009  5.492323   \n",
       "2  5.485126  4.187426  5.491340  5.469662  5.490478  1.953375  5.494656   \n",
       "3  5.489590  4.863187  1.500003  5.484699  5.492657  5.491270  4.091023   \n",
       "4  1.500001  5.480769  5.489725  1.500044  2.695212  5.492262  3.381424   \n",
       "\n",
       "         x8        x9       x10  ...      x991      x992      x993      x994  \\\n",
       "0  5.493533  3.743509  5.492373  ...  2.793883  1.500004  5.487526  5.493518   \n",
       "1  2.968531  3.576358  5.491456  ...  1.500033  3.369529  1.500016  3.103297   \n",
       "2  3.741680  4.862400  5.490701  ...  5.491728  2.459981  5.475697  3.114158   \n",
       "3  5.495239  5.492804  1.500046  ...  1.500034  1.500012  5.483070  2.475049   \n",
       "4  4.805420  1.500047  5.474376  ...  1.500046  2.586990  5.440610  4.376103   \n",
       "\n",
       "       x995      x996      x997      x998      x999     x1000  \n",
       "0  3.599047  5.491461  5.486244  5.487390  5.493492  3.762523  \n",
       "1  5.493214  3.831125  5.492104  5.474811  5.492416  3.268805  \n",
       "2  1.500004  1.500019  4.113815  5.470539  5.494373  5.481754  \n",
       "3  5.493846  3.287076  3.696412  5.487583  1.500044  2.760404  \n",
       "4  1.500030  4.713223  5.491059  3.230658  1.500045  5.488727  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/regression_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "      <th>x1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.609926</td>\n",
       "      <td>5.491258</td>\n",
       "      <td>3.318610</td>\n",
       "      <td>5.444070</td>\n",
       "      <td>2.884154</td>\n",
       "      <td>5.486857</td>\n",
       "      <td>5.496554</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.482893</td>\n",
       "      <td>1.824835</td>\n",
       "      <td>...</td>\n",
       "      <td>4.478641</td>\n",
       "      <td>5.485122</td>\n",
       "      <td>4.915985</td>\n",
       "      <td>4.073239</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.492295</td>\n",
       "      <td>1.500005</td>\n",
       "      <td>1.559586</td>\n",
       "      <td>5.496415</td>\n",
       "      <td>4.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.488959</td>\n",
       "      <td>3.739806</td>\n",
       "      <td>5.489474</td>\n",
       "      <td>1.500021</td>\n",
       "      <td>5.492632</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.484813</td>\n",
       "      <td>5.467055</td>\n",
       "      <td>5.491282</td>\n",
       "      <td>1.874777</td>\n",
       "      <td>...</td>\n",
       "      <td>5.498820</td>\n",
       "      <td>5.493926</td>\n",
       "      <td>5.487404</td>\n",
       "      <td>3.162812</td>\n",
       "      <td>1.846298</td>\n",
       "      <td>5.492417</td>\n",
       "      <td>1.919107</td>\n",
       "      <td>5.480324</td>\n",
       "      <td>5.467765</td>\n",
       "      <td>5.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.498418</td>\n",
       "      <td>4.250451</td>\n",
       "      <td>5.488116</td>\n",
       "      <td>4.162031</td>\n",
       "      <td>5.494052</td>\n",
       "      <td>5.472900</td>\n",
       "      <td>1.500057</td>\n",
       "      <td>5.491497</td>\n",
       "      <td>5.491935</td>\n",
       "      <td>1.500033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.966474</td>\n",
       "      <td>5.475258</td>\n",
       "      <td>3.848034</td>\n",
       "      <td>2.863883</td>\n",
       "      <td>4.370685</td>\n",
       "      <td>5.494647</td>\n",
       "      <td>5.478855</td>\n",
       "      <td>2.465739</td>\n",
       "      <td>1.500018</td>\n",
       "      <td>5.486403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.486107</td>\n",
       "      <td>1.917414</td>\n",
       "      <td>5.414975</td>\n",
       "      <td>5.492364</td>\n",
       "      <td>2.027914</td>\n",
       "      <td>5.491349</td>\n",
       "      <td>5.494135</td>\n",
       "      <td>5.491245</td>\n",
       "      <td>1.500039</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.556995</td>\n",
       "      <td>5.457072</td>\n",
       "      <td>2.071106</td>\n",
       "      <td>5.417333</td>\n",
       "      <td>5.491818</td>\n",
       "      <td>5.473390</td>\n",
       "      <td>4.374154</td>\n",
       "      <td>5.489109</td>\n",
       "      <td>4.515340</td>\n",
       "      <td>1.500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.319623</td>\n",
       "      <td>5.482776</td>\n",
       "      <td>1.500035</td>\n",
       "      <td>5.485141</td>\n",
       "      <td>5.491019</td>\n",
       "      <td>3.733982</td>\n",
       "      <td>5.494374</td>\n",
       "      <td>3.077159</td>\n",
       "      <td>5.493188</td>\n",
       "      <td>1.500001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485356</td>\n",
       "      <td>1.500059</td>\n",
       "      <td>5.400762</td>\n",
       "      <td>5.489606</td>\n",
       "      <td>5.494583</td>\n",
       "      <td>5.490943</td>\n",
       "      <td>5.123794</td>\n",
       "      <td>5.473465</td>\n",
       "      <td>3.274979</td>\n",
       "      <td>3.700653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "995  2.609926  5.491258  3.318610  5.444070  2.884154  5.486857  5.496554   \n",
       "996  5.488959  3.739806  5.489474  1.500021  5.492632  1.500019  5.484813   \n",
       "997  3.498418  4.250451  5.488116  4.162031  5.494052  5.472900  1.500057   \n",
       "998  5.486107  1.917414  5.414975  5.492364  2.027914  5.491349  5.494135   \n",
       "999  5.319623  5.482776  1.500035  5.485141  5.491019  3.733982  5.494374   \n",
       "\n",
       "           x8        x9       x10  ...      x991      x992      x993  \\\n",
       "995  1.500019  5.482893  1.824835  ...  4.478641  5.485122  4.915985   \n",
       "996  5.467055  5.491282  1.874777  ...  5.498820  5.493926  5.487404   \n",
       "997  5.491497  5.491935  1.500033  ...  1.966474  5.475258  3.848034   \n",
       "998  5.491245  1.500039  1.500019  ...  4.556995  5.457072  2.071106   \n",
       "999  3.077159  5.493188  1.500001  ...  5.485356  1.500059  5.400762   \n",
       "\n",
       "         x994      x995      x996      x997      x998      x999     x1000  \n",
       "995  4.073239  1.500019  5.492295  1.500005  1.559586  5.496415  4.171127  \n",
       "996  3.162812  1.846298  5.492417  1.919107  5.480324  5.467765  5.457627  \n",
       "997  2.863883  4.370685  5.494647  5.478855  2.465739  1.500018  5.486403  \n",
       "998  5.417333  5.491818  5.473390  4.374154  5.489109  4.515340  1.500020  \n",
       "999  5.489606  5.494583  5.490943  5.123794  5.473465  3.274979  3.700653  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repeatition, the deepbiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.997270\n",
       "1    5.004092\n",
       "2    5.485126\n",
       "3    5.489590\n",
       "4    1.500001\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    2.609926\n",
       "996    5.488959\n",
       "997    3.498418\n",
       "998    5.486107\n",
       "999    5.319623\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (classification)\n",
    "\n",
    "This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetitions in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  ...   1.0   1.0   0.0   \n",
       "1  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   1.0   1.0   1.0   \n",
       "2  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   0.0   1.0   1.0   \n",
       "3  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...   1.0   1.0   0.0   \n",
       "4  1.0  1.0  0.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "\n",
       "   V994  V995  V996  V997  V998  V999  V1000  \n",
       "0   0.0   1.0   0.0   0.0   0.0   0.0    1.0  \n",
       "1   1.0   0.0   1.0   0.0   1.0   0.0    1.0  \n",
       "2   1.0   1.0   1.0   1.0   1.0   0.0    0.0  \n",
       "3   1.0   0.0   1.0   1.0   0.0   1.0    1.0  \n",
       "4   1.0   1.0   1.0   0.0   1.0   1.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/classification_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "995  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "996  0.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  ...   0.0   0.0   0.0   \n",
       "997  1.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  ...   1.0   1.0   1.0   \n",
       "998  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "999  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  ...   0.0   1.0   1.0   \n",
       "\n",
       "     V994  V995  V996  V997  V998  V999  V1000  \n",
       "995   1.0   1.0   0.0   1.0   1.0   0.0    1.0  \n",
       "996   1.0   1.0   0.0   1.0   0.0   1.0    1.0  \n",
       "997   1.0   1.0   0.0   1.0   1.0   1.0    0.0  \n",
       "998   1.0   0.0   1.0   1.0   0.0   1.0    1.0  \n",
       "999   0.0   0.0   0.0   1.0   1.0   1.0    1.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repeatition, the deepbiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    1.0\n",
       "996    0.0\n",
       "997    1.0\n",
       "998    0.0\n",
       "999    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exmple of the training index file for repetition\n",
    "\n",
    "For each repeatition, we have to set the training and test set. If the index file is given, the deepbiome library set the training set and test set based on the index file. Below is the example of the index file. Each column has the training indexs for each repeatition. The deepbiome will only use the samples in this index set for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>690</td>\n",
       "      <td>62</td>\n",
       "      <td>703</td>\n",
       "      <td>690</td>\n",
       "      <td>845</td>\n",
       "      <td>150</td>\n",
       "      <td>268</td>\n",
       "      <td>488</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>675</td>\n",
       "      <td>886</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>781</td>\n",
       "      <td>778</td>\n",
       "      <td>603</td>\n",
       "      <td>222</td>\n",
       "      <td>254</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498</td>\n",
       "      <td>968</td>\n",
       "      <td>123</td>\n",
       "      <td>913</td>\n",
       "      <td>348</td>\n",
       "      <td>262</td>\n",
       "      <td>705</td>\n",
       "      <td>239</td>\n",
       "      <td>632</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>636</td>\n",
       "      <td>216</td>\n",
       "      <td>495</td>\n",
       "      <td>557</td>\n",
       "      <td>196</td>\n",
       "      <td>516</td>\n",
       "      <td>23</td>\n",
       "      <td>351</td>\n",
       "      <td>472</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389</td>\n",
       "      <td>999</td>\n",
       "      <td>335</td>\n",
       "      <td>947</td>\n",
       "      <td>215</td>\n",
       "      <td>696</td>\n",
       "      <td>793</td>\n",
       "      <td>349</td>\n",
       "      <td>734</td>\n",
       "      <td>624</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>230</td>\n",
       "      <td>26</td>\n",
       "      <td>330</td>\n",
       "      <td>470</td>\n",
       "      <td>992</td>\n",
       "      <td>329</td>\n",
       "      <td>532</td>\n",
       "      <td>655</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>139</td>\n",
       "      <td>843</td>\n",
       "      <td>491</td>\n",
       "      <td>47</td>\n",
       "      <td>421</td>\n",
       "      <td>892</td>\n",
       "      <td>32</td>\n",
       "      <td>438</td>\n",
       "      <td>996</td>\n",
       "      <td>...</td>\n",
       "      <td>956</td>\n",
       "      <td>706</td>\n",
       "      <td>836</td>\n",
       "      <td>151</td>\n",
       "      <td>80</td>\n",
       "      <td>409</td>\n",
       "      <td>671</td>\n",
       "      <td>772</td>\n",
       "      <td>882</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>83</td>\n",
       "      <td>204</td>\n",
       "      <td>810</td>\n",
       "      <td>198</td>\n",
       "      <td>955</td>\n",
       "      <td>357</td>\n",
       "      <td>125</td>\n",
       "      <td>190</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>542</td>\n",
       "      <td>108</td>\n",
       "      <td>959</td>\n",
       "      <td>311</td>\n",
       "      <td>771</td>\n",
       "      <td>902</td>\n",
       "      <td>986</td>\n",
       "      <td>481</td>\n",
       "      <td>922</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "0  490  690   62  703  690  845  150  268  488  179  ...   675   886   225   \n",
       "1  498  968  123  913  348  262  705  239  632   44  ...   636   216   495   \n",
       "2  389  999  335  947  215  696  793  349  734  624  ...   626   230    26   \n",
       "3   51  139  843  491   47  421  892   32  438  996  ...   956   706   836   \n",
       "4  592   83  204  810  198  955  357  125  190  162  ...   542   108   959   \n",
       "\n",
       "   V994  V995  V996  V997  V998  V999  V1000  \n",
       "0   222   781   778   603   222   254    407  \n",
       "1   557   196   516    23   351   472    945  \n",
       "2   330   470   992   329   532   655    426  \n",
       "3   151    80   409   671   772   882    181  \n",
       "4   311   771   902   986   481   922    305  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = pd.read_csv(resource_filename('deepbiome', 'tests/data/regression_idx.csv'), dtype=np.int)\n",
    "idxs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>599</td>\n",
       "      <td>824</td>\n",
       "      <td>997</td>\n",
       "      <td>216</td>\n",
       "      <td>586</td>\n",
       "      <td>796</td>\n",
       "      <td>806</td>\n",
       "      <td>39</td>\n",
       "      <td>483</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>573</td>\n",
       "      <td>861</td>\n",
       "      <td>366</td>\n",
       "      <td>374</td>\n",
       "      <td>585</td>\n",
       "      <td>871</td>\n",
       "      <td>140</td>\n",
       "      <td>597</td>\n",
       "      <td>795</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>720</td>\n",
       "      <td>633</td>\n",
       "      <td>821</td>\n",
       "      <td>149</td>\n",
       "      <td>339</td>\n",
       "      <td>461</td>\n",
       "      <td>750</td>\n",
       "      <td>194</td>\n",
       "      <td>769</td>\n",
       "      <td>699</td>\n",
       "      <td>...</td>\n",
       "      <td>913</td>\n",
       "      <td>570</td>\n",
       "      <td>670</td>\n",
       "      <td>249</td>\n",
       "      <td>840</td>\n",
       "      <td>889</td>\n",
       "      <td>242</td>\n",
       "      <td>959</td>\n",
       "      <td>791</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>80</td>\n",
       "      <td>268</td>\n",
       "      <td>661</td>\n",
       "      <td>187</td>\n",
       "      <td>929</td>\n",
       "      <td>469</td>\n",
       "      <td>481</td>\n",
       "      <td>332</td>\n",
       "      <td>781</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>985</td>\n",
       "      <td>459</td>\n",
       "      <td>965</td>\n",
       "      <td>888</td>\n",
       "      <td>461</td>\n",
       "      <td>551</td>\n",
       "      <td>465</td>\n",
       "      <td>827</td>\n",
       "      <td>557</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>570</td>\n",
       "      <td>32</td>\n",
       "      <td>750</td>\n",
       "      <td>332</td>\n",
       "      <td>902</td>\n",
       "      <td>107</td>\n",
       "      <td>281</td>\n",
       "      <td>667</td>\n",
       "      <td>917</td>\n",
       "      <td>793</td>\n",
       "      <td>...</td>\n",
       "      <td>924</td>\n",
       "      <td>662</td>\n",
       "      <td>975</td>\n",
       "      <td>199</td>\n",
       "      <td>32</td>\n",
       "      <td>715</td>\n",
       "      <td>668</td>\n",
       "      <td>241</td>\n",
       "      <td>299</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>440</td>\n",
       "      <td>589</td>\n",
       "      <td>607</td>\n",
       "      <td>597</td>\n",
       "      <td>380</td>\n",
       "      <td>961</td>\n",
       "      <td>747</td>\n",
       "      <td>396</td>\n",
       "      <td>649</td>\n",
       "      <td>974</td>\n",
       "      <td>...</td>\n",
       "      <td>867</td>\n",
       "      <td>839</td>\n",
       "      <td>234</td>\n",
       "      <td>99</td>\n",
       "      <td>901</td>\n",
       "      <td>19</td>\n",
       "      <td>821</td>\n",
       "      <td>450</td>\n",
       "      <td>780</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "745  599  824  997  216  586  796  806   39  483  518  ...   573   861   366   \n",
       "746  720  633  821  149  339  461  750  194  769  699  ...   913   570   670   \n",
       "747   80  268  661  187  929  469  481  332  781  615  ...   985   459   965   \n",
       "748  570   32  750  332  902  107  281  667  917  793  ...   924   662   975   \n",
       "749  440  589  607  597  380  961  747  396  649  974  ...   867   839   234   \n",
       "\n",
       "     V994  V995  V996  V997  V998  V999  V1000  \n",
       "745   374   585   871   140   597   795    743  \n",
       "746   249   840   889   242   959   791    954  \n",
       "747   888   461   551   465   827   557    662  \n",
       "748   199    32   715   668   241   299    518  \n",
       "749    99   901    19   821   450   780    326  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the index set for 1st repetition. From 1000 samples above, it uses 750 samples for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    490\n",
       "1    498\n",
       "2    389\n",
       "3     51\n",
       "4    592\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745    599\n",
       "746    720\n",
       "747     80\n",
       "748    570\n",
       "749    440\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the configuration\n",
    "\n",
    "For detailed configuration, we used python dictionary as inputs for the main training function.\n",
    "You can build the configuration information for the network training by:\n",
    "1. the python dictionary format\n",
    "1. the configufation file (.cfg).\n",
    "\n",
    "In this notebook, we showed the dictionary python dictionary format configuration.\n",
    "\n",
    "Please check the detailed information about each options in the [documantation](https://young-won.github.io/deepbiome/prerequisites.html#configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the network information (`network_info`)\n",
    "\n",
    "For giving the information about the training hyper-parameter, you have to provide the dictionary for configuration to the `netowrk_info` field.\n",
    "Your configuration for the network training should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'taxa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'training_info': {\n",
    "        'batch_size': '50', \n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the path information (`path_info`)\n",
    "\n",
    "To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, we provide the dictionary for configuration to the `path_info` feild.\n",
    "Your configuration for the path information should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/classification_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'history': 'hist.json',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepBiome Training\n",
    "\n",
    "Now we can train the DeepBiome network based on the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logging, we use the python logging library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.\n",
    "\n",
    "If we set `number_of_fold`, then the deepbiome package do the cross-validation based on that value. If not, the deepbiome package do the cross-validation based on the index file. If both `number_of_fold` option and the index file is not given, then the library do leave-one-out-cross-validation (LOOCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6690 - binary_accuracy: 0.6883 - sensitivity: 0.9944 - specificity: 0.0083 - gmeasure: 0.0255 - auc: 0.5398 - val_loss: 0.6384 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6168\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6296 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5535 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5639\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.6222 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5930 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7221\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7564 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7981\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7830 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8111\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 173us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7904 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8117\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7970 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8141\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8025 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8189\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8005 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8233\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8094 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8259\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6215 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8090 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8284\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8157 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8383\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8202 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8426\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8218 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8465\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8177 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8472\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8265 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8513\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8190 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8527\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8286 - val_loss: 0.6103 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8588\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8334 - val_loss: 0.6102 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8592\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8350 - val_loss: 0.6108 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6198 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8393 - val_loss: 0.6100 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8579\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6197 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8338 - val_loss: 0.6101 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8595\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 236us/step - loss: 0.6199 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8329 - val_loss: 0.6093 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8575\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8333 - val_loss: 0.6096 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6201 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8283 - val_loss: 0.6086 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8542\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6193 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8290 - val_loss: 0.6099 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8578\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6182 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8333 - val_loss: 0.6082 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8608\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.6177 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.6069 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8562\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6174 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8424 - val_loss: 0.6068 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8598\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.6152 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8353 - val_loss: 0.6050 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8592\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6140 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8374 - val_loss: 0.6031 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8598\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 227us/step - loss: 0.6125 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8450 - val_loss: 0.6020 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 234us/step - loss: 0.6088 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8366 - val_loss: 0.5978 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8516\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.6056 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.5936 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8537\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.6006 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8433 - val_loss: 0.5878 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8544\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5929 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8420 - val_loss: 0.5805 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8525\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5854 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8549 - val_loss: 0.5720 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8538\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5723 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8486 - val_loss: 0.5572 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8516\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.5568 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8527 - val_loss: 0.5427 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8558\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5398 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8574 - val_loss: 0.5257 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8622\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.5238 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8752 - val_loss: 0.5061 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8698\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5123 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8802 - val_loss: 0.5066 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8825\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.4857 - binary_accuracy: 0.7233 - sensitivity: 0.9881 - specificity: 0.1467 - gmeasure: 0.3425 - auc: 0.8856 - val_loss: 0.4752 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9907 - val_specificity: 0.2058 - val_gmeasure: 0.4469 - val_auc: 0.8808\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.4675 - binary_accuracy: 0.7633 - sensitivity: 0.9811 - specificity: 0.2881 - gmeasure: 0.5206 - auc: 0.8939 - val_loss: 0.4615 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9907 - val_specificity: 0.3028 - val_gmeasure: 0.5470 - val_auc: 0.8886\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.4524 - binary_accuracy: 0.7817 - sensitivity: 0.9762 - specificity: 0.3274 - gmeasure: 0.5289 - auc: 0.8992 - val_loss: 0.4666 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9140 - val_specificity: 0.6335 - val_gmeasure: 0.7602 - val_auc: 0.9020\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.4537 - binary_accuracy: 0.8117 - sensitivity: 0.9724 - specificity: 0.4768 - gmeasure: 0.6650 - auc: 0.9045 - val_loss: 0.4372 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9422 - val_specificity: 0.4812 - val_gmeasure: 0.6686 - val_auc: 0.9004\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.4255 - binary_accuracy: 0.8017 - sensitivity: 0.9714 - specificity: 0.4250 - gmeasure: 0.6320 - auc: 0.9064 - val_loss: 0.4220 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9729 - val_specificity: 0.3634 - val_gmeasure: 0.5922 - val_auc: 0.9039\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.4167 - binary_accuracy: 0.8250 - sensitivity: 0.9583 - specificity: 0.5348 - gmeasure: 0.7123 - auc: 0.9173 - val_loss: 0.4102 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9729 - val_specificity: 0.3801 - val_gmeasure: 0.6058 - val_auc: 0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.4021 - binary_accuracy: 0.8267 - sensitivity: 0.9449 - specificity: 0.5452 - gmeasure: 0.7072 - auc: 0.9163 - val_loss: 0.4010 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9251 - val_specificity: 0.5931 - val_gmeasure: 0.7393 - val_auc: 0.9137\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.3993 - binary_accuracy: 0.8383 - sensitivity: 0.9508 - specificity: 0.5871 - gmeasure: 0.7392 - auc: 0.9160 - val_loss: 0.3943 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.8969 - val_specificity: 0.6574 - val_gmeasure: 0.7663 - val_auc: 0.9192\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.3871 - binary_accuracy: 0.8333 - sensitivity: 0.9415 - specificity: 0.5890 - gmeasure: 0.7390 - auc: 0.9276 - val_loss: 0.3815 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9251 - val_specificity: 0.6169 - val_gmeasure: 0.7534 - val_auc: 0.9172\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.3787 - binary_accuracy: 0.8483 - sensitivity: 0.9401 - specificity: 0.6394 - gmeasure: 0.7676 - auc: 0.9261 - val_loss: 0.3747 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9080 - val_specificity: 0.6907 - val_gmeasure: 0.7914 - val_auc: 0.9251\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.3687 - binary_accuracy: 0.8367 - sensitivity: 0.9290 - specificity: 0.6507 - gmeasure: 0.7732 - auc: 0.9314 - val_loss: 0.3767 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9251 - val_specificity: 0.4574 - val_gmeasure: 0.6411 - val_auc: 0.9241\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.3592 - binary_accuracy: 0.8400 - sensitivity: 0.9273 - specificity: 0.6327 - gmeasure: 0.7581 - auc: 0.9300 - val_loss: 0.3608 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.8772 - val_specificity: 0.7145 - val_gmeasure: 0.7910 - val_auc: 0.9264\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 188us/step - loss: 0.3492 - binary_accuracy: 0.8483 - sensitivity: 0.9290 - specificity: 0.6599 - gmeasure: 0.7753 - auc: 0.9391 - val_loss: 0.3479 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9165 - val_specificity: 0.6574 - val_gmeasure: 0.7742 - val_auc: 0.9321\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.3443 - binary_accuracy: 0.8567 - sensitivity: 0.9227 - specificity: 0.7173 - gmeasure: 0.8090 - auc: 0.9401 - val_loss: 0.3430 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9165 - val_specificity: 0.6574 - val_gmeasure: 0.7742 - val_auc: 0.9290\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.3318 - binary_accuracy: 0.8633 - sensitivity: 0.9154 - specificity: 0.7479 - gmeasure: 0.8226 - auc: 0.9430 - val_loss: 0.3373 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9165 - val_specificity: 0.6097 - val_gmeasure: 0.7468 - val_auc: 0.9342\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.3279 - binary_accuracy: 0.8483 - sensitivity: 0.9173 - specificity: 0.7085 - gmeasure: 0.8023 - auc: 0.9483 - val_loss: 0.3280 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9080 - val_specificity: 0.7383 - val_gmeasure: 0.8164 - val_auc: 0.9307\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.3254 - binary_accuracy: 0.8550 - sensitivity: 0.9039 - specificity: 0.7533 - gmeasure: 0.8220 - auc: 0.9454 - val_loss: 0.3389 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8594 - val_specificity: 0.8758 - val_gmeasure: 0.8670 - val_auc: 0.9371\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.3154 - binary_accuracy: 0.8667 - sensitivity: 0.8992 - specificity: 0.7986 - gmeasure: 0.8431 - auc: 0.9520 - val_loss: 0.3167 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8772 - val_specificity: 0.8424 - val_gmeasure: 0.8590 - val_auc: 0.9374\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.3051 - binary_accuracy: 0.8733 - sensitivity: 0.9270 - specificity: 0.7445 - gmeasure: 0.8243 - auc: 0.9523 - val_loss: 0.3434 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8409 - val_specificity: 0.9061 - val_gmeasure: 0.8725 - val_auc: 0.9419\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.2966 - binary_accuracy: 0.8817 - sensitivity: 0.9148 - specificity: 0.7833 - gmeasure: 0.8423 - auc: 0.9521 - val_loss: 0.3157 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9336 - val_specificity: 0.6812 - val_gmeasure: 0.7942 - val_auc: 0.9416\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.2981 - binary_accuracy: 0.8683 - sensitivity: 0.9152 - specificity: 0.7672 - gmeasure: 0.8341 - auc: 0.9581 - val_loss: 0.3033 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9165 - val_specificity: 0.7686 - val_gmeasure: 0.8372 - val_auc: 0.9443\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2839 - binary_accuracy: 0.8800 - sensitivity: 0.9119 - specificity: 0.8002 - gmeasure: 0.8515 - auc: 0.9546 - val_loss: 0.3109 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8765 - val_specificity: 0.9061 - val_gmeasure: 0.8909 - val_auc: 0.9440\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.2814 - binary_accuracy: 0.8800 - sensitivity: 0.9116 - specificity: 0.8054 - gmeasure: 0.8546 - auc: 0.9603 - val_loss: 0.2953 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8772 - val_specificity: 0.8591 - val_gmeasure: 0.8675 - val_auc: 0.9439\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 192us/step - loss: 0.2728 - binary_accuracy: 0.8883 - sensitivity: 0.9136 - specificity: 0.8277 - gmeasure: 0.8679 - auc: 0.9611 - val_loss: 0.2916 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9336 - val_specificity: 0.7686 - val_gmeasure: 0.8449 - val_auc: 0.9451\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.2692 - binary_accuracy: 0.8900 - sensitivity: 0.9139 - specificity: 0.8264 - gmeasure: 0.8674 - auc: 0.9658 - val_loss: 0.2837 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9251 - val_specificity: 0.8091 - val_gmeasure: 0.8627 - val_auc: 0.9461\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2741 - binary_accuracy: 0.8867 - sensitivity: 0.9255 - specificity: 0.8027 - gmeasure: 0.8578 - auc: 0.9586 - val_loss: 0.2824 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9336 - val_specificity: 0.7853 - val_gmeasure: 0.8547 - val_auc: 0.9463\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2578 - binary_accuracy: 0.8933 - sensitivity: 0.9090 - specificity: 0.8492 - gmeasure: 0.8759 - auc: 0.9650 - val_loss: 0.2818 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9165 - val_specificity: 0.8758 - val_gmeasure: 0.8949 - val_auc: 0.9478\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.2569 - binary_accuracy: 0.9017 - sensitivity: 0.9233 - specificity: 0.8562 - gmeasure: 0.8878 - auc: 0.9638 - val_loss: 0.2839 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8765 - val_specificity: 0.9061 - val_gmeasure: 0.8909 - val_auc: 0.9433\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.2619 - binary_accuracy: 0.8967 - sensitivity: 0.9278 - specificity: 0.8326 - gmeasure: 0.8744 - auc: 0.9655 - val_loss: 0.2741 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9336 - val_specificity: 0.8424 - val_gmeasure: 0.8851 - val_auc: 0.9456\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.2480 - binary_accuracy: 0.9100 - sensitivity: 0.9171 - specificity: 0.8901 - gmeasure: 0.9018 - auc: 0.9674 - val_loss: 0.2709 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9165 - val_specificity: 0.8758 - val_gmeasure: 0.8949 - val_auc: 0.9468\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2455 - binary_accuracy: 0.9083 - sensitivity: 0.9275 - specificity: 0.8660 - gmeasure: 0.8940 - auc: 0.9667 - val_loss: 0.2845 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8672 - val_specificity: 0.9061 - val_gmeasure: 0.8860 - val_auc: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.2418 - binary_accuracy: 0.9100 - sensitivity: 0.9232 - specificity: 0.8816 - gmeasure: 0.9004 - auc: 0.9693 - val_loss: 0.2713 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9422 - val_specificity: 0.8258 - val_gmeasure: 0.8797 - val_auc: 0.9471\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.2432 - binary_accuracy: 0.9000 - sensitivity: 0.9340 - specificity: 0.8299 - gmeasure: 0.8760 - auc: 0.9685 - val_loss: 0.2996 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8309 - val_specificity: 0.9364 - val_gmeasure: 0.8815 - val_auc: 0.9515\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2546 - binary_accuracy: 0.9000 - sensitivity: 0.9151 - specificity: 0.8703 - gmeasure: 0.8897 - auc: 0.9670 - val_loss: 0.2830 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9061 - val_gmeasure: 0.8958 - val_auc: 0.9477\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.2350 - binary_accuracy: 0.9133 - sensitivity: 0.9206 - specificity: 0.8857 - gmeasure: 0.9004 - auc: 0.9686 - val_loss: 0.2633 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9336 - val_specificity: 0.8591 - val_gmeasure: 0.8940 - val_auc: 0.9501\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2271 - binary_accuracy: 0.9150 - sensitivity: 0.9284 - specificity: 0.8901 - gmeasure: 0.9077 - auc: 0.9731 - val_loss: 0.2613 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9251 - val_specificity: 0.8591 - val_gmeasure: 0.8901 - val_auc: 0.9461\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2299 - binary_accuracy: 0.9083 - sensitivity: 0.9304 - specificity: 0.8700 - gmeasure: 0.8986 - auc: 0.9708 - val_loss: 0.2588 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9336 - val_specificity: 0.8591 - val_gmeasure: 0.8940 - val_auc: 0.9524\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2303 - binary_accuracy: 0.9133 - sensitivity: 0.9205 - specificity: 0.8981 - gmeasure: 0.9080 - auc: 0.9691 - val_loss: 0.2665 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9422 - val_specificity: 0.8258 - val_gmeasure: 0.8797 - val_auc: 0.9460\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2187 - binary_accuracy: 0.9167 - sensitivity: 0.9238 - specificity: 0.9055 - gmeasure: 0.9131 - auc: 0.9747 - val_loss: 0.2605 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9251 - val_specificity: 0.8591 - val_gmeasure: 0.8901 - val_auc: 0.9510\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2190 - binary_accuracy: 0.9250 - sensitivity: 0.9284 - specificity: 0.9189 - gmeasure: 0.9222 - auc: 0.9756 - val_loss: 0.2642 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9514 - val_specificity: 0.8424 - val_gmeasure: 0.8936 - val_auc: 0.9480\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.2197 - binary_accuracy: 0.9183 - sensitivity: 0.9275 - specificity: 0.9022 - gmeasure: 0.9138 - auc: 0.9721 - val_loss: 0.2615 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9499\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2264 - binary_accuracy: 0.9233 - sensitivity: 0.9312 - specificity: 0.9095 - gmeasure: 0.9183 - auc: 0.9719 - val_loss: 0.2785 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9514 - val_specificity: 0.8091 - val_gmeasure: 0.8750 - val_auc: 0.9472\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.2255 - binary_accuracy: 0.9133 - sensitivity: 0.9326 - specificity: 0.8735 - gmeasure: 0.8988 - auc: 0.9727 - val_loss: 0.2548 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9140 - val_specificity: 0.8591 - val_gmeasure: 0.8848 - val_auc: 0.9537\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.2069 - binary_accuracy: 0.9200 - sensitivity: 0.9316 - specificity: 0.9040 - gmeasure: 0.9165 - auc: 0.9761 - val_loss: 0.2567 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8591 - val_gmeasure: 0.8987 - val_auc: 0.9522\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.2065 - binary_accuracy: 0.9233 - sensitivity: 0.9314 - specificity: 0.9094 - gmeasure: 0.9196 - auc: 0.9704 - val_loss: 0.2651 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9514 - val_specificity: 0.8424 - val_gmeasure: 0.8936 - val_auc: 0.9485\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2069 - binary_accuracy: 0.9317 - sensitivity: 0.9397 - specificity: 0.9171 - gmeasure: 0.9267 - auc: 0.9754 - val_loss: 0.2620 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9514 - val_specificity: 0.8258 - val_gmeasure: 0.8844 - val_auc: 0.9506\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 193us/step - loss: 0.2055 - binary_accuracy: 0.9283 - sensitivity: 0.9325 - specificity: 0.9242 - gmeasure: 0.9266 - auc: 0.9779 - val_loss: 0.2611 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9486\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.2026 - binary_accuracy: 0.9250 - sensitivity: 0.9321 - specificity: 0.9055 - gmeasure: 0.9175 - auc: 0.9689 - val_loss: 0.2526 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8591 - val_gmeasure: 0.8987 - val_auc: 0.9548\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.2048 - binary_accuracy: 0.9217 - sensitivity: 0.9197 - specificity: 0.9221 - gmeasure: 0.9197 - auc: 0.9728 - val_loss: 0.2548 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9343 - val_specificity: 0.8591 - val_gmeasure: 0.8949 - val_auc: 0.9497\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1990 - binary_accuracy: 0.9267 - sensitivity: 0.9331 - specificity: 0.9066 - gmeasure: 0.9190 - auc: 0.9719 - val_loss: 0.2576 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8962 - val_specificity: 0.8894 - val_gmeasure: 0.8922 - val_auc: 0.9526\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.1944 - binary_accuracy: 0.9300 - sensitivity: 0.9365 - specificity: 0.9213 - gmeasure: 0.9283 - auc: 0.9768 - val_loss: 0.2484 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9336 - val_specificity: 0.8894 - val_gmeasure: 0.9105 - val_auc: 0.9553\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.1980 - binary_accuracy: 0.9283 - sensitivity: 0.9348 - specificity: 0.9209 - gmeasure: 0.9264 - auc: 0.9779 - val_loss: 0.2593 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9522\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2210 - binary_accuracy: 0.9267 - sensitivity: 0.9297 - specificity: 0.9257 - gmeasure: 0.9249 - auc: 0.9750 - val_loss: 0.2574 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9514 - val_specificity: 0.8591 - val_gmeasure: 0.9025 - val_auc: 0.9505\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.2135 - binary_accuracy: 0.9200 - sensitivity: 0.9329 - specificity: 0.8973 - gmeasure: 0.9137 - auc: 0.9736 - val_loss: 0.2521 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9336 - val_specificity: 0.8894 - val_gmeasure: 0.9105 - val_auc: 0.9521\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.1901 - binary_accuracy: 0.9300 - sensitivity: 0.9454 - specificity: 0.8897 - gmeasure: 0.9158 - auc: 0.9756 - val_loss: 0.2683 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8776 - val_specificity: 0.9197 - val_gmeasure: 0.8976 - val_auc: 0.9517\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.1866 - binary_accuracy: 0.9300 - sensitivity: 0.9390 - specificity: 0.9139 - gmeasure: 0.9258 - auc: 0.9769 - val_loss: 0.2504 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9047 - val_specificity: 0.8894 - val_gmeasure: 0.8963 - val_auc: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.1896 - binary_accuracy: 0.9317 - sensitivity: 0.9382 - specificity: 0.9265 - gmeasure: 0.9308 - auc: 0.9765 - val_loss: 0.2567 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9197 - val_gmeasure: 0.9026 - val_auc: 0.9495\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.1857 - binary_accuracy: 0.9333 - sensitivity: 0.9434 - specificity: 0.9220 - gmeasure: 0.9315 - auc: 0.9770 - val_loss: 0.2595 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8869 - val_specificity: 0.9197 - val_gmeasure: 0.9026 - val_auc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 15.505073070526123!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012549400329589844!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.2006135731935501, 0.9306666851043701, 0.9169884324073792, 0.9612069129943848, 0.9388373494148254, 0.9727108478546143]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.01367950439453125!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.21072882413864136, 0.9359999895095825, 0.9349112510681152, 0.9382715821266174, 0.9365898966789246, 0.9612827897071838]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 18.371322631835938\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 890us/step - loss: 0.6784 - binary_accuracy: 0.7050 - sensitivity: 0.9310 - specificity: 0.0833 - gmeasure: 0.0345 - auc: 0.5210 - val_loss: 0.6558 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5565\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6342 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4836 - val_loss: 0.6088 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4704\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5920 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5116 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5116\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5899 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5532 - val_loss: 0.5900 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5864\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5859 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7038 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8023\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5860 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7640 - val_loss: 0.5868 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7640\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7522 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7517\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5861 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7388 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7498\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 227us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7436 - val_loss: 0.5863 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7520\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7484 - val_loss: 0.5862 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7565\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.5854 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7360 - val_loss: 0.5862 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7638\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5847 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7491 - val_loss: 0.5860 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7739\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5853 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7552 - val_loss: 0.5860 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7820\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.5849 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7757 - val_loss: 0.5858 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7952\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5859 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7914 - val_loss: 0.5861 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8043\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.5840 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7954 - val_loss: 0.5849 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8113\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5836 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8057 - val_loss: 0.5843 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8360\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5826 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8149 - val_loss: 0.5834 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8452\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5819 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8345 - val_loss: 0.5820 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8507\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.5803 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8313 - val_loss: 0.5801 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8609\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5790 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8440 - val_loss: 0.5778 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8605\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5762 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8383 - val_loss: 0.5749 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8575\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.5743 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8421 - val_loss: 0.5720 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8615\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.5701 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8538 - val_loss: 0.5674 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5662 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8502 - val_loss: 0.5625 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8615\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.5606 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8504 - val_loss: 0.5569 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8600\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.5553 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8527 - val_loss: 0.5488 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8614\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.5493 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8585 - val_loss: 0.5415 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8613\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.5396 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8571 - val_loss: 0.5305 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8633\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5312 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8555 - val_loss: 0.5199 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8647\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.5195 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8519 - val_loss: 0.5071 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8647\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.5081 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8561 - val_loss: 0.4951 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8681\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.4969 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8691 - val_loss: 0.4825 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8661\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.4887 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8666 - val_loss: 0.4720 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8720\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.4804 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8600 - val_loss: 0.4632 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8715\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.4750 - binary_accuracy: 0.7317 - sensitivity: 1.0000 - specificity: 0.0185 - gmeasure: 0.0393 - auc: 0.8815 - val_loss: 0.4559 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9642 - val_specificity: 0.3365 - val_gmeasure: 0.5667 - val_auc: 0.8769\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.4593 - binary_accuracy: 0.7783 - sensitivity: 0.9423 - specificity: 0.3399 - gmeasure: 0.5567 - auc: 0.8724 - val_loss: 0.4488 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9284 - val_specificity: 0.3365 - val_gmeasure: 0.5556 - val_auc: 0.8765\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.4518 - binary_accuracy: 0.7883 - sensitivity: 0.9571 - specificity: 0.3397 - gmeasure: 0.5632 - auc: 0.8839 - val_loss: 0.4387 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9642 - val_specificity: 0.3365 - val_gmeasure: 0.5667 - val_auc: 0.8829\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.4393 - binary_accuracy: 0.7917 - sensitivity: 0.9551 - specificity: 0.3521 - gmeasure: 0.5718 - auc: 0.8855 - val_loss: 0.4298 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9732 - val_specificity: 0.3365 - val_gmeasure: 0.5696 - val_auc: 0.8867\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.4300 - binary_accuracy: 0.8017 - sensitivity: 0.9641 - specificity: 0.3708 - gmeasure: 0.5853 - auc: 0.8918 - val_loss: 0.4197 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9454 - val_specificity: 0.4177 - val_gmeasure: 0.6273 - val_auc: 0.8909\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.4209 - binary_accuracy: 0.7983 - sensitivity: 0.9437 - specificity: 0.4363 - gmeasure: 0.6316 - auc: 0.9023 - val_loss: 0.4108 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9544 - val_specificity: 0.4177 - val_gmeasure: 0.6305 - val_auc: 0.8945\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.4084 - binary_accuracy: 0.8150 - sensitivity: 0.9491 - specificity: 0.4591 - gmeasure: 0.6491 - auc: 0.9022 - val_loss: 0.4005 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9544 - val_specificity: 0.4434 - val_gmeasure: 0.6479 - val_auc: 0.9012\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.3975 - binary_accuracy: 0.8267 - sensitivity: 0.9400 - specificity: 0.5262 - gmeasure: 0.6990 - auc: 0.8982 - val_loss: 0.3888 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9544 - val_specificity: 0.4434 - val_gmeasure: 0.6479 - val_auc: 0.9124\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.3842 - binary_accuracy: 0.8450 - sensitivity: 0.9700 - specificity: 0.5077 - gmeasure: 0.6984 - auc: 0.9144 - val_loss: 0.3768 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9544 - val_specificity: 0.4920 - val_gmeasure: 0.6843 - val_auc: 0.9189\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.3744 - binary_accuracy: 0.8450 - sensitivity: 0.9541 - specificity: 0.5337 - gmeasure: 0.7044 - auc: 0.9206 - val_loss: 0.3747 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9724 - val_specificity: 0.3691 - val_gmeasure: 0.5969 - val_auc: 0.9256\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.3630 - binary_accuracy: 0.8517 - sensitivity: 0.9611 - specificity: 0.5453 - gmeasure: 0.7203 - auc: 0.9261 - val_loss: 0.3540 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9634 - val_specificity: 0.5176 - val_gmeasure: 0.7041 - val_auc: 0.9374\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.3551 - binary_accuracy: 0.8550 - sensitivity: 0.9595 - specificity: 0.5893 - gmeasure: 0.7470 - auc: 0.9405 - val_loss: 0.3461 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9274 - val_specificity: 0.6565 - val_gmeasure: 0.7802 - val_auc: 0.9361\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.3448 - binary_accuracy: 0.8583 - sensitivity: 0.9548 - specificity: 0.6041 - gmeasure: 0.7535 - auc: 0.9382 - val_loss: 0.3373 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9634 - val_specificity: 0.5176 - val_gmeasure: 0.7041 - val_auc: 0.9419\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 213us/step - loss: 0.3320 - binary_accuracy: 0.8667 - sensitivity: 0.9519 - specificity: 0.6274 - gmeasure: 0.7663 - auc: 0.9431 - val_loss: 0.3245 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9634 - val_specificity: 0.5662 - val_gmeasure: 0.7377 - val_auc: 0.9469\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.3225 - binary_accuracy: 0.8733 - sensitivity: 0.9579 - specificity: 0.6284 - gmeasure: 0.7721 - auc: 0.9475 - val_loss: 0.3174 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9364 - val_specificity: 0.7147 - val_gmeasure: 0.8164 - val_auc: 0.9524\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.3205 - binary_accuracy: 0.8783 - sensitivity: 0.9536 - specificity: 0.6726 - gmeasure: 0.7954 - auc: 0.9538 - val_loss: 0.3043 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9552\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.3067 - binary_accuracy: 0.8817 - sensitivity: 0.9488 - specificity: 0.7146 - gmeasure: 0.8197 - auc: 0.9527 - val_loss: 0.2988 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9544 - val_specificity: 0.6384 - val_gmeasure: 0.7778 - val_auc: 0.9592\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2995 - binary_accuracy: 0.8850 - sensitivity: 0.9614 - specificity: 0.6787 - gmeasure: 0.8047 - auc: 0.9531 - val_loss: 0.2994 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9544 - val_specificity: 0.5849 - val_gmeasure: 0.7447 - val_auc: 0.9619\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 191us/step - loss: 0.2889 - binary_accuracy: 0.8900 - sensitivity: 0.9617 - specificity: 0.6971 - gmeasure: 0.8166 - auc: 0.9556 - val_loss: 0.2826 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9653\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.2883 - binary_accuracy: 0.8850 - sensitivity: 0.9535 - specificity: 0.6918 - gmeasure: 0.8073 - auc: 0.9559 - val_loss: 0.2861 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9364 - val_specificity: 0.8632 - val_gmeasure: 0.8971 - val_auc: 0.9631\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2786 - binary_accuracy: 0.8917 - sensitivity: 0.9550 - specificity: 0.7134 - gmeasure: 0.8214 - auc: 0.9633 - val_loss: 0.2725 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9544 - val_specificity: 0.6870 - val_gmeasure: 0.8084 - val_auc: 0.9693\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2812 - binary_accuracy: 0.8933 - sensitivity: 0.9579 - specificity: 0.7148 - gmeasure: 0.8204 - auc: 0.9644 - val_loss: 0.2665 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9544 - val_specificity: 0.7147 - val_gmeasure: 0.8247 - val_auc: 0.9714\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.2754 - binary_accuracy: 0.8983 - sensitivity: 0.9388 - specificity: 0.7555 - gmeasure: 0.8243 - auc: 0.9661 - val_loss: 0.3071 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9912 - val_specificity: 0.4738 - val_gmeasure: 0.6760 - val_auc: 0.9713\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.2712 - binary_accuracy: 0.8967 - sensitivity: 0.9535 - specificity: 0.7490 - gmeasure: 0.8408 - auc: 0.9665 - val_loss: 0.2582 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9677\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2565 - binary_accuracy: 0.8950 - sensitivity: 0.9620 - specificity: 0.7356 - gmeasure: 0.8383 - auc: 0.9714 - val_loss: 0.2523 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9728\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.2530 - binary_accuracy: 0.9050 - sensitivity: 0.9471 - specificity: 0.8068 - gmeasure: 0.8715 - auc: 0.9678 - val_loss: 0.2582 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9544 - val_specificity: 0.6592 - val_gmeasure: 0.7911 - val_auc: 0.9748\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2407 - binary_accuracy: 0.9067 - sensitivity: 0.9567 - specificity: 0.7623 - gmeasure: 0.8522 - auc: 0.9686 - val_loss: 0.2441 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9735\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2347 - binary_accuracy: 0.9117 - sensitivity: 0.9522 - specificity: 0.7948 - gmeasure: 0.8683 - auc: 0.9721 - val_loss: 0.2553 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9732 - val_specificity: 0.6592 - val_gmeasure: 0.7991 - val_auc: 0.9754\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.2344 - binary_accuracy: 0.9083 - sensitivity: 0.9587 - specificity: 0.7691 - gmeasure: 0.8535 - auc: 0.9729 - val_loss: 0.2377 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9756\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.2251 - binary_accuracy: 0.9200 - sensitivity: 0.9591 - specificity: 0.8128 - gmeasure: 0.8823 - auc: 0.9723 - val_loss: 0.2415 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9642 - val_specificity: 0.7078 - val_gmeasure: 0.8252 - val_auc: 0.9760\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2239 - binary_accuracy: 0.9267 - sensitivity: 0.9547 - specificity: 0.8505 - gmeasure: 0.8991 - auc: 0.9715 - val_loss: 0.2419 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9634 - val_specificity: 0.7682 - val_gmeasure: 0.8581 - val_auc: 0.9761\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2237 - binary_accuracy: 0.9117 - sensitivity: 0.9548 - specificity: 0.8069 - gmeasure: 0.8758 - auc: 0.9726 - val_loss: 0.2329 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9755\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.2121 - binary_accuracy: 0.9150 - sensitivity: 0.9636 - specificity: 0.7811 - gmeasure: 0.8658 - auc: 0.9734 - val_loss: 0.2259 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9776\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2106 - binary_accuracy: 0.9250 - sensitivity: 0.9606 - specificity: 0.8123 - gmeasure: 0.8798 - auc: 0.9725 - val_loss: 0.2329 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9788\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2062 - binary_accuracy: 0.9250 - sensitivity: 0.9571 - specificity: 0.8361 - gmeasure: 0.8908 - auc: 0.9756 - val_loss: 0.2299 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9781\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.2004 - binary_accuracy: 0.9286 - sensitivity: 0.9646 - specificity: 0.8246 - gmeasure: 0.8898 - auc: 0.97 - 0s 207us/step - loss: 0.2043 - binary_accuracy: 0.9200 - sensitivity: 0.9604 - specificity: 0.8132 - gmeasure: 0.8818 - auc: 0.9775 - val_loss: 0.2215 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9776\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.1976 - binary_accuracy: 0.9300 - sensitivity: 0.9517 - specificity: 0.8658 - gmeasure: 0.9056 - auc: 0.9744 - val_loss: 0.2192 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9802\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 218us/step - loss: 0.1942 - binary_accuracy: 0.9267 - sensitivity: 0.9627 - specificity: 0.8286 - gmeasure: 0.8900 - auc: 0.9771 - val_loss: 0.2135 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8168 - val_gmeasure: 0.8811 - val_auc: 0.9782\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.1919 - binary_accuracy: 0.9233 - sensitivity: 0.9572 - specificity: 0.8431 - gmeasure: 0.8971 - auc: 0.9765 - val_loss: 0.2157 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9795\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.1890 - binary_accuracy: 0.9333 - sensitivity: 0.9591 - specificity: 0.8641 - gmeasure: 0.9088 - auc: 0.9762 - val_loss: 0.2095 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9796\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.1886 - binary_accuracy: 0.9317 - sensitivity: 0.9607 - specificity: 0.8520 - gmeasure: 0.9031 - auc: 0.9778 - val_loss: 0.2083 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9751\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.1816 - binary_accuracy: 0.9383 - sensitivity: 0.9639 - specificity: 0.8655 - gmeasure: 0.9127 - auc: 0.9783 - val_loss: 0.2159 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9809\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1814 - binary_accuracy: 0.9367 - sensitivity: 0.9583 - specificity: 0.8808 - gmeasure: 0.9175 - auc: 0.9791 - val_loss: 0.2080 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9809\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.1758 - binary_accuracy: 0.9333 - sensitivity: 0.9632 - specificity: 0.8505 - gmeasure: 0.9032 - auc: 0.9782 - val_loss: 0.2006 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9809\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.1780 - binary_accuracy: 0.9317 - sensitivity: 0.9524 - specificity: 0.8614 - gmeasure: 0.9034 - auc: 0.9794 - val_loss: 0.2038 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9544 - val_specificity: 0.7612 - val_gmeasure: 0.8511 - val_auc: 0.9816\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.1742 - binary_accuracy: 0.9400 - sensitivity: 0.9611 - specificity: 0.8932 - gmeasure: 0.9252 - auc: 0.9790 - val_loss: 0.2008 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.1743 - binary_accuracy: 0.9400 - sensitivity: 0.9528 - specificity: 0.9061 - gmeasure: 0.9278 - auc: 0.9806 - val_loss: 0.2081 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9816\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.1701 - binary_accuracy: 0.9467 - sensitivity: 0.9610 - specificity: 0.9224 - gmeasure: 0.9405 - auc: 0.9798 - val_loss: 0.1970 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.1657 - binary_accuracy: 0.9450 - sensitivity: 0.9634 - specificity: 0.8998 - gmeasure: 0.9306 - auc: 0.9817 - val_loss: 0.1994 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9544 - val_specificity: 0.7890 - val_gmeasure: 0.8665 - val_auc: 0.9816\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 225us/step - loss: 0.1684 - binary_accuracy: 0.9433 - sensitivity: 0.9668 - specificity: 0.8942 - gmeasure: 0.9280 - auc: 0.9794 - val_loss: 0.1975 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9274 - val_specificity: 0.9049 - val_gmeasure: 0.9152 - val_auc: 0.9791\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.1687 - binary_accuracy: 0.9350 - sensitivity: 0.9511 - specificity: 0.8869 - gmeasure: 0.9165 - auc: 0.9840 - val_loss: 0.1940 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9829\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.1598 - binary_accuracy: 0.9467 - sensitivity: 0.9629 - specificity: 0.8897 - gmeasure: 0.9240 - auc: 0.9827 - val_loss: 0.1983 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9816\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.1579 - binary_accuracy: 0.9467 - sensitivity: 0.9614 - specificity: 0.9106 - gmeasure: 0.9351 - auc: 0.9804 - val_loss: 0.1955 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9642 - val_specificity: 0.7869 - val_gmeasure: 0.8682 - val_auc: 0.9823\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.1561 - binary_accuracy: 0.9500 - sensitivity: 0.9573 - specificity: 0.9251 - gmeasure: 0.9399 - auc: 0.9807 - val_loss: 0.1954 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9544 - val_specificity: 0.8146 - val_gmeasure: 0.8795 - val_auc: 0.9816\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1611 - binary_accuracy: 0.9383 - sensitivity: 0.9602 - specificity: 0.8868 - gmeasure: 0.9208 - auc: 0.9833 - val_loss: 0.1942 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9364 - val_specificity: 0.9049 - val_gmeasure: 0.9199 - val_auc: 0.9772\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.1686 - binary_accuracy: 0.9350 - sensitivity: 0.9574 - specificity: 0.8846 - gmeasure: 0.9180 - auc: 0.9845 - val_loss: 0.1906 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9544 - val_specificity: 0.8424 - val_gmeasure: 0.8942 - val_auc: 0.9841\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.1538 - binary_accuracy: 0.9533 - sensitivity: 0.9587 - specificity: 0.9311 - gmeasure: 0.9436 - auc: 0.9815 - val_loss: 0.1960 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9835\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.1562 - binary_accuracy: 0.9483 - sensitivity: 0.9550 - specificity: 0.9230 - gmeasure: 0.9374 - auc: 0.9827 - val_loss: 0.1932 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9544 - val_specificity: 0.8632 - val_gmeasure: 0.9063 - val_auc: 0.9799\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.1580 - binary_accuracy: 0.9467 - sensitivity: 0.9622 - specificity: 0.9221 - gmeasure: 0.9408 - auc: 0.9835 - val_loss: 0.1843 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9840\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 187us/step - loss: 0.1473 - binary_accuracy: 0.9550 - sensitivity: 0.9632 - specificity: 0.9325 - gmeasure: 0.9467 - auc: 0.9861 - val_loss: 0.1987 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9642 - val_specificity: 0.7612 - val_gmeasure: 0.8552 - val_auc: 0.9821\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.1438 - binary_accuracy: 0.9533 - sensitivity: 0.9642 - specificity: 0.9262 - gmeasure: 0.9440 - auc: 0.9843 - val_loss: 0.1844 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9854\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.1456 - binary_accuracy: 0.9567 - sensitivity: 0.9605 - specificity: 0.9458 - gmeasure: 0.9524 - auc: 0.9847 - val_loss: 0.1899 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9642 - val_specificity: 0.7869 - val_gmeasure: 0.8682 - val_auc: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.1427 - binary_accuracy: 0.9583 - sensitivity: 0.9561 - specificity: 0.9637 - gmeasure: 0.9595 - auc: 0.9856 - val_loss: 0.2170 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9822 - val_specificity: 0.7334 - val_gmeasure: 0.8474 - val_auc: 0.9841\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.1544 - binary_accuracy: 0.9483 - sensitivity: 0.9672 - specificity: 0.8937 - gmeasure: 0.9252 - auc: 0.9817 - val_loss: 0.1880 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9454 - val_specificity: 0.9049 - val_gmeasure: 0.9246 - val_auc: 0.9809\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1455 - binary_accuracy: 0.9517 - sensitivity: 0.9697 - specificity: 0.9058 - gmeasure: 0.9361 - auc: 0.9838 - val_loss: 0.1816 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9454 - val_specificity: 0.8632 - val_gmeasure: 0.9018 - val_auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 14.831358671188354!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.010845184326171875!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.14836500585079193, 0.9493333101272583, 0.9523809552192688, 0.9411764740943909, 0.9467621445655823, 0.9843155145645142]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.011316776275634766!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.237688347697258, 0.9039999842643738, 0.9367815852165222, 0.8289473652839661, 0.8812165260314941, 0.9612069129943848]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 16.136231422424316\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 925us/step - loss: 0.6698 - binary_accuracy: 0.6583 - sensitivity: 0.9167 - specificity: 0.0833 - gmeasure: 0.0000e+00 - auc: 0.5761 - val_loss: 0.6539 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4036\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.6283 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5441 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4674\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6225 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5044 - val_loss: 0.6547 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4405\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5435 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4083\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5460 - val_loss: 0.6464 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4065\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5374 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4117\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5356 - val_loss: 0.6498 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4140\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5392 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4191\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5299 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4216\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.6239 - binary_accuracy: 0.6850 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.55 - 0s 212us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5508 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4228\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 236us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5435 - val_loss: 0.6486 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4268\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5415 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4280\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5551 - val_loss: 0.6467 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4293\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5551 - val_loss: 0.6505 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4347\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5472 - val_loss: 0.6484 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4386\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5582 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4432\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5471 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4473\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5511 - val_loss: 0.6487 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4486\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5573 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4494\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5540 - val_loss: 0.6489 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4556\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5704 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4564\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5600 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4554\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5534 - val_loss: 0.6474 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4581\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 206us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5562 - val_loss: 0.6493 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4583\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5574 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4612\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5583 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4615\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5605 - val_loss: 0.6471 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4635\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5645 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4632\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5570 - val_loss: 0.6493 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4608\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5682 - val_loss: 0.6481 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4601\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5725 - val_loss: 0.6474 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4594\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5701 - val_loss: 0.6488 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4601\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4590\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5557 - val_loss: 0.6491 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4597\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5664 - val_loss: 0.6477 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5597 - val_loss: 0.6488 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4612\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5552 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4691\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5651 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4706\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5557 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4698\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5683 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4724\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6495 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4716\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5592 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4733\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5661 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4733\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.6214 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5714 - val_loss: 0.6501 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4781\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5684 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4814\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5813 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4898\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5798 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5813 - val_loss: 0.6477 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4975\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5943 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5013\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6015 - val_loss: 0.6487 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6032 - val_loss: 0.6484 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5162\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6064 - val_loss: 0.6479 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5225\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6145 - val_loss: 0.6469 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5401\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6160 - val_loss: 0.6480 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5470\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6213 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6190 - val_loss: 0.6496 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5511\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6239 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5517\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6265 - val_loss: 0.6478 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5663\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6190 - val_loss: 0.6462 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6322\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6194 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6412 - val_loss: 0.6466 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6460\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6387 - val_loss: 0.6423 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6767\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6178 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6503 - val_loss: 0.6448 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6759\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 228us/step - loss: 0.6172 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6484 - val_loss: 0.6422 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6861\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6156 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6472 - val_loss: 0.6419 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6909\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6145 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6513 - val_loss: 0.6413 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6939\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6134 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6631 - val_loss: 0.6389 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6981\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6119 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6561 - val_loss: 0.6378 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7019\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.6099 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6691 - val_loss: 0.6355 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7045\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6086 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6771 - val_loss: 0.6342 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7069\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.6057 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6794 - val_loss: 0.6307 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7103\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6047 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6741 - val_loss: 0.6297 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7118\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6019 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6856 - val_loss: 0.6285 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6016 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6877 - val_loss: 0.6238 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7195\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5968 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6837 - val_loss: 0.6208 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7211\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5933 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7010 - val_loss: 0.6199 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7235\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 225us/step - loss: 0.5893 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6947 - val_loss: 0.6174 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7270\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5894 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6959 - val_loss: 0.6171 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7286\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.5873 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6991 - val_loss: 0.6151 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7312\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5842 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7068 - val_loss: 0.6123 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7351\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.5811 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7115 - val_loss: 0.6102 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7355\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5784 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7141 - val_loss: 0.6092 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7380\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.5749 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7121 - val_loss: 0.6073 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7369\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5725 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7088 - val_loss: 0.6071 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7395\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5760 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7255 - val_loss: 0.6142 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7375\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5702 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7281 - val_loss: 0.6060 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.5687 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7210 - val_loss: 0.6184 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7405\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5736 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7281 - val_loss: 0.6034 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7440\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5697 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7393 - val_loss: 0.5962 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7473\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5611 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7375 - val_loss: 0.5966 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7506\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5611 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7351 - val_loss: 0.6019 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7540\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5567 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7457 - val_loss: 0.6048 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5600 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7501 - val_loss: 0.5962 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7545\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5507 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7463 - val_loss: 0.5961 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7549\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5566 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7539 - val_loss: 0.5958 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7600\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.5517 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7537 - val_loss: 0.5895 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7589\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5493 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7574 - val_loss: 0.5879 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.5472 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7599 - val_loss: 0.5946 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7620\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5456 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7624 - val_loss: 0.5869 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7642\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.5414 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7601 - val_loss: 0.5879 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7710\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.5477 - binary_accuracy: 0.6967 - sensitivity: 0.9892 - specificity: 0.0711 - gmeasure: 0.1628 - auc: 0.7583 - val_loss: 0.5924 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7671\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5445 - binary_accuracy: 0.7150 - sensitivity: 0.9787 - specificity: 0.1429 - gmeasure: 0.2987 - auc: 0.7673 - val_loss: 0.5860 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9408 - val_specificity: 0.4144 - val_gmeasure: 0.6230 - val_auc: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 14.849649667739868!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.013460636138916016!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5479835867881775, 0.7480000257492065, 0.9412915706634521, 0.33472803235054016, 0.5613169074058533, 0.7735673189163208]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.011509180068969727!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5602806210517883, 0.6959999799728394, 0.9044944047927856, 0.1805555522441864, 0.404118150472641, 0.6734550595283508]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 16.241212129592896\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.29898739 0.87600001 0.93688699 0.74570381 0.8156388  0.91019789]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.17735427 0.0908299  0.0147808  0.29071879 0.17986184 0.09672849]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.3362326  0.84533332 0.92539575 0.64925817 0.74064152 0.86531492]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.15880773 0.10639967 0.01479919 0.33441446 0.23902934 0.13566541]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, network_info, path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deepbiome_train` saves the trained model weights, evaluation results and history based on the path information from the configuration.\n",
    "\n",
    "From the example above, we can check that `hist_*.json`, `weight_*.h5`, `test_eval.npy`, `train_eval.npy` files were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hist_0.json',\n",
       " 'weight_2.h5',\n",
       " 'test_eval.npy',\n",
       " 'weight_0.h5',\n",
       " 'train_eval.npy',\n",
       " 'hist_2.json',\n",
       " 'weight_1.h5',\n",
       " 'hist_1.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_info['model_info']['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the history files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzyK4tAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33241e0da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21072882, 0.93599999, 0.93491125, 0.93827158, 0.9365899 ,\n",
       "        0.96128279],\n",
       "       [0.23768835, 0.90399998, 0.93678159, 0.82894737, 0.88121653,\n",
       "        0.96120691],\n",
       "       [0.56028062, 0.69599998, 0.9044944 , 0.18055555, 0.40411815,\n",
       "        0.67345506]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20061357, 0.93066669, 0.91698843, 0.96120691, 0.93883735,\n",
       "        0.97271085],\n",
       "       [0.14836501, 0.94933331, 0.95238096, 0.94117647, 0.94676214,\n",
       "        0.98431551],\n",
       "       [0.54798359, 0.74800003, 0.94129157, 0.33472803, 0.56131691,\n",
       "        0.77356732]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the pre-trained network for training\n",
    "\n",
    "If you have pre-trianed model, you can use the pre-trained weight for next training. For using pre-trained weights, you have to use `warm_start` option in `training_inro` with addding the file path of the pre-trained weights in the `warm_start_model` option. Below is the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warm_start_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'taxa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'training_info': {\n",
    "        'warm_start':'True',\n",
    "        'warm_start_model':'./example_result/weight.h5',\n",
    "        'batch_size': '200',\n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 686us/step - loss: 0.2182 - binary_accuracy: 0.9167 - sensitivity: 0.9518 - specificity: 0.8445 - gmeasure: 0.8930 - auc: 0.9733 - val_loss: 0.2641 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8667 - val_specificity: 0.9111 - val_gmeasure: 0.8886 - val_auc: 0.9512\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1991 - binary_accuracy: 0.9300 - sensitivity: 0.9032 - specificity: 0.9898 - gmeasure: 0.9455 - auc: 0.9791 - val_loss: 0.2558 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8762 - val_specificity: 0.9111 - val_gmeasure: 0.8935 - val_auc: 0.9491\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1879 - binary_accuracy: 0.9267 - sensitivity: 0.9347 - specificity: 0.9099 - gmeasure: 0.9214 - auc: 0.9772 - val_loss: 0.2728 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9475\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1875 - binary_accuracy: 0.9267 - sensitivity: 0.9593 - specificity: 0.8507 - gmeasure: 0.9023 - auc: 0.9768 - val_loss: 0.2501 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9496\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1804 - binary_accuracy: 0.9433 - sensitivity: 0.9378 - specificity: 0.9559 - gmeasure: 0.9467 - auc: 0.9784 - val_loss: 0.2614 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8857 - val_specificity: 0.9111 - val_gmeasure: 0.8983 - val_auc: 0.9492\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1827 - binary_accuracy: 0.9400 - sensitivity: 0.9346 - specificity: 0.9552 - gmeasure: 0.9446 - auc: 0.9780 - val_loss: 0.2519 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9496\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1749 - binary_accuracy: 0.9300 - sensitivity: 0.9470 - specificity: 0.8934 - gmeasure: 0.9195 - auc: 0.9784 - val_loss: 0.2526 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9510\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1725 - binary_accuracy: 0.9333 - sensitivity: 0.9442 - specificity: 0.9090 - gmeasure: 0.9264 - auc: 0.9771 - val_loss: 0.2503 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9475\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1715 - binary_accuracy: 0.9367 - sensitivity: 0.9390 - specificity: 0.9296 - gmeasure: 0.9341 - auc: 0.9772 - val_loss: 0.2494 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1700 - binary_accuracy: 0.9383 - sensitivity: 0.9442 - specificity: 0.9246 - gmeasure: 0.9343 - auc: 0.9804 - val_loss: 0.2497 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9333 - val_specificity: 0.8667 - val_gmeasure: 0.8994 - val_auc: 0.9490\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1701 - binary_accuracy: 0.9350 - sensitivity: 0.9477 - specificity: 0.9105 - gmeasure: 0.9282 - auc: 0.9794 - val_loss: 0.2475 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9505\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1679 - binary_accuracy: 0.9400 - sensitivity: 0.9439 - specificity: 0.9300 - gmeasure: 0.9369 - auc: 0.9779 - val_loss: 0.2474 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9496\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1672 - binary_accuracy: 0.9383 - sensitivity: 0.9448 - specificity: 0.9232 - gmeasure: 0.9339 - auc: 0.9763 - val_loss: 0.2475 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9490\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1658 - binary_accuracy: 0.9383 - sensitivity: 0.9443 - specificity: 0.9212 - gmeasure: 0.9324 - auc: 0.9776 - val_loss: 0.2474 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9492\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1657 - binary_accuracy: 0.9400 - sensitivity: 0.9471 - specificity: 0.9268 - gmeasure: 0.9365 - auc: 0.9790 - val_loss: 0.2480 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9513\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1635 - binary_accuracy: 0.9383 - sensitivity: 0.9441 - specificity: 0.9243 - gmeasure: 0.9341 - auc: 0.9784 - val_loss: 0.2480 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9503\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1637 - binary_accuracy: 0.9383 - sensitivity: 0.9492 - specificity: 0.9151 - gmeasure: 0.9320 - auc: 0.9800 - val_loss: 0.2478 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9519\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 0.1615 - binary_accuracy: 0.9367 - sensitivity: 0.9386 - specificity: 0.9289 - gmeasure: 0.9335 - auc: 0.9787 - val_loss: 0.2480 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9492\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1609 - binary_accuracy: 0.9417 - sensitivity: 0.9421 - specificity: 0.9413 - gmeasure: 0.9417 - auc: 0.9798 - val_loss: 0.2482 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9492\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1664 - binary_accuracy: 0.9383 - sensitivity: 0.9568 - specificity: 0.9006 - gmeasure: 0.9278 - auc: 0.9786 - val_loss: 0.2489 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9512\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1634 - binary_accuracy: 0.9433 - sensitivity: 0.9362 - specificity: 0.9644 - gmeasure: 0.9500 - auc: 0.9795 - val_loss: 0.2520 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9501\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1594 - binary_accuracy: 0.9467 - sensitivity: 0.9418 - specificity: 0.9570 - gmeasure: 0.9493 - auc: 0.9788 - val_loss: 0.2552 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9506\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1625 - binary_accuracy: 0.9367 - sensitivity: 0.9612 - specificity: 0.8812 - gmeasure: 0.9203 - auc: 0.9791 - val_loss: 0.2500 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9525\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1600 - binary_accuracy: 0.9417 - sensitivity: 0.9328 - specificity: 0.9640 - gmeasure: 0.9481 - auc: 0.9788 - val_loss: 0.2512 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9503\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1579 - binary_accuracy: 0.9400 - sensitivity: 0.9454 - specificity: 0.9327 - gmeasure: 0.9386 - auc: 0.9804 - val_loss: 0.2573 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1563 - binary_accuracy: 0.9383 - sensitivity: 0.9536 - specificity: 0.9064 - gmeasure: 0.9293 - auc: 0.9798 - val_loss: 0.2502 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9520\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1567 - binary_accuracy: 0.9417 - sensitivity: 0.9460 - specificity: 0.9338 - gmeasure: 0.9396 - auc: 0.9793 - val_loss: 0.2497 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9535\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1527 - binary_accuracy: 0.9467 - sensitivity: 0.9491 - specificity: 0.9423 - gmeasure: 0.9455 - auc: 0.9805 - val_loss: 0.2493 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9535\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1593 - binary_accuracy: 0.9367 - sensitivity: 0.9517 - specificity: 0.9019 - gmeasure: 0.9261 - auc: 0.9802 - val_loss: 0.2506 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9509\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1590 - binary_accuracy: 0.9400 - sensitivity: 0.9299 - specificity: 0.9631 - gmeasure: 0.9457 - auc: 0.9808 - val_loss: 0.2504 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9540\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1518 - binary_accuracy: 0.9400 - sensitivity: 0.9469 - specificity: 0.9238 - gmeasure: 0.9348 - auc: 0.9805 - val_loss: 0.2592 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9509\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1537 - binary_accuracy: 0.9400 - sensitivity: 0.9588 - specificity: 0.9003 - gmeasure: 0.9291 - auc: 0.9798 - val_loss: 0.2540 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9534\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1612 - binary_accuracy: 0.9417 - sensitivity: 0.9251 - specificity: 0.9777 - gmeasure: 0.9509 - auc: 0.9813 - val_loss: 0.2501 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9514\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1517 - binary_accuracy: 0.9450 - sensitivity: 0.9564 - specificity: 0.9172 - gmeasure: 0.9362 - auc: 0.9818 - val_loss: 0.2639 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9524 - val_specificity: 0.8667 - val_gmeasure: 0.9085 - val_auc: 0.9505\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1544 - binary_accuracy: 0.9417 - sensitivity: 0.9540 - specificity: 0.9135 - gmeasure: 0.9331 - auc: 0.9805 - val_loss: 0.2520 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9512\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1503 - binary_accuracy: 0.9467 - sensitivity: 0.9367 - specificity: 0.9648 - gmeasure: 0.9503 - auc: 0.9816 - val_loss: 0.2522 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9532\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1467 - binary_accuracy: 0.9450 - sensitivity: 0.9539 - specificity: 0.9250 - gmeasure: 0.9390 - auc: 0.9811 - val_loss: 0.2537 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9515\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1455 - binary_accuracy: 0.9500 - sensitivity: 0.9586 - specificity: 0.9315 - gmeasure: 0.9449 - auc: 0.9805 - val_loss: 0.2525 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9515\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1463 - binary_accuracy: 0.9517 - sensitivity: 0.9431 - specificity: 0.9683 - gmeasure: 0.9556 - auc: 0.9809 - val_loss: 0.2526 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9509\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1435 - binary_accuracy: 0.9517 - sensitivity: 0.9591 - specificity: 0.9347 - gmeasure: 0.9467 - auc: 0.9812 - val_loss: 0.2583 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9510\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1492 - binary_accuracy: 0.9467 - sensitivity: 0.9514 - specificity: 0.9367 - gmeasure: 0.9437 - auc: 0.9798 - val_loss: 0.2542 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9522\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1432 - binary_accuracy: 0.9550 - sensitivity: 0.9527 - specificity: 0.9631 - gmeasure: 0.9578 - auc: 0.9811 - val_loss: 0.2556 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9515\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1453 - binary_accuracy: 0.9500 - sensitivity: 0.9588 - specificity: 0.9306 - gmeasure: 0.9445 - auc: 0.9817 - val_loss: 0.2536 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9525\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1543 - binary_accuracy: 0.9483 - sensitivity: 0.9372 - specificity: 0.9744 - gmeasure: 0.9556 - auc: 0.9835 - val_loss: 0.2544 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9522\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1415 - binary_accuracy: 0.9500 - sensitivity: 0.9595 - specificity: 0.9304 - gmeasure: 0.9448 - auc: 0.9826 - val_loss: 0.2668 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9429 - val_specificity: 0.8444 - val_gmeasure: 0.8923 - val_auc: 0.9515\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1453 - binary_accuracy: 0.9500 - sensitivity: 0.9569 - specificity: 0.9391 - gmeasure: 0.9470 - auc: 0.9833 - val_loss: 0.2562 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9537\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1423 - binary_accuracy: 0.9533 - sensitivity: 0.9494 - specificity: 0.9634 - gmeasure: 0.9563 - auc: 0.9833 - val_loss: 0.2577 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9515\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1447 - binary_accuracy: 0.9467 - sensitivity: 0.9603 - specificity: 0.9194 - gmeasure: 0.9392 - auc: 0.9801 - val_loss: 0.2578 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9512\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1574 - binary_accuracy: 0.9400 - sensitivity: 0.9335 - specificity: 0.9617 - gmeasure: 0.9469 - auc: 0.9827 - val_loss: 0.2596 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9543\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1471 - binary_accuracy: 0.9483 - sensitivity: 0.9507 - specificity: 0.9521 - gmeasure: 0.9510 - auc: 0.9821 - val_loss: 0.2802 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1600 - binary_accuracy: 0.9383 - sensitivity: 0.9489 - specificity: 0.9231 - gmeasure: 0.9353 - auc: 0.9810 - val_loss: 0.2695 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8571 - val_specificity: 0.9333 - val_gmeasure: 0.8944 - val_auc: 0.9513\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1451 - binary_accuracy: 0.9533 - sensitivity: 0.9418 - specificity: 0.9793 - gmeasure: 0.9604 - auc: 0.9840 - val_loss: 0.2655 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9517\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1538 - binary_accuracy: 0.9383 - sensitivity: 0.9642 - specificity: 0.8804 - gmeasure: 0.9211 - auc: 0.9818 - val_loss: 0.2655 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9523\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1511 - binary_accuracy: 0.9433 - sensitivity: 0.9425 - specificity: 0.9487 - gmeasure: 0.9449 - auc: 0.9827 - val_loss: 0.2730 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8571 - val_specificity: 0.9333 - val_gmeasure: 0.8944 - val_auc: 0.9502\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1529 - binary_accuracy: 0.9433 - sensitivity: 0.9382 - specificity: 0.9590 - gmeasure: 0.9480 - auc: 0.9829 - val_loss: 0.2771 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9524 - val_specificity: 0.8444 - val_gmeasure: 0.8968 - val_auc: 0.9522\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1416 - binary_accuracy: 0.9400 - sensitivity: 0.9614 - specificity: 0.8949 - gmeasure: 0.9270 - auc: 0.9833 - val_loss: 0.2593 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9048 - val_specificity: 0.8889 - val_gmeasure: 0.8968 - val_auc: 0.9528\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1432 - binary_accuracy: 0.9483 - sensitivity: 0.9396 - specificity: 0.9687 - gmeasure: 0.9539 - auc: 0.9839 - val_loss: 0.2591 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9535\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1346 - binary_accuracy: 0.9517 - sensitivity: 0.9540 - specificity: 0.9458 - gmeasure: 0.9498 - auc: 0.9834 - val_loss: 0.2720 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9513\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1399 - binary_accuracy: 0.9400 - sensitivity: 0.9610 - specificity: 0.8956 - gmeasure: 0.9277 - auc: 0.9828 - val_loss: 0.2604 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.8952 - val_specificity: 0.9333 - val_gmeasure: 0.9141 - val_auc: 0.9515\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1374 - binary_accuracy: 0.9550 - sensitivity: 0.9466 - specificity: 0.9728 - gmeasure: 0.9596 - auc: 0.9846 - val_loss: 0.2593 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9532\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1354 - binary_accuracy: 0.9567 - sensitivity: 0.9588 - specificity: 0.9510 - gmeasure: 0.9546 - auc: 0.9837 - val_loss: 0.2642 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9526\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1342 - binary_accuracy: 0.9533 - sensitivity: 0.9565 - specificity: 0.9466 - gmeasure: 0.9513 - auc: 0.9837 - val_loss: 0.2623 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9535\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1356 - binary_accuracy: 0.9517 - sensitivity: 0.9497 - specificity: 0.9562 - gmeasure: 0.9528 - auc: 0.9842 - val_loss: 0.2624 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9532\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1315 - binary_accuracy: 0.9567 - sensitivity: 0.9588 - specificity: 0.9520 - gmeasure: 0.9554 - auc: 0.9843 - val_loss: 0.2614 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9534\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1309 - binary_accuracy: 0.9600 - sensitivity: 0.9586 - specificity: 0.9596 - gmeasure: 0.9590 - auc: 0.9837 - val_loss: 0.2606 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9540\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1312 - binary_accuracy: 0.9567 - sensitivity: 0.9591 - specificity: 0.9545 - gmeasure: 0.9566 - auc: 0.9842 - val_loss: 0.2595 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9559\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1317 - binary_accuracy: 0.9617 - sensitivity: 0.9594 - specificity: 0.9697 - gmeasure: 0.9644 - auc: 0.9856 - val_loss: 0.2589 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9558\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1291 - binary_accuracy: 0.9617 - sensitivity: 0.9576 - specificity: 0.9672 - gmeasure: 0.9623 - auc: 0.9855 - val_loss: 0.2622 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9537\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1296 - binary_accuracy: 0.9567 - sensitivity: 0.9585 - specificity: 0.9518 - gmeasure: 0.9551 - auc: 0.9841 - val_loss: 0.2597 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9549\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1291 - binary_accuracy: 0.9633 - sensitivity: 0.9582 - specificity: 0.9729 - gmeasure: 0.9654 - auc: 0.9845 - val_loss: 0.2596 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.8952 - val_specificity: 0.8889 - val_gmeasure: 0.8921 - val_auc: 0.9557\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1276 - binary_accuracy: 0.9617 - sensitivity: 0.9588 - specificity: 0.9675 - gmeasure: 0.9632 - auc: 0.9844 - val_loss: 0.2616 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9543\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1276 - binary_accuracy: 0.9617 - sensitivity: 0.9587 - specificity: 0.9681 - gmeasure: 0.9633 - auc: 0.9840 - val_loss: 0.2619 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9534\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1269 - binary_accuracy: 0.9583 - sensitivity: 0.9588 - specificity: 0.9571 - gmeasure: 0.9579 - auc: 0.9843 - val_loss: 0.2623 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9539\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1275 - binary_accuracy: 0.9617 - sensitivity: 0.9593 - specificity: 0.9679 - gmeasure: 0.9635 - auc: 0.9863 - val_loss: 0.2603 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9560\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1261 - binary_accuracy: 0.9583 - sensitivity: 0.9589 - specificity: 0.9574 - gmeasure: 0.9581 - auc: 0.9853 - val_loss: 0.2627 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 0.1255 - binary_accuracy: 0.9567 - sensitivity: 0.9583 - specificity: 0.9525 - gmeasure: 0.9553 - auc: 0.9851 - val_loss: 0.2601 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9553\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.1032 - binary_accuracy: 0.9750 - sensitivity: 0.9708 - specificity: 0.9841 - gmeasure: 0.9774 - auc: 0.99 - 0s 66us/step - loss: 0.1254 - binary_accuracy: 0.9600 - sensitivity: 0.9592 - specificity: 0.9637 - gmeasure: 0.9613 - auc: 0.9858 - val_loss: 0.2605 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9549\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1245 - binary_accuracy: 0.9633 - sensitivity: 0.9587 - specificity: 0.9723 - gmeasure: 0.9654 - auc: 0.9863 - val_loss: 0.2613 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9143 - val_specificity: 0.8889 - val_gmeasure: 0.9015 - val_auc: 0.9547\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1246 - binary_accuracy: 0.9633 - sensitivity: 0.9585 - specificity: 0.9737 - gmeasure: 0.9661 - auc: 0.9849 - val_loss: 0.2628 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9560\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1233 - binary_accuracy: 0.9600 - sensitivity: 0.9594 - specificity: 0.9608 - gmeasure: 0.9601 - auc: 0.9858 - val_loss: 0.2647 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9333 - val_specificity: 0.8889 - val_gmeasure: 0.9108 - val_auc: 0.9537\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1233 - binary_accuracy: 0.9583 - sensitivity: 0.9589 - specificity: 0.9569 - gmeasure: 0.9576 - auc: 0.9865 - val_loss: 0.2630 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9551\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1255 - binary_accuracy: 0.9633 - sensitivity: 0.9594 - specificity: 0.9754 - gmeasure: 0.9672 - auc: 0.9868 - val_loss: 0.2609 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9549\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1241 - binary_accuracy: 0.9583 - sensitivity: 0.9615 - specificity: 0.9554 - gmeasure: 0.9583 - auc: 0.9861 - val_loss: 0.2684 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9549\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1236 - binary_accuracy: 0.9567 - sensitivity: 0.9587 - specificity: 0.9519 - gmeasure: 0.9552 - auc: 0.9849 - val_loss: 0.2607 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9560\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1236 - binary_accuracy: 0.9567 - sensitivity: 0.9537 - specificity: 0.9646 - gmeasure: 0.9590 - auc: 0.9864 - val_loss: 0.2689 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9545\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1225 - binary_accuracy: 0.9583 - sensitivity: 0.9636 - specificity: 0.9460 - gmeasure: 0.9546 - auc: 0.9859 - val_loss: 0.2628 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8952 - val_specificity: 0.9111 - val_gmeasure: 0.9031 - val_auc: 0.9562\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1204 - binary_accuracy: 0.9617 - sensitivity: 0.9559 - specificity: 0.9740 - gmeasure: 0.9649 - auc: 0.9874 - val_loss: 0.2636 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9566\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1218 - binary_accuracy: 0.9633 - sensitivity: 0.9602 - specificity: 0.9744 - gmeasure: 0.9671 - auc: 0.9883 - val_loss: 0.2679 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9557\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1206 - binary_accuracy: 0.9583 - sensitivity: 0.9633 - specificity: 0.9456 - gmeasure: 0.9543 - auc: 0.9848 - val_loss: 0.2662 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9429 - val_specificity: 0.8889 - val_gmeasure: 0.9155 - val_auc: 0.9553\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1247 - binary_accuracy: 0.9617 - sensitivity: 0.9566 - specificity: 0.9735 - gmeasure: 0.9650 - auc: 0.9873 - val_loss: 0.2639 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.8857 - val_specificity: 0.9333 - val_gmeasure: 0.9092 - val_auc: 0.9576\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1180 - binary_accuracy: 0.9617 - sensitivity: 0.9613 - specificity: 0.9619 - gmeasure: 0.9616 - auc: 0.9873 - val_loss: 0.2739 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9429 - val_specificity: 0.8444 - val_gmeasure: 0.8923 - val_auc: 0.9547\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1206 - binary_accuracy: 0.9550 - sensitivity: 0.9637 - specificity: 0.9358 - gmeasure: 0.9496 - auc: 0.9861 - val_loss: 0.2615 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9566\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1183 - binary_accuracy: 0.9633 - sensitivity: 0.9563 - specificity: 0.9785 - gmeasure: 0.9673 - auc: 0.9878 - val_loss: 0.2632 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9238 - val_specificity: 0.9111 - val_gmeasure: 0.9174 - val_auc: 0.9558\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1166 - binary_accuracy: 0.9567 - sensitivity: 0.9560 - specificity: 0.9551 - gmeasure: 0.9554 - auc: 0.9870 - val_loss: 0.2676 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9429 - val_specificity: 0.8667 - val_gmeasure: 0.9040 - val_auc: 0.9558\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1159 - binary_accuracy: 0.9650 - sensitivity: 0.9610 - specificity: 0.9732 - gmeasure: 0.9669 - auc: 0.9878 - val_loss: 0.2640 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9048 - val_specificity: 0.9333 - val_gmeasure: 0.9189 - val_auc: 0.9564\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1170 - binary_accuracy: 0.9650 - sensitivity: 0.9613 - specificity: 0.9729 - gmeasure: 0.9671 - auc: 0.9869 - val_loss: 0.2667 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9549\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1155 - binary_accuracy: 0.9633 - sensitivity: 0.9638 - specificity: 0.9608 - gmeasure: 0.9623 - auc: 0.9867 - val_loss: 0.2644 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9048 - val_specificity: 0.9111 - val_gmeasure: 0.9079 - val_auc: 0.9553\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1183 - binary_accuracy: 0.9617 - sensitivity: 0.9562 - specificity: 0.9737 - gmeasure: 0.9649 - auc: 0.9874 - val_loss: 0.2646 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9143 - val_specificity: 0.9111 - val_gmeasure: 0.9127 - val_auc: 0.9549\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1190 - binary_accuracy: 0.9567 - sensitivity: 0.9635 - specificity: 0.9400 - gmeasure: 0.9513 - auc: 0.9871 - val_loss: 0.2673 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9238 - val_specificity: 0.8889 - val_gmeasure: 0.9062 - val_auc: 0.9553\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/600 [=========>....................] - ETA: 0s - loss: 0.1182 - binary_accuracy: 0.9650 - sensitivity: 0.9507 - specificity: 1.0000 - gmeasure: 0.9750 - auc: 0.9818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1134 - binary_accuracy: 0.9650 - sensitivity: 0.9638 - specificity: 0.9655 - gmeasure: 0.9643 - auc: 0.9873 - val_loss: 0.2639 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9048 - val_specificity: 0.9333 - val_gmeasure: 0.9189 - val_auc: 0.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 5.950875282287598!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 9us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.013648033142089844!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.14493373036384583, 0.9546666741371155, 0.9478764533996582, 0.9698275923728943, 0.9587891697883606, 0.9821844696998596]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.013254642486572266!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.20152749121189117, 0.9319999814033508, 0.9349112510681152, 0.9259259104728699, 0.930407702922821, 0.966177225112915]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 7.348566770553589\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 691us/step - loss: 0.1415 - binary_accuracy: 0.9517 - sensitivity: 0.9675 - specificity: 0.9035 - gmeasure: 0.9339 - auc: 0.9852 - val_loss: 0.1819 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9794\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1382 - binary_accuracy: 0.9583 - sensitivity: 0.9561 - specificity: 0.9630 - gmeasure: 0.9595 - auc: 0.9856 - val_loss: 0.1909 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9783\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1418 - binary_accuracy: 0.9450 - sensitivity: 0.9706 - specificity: 0.8815 - gmeasure: 0.9243 - auc: 0.9863 - val_loss: 0.1910 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9541 - val_specificity: 0.8049 - val_gmeasure: 0.8763 - val_auc: 0.9787\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1403 - binary_accuracy: 0.9550 - sensitivity: 0.9571 - specificity: 0.9561 - gmeasure: 0.9561 - auc: 0.9852 - val_loss: 0.1808 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9450 - val_specificity: 0.9024 - val_gmeasure: 0.9235 - val_auc: 0.9796\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1376 - binary_accuracy: 0.9533 - sensitivity: 0.9590 - specificity: 0.9415 - gmeasure: 0.9494 - auc: 0.9866 - val_loss: 0.1939 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9794\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1362 - binary_accuracy: 0.9500 - sensitivity: 0.9727 - specificity: 0.9000 - gmeasure: 0.9349 - auc: 0.9860 - val_loss: 0.1914 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9794\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1350 - binary_accuracy: 0.9583 - sensitivity: 0.9636 - specificity: 0.9458 - gmeasure: 0.9542 - auc: 0.9866 - val_loss: 0.1799 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9450 - val_specificity: 0.9024 - val_gmeasure: 0.9235 - val_auc: 0.9801\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1326 - binary_accuracy: 0.9583 - sensitivity: 0.9566 - specificity: 0.9639 - gmeasure: 0.9602 - auc: 0.9866 - val_loss: 0.1858 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9790\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1285 - binary_accuracy: 0.9583 - sensitivity: 0.9676 - specificity: 0.9318 - gmeasure: 0.9494 - auc: 0.9859 - val_loss: 0.1967 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9633 - val_specificity: 0.7805 - val_gmeasure: 0.8671 - val_auc: 0.9790\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1285 - binary_accuracy: 0.9550 - sensitivity: 0.9701 - specificity: 0.9142 - gmeasure: 0.9417 - auc: 0.9858 - val_loss: 0.1847 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9792\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1278 - binary_accuracy: 0.9550 - sensitivity: 0.9570 - specificity: 0.9484 - gmeasure: 0.9525 - auc: 0.9869 - val_loss: 0.1770 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9805\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1259 - binary_accuracy: 0.9617 - sensitivity: 0.9590 - specificity: 0.9683 - gmeasure: 0.9636 - auc: 0.9865 - val_loss: 0.1879 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1265 - binary_accuracy: 0.9567 - sensitivity: 0.9725 - specificity: 0.9129 - gmeasure: 0.9422 - auc: 0.9855 - val_loss: 0.1901 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9790\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1221 - binary_accuracy: 0.9633 - sensitivity: 0.9697 - specificity: 0.9409 - gmeasure: 0.9549 - auc: 0.9863 - val_loss: 0.1835 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9796\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1241 - binary_accuracy: 0.9600 - sensitivity: 0.9591 - specificity: 0.9660 - gmeasure: 0.9625 - auc: 0.9869 - val_loss: 0.1839 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1220 - binary_accuracy: 0.9617 - sensitivity: 0.9656 - specificity: 0.9518 - gmeasure: 0.9584 - auc: 0.9864 - val_loss: 0.1939 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9794\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1209 - binary_accuracy: 0.9600 - sensitivity: 0.9702 - specificity: 0.9320 - gmeasure: 0.9507 - auc: 0.9862 - val_loss: 0.1829 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9541 - val_specificity: 0.8293 - val_gmeasure: 0.8895 - val_auc: 0.9799\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1194 - binary_accuracy: 0.9700 - sensitivity: 0.9705 - specificity: 0.9719 - gmeasure: 0.9711 - auc: 0.9874 - val_loss: 0.1811 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1202 - binary_accuracy: 0.9650 - sensitivity: 0.9671 - specificity: 0.9629 - gmeasure: 0.9649 - auc: 0.9866 - val_loss: 0.1840 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1176 - binary_accuracy: 0.9717 - sensitivity: 0.9731 - specificity: 0.9700 - gmeasure: 0.9715 - auc: 0.9872 - val_loss: 0.1836 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9801\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1164 - binary_accuracy: 0.9667 - sensitivity: 0.9683 - specificity: 0.9615 - gmeasure: 0.9648 - auc: 0.9872 - val_loss: 0.1918 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1164 - binary_accuracy: 0.9600 - sensitivity: 0.9680 - specificity: 0.9381 - gmeasure: 0.9526 - auc: 0.9872 - val_loss: 0.1888 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1158 - binary_accuracy: 0.9683 - sensitivity: 0.9680 - specificity: 0.9695 - gmeasure: 0.9688 - auc: 0.9873 - val_loss: 0.1853 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9801\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1135 - binary_accuracy: 0.9683 - sensitivity: 0.9680 - specificity: 0.9710 - gmeasure: 0.9694 - auc: 0.9881 - val_loss: 0.1899 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1133 - binary_accuracy: 0.9683 - sensitivity: 0.9723 - specificity: 0.9575 - gmeasure: 0.9648 - auc: 0.9871 - val_loss: 0.1861 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9541 - val_specificity: 0.8293 - val_gmeasure: 0.8895 - val_auc: 0.9803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1127 - binary_accuracy: 0.9683 - sensitivity: 0.9678 - specificity: 0.9685 - gmeasure: 0.9681 - auc: 0.9878 - val_loss: 0.1854 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9801\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1112 - binary_accuracy: 0.9700 - sensitivity: 0.9702 - specificity: 0.9689 - gmeasure: 0.9695 - auc: 0.9880 - val_loss: 0.1905 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1126 - binary_accuracy: 0.9650 - sensitivity: 0.9725 - specificity: 0.9476 - gmeasure: 0.9597 - auc: 0.9870 - val_loss: 0.1865 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1099 - binary_accuracy: 0.9700 - sensitivity: 0.9704 - specificity: 0.9681 - gmeasure: 0.9692 - auc: 0.9874 - val_loss: 0.1828 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1123 - binary_accuracy: 0.9667 - sensitivity: 0.9703 - specificity: 0.9579 - gmeasure: 0.9637 - auc: 0.9885 - val_loss: 0.1942 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1084 - binary_accuracy: 0.9683 - sensitivity: 0.9725 - specificity: 0.9572 - gmeasure: 0.9648 - auc: 0.9880 - val_loss: 0.1832 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9805\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1111 - binary_accuracy: 0.9667 - sensitivity: 0.9616 - specificity: 0.9806 - gmeasure: 0.9710 - auc: 0.9887 - val_loss: 0.1839 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9810\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1063 - binary_accuracy: 0.9667 - sensitivity: 0.9675 - specificity: 0.9640 - gmeasure: 0.9656 - auc: 0.9887 - val_loss: 0.2031 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1093 - binary_accuracy: 0.9617 - sensitivity: 0.9749 - specificity: 0.9272 - gmeasure: 0.9504 - auc: 0.9881 - val_loss: 0.1875 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9812\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1069 - binary_accuracy: 0.9700 - sensitivity: 0.9681 - specificity: 0.9748 - gmeasure: 0.9713 - auc: 0.9880 - val_loss: 0.1872 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1076 - binary_accuracy: 0.9683 - sensitivity: 0.9681 - specificity: 0.9709 - gmeasure: 0.9694 - auc: 0.9884 - val_loss: 0.1929 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9812\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1057 - binary_accuracy: 0.9683 - sensitivity: 0.9746 - specificity: 0.9494 - gmeasure: 0.9616 - auc: 0.9888 - val_loss: 0.1817 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9814\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1041 - binary_accuracy: 0.9650 - sensitivity: 0.9612 - specificity: 0.9743 - gmeasure: 0.9677 - auc: 0.9893 - val_loss: 0.1890 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9810\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1037 - binary_accuracy: 0.9700 - sensitivity: 0.9752 - specificity: 0.9556 - gmeasure: 0.9651 - auc: 0.9881 - val_loss: 0.1981 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1030 - binary_accuracy: 0.9700 - sensitivity: 0.9748 - specificity: 0.9567 - gmeasure: 0.9657 - auc: 0.9882 - val_loss: 0.1866 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9808\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1016 - binary_accuracy: 0.9667 - sensitivity: 0.9633 - specificity: 0.9752 - gmeasure: 0.9692 - auc: 0.9891 - val_loss: 0.1858 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9805\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1009 - binary_accuracy: 0.9717 - sensitivity: 0.9708 - specificity: 0.9761 - gmeasure: 0.9734 - auc: 0.9889 - val_loss: 0.1973 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1003 - binary_accuracy: 0.9700 - sensitivity: 0.9747 - specificity: 0.9557 - gmeasure: 0.9651 - auc: 0.9884 - val_loss: 0.1933 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9810\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1035 - binary_accuracy: 0.9683 - sensitivity: 0.9663 - specificity: 0.9783 - gmeasure: 0.9722 - auc: 0.9895 - val_loss: 0.1898 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9805\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1030 - binary_accuracy: 0.9667 - sensitivity: 0.9749 - specificity: 0.9440 - gmeasure: 0.9589 - auc: 0.9893 - val_loss: 0.1997 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9810\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0997 - binary_accuracy: 0.9717 - sensitivity: 0.9701 - specificity: 0.9743 - gmeasure: 0.9721 - auc: 0.9890 - val_loss: 0.1844 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9778\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1008 - binary_accuracy: 0.9717 - sensitivity: 0.9681 - specificity: 0.9819 - gmeasure: 0.9748 - auc: 0.9894 - val_loss: 0.1959 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.0975 - binary_accuracy: 0.9733 - sensitivity: 0.9770 - specificity: 0.9632 - gmeasure: 0.9700 - auc: 0.9890 - val_loss: 0.1965 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0984 - binary_accuracy: 0.9750 - sensitivity: 0.9725 - specificity: 0.9814 - gmeasure: 0.9769 - auc: 0.9883 - val_loss: 0.1957 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9808\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.0963 - binary_accuracy: 0.9750 - sensitivity: 0.9728 - specificity: 0.9827 - gmeasure: 0.9777 - auc: 0.9893 - val_loss: 0.1979 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0958 - binary_accuracy: 0.9717 - sensitivity: 0.9729 - specificity: 0.9722 - gmeasure: 0.9725 - auc: 0.9897 - val_loss: 0.1970 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0966 - binary_accuracy: 0.9700 - sensitivity: 0.9751 - specificity: 0.9623 - gmeasure: 0.9684 - auc: 0.9898 - val_loss: 0.1881 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9803\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1003 - binary_accuracy: 0.9683 - sensitivity: 0.9630 - specificity: 0.9820 - gmeasure: 0.9723 - auc: 0.9901 - val_loss: 0.1891 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9450 - val_specificity: 0.8537 - val_gmeasure: 0.8981 - val_auc: 0.9776\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1012 - binary_accuracy: 0.9650 - sensitivity: 0.9705 - specificity: 0.9585 - gmeasure: 0.9641 - auc: 0.9900 - val_loss: 0.2116 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.0962 - binary_accuracy: 0.9733 - sensitivity: 0.9749 - specificity: 0.9699 - gmeasure: 0.9722 - auc: 0.9899 - val_loss: 0.1863 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9781\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0942 - binary_accuracy: 0.9750 - sensitivity: 0.9704 - specificity: 0.9885 - gmeasure: 0.9793 - auc: 0.9899 - val_loss: 0.1956 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0928 - binary_accuracy: 0.9733 - sensitivity: 0.9748 - specificity: 0.9691 - gmeasure: 0.9719 - auc: 0.9899 - val_loss: 0.2025 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.0920 - binary_accuracy: 0.9717 - sensitivity: 0.9745 - specificity: 0.9643 - gmeasure: 0.9694 - auc: 0.9898 - val_loss: 0.1898 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9541 - val_specificity: 0.8537 - val_gmeasure: 0.9025 - val_auc: 0.9810\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.0919 - binary_accuracy: 0.9767 - sensitivity: 0.9729 - specificity: 0.9880 - gmeasure: 0.9803 - auc: 0.9900 - val_loss: 0.1998 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.0910 - binary_accuracy: 0.9767 - sensitivity: 0.9775 - specificity: 0.9733 - gmeasure: 0.9754 - auc: 0.9906 - val_loss: 0.2048 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.0907 - binary_accuracy: 0.9767 - sensitivity: 0.9772 - specificity: 0.9753 - gmeasure: 0.9762 - auc: 0.9905 - val_loss: 0.1917 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9810\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.0896 - binary_accuracy: 0.9767 - sensitivity: 0.9749 - specificity: 0.9820 - gmeasure: 0.9784 - auc: 0.9906 - val_loss: 0.1968 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9808\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.0893 - binary_accuracy: 0.9767 - sensitivity: 0.9752 - specificity: 0.9805 - gmeasure: 0.9779 - auc: 0.9908 - val_loss: 0.1991 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9801\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0881 - binary_accuracy: 0.9783 - sensitivity: 0.9771 - specificity: 0.9830 - gmeasure: 0.9801 - auc: 0.9909 - val_loss: 0.2026 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.0875 - binary_accuracy: 0.9783 - sensitivity: 0.9772 - specificity: 0.9816 - gmeasure: 0.9794 - auc: 0.9907 - val_loss: 0.2008 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.0869 - binary_accuracy: 0.9783 - sensitivity: 0.9746 - specificity: 0.9867 - gmeasure: 0.9806 - auc: 0.9905 - val_loss: 0.1986 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0866 - binary_accuracy: 0.9733 - sensitivity: 0.9748 - specificity: 0.9696 - gmeasure: 0.9721 - auc: 0.9906 - val_loss: 0.1989 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0854 - binary_accuracy: 0.9800 - sensitivity: 0.9751 - specificity: 0.9933 - gmeasure: 0.9842 - auc: 0.9909 - val_loss: 0.2006 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9803\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.0858 - binary_accuracy: 0.9800 - sensitivity: 0.9770 - specificity: 0.9872 - gmeasure: 0.9821 - auc: 0.9912 - val_loss: 0.2060 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9799\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0846 - binary_accuracy: 0.9783 - sensitivity: 0.9773 - specificity: 0.9812 - gmeasure: 0.9792 - auc: 0.9907 - val_loss: 0.1975 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.0852 - binary_accuracy: 0.9767 - sensitivity: 0.9749 - specificity: 0.9822 - gmeasure: 0.9785 - auc: 0.9911 - val_loss: 0.1964 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9803\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.0839 - binary_accuracy: 0.9767 - sensitivity: 0.9750 - specificity: 0.9814 - gmeasure: 0.9782 - auc: 0.9911 - val_loss: 0.2061 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9799\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.0840 - binary_accuracy: 0.9817 - sensitivity: 0.9796 - specificity: 0.9881 - gmeasure: 0.9838 - auc: 0.9913 - val_loss: 0.2037 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9781\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.0841 - binary_accuracy: 0.9817 - sensitivity: 0.9794 - specificity: 0.9883 - gmeasure: 0.9838 - auc: 0.9907 - val_loss: 0.2048 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0823 - binary_accuracy: 0.9800 - sensitivity: 0.9787 - specificity: 0.9811 - gmeasure: 0.9799 - auc: 0.9909 - val_loss: 0.1948 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.0831 - binary_accuracy: 0.9767 - sensitivity: 0.9702 - specificity: 0.9943 - gmeasure: 0.9821 - auc: 0.9917 - val_loss: 0.2030 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9805\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.0816 - binary_accuracy: 0.9750 - sensitivity: 0.9771 - specificity: 0.9713 - gmeasure: 0.9740 - auc: 0.9925 - val_loss: 0.2130 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9796\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.0813 - binary_accuracy: 0.9767 - sensitivity: 0.9797 - specificity: 0.9676 - gmeasure: 0.9736 - auc: 0.9919 - val_loss: 0.2050 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0805 - binary_accuracy: 0.9817 - sensitivity: 0.9771 - specificity: 0.9947 - gmeasure: 0.9859 - auc: 0.9912 - val_loss: 0.2030 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9781\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0798 - binary_accuracy: 0.9817 - sensitivity: 0.9770 - specificity: 0.9944 - gmeasure: 0.9856 - auc: 0.9916 - val_loss: 0.2043 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9801\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0796 - binary_accuracy: 0.9817 - sensitivity: 0.9795 - specificity: 0.9880 - gmeasure: 0.9837 - auc: 0.9926 - val_loss: 0.2062 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9799\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.0788 - binary_accuracy: 0.9817 - sensitivity: 0.9773 - specificity: 0.9940 - gmeasure: 0.9856 - auc: 0.9924 - val_loss: 0.2033 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.0787 - binary_accuracy: 0.9783 - sensitivity: 0.9798 - specificity: 0.9744 - gmeasure: 0.9771 - auc: 0.9922 - val_loss: 0.2111 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9794\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.0805 - binary_accuracy: 0.9800 - sensitivity: 0.9746 - specificity: 0.9933 - gmeasure: 0.9839 - auc: 0.9928 - val_loss: 0.2025 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9777\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.0790 - binary_accuracy: 0.9767 - sensitivity: 0.9793 - specificity: 0.9695 - gmeasure: 0.9742 - auc: 0.9926 - val_loss: 0.2186 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9790\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0790 - binary_accuracy: 0.9783 - sensitivity: 0.9753 - specificity: 0.9892 - gmeasure: 0.9821 - auc: 0.9926 - val_loss: 0.1964 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0767 - binary_accuracy: 0.9783 - sensitivity: 0.9773 - specificity: 0.9825 - gmeasure: 0.9798 - auc: 0.9928 - val_loss: 0.2171 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9792\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.0759 - binary_accuracy: 0.9783 - sensitivity: 0.9816 - specificity: 0.9702 - gmeasure: 0.9757 - auc: 0.9924 - val_loss: 0.2073 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9775\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0747 - binary_accuracy: 0.9833 - sensitivity: 0.9795 - specificity: 0.9933 - gmeasure: 0.9864 - auc: 0.9930 - val_loss: 0.2128 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9762\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0753 - binary_accuracy: 0.9800 - sensitivity: 0.9810 - specificity: 0.9733 - gmeasure: 0.9769 - auc: 0.9926 - val_loss: 0.2163 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9785\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.0736 - binary_accuracy: 0.9850 - sensitivity: 0.9813 - specificity: 0.9931 - gmeasure: 0.9871 - auc: 0.9929 - val_loss: 0.2020 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9777\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.0734 - binary_accuracy: 0.9817 - sensitivity: 0.9797 - specificity: 0.9883 - gmeasure: 0.9839 - auc: 0.9930 - val_loss: 0.2134 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9794\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.0726 - binary_accuracy: 0.9833 - sensitivity: 0.9794 - specificity: 0.9936 - gmeasure: 0.9865 - auc: 0.9925 - val_loss: 0.2117 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9770\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0754 - binary_accuracy: 0.9800 - sensitivity: 0.9750 - specificity: 0.9944 - gmeasure: 0.9846 - auc: 0.9932 - val_loss: 0.2075 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9782\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.0744 - binary_accuracy: 0.9783 - sensitivity: 0.9794 - specificity: 0.9758 - gmeasure: 0.9773 - auc: 0.9930 - val_loss: 0.2269 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9790\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.0725 - binary_accuracy: 0.9800 - sensitivity: 0.9797 - specificity: 0.9822 - gmeasure: 0.9809 - auc: 0.9932 - val_loss: 0.1935 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9633 - val_specificity: 0.8780 - val_gmeasure: 0.9197 - val_auc: 0.9785\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.0735 - binary_accuracy: 0.9783 - sensitivity: 0.9725 - specificity: 0.9939 - gmeasure: 0.9831 - auc: 0.9933 - val_loss: 0.2176 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9794\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.0719 - binary_accuracy: 0.9800 - sensitivity: 0.9815 - specificity: 0.9772 - gmeasure: 0.9793 - auc: 0.9928 - val_loss: 0.2189 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9796\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.0697 - binary_accuracy: 0.9833 - sensitivity: 0.9793 - specificity: 0.9936 - gmeasure: 0.9864 - auc: 0.9934 - val_loss: 0.2047 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9633 - val_specificity: 0.8537 - val_gmeasure: 0.9068 - val_auc: 0.9786\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.0696 - binary_accuracy: 0.9817 - sensitivity: 0.9770 - specificity: 0.9939 - gmeasure: 0.9854 - auc: 0.9935 - val_loss: 0.2214 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 5.911888599395752!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012015104293823242!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.09940922260284424, 0.9706666469573975, 0.9798534512519836, 0.9460784196853638, 0.9628178477287292, 0.9906180500984192]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.013327836990356445!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.32912105321884155, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.9599969983100891]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 7.48249077796936\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.5407 - binary_accuracy: 0.7183 - sensitivity: 0.9787 - specificity: 0.1501 - gmeasure: 0.3349 - auc: 0.7700 - val_loss: 0.5851 - val_binary_accuracy: 0.6733 - val_sensitivity: 0.9796 - val_specificity: 0.0962 - val_gmeasure: 0.3069 - val_auc: 0.7597\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5363 - binary_accuracy: 0.7317 - sensitivity: 0.9544 - specificity: 0.2456 - gmeasure: 0.4715 - auc: 0.7742 - val_loss: 0.5865 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9286 - val_specificity: 0.4423 - val_gmeasure: 0.6409 - val_auc: 0.7661\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.5347 - binary_accuracy: 0.7550 - sensitivity: 0.9471 - specificity: 0.3336 - gmeasure: 0.5609 - auc: 0.7787 - val_loss: 0.5843 - val_binary_accuracy: 0.6867 - val_sensitivity: 0.9694 - val_specificity: 0.1538 - val_gmeasure: 0.3862 - val_auc: 0.7633\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.5342 - binary_accuracy: 0.7317 - sensitivity: 0.9805 - specificity: 0.1848 - gmeasure: 0.4167 - auc: 0.7722 - val_loss: 0.5872 - val_binary_accuracy: 0.6867 - val_sensitivity: 0.9694 - val_specificity: 0.1538 - val_gmeasure: 0.3862 - val_auc: 0.7594\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.5316 - binary_accuracy: 0.7300 - sensitivity: 0.9659 - specificity: 0.2071 - gmeasure: 0.4466 - auc: 0.7723 - val_loss: 0.5825 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.9388 - val_specificity: 0.3846 - val_gmeasure: 0.6009 - val_auc: 0.7624\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5307 - binary_accuracy: 0.7467 - sensitivity: 0.9200 - specificity: 0.3658 - gmeasure: 0.5785 - auc: 0.7773 - val_loss: 0.5825 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7691\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.5295 - binary_accuracy: 0.7383 - sensitivity: 0.9055 - specificity: 0.3685 - gmeasure: 0.5771 - auc: 0.7779 - val_loss: 0.5809 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9184 - val_specificity: 0.3846 - val_gmeasure: 0.5943 - val_auc: 0.7651\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5294 - binary_accuracy: 0.7367 - sensitivity: 0.9325 - specificity: 0.3068 - gmeasure: 0.5250 - auc: 0.7809 - val_loss: 0.5846 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9490 - val_specificity: 0.2885 - val_gmeasure: 0.5232 - val_auc: 0.7622\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.5268 - binary_accuracy: 0.7333 - sensitivity: 0.9274 - specificity: 0.3023 - gmeasure: 0.5256 - auc: 0.7782 - val_loss: 0.5793 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7682\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.5265 - binary_accuracy: 0.7383 - sensitivity: 0.8939 - specificity: 0.3946 - gmeasure: 0.5872 - auc: 0.7823 - val_loss: 0.5787 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.7735\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5242 - binary_accuracy: 0.7333 - sensitivity: 0.8957 - specificity: 0.3781 - gmeasure: 0.5789 - auc: 0.7834 - val_loss: 0.5790 - val_binary_accuracy: 0.7067 - val_sensitivity: 0.8980 - val_specificity: 0.3462 - val_gmeasure: 0.5575 - val_auc: 0.7686\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.5227 - binary_accuracy: 0.7283 - sensitivity: 0.9099 - specificity: 0.3232 - gmeasure: 0.5403 - auc: 0.7801 - val_loss: 0.5779 - val_binary_accuracy: 0.7067 - val_sensitivity: 0.8980 - val_specificity: 0.3462 - val_gmeasure: 0.5575 - val_auc: 0.7694\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.5213 - binary_accuracy: 0.7333 - sensitivity: 0.9013 - specificity: 0.3646 - gmeasure: 0.5702 - auc: 0.7850 - val_loss: 0.5752 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.7714\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.5196 - binary_accuracy: 0.7400 - sensitivity: 0.8955 - specificity: 0.3898 - gmeasure: 0.5880 - auc: 0.7859 - val_loss: 0.5750 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7695\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.5179 - binary_accuracy: 0.7400 - sensitivity: 0.9007 - specificity: 0.3887 - gmeasure: 0.5900 - auc: 0.7886 - val_loss: 0.5747 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7698\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.5174 - binary_accuracy: 0.7383 - sensitivity: 0.9017 - specificity: 0.3815 - gmeasure: 0.5853 - auc: 0.7882 - val_loss: 0.5733 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8980 - val_specificity: 0.4615 - val_gmeasure: 0.6438 - val_auc: 0.7712\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5154 - binary_accuracy: 0.7450 - sensitivity: 0.8967 - specificity: 0.3997 - gmeasure: 0.5964 - auc: 0.7912 - val_loss: 0.5716 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8776 - val_specificity: 0.4808 - val_gmeasure: 0.6495 - val_auc: 0.7747\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.5144 - binary_accuracy: 0.7383 - sensitivity: 0.9030 - specificity: 0.3764 - gmeasure: 0.5812 - auc: 0.7918 - val_loss: 0.5730 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.9184 - val_specificity: 0.3654 - val_gmeasure: 0.5793 - val_auc: 0.7761\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.5126 - binary_accuracy: 0.7433 - sensitivity: 0.9026 - specificity: 0.3905 - gmeasure: 0.5896 - auc: 0.7926 - val_loss: 0.5694 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.7785\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.5106 - binary_accuracy: 0.7483 - sensitivity: 0.8957 - specificity: 0.4232 - gmeasure: 0.6151 - auc: 0.7948 - val_loss: 0.5691 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7779\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5099 - binary_accuracy: 0.7500 - sensitivity: 0.9009 - specificity: 0.4219 - gmeasure: 0.6148 - auc: 0.7999 - val_loss: 0.5680 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7794\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.5072 - binary_accuracy: 0.7567 - sensitivity: 0.9179 - specificity: 0.4034 - gmeasure: 0.6078 - auc: 0.7979 - val_loss: 0.5708 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9184 - val_specificity: 0.4038 - val_gmeasure: 0.6090 - val_auc: 0.7804\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.5070 - binary_accuracy: 0.7600 - sensitivity: 0.9152 - specificity: 0.4173 - gmeasure: 0.6179 - auc: 0.7983 - val_loss: 0.5653 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8776 - val_specificity: 0.4615 - val_gmeasure: 0.6364 - val_auc: 0.7834\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.5038 - binary_accuracy: 0.7633 - sensitivity: 0.9057 - specificity: 0.4496 - gmeasure: 0.6367 - auc: 0.8049 - val_loss: 0.5647 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8776 - val_specificity: 0.4423 - val_gmeasure: 0.6230 - val_auc: 0.7841\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5016 - binary_accuracy: 0.7583 - sensitivity: 0.9106 - specificity: 0.4231 - gmeasure: 0.6205 - auc: 0.8020 - val_loss: 0.5659 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.8878 - val_specificity: 0.4038 - val_gmeasure: 0.5988 - val_auc: 0.7849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.5009 - binary_accuracy: 0.7650 - sensitivity: 0.9127 - specificity: 0.4420 - gmeasure: 0.6340 - auc: 0.8004 - val_loss: 0.5629 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7879\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.5010 - binary_accuracy: 0.7600 - sensitivity: 0.9131 - specificity: 0.4172 - gmeasure: 0.6162 - auc: 0.8030 - val_loss: 0.5645 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.8878 - val_specificity: 0.4038 - val_gmeasure: 0.5988 - val_auc: 0.7883\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4975 - binary_accuracy: 0.7717 - sensitivity: 0.9105 - specificity: 0.4668 - gmeasure: 0.6505 - auc: 0.8098 - val_loss: 0.5622 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8673 - val_specificity: 0.5000 - val_gmeasure: 0.6585 - val_auc: 0.7891\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4975 - binary_accuracy: 0.7733 - sensitivity: 0.9120 - specificity: 0.4751 - gmeasure: 0.6565 - auc: 0.8101 - val_loss: 0.5625 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7922\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.4938 - binary_accuracy: 0.7700 - sensitivity: 0.9295 - specificity: 0.4171 - gmeasure: 0.6217 - auc: 0.8106 - val_loss: 0.5605 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7939\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4970 - binary_accuracy: 0.7750 - sensitivity: 0.8986 - specificity: 0.5135 - gmeasure: 0.6738 - auc: 0.8151 - val_loss: 0.5592 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7947\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4909 - binary_accuracy: 0.7767 - sensitivity: 0.9281 - specificity: 0.4413 - gmeasure: 0.6333 - auc: 0.8127 - val_loss: 0.5669 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8980 - val_specificity: 0.4038 - val_gmeasure: 0.6022 - val_auc: 0.7926\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4896 - binary_accuracy: 0.7733 - sensitivity: 0.9295 - specificity: 0.4308 - gmeasure: 0.6305 - auc: 0.8143 - val_loss: 0.5570 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8878 - val_specificity: 0.4423 - val_gmeasure: 0.6266 - val_auc: 0.7975\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4858 - binary_accuracy: 0.7900 - sensitivity: 0.9181 - specificity: 0.5080 - gmeasure: 0.6828 - auc: 0.8205 - val_loss: 0.5569 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7969\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.4831 - binary_accuracy: 0.7850 - sensitivity: 0.9263 - specificity: 0.4731 - gmeasure: 0.6610 - auc: 0.8203 - val_loss: 0.5596 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7976\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.4811 - binary_accuracy: 0.7833 - sensitivity: 0.9322 - specificity: 0.4553 - gmeasure: 0.6514 - auc: 0.8225 - val_loss: 0.5585 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7967\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.4792 - binary_accuracy: 0.7883 - sensitivity: 0.9271 - specificity: 0.4855 - gmeasure: 0.6692 - auc: 0.8251 - val_loss: 0.5574 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7961\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4772 - binary_accuracy: 0.7950 - sensitivity: 0.9281 - specificity: 0.5039 - gmeasure: 0.6833 - auc: 0.8268 - val_loss: 0.5565 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7959\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4745 - binary_accuracy: 0.7933 - sensitivity: 0.9320 - specificity: 0.4866 - gmeasure: 0.6734 - auc: 0.8285 - val_loss: 0.5570 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7960\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4723 - binary_accuracy: 0.8017 - sensitivity: 0.9393 - specificity: 0.4921 - gmeasure: 0.6782 - auc: 0.8308 - val_loss: 0.5555 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7969\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4708 - binary_accuracy: 0.8100 - sensitivity: 0.9374 - specificity: 0.5269 - gmeasure: 0.7027 - auc: 0.8308 - val_loss: 0.5555 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7961\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.4693 - binary_accuracy: 0.7983 - sensitivity: 0.9394 - specificity: 0.4922 - gmeasure: 0.6773 - auc: 0.8335 - val_loss: 0.5598 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8980 - val_specificity: 0.4231 - val_gmeasure: 0.6164 - val_auc: 0.7982\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.4661 - binary_accuracy: 0.8100 - sensitivity: 0.9420 - specificity: 0.5220 - gmeasure: 0.7006 - auc: 0.8358 - val_loss: 0.5556 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8878 - val_specificity: 0.4615 - val_gmeasure: 0.6401 - val_auc: 0.7969\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4635 - binary_accuracy: 0.8117 - sensitivity: 0.9425 - specificity: 0.5284 - gmeasure: 0.7049 - auc: 0.8394 - val_loss: 0.5568 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.8878 - val_specificity: 0.4231 - val_gmeasure: 0.6129 - val_auc: 0.7965\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4610 - binary_accuracy: 0.8100 - sensitivity: 0.9466 - specificity: 0.5093 - gmeasure: 0.6934 - auc: 0.8410 - val_loss: 0.5550 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.8776 - val_specificity: 0.4615 - val_gmeasure: 0.6364 - val_auc: 0.7963\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4595 - binary_accuracy: 0.8150 - sensitivity: 0.9345 - specificity: 0.5520 - gmeasure: 0.7179 - auc: 0.8445 - val_loss: 0.5537 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.7945\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4557 - binary_accuracy: 0.8267 - sensitivity: 0.9445 - specificity: 0.5635 - gmeasure: 0.7270 - auc: 0.8437 - val_loss: 0.5592 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9082 - val_specificity: 0.4038 - val_gmeasure: 0.6056 - val_auc: 0.7982\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4546 - binary_accuracy: 0.8167 - sensitivity: 0.9514 - specificity: 0.5233 - gmeasure: 0.7025 - auc: 0.8474 - val_loss: 0.5545 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.7979\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4511 - binary_accuracy: 0.8250 - sensitivity: 0.9512 - specificity: 0.5476 - gmeasure: 0.7214 - auc: 0.8502 - val_loss: 0.5562 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9082 - val_specificity: 0.4231 - val_gmeasure: 0.6199 - val_auc: 0.7971\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.4481 - binary_accuracy: 0.8200 - sensitivity: 0.9538 - specificity: 0.5233 - gmeasure: 0.7064 - auc: 0.8514 - val_loss: 0.5542 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.8980 - val_specificity: 0.5192 - val_gmeasure: 0.6828 - val_auc: 0.7961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4454 - binary_accuracy: 0.8300 - sensitivity: 0.9549 - specificity: 0.5555 - gmeasure: 0.7280 - auc: 0.8518 - val_loss: 0.5547 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.7977\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.4444 - binary_accuracy: 0.8183 - sensitivity: 0.9543 - specificity: 0.5197 - gmeasure: 0.7025 - auc: 0.8566 - val_loss: 0.5569 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.8980 - val_specificity: 0.4423 - val_gmeasure: 0.6302 - val_auc: 0.7993\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.4492 - binary_accuracy: 0.8283 - sensitivity: 0.9327 - specificity: 0.6139 - gmeasure: 0.7542 - auc: 0.8612 - val_loss: 0.5516 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.7987\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4427 - binary_accuracy: 0.8167 - sensitivity: 0.9469 - specificity: 0.5302 - gmeasure: 0.7066 - auc: 0.8613 - val_loss: 0.5752 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.9490 - val_specificity: 0.3654 - val_gmeasure: 0.5888 - val_auc: 0.8031\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4403 - binary_accuracy: 0.8167 - sensitivity: 0.9520 - specificity: 0.5152 - gmeasure: 0.6964 - auc: 0.8636 - val_loss: 0.5503 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8673 - val_specificity: 0.5385 - val_gmeasure: 0.6834 - val_auc: 0.7992\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.4386 - binary_accuracy: 0.8200 - sensitivity: 0.9348 - specificity: 0.5707 - gmeasure: 0.7298 - auc: 0.8614 - val_loss: 0.5556 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8042\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4351 - binary_accuracy: 0.8183 - sensitivity: 0.9576 - specificity: 0.5174 - gmeasure: 0.7033 - auc: 0.8704 - val_loss: 0.5534 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8052\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4370 - binary_accuracy: 0.8267 - sensitivity: 0.9265 - specificity: 0.6121 - gmeasure: 0.7515 - auc: 0.8683 - val_loss: 0.5479 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.8070\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4322 - binary_accuracy: 0.8233 - sensitivity: 0.9469 - specificity: 0.5522 - gmeasure: 0.7224 - auc: 0.8655 - val_loss: 0.5667 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9388 - val_specificity: 0.4231 - val_gmeasure: 0.6302 - val_auc: 0.8086\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4328 - binary_accuracy: 0.8233 - sensitivity: 0.9431 - specificity: 0.5715 - gmeasure: 0.7325 - auc: 0.8689 - val_loss: 0.5470 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8776 - val_specificity: 0.5192 - val_gmeasure: 0.6750 - val_auc: 0.8081\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4277 - binary_accuracy: 0.8300 - sensitivity: 0.9469 - specificity: 0.5749 - gmeasure: 0.7375 - auc: 0.8708 - val_loss: 0.5607 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9286 - val_specificity: 0.4615 - val_gmeasure: 0.6547 - val_auc: 0.8090\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.4245 - binary_accuracy: 0.8350 - sensitivity: 0.9583 - specificity: 0.5630 - gmeasure: 0.7344 - auc: 0.8711 - val_loss: 0.5475 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8100\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4230 - binary_accuracy: 0.8383 - sensitivity: 0.9396 - specificity: 0.6194 - gmeasure: 0.7617 - auc: 0.8713 - val_loss: 0.5491 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8127\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4216 - binary_accuracy: 0.8300 - sensitivity: 0.9531 - specificity: 0.5536 - gmeasure: 0.7246 - auc: 0.8727 - val_loss: 0.5609 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9184 - val_specificity: 0.4615 - val_gmeasure: 0.6510 - val_auc: 0.8137\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.4182 - binary_accuracy: 0.8267 - sensitivity: 0.9510 - specificity: 0.5505 - gmeasure: 0.7234 - auc: 0.8745 - val_loss: 0.5439 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8776 - val_specificity: 0.5385 - val_gmeasure: 0.6874 - val_auc: 0.8120\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 0.4200 - binary_accuracy: 0.8267 - sensitivity: 0.9203 - specificity: 0.6160 - gmeasure: 0.7519 - auc: 0.8721 - val_loss: 0.5553 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8155\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.4165 - binary_accuracy: 0.8300 - sensitivity: 0.9601 - specificity: 0.5538 - gmeasure: 0.7271 - auc: 0.8826 - val_loss: 0.5560 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8158\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.4127 - binary_accuracy: 0.8367 - sensitivity: 0.9563 - specificity: 0.5711 - gmeasure: 0.7384 - auc: 0.8767 - val_loss: 0.5430 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8673 - val_specificity: 0.5385 - val_gmeasure: 0.6834 - val_auc: 0.8148\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4157 - binary_accuracy: 0.8283 - sensitivity: 0.9180 - specificity: 0.6318 - gmeasure: 0.7611 - auc: 0.8771 - val_loss: 0.5549 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8178\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.4122 - binary_accuracy: 0.8283 - sensitivity: 0.9614 - specificity: 0.5333 - gmeasure: 0.7152 - auc: 0.8783 - val_loss: 0.5546 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8190\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4092 - binary_accuracy: 0.8383 - sensitivity: 0.9460 - specificity: 0.6015 - gmeasure: 0.7541 - auc: 0.8802 - val_loss: 0.5462 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8194\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4074 - binary_accuracy: 0.8383 - sensitivity: 0.9343 - specificity: 0.6181 - gmeasure: 0.7575 - auc: 0.8797 - val_loss: 0.5521 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8189\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4061 - binary_accuracy: 0.8400 - sensitivity: 0.9497 - specificity: 0.6001 - gmeasure: 0.7524 - auc: 0.8826 - val_loss: 0.5515 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8980 - val_specificity: 0.4808 - val_gmeasure: 0.6570 - val_auc: 0.8197\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.4041 - binary_accuracy: 0.8417 - sensitivity: 0.9491 - specificity: 0.6045 - gmeasure: 0.7570 - auc: 0.8822 - val_loss: 0.5483 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8218\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.4025 - binary_accuracy: 0.8417 - sensitivity: 0.9443 - specificity: 0.6133 - gmeasure: 0.7606 - auc: 0.8842 - val_loss: 0.5506 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.4024 - binary_accuracy: 0.8367 - sensitivity: 0.9487 - specificity: 0.5913 - gmeasure: 0.7481 - auc: 0.8848 - val_loss: 0.5455 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8244\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3995 - binary_accuracy: 0.8383 - sensitivity: 0.9345 - specificity: 0.6253 - gmeasure: 0.7639 - auc: 0.8861 - val_loss: 0.5539 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8225\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.4021 - binary_accuracy: 0.8300 - sensitivity: 0.9546 - specificity: 0.5561 - gmeasure: 0.7284 - auc: 0.8886 - val_loss: 0.5454 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8776 - val_specificity: 0.5000 - val_gmeasure: 0.6624 - val_auc: 0.8216\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4051 - binary_accuracy: 0.8300 - sensitivity: 0.9059 - specificity: 0.6663 - gmeasure: 0.7760 - auc: 0.8858 - val_loss: 0.5465 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8233\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3958 - binary_accuracy: 0.8400 - sensitivity: 0.9613 - specificity: 0.5728 - gmeasure: 0.7418 - auc: 0.8905 - val_loss: 0.5636 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8240\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3950 - binary_accuracy: 0.8400 - sensitivity: 0.9385 - specificity: 0.6181 - gmeasure: 0.7597 - auc: 0.8905 - val_loss: 0.5397 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8571 - val_specificity: 0.5577 - val_gmeasure: 0.6914 - val_auc: 0.8255\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3948 - binary_accuracy: 0.8367 - sensitivity: 0.9191 - specificity: 0.6505 - gmeasure: 0.7728 - auc: 0.8869 - val_loss: 0.5591 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8292\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.4004 - binary_accuracy: 0.8267 - sensitivity: 0.9614 - specificity: 0.5312 - gmeasure: 0.7135 - auc: 0.8936 - val_loss: 0.5468 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.8292\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3926 - binary_accuracy: 0.8350 - sensitivity: 0.9119 - specificity: 0.6719 - gmeasure: 0.7812 - auc: 0.8920 - val_loss: 0.5383 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.8571 - val_specificity: 0.6154 - val_gmeasure: 0.7263 - val_auc: 0.8283\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3882 - binary_accuracy: 0.8350 - sensitivity: 0.9297 - specificity: 0.6253 - gmeasure: 0.7622 - auc: 0.8942 - val_loss: 0.5689 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9184 - val_specificity: 0.4423 - val_gmeasure: 0.6373 - val_auc: 0.8250\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3902 - binary_accuracy: 0.8417 - sensitivity: 0.9617 - specificity: 0.5770 - gmeasure: 0.7449 - auc: 0.8950 - val_loss: 0.5371 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.8571 - val_specificity: 0.5962 - val_gmeasure: 0.7148 - val_auc: 0.8289\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3944 - binary_accuracy: 0.8433 - sensitivity: 0.9058 - specificity: 0.7082 - gmeasure: 0.8004 - auc: 0.8937 - val_loss: 0.5485 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8314\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3949 - binary_accuracy: 0.8300 - sensitivity: 0.9567 - specificity: 0.5505 - gmeasure: 0.7257 - auc: 0.8957 - val_loss: 0.5596 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9082 - val_specificity: 0.4615 - val_gmeasure: 0.6474 - val_auc: 0.8291\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3935 - binary_accuracy: 0.8350 - sensitivity: 0.9230 - specificity: 0.6444 - gmeasure: 0.7680 - auc: 0.8941 - val_loss: 0.5364 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.8571 - val_specificity: 0.6731 - val_gmeasure: 0.7596 - val_auc: 0.8308\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3858 - binary_accuracy: 0.8367 - sensitivity: 0.9275 - specificity: 0.6401 - gmeasure: 0.7687 - auc: 0.8961 - val_loss: 0.5779 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9286 - val_specificity: 0.4423 - val_gmeasure: 0.6409 - val_auc: 0.8259\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3879 - binary_accuracy: 0.8367 - sensitivity: 0.9613 - specificity: 0.5610 - gmeasure: 0.7324 - auc: 0.8995 - val_loss: 0.5384 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.8571 - val_specificity: 0.6154 - val_gmeasure: 0.7263 - val_auc: 0.8328\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3828 - binary_accuracy: 0.8433 - sensitivity: 0.9176 - specificity: 0.6785 - gmeasure: 0.7886 - auc: 0.8976 - val_loss: 0.5471 - val_binary_accuracy: 0.7467 - val_sensitivity: 0.8878 - val_specificity: 0.4808 - val_gmeasure: 0.6533 - val_auc: 0.8303\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3813 - binary_accuracy: 0.8483 - sensitivity: 0.9491 - specificity: 0.6263 - gmeasure: 0.7707 - auc: 0.9008 - val_loss: 0.5540 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8318\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3892 - binary_accuracy: 0.8350 - sensitivity: 0.9173 - specificity: 0.6609 - gmeasure: 0.7745 - auc: 0.9004 - val_loss: 0.5370 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.8571 - val_specificity: 0.6346 - val_gmeasure: 0.7375 - val_auc: 0.8340\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3798 - binary_accuracy: 0.8450 - sensitivity: 0.9515 - specificity: 0.6100 - gmeasure: 0.7609 - auc: 0.9003 - val_loss: 0.5702 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9184 - val_specificity: 0.4615 - val_gmeasure: 0.6510 - val_auc: 0.8324\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3782 - binary_accuracy: 0.8383 - sensitivity: 0.9542 - specificity: 0.5771 - gmeasure: 0.7407 - auc: 0.9032 - val_loss: 0.5345 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.8571 - val_specificity: 0.6731 - val_gmeasure: 0.7596 - val_auc: 0.8350\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.3792 - binary_accuracy: 0.8483 - sensitivity: 0.9178 - specificity: 0.6917 - gmeasure: 0.7956 - auc: 0.8957 - val_loss: 0.5468 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.8980 - val_specificity: 0.5000 - val_gmeasure: 0.6701 - val_auc: 0.8359\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.3749 - binary_accuracy: 0.8467 - sensitivity: 0.9468 - specificity: 0.6255 - gmeasure: 0.7677 - auc: 0.9040 - val_loss: 0.5529 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9082 - val_specificity: 0.4808 - val_gmeasure: 0.6608 - val_auc: 0.8359\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3713 - binary_accuracy: 0.8467 - sensitivity: 0.9444 - specificity: 0.6312 - gmeasure: 0.7720 - auc: 0.9038 - val_loss: 0.5392 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.8673 - val_specificity: 0.6346 - val_gmeasure: 0.7419 - val_auc: 0.8367\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3717 - binary_accuracy: 0.8483 - sensitivity: 0.9281 - specificity: 0.6763 - gmeasure: 0.7919 - auc: 0.9017 - val_loss: 0.5460 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.8878 - val_specificity: 0.5000 - val_gmeasure: 0.6662 - val_auc: 0.8373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 6.008526563644409!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.010854005813598633!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.40481051802635193, 0.828000009059906, 0.931506872177124, 0.6066945791244507, 0.7517580389976501, 0.8901817202568054]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.010163545608520508!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.4838153123855591, 0.7680000066757202, 0.8932584524154663, 0.4583333432674408, 0.6398516297340393, 0.8164793848991394]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 7.612103700637817\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.21638449 0.91777778 0.95307893 0.84086686 0.89112169 0.95432808]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.13452731 0.06381763 0.0200773  0.16586842 0.0985587  0.04548881]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.33815462 0.86266667 0.92739757 0.70703378 0.80289634 0.91421787]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.11542041 0.06930768 0.02536959 0.19205399 0.1212509  0.06915758]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, warm_start_network_info, path_info, \n",
    "                                                                       number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the history plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33241e06a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load the pre-trained network for testing\n",
    "\n",
    "If you want to test the trained model, you can use the `deepbiome_test` function. If you use the index file, this function provide the evaluation using test index (index set not included in the index file) for each fold. If not, this function provide the evaluation using the whole samples. If `number_of_fold` is setted as `k`, the function will test the model only with first `k` folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/classification_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:294] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 329us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.24315500259399414!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.20152749121189117, 0.9319999814033508, 0.9349112510681152, 0.9259259104728699, 0.930407702922821, 0.966177225112915]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.4478569030761719\n",
      "[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 283us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.20883989334106445!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.32912105321884155, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.9599969983100891]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.3928356170654297\n",
      "[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 282us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.18898677825927734!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.4838153123855591, 0.7680000066757202, 0.8932584524154663, 0.4583333432674408, 0.6398516297340393, 0.8164793848991394]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.4299449920654297\n",
      "[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:328] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:331]       mean : [0.33815462 0.86266667 0.92739757 0.70703378 0.80289634 0.91421787]\n",
      "[root    |INFO|deepbiome.py:332]        std : [0.11542041 0.06930768 0.02536959 0.19205399 0.1212509  0.06915758]\n",
      "[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:336] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluation = deepbiome.deepbiome_test(log, test_network_info, test_path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function provides the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc\n",
      "Mean:           0.3382          0.8627          0.9274          0.7070          0.8029          0.9142\n",
      "Std :           0.1154          0.0693          0.0254          0.1921          0.1213          0.0692\n"
     ]
    }
   ],
   "source": [
    "print('      %s' % ''.join(['%16s'%'loss']+ ['%16s'%s.strip() for s in network_info['model_info']['metrics'].split(',')]))\n",
    "print('Mean: %s' % ''.join(['%16.4f'%v for v in np.mean(evaluation, axis=0)]))\n",
    "print('Std : %s' % ''.join(['%16.4f'%v for v in np.std(evaluation, axis=0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load the pre-trained network for prediction\n",
    "\n",
    "For prediction using the pre-trained model, we can use the `deepbiome_prediction` function. If `number_of_fold` is set to `k`, the function will predict only with first `k` folds sample's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'taxa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight_0.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.0282289981842041!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 0.9565651416778564\n",
      "[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.04712557792663574!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 0.9941525459289551\n",
      "[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Family', 'Genus', 'Order', 'Number', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.03409934043884277!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 1.0578253269195557\n",
      "[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:449] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prediction = deepbiome.deepbiome_prediction(log, prediction_network_info, prediction_path_info,\n",
    "                                            num_classes = 1, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9551762 ],\n",
       "       [0.7373678 ],\n",
       "       [0.07542831],\n",
       "       [0.07542831],\n",
       "       [0.9999994 ],\n",
       "       [0.9921325 ],\n",
       "       [0.07542831],\n",
       "       [0.07542831],\n",
       "       [0.9999854 ],\n",
       "       [0.9997467 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0,:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
