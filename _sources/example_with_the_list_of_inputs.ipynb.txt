{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : k times repetition with the list of k input files \n",
    "\n",
    "DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.\n",
    "\n",
    "To use DeepBiome, you can experiment (1) __k times repetition__ or (2) __k fold cross-validation__.\n",
    "For each experiment, we asuume that the dataset is given by\n",
    "- __A list of k input files for k times repetition.__\n",
    "- __One input file for k fold cross-validation.__\n",
    "\n",
    "This notebook contains an example of (1) __k times repetition__ for the deep neural netowrk using deepbiome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load library\n",
    "\n",
    "First, we have to load deepbiome package. The deepbiome package is build on the tensorflow and keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepbiome import deepbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset\n",
    "\n",
    "In this example, we assume that we have __a list of k input files for k times repetition.__\n",
    "\n",
    "DeepBiome needs 4 data files as follows:\n",
    "1. __the tree information__\n",
    "1. __the lists of the input files__ (each file has all sample's information for one repetition)\n",
    "1. __the list of the names of input files__ \n",
    "1. __y__\n",
    "\n",
    "In addition, we can set __the training index for each repetition__. If we set the index file, DeepBiome builds the training set for each repetition based on each fold index in the index file. If not, DeepBiome will generate the index file locally.\n",
    "\n",
    "\n",
    "Eath data should have the csv format. Below is the example of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the tree information\n",
    "\n",
    "First we need a file about the phylogenetic tree information. This tree information file should have the format below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genus</th>\n",
       "      <th>Family</th>\n",
       "      <th>Order</th>\n",
       "      <th>Class</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Streptococcus</td>\n",
       "      <td>Streptococcaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tropheryma</td>\n",
       "      <td>Cellulomonadaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veillonella</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actinomyces</td>\n",
       "      <td>Actinomycetaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flavobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prevotella</td>\n",
       "      <td>Prevotellaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Porphyromonas</td>\n",
       "      <td>Porphyromonadaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parvimonas</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fusobacterium</td>\n",
       "      <td>Fusobacteriaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Propionibacterium</td>\n",
       "      <td>Propionibacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gemella</td>\n",
       "      <td>Bacillales_Incertae_Sedis_XI</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rothia</td>\n",
       "      <td>Micrococcaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Granulicatella</td>\n",
       "      <td>Carnobacteriaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Neisseria</td>\n",
       "      <td>Neisseriaceae</td>\n",
       "      <td>Neisseriales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lactobacillus</td>\n",
       "      <td>Lactobacillaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Megasphaera</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Catonella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atopobium</td>\n",
       "      <td>Coriobacteriaceae</td>\n",
       "      <td>Coriobacteriales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>Campylobacteraceae</td>\n",
       "      <td>Campylobacterales</td>\n",
       "      <td>Epsilonproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Capnocytophaga</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solobacterium</td>\n",
       "      <td>Erysipelotrichaceae</td>\n",
       "      <td>Erysipelotrichales</td>\n",
       "      <td>Erysipelotrichia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Moryella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Staphylococcus</td>\n",
       "      <td>Staphylococcaceae</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Filifactor</td>\n",
       "      <td>Peptostreptococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oribacterium</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Burkholderia</td>\n",
       "      <td>Burkholderiaceae</td>\n",
       "      <td>Burkholderiales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sneathia</td>\n",
       "      <td>Leptotrichiaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Treponema</td>\n",
       "      <td>Spirochaetaceae</td>\n",
       "      <td>Spirochaetales</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Moraxella</td>\n",
       "      <td>Moraxellaceae</td>\n",
       "      <td>Pseudomonadales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Haemophilus</td>\n",
       "      <td>Pasteurellaceae</td>\n",
       "      <td>Pasteurellales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Selenomonas</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Corynebacterium</td>\n",
       "      <td>Corynebacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rhizobium</td>\n",
       "      <td>Rhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bradyrhizobium</td>\n",
       "      <td>Bradyrhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Methylobacterium</td>\n",
       "      <td>Methylobacteriaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Finegoldia</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Microbacterium</td>\n",
       "      <td>Microbacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sphingomonas</td>\n",
       "      <td>Sphingomonadaceae</td>\n",
       "      <td>Sphingomonadales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Chryseobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bacteroides</td>\n",
       "      <td>Bacteroidaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bdellovibrio</td>\n",
       "      <td>Bdellovibrionaceae</td>\n",
       "      <td>Bdellovibrionales</td>\n",
       "      <td>Deltaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Streptophyta</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Cyanobacteria_Chloroplast</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Lachnospiracea_incertae_sedis</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Paracoccus</td>\n",
       "      <td>Rhodobacteraceae</td>\n",
       "      <td>Rhodobacterales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fastidiosipila</td>\n",
       "      <td>Ruminococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pseudonocardia</td>\n",
       "      <td>Pseudonocardiaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Genus                           Family  \\\n",
       "0                   Streptococcus                 Streptococcaceae   \n",
       "1                      Tropheryma                Cellulomonadaceae   \n",
       "2                     Veillonella                  Veillonellaceae   \n",
       "3                     Actinomyces                 Actinomycetaceae   \n",
       "4                  Flavobacterium                Flavobacteriaceae   \n",
       "5                      Prevotella                   Prevotellaceae   \n",
       "6                   Porphyromonas               Porphyromonadaceae   \n",
       "7                      Parvimonas  Clostridiales_Incertae_Sedis_XI   \n",
       "8                   Fusobacterium                 Fusobacteriaceae   \n",
       "9               Propionibacterium             Propionibacteriaceae   \n",
       "10                        Gemella     Bacillales_Incertae_Sedis_XI   \n",
       "11                         Rothia                   Micrococcaceae   \n",
       "12                 Granulicatella                Carnobacteriaceae   \n",
       "13                      Neisseria                    Neisseriaceae   \n",
       "14                  Lactobacillus                 Lactobacillaceae   \n",
       "15                    Megasphaera                  Veillonellaceae   \n",
       "16                      Catonella                  Lachnospiraceae   \n",
       "17                      Atopobium                Coriobacteriaceae   \n",
       "18                  Campylobacter               Campylobacteraceae   \n",
       "19                 Capnocytophaga                Flavobacteriaceae   \n",
       "20                  Solobacterium              Erysipelotrichaceae   \n",
       "21                       Moryella                  Lachnospiraceae   \n",
       "22      TM7_genera_incertae_sedis        TM7_genera_incertae_sedis   \n",
       "23                 Staphylococcus                Staphylococcaceae   \n",
       "24                     Filifactor            Peptostreptococcaceae   \n",
       "25                   Oribacterium                  Lachnospiraceae   \n",
       "26                   Burkholderia                 Burkholderiaceae   \n",
       "27                       Sneathia                 Leptotrichiaceae   \n",
       "28                      Treponema                  Spirochaetaceae   \n",
       "29                      Moraxella                    Moraxellaceae   \n",
       "30                    Haemophilus                  Pasteurellaceae   \n",
       "31                    Selenomonas                  Veillonellaceae   \n",
       "32                Corynebacterium               Corynebacteriaceae   \n",
       "33                      Rhizobium                     Rhizobiaceae   \n",
       "34                 Bradyrhizobium                Bradyrhizobiaceae   \n",
       "35               Methylobacterium              Methylobacteriaceae   \n",
       "36      OD1_genera_incertae_sedis        OD1_genera_incertae_sedis   \n",
       "37                     Finegoldia  Clostridiales_Incertae_Sedis_XI   \n",
       "38                 Microbacterium                Microbacteriaceae   \n",
       "39                   Sphingomonas                Sphingomonadaceae   \n",
       "40               Chryseobacterium                Flavobacteriaceae   \n",
       "41                    Bacteroides                   Bacteroidaceae   \n",
       "42                   Bdellovibrio               Bdellovibrionaceae   \n",
       "43                   Streptophyta                      Chloroplast   \n",
       "44  Lachnospiracea_incertae_sedis                  Lachnospiraceae   \n",
       "45                     Paracoccus                 Rhodobacteraceae   \n",
       "46                 Fastidiosipila                  Ruminococcaceae   \n",
       "47                 Pseudonocardia               Pseudonocardiaceae   \n",
       "\n",
       "                        Order                      Class  \\\n",
       "0             Lactobacillales                    Bacilli   \n",
       "1             Actinomycetales             Actinobacteria   \n",
       "2             Selenomonadales              Negativicutes   \n",
       "3             Actinomycetales             Actinobacteria   \n",
       "4            Flavobacteriales              Flavobacteria   \n",
       "5               Bacteroidales                Bacteroidia   \n",
       "6               Bacteroidales                Bacteroidia   \n",
       "7               Clostridiales                 Clostridia   \n",
       "8             Fusobacteriales               Fusobacteria   \n",
       "9             Actinomycetales             Actinobacteria   \n",
       "10                 Bacillales                    Bacilli   \n",
       "11            Actinomycetales             Actinobacteria   \n",
       "12            Lactobacillales                    Bacilli   \n",
       "13               Neisseriales         Betaproteobacteria   \n",
       "14            Lactobacillales                    Bacilli   \n",
       "15            Selenomonadales              Negativicutes   \n",
       "16              Clostridiales                 Clostridia   \n",
       "17           Coriobacteriales             Actinobacteria   \n",
       "18          Campylobacterales      Epsilonproteobacteria   \n",
       "19           Flavobacteriales              Flavobacteria   \n",
       "20         Erysipelotrichales           Erysipelotrichia   \n",
       "21              Clostridiales                 Clostridia   \n",
       "22  TM7_genera_incertae_sedis  TM7_genera_incertae_sedis   \n",
       "23                 Bacillales                    Bacilli   \n",
       "24              Clostridiales                 Clostridia   \n",
       "25              Clostridiales                 Clostridia   \n",
       "26            Burkholderiales         Betaproteobacteria   \n",
       "27            Fusobacteriales               Fusobacteria   \n",
       "28             Spirochaetales               Spirochaetes   \n",
       "29            Pseudomonadales        Gammaproteobacteria   \n",
       "30             Pasteurellales        Gammaproteobacteria   \n",
       "31            Selenomonadales              Negativicutes   \n",
       "32            Actinomycetales             Actinobacteria   \n",
       "33                Rhizobiales        Alphaproteobacteria   \n",
       "34                Rhizobiales        Alphaproteobacteria   \n",
       "35                Rhizobiales        Alphaproteobacteria   \n",
       "36  OD1_genera_incertae_sedis  OD1_genera_incertae_sedis   \n",
       "37              Clostridiales                 Clostridia   \n",
       "38            Actinomycetales             Actinobacteria   \n",
       "39           Sphingomonadales        Alphaproteobacteria   \n",
       "40           Flavobacteriales              Flavobacteria   \n",
       "41              Bacteroidales                Bacteroidia   \n",
       "42          Bdellovibrionales        Deltaproteobacteria   \n",
       "43                Chloroplast                Chloroplast   \n",
       "44              Clostridiales                 Clostridia   \n",
       "45            Rhodobacterales        Alphaproteobacteria   \n",
       "46              Clostridiales                 Clostridia   \n",
       "47            Actinomycetales             Actinobacteria   \n",
       "\n",
       "                       Phylum    Domain  \n",
       "0                  Firmicutes  Bacteria  \n",
       "1              Actinobacteria  Bacteria  \n",
       "2                  Firmicutes  Bacteria  \n",
       "3              Actinobacteria  Bacteria  \n",
       "4               Bacteroidetes  Bacteria  \n",
       "5               Bacteroidetes  Bacteria  \n",
       "6               Bacteroidetes  Bacteria  \n",
       "7                  Firmicutes  Bacteria  \n",
       "8                Fusobacteria  Bacteria  \n",
       "9              Actinobacteria  Bacteria  \n",
       "10                 Firmicutes  Bacteria  \n",
       "11             Actinobacteria  Bacteria  \n",
       "12                 Firmicutes  Bacteria  \n",
       "13             Proteobacteria  Bacteria  \n",
       "14                 Firmicutes  Bacteria  \n",
       "15                 Firmicutes  Bacteria  \n",
       "16                 Firmicutes  Bacteria  \n",
       "17             Actinobacteria  Bacteria  \n",
       "18             Proteobacteria  Bacteria  \n",
       "19              Bacteroidetes  Bacteria  \n",
       "20                 Firmicutes  Bacteria  \n",
       "21                 Firmicutes  Bacteria  \n",
       "22                        TM7  Bacteria  \n",
       "23                 Firmicutes  Bacteria  \n",
       "24                 Firmicutes  Bacteria  \n",
       "25                 Firmicutes  Bacteria  \n",
       "26             Proteobacteria  Bacteria  \n",
       "27               Fusobacteria  Bacteria  \n",
       "28               Spirochaetes  Bacteria  \n",
       "29             Proteobacteria  Bacteria  \n",
       "30             Proteobacteria  Bacteria  \n",
       "31                 Firmicutes  Bacteria  \n",
       "32             Actinobacteria  Bacteria  \n",
       "33             Proteobacteria  Bacteria  \n",
       "34             Proteobacteria  Bacteria  \n",
       "35             Proteobacteria  Bacteria  \n",
       "36                        OD1  Bacteria  \n",
       "37                 Firmicutes  Bacteria  \n",
       "38             Actinobacteria  Bacteria  \n",
       "39             Proteobacteria  Bacteria  \n",
       "40              Bacteroidetes  Bacteria  \n",
       "41              Bacteroidetes  Bacteria  \n",
       "42             Proteobacteria  Bacteria  \n",
       "43  Cyanobacteria_Chloroplast  Bacteria  \n",
       "44                 Firmicutes  Bacteria  \n",
       "45             Proteobacteria  Bacteria  \n",
       "46                 Firmicutes  Bacteria  \n",
       "47             Actinobacteria  Bacteria  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_information = pd.read_csv(resource_filename('deepbiome', 'tests/data/genus48_dic.csv'))\n",
    "tree_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the list of the name of input files\n",
    "\n",
    "In this example. we assume that input is given by the lists of files. Each file has all sample's information for one repeatition.\n",
    "If we want to use the list of the input files, we need to make a list of the names of each input file. Below is an example file for `k=1000` repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gcount_0001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gcount_0002.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gcount_0003.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcount_0004.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gcount_0005.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0  gcount_0001.csv\n",
       "1  gcount_0002.csv\n",
       "2  gcount_0003.csv\n",
       "3  gcount_0004.csv\n",
       "4  gcount_0005.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_input_files = pd.read_csv(resource_filename('deepbiome', 'tests/data/gcount_list.csv'), header=None)\n",
    "list_of_input_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>gcount_0996.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gcount_0997.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>gcount_0998.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>gcount_0999.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>gcount_1000.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "995  gcount_0996.csv\n",
       "996  gcount_0997.csv\n",
       "997  gcount_0998.csv\n",
       "998  gcount_0999.csv\n",
       "999  gcount_1000.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_input_files.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the lists of the input files\n",
    "\n",
    "Below is an example of each input file. This example has 1000 samples as rows, and the abandunce of each microbiome as columns. Below is an example file for `k=1000` repetition. This example is `gcount_0001.csv` for the first repetition in the list of the names of input files above. This file has the 4 samples' microbiome abandunce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>3224</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>1278</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1259</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>969</td>\n",
       "      <td>163</td>\n",
       "      <td>1515</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "0            841           0          813          505               5   \n",
       "1           1445           0            1          573               0   \n",
       "2           1259           0          805          650               0   \n",
       "3            982           0          327          594               0   \n",
       "4           1162           0          130          969             163   \n",
       "\n",
       "   Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "0        3224              0         362             11                 65   \n",
       "1        1278             82          85             69                154   \n",
       "2        1088              0           0             74                  0   \n",
       "3         960             81          19              9                  0   \n",
       "4        1515            167           4            162                  3   \n",
       "\n",
       "   ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "0  ...               0            87                 0            0   \n",
       "1  ...               0             1                 2            0   \n",
       "2  ...               0             2                 8            1   \n",
       "3  ...             157             1                 0            4   \n",
       "4  ...               0             9                 0            0   \n",
       "\n",
       "   Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "0             0             0                              0           0   \n",
       "1             0             0                              0           0   \n",
       "2            39             0                              0           0   \n",
       "3            60             0                              0           0   \n",
       "4             0             0                             60           0   \n",
       "\n",
       "   Fastidiosipila  Pseudonocardia  \n",
       "0               0            2133  \n",
       "1               0            3638  \n",
       "2               0            3445  \n",
       "3               0            3507  \n",
       "4               0            3945  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = pd.read_csv(resource_filename('deepbiome', 'tests/data/count/%s' % list_of_input_files.iloc[0,0]))\n",
    "x_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1401</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2655</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>259</td>\n",
       "      <td>67</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>649</td>\n",
       "      <td>69</td>\n",
       "      <td>966</td>\n",
       "      <td>1227</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>2348</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "995           1401           4           30          526               0   \n",
       "996           2655           6          106           74               0   \n",
       "997            335           0           71          259              67   \n",
       "998            649          69          966         1227               0   \n",
       "999           1258           0            0         1119               0   \n",
       "\n",
       "     Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "995         923             25           0            127                  0   \n",
       "996         952             76          13            158                125   \n",
       "997         718              1           4              4                167   \n",
       "998         508              2          30            550                  0   \n",
       "999        2348             25           0            137                176   \n",
       "\n",
       "     ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "995  ...               0             0                 7            0   \n",
       "996  ...               0             2                 0            0   \n",
       "997  ...               0           246                 0            0   \n",
       "998  ...               0             0                 0            0   \n",
       "999  ...               0             2                 0            0   \n",
       "\n",
       "     Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "995             0             0                              0           0   \n",
       "996             0             0                              0           0   \n",
       "997             6             0                              0           0   \n",
       "998             0             6                              0           0   \n",
       "999             0             0                              0           0   \n",
       "\n",
       "     Fastidiosipila  Pseudonocardia  \n",
       "995               0            4470  \n",
       "996               0            2826  \n",
       "997               0            6527  \n",
       "998               0            4402  \n",
       "999               0            2585  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (regression)\n",
    "\n",
    "This is an example of the output file for regression problem. One column contains y samples for one repeatition. \n",
    "For each repeatition (column) has outputs of 4 samples for each repeatition. Below example file has 1000 samples in row, `k=1000` repetition in column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "      <th>x1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.997270</td>\n",
       "      <td>5.492354</td>\n",
       "      <td>5.473725</td>\n",
       "      <td>1.759484</td>\n",
       "      <td>5.313252</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>4.949712</td>\n",
       "      <td>5.493533</td>\n",
       "      <td>3.743509</td>\n",
       "      <td>5.492373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.793883</td>\n",
       "      <td>1.500004</td>\n",
       "      <td>5.487526</td>\n",
       "      <td>5.493518</td>\n",
       "      <td>3.599047</td>\n",
       "      <td>5.491461</td>\n",
       "      <td>5.486244</td>\n",
       "      <td>5.487390</td>\n",
       "      <td>5.493492</td>\n",
       "      <td>3.762523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004092</td>\n",
       "      <td>1.500002</td>\n",
       "      <td>4.640348</td>\n",
       "      <td>1.538071</td>\n",
       "      <td>5.491065</td>\n",
       "      <td>5.481009</td>\n",
       "      <td>5.492323</td>\n",
       "      <td>2.968531</td>\n",
       "      <td>3.576358</td>\n",
       "      <td>5.491456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500033</td>\n",
       "      <td>3.369529</td>\n",
       "      <td>1.500016</td>\n",
       "      <td>3.103297</td>\n",
       "      <td>5.493214</td>\n",
       "      <td>3.831125</td>\n",
       "      <td>5.492104</td>\n",
       "      <td>5.474811</td>\n",
       "      <td>5.492416</td>\n",
       "      <td>3.268805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.485126</td>\n",
       "      <td>4.187426</td>\n",
       "      <td>5.491340</td>\n",
       "      <td>5.469662</td>\n",
       "      <td>5.490478</td>\n",
       "      <td>1.953375</td>\n",
       "      <td>5.494656</td>\n",
       "      <td>3.741680</td>\n",
       "      <td>4.862400</td>\n",
       "      <td>5.490701</td>\n",
       "      <td>...</td>\n",
       "      <td>5.491728</td>\n",
       "      <td>2.459981</td>\n",
       "      <td>5.475697</td>\n",
       "      <td>3.114158</td>\n",
       "      <td>1.500004</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>4.113815</td>\n",
       "      <td>5.470539</td>\n",
       "      <td>5.494373</td>\n",
       "      <td>5.481754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.489590</td>\n",
       "      <td>4.863187</td>\n",
       "      <td>1.500003</td>\n",
       "      <td>5.484699</td>\n",
       "      <td>5.492657</td>\n",
       "      <td>5.491270</td>\n",
       "      <td>4.091023</td>\n",
       "      <td>5.495239</td>\n",
       "      <td>5.492804</td>\n",
       "      <td>1.500046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500034</td>\n",
       "      <td>1.500012</td>\n",
       "      <td>5.483070</td>\n",
       "      <td>2.475049</td>\n",
       "      <td>5.493846</td>\n",
       "      <td>3.287076</td>\n",
       "      <td>3.696412</td>\n",
       "      <td>5.487583</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>2.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500001</td>\n",
       "      <td>5.480769</td>\n",
       "      <td>5.489725</td>\n",
       "      <td>1.500044</td>\n",
       "      <td>2.695212</td>\n",
       "      <td>5.492262</td>\n",
       "      <td>3.381424</td>\n",
       "      <td>4.805420</td>\n",
       "      <td>1.500047</td>\n",
       "      <td>5.474376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500046</td>\n",
       "      <td>2.586990</td>\n",
       "      <td>5.440610</td>\n",
       "      <td>4.376103</td>\n",
       "      <td>1.500030</td>\n",
       "      <td>4.713223</td>\n",
       "      <td>5.491059</td>\n",
       "      <td>3.230658</td>\n",
       "      <td>1.500045</td>\n",
       "      <td>5.488727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  4.997270  5.492354  5.473725  1.759484  5.313252  1.500044  4.949712   \n",
       "1  5.004092  1.500002  4.640348  1.538071  5.491065  5.481009  5.492323   \n",
       "2  5.485126  4.187426  5.491340  5.469662  5.490478  1.953375  5.494656   \n",
       "3  5.489590  4.863187  1.500003  5.484699  5.492657  5.491270  4.091023   \n",
       "4  1.500001  5.480769  5.489725  1.500044  2.695212  5.492262  3.381424   \n",
       "\n",
       "         x8        x9       x10  ...      x991      x992      x993      x994  \\\n",
       "0  5.493533  3.743509  5.492373  ...  2.793883  1.500004  5.487526  5.493518   \n",
       "1  2.968531  3.576358  5.491456  ...  1.500033  3.369529  1.500016  3.103297   \n",
       "2  3.741680  4.862400  5.490701  ...  5.491728  2.459981  5.475697  3.114158   \n",
       "3  5.495239  5.492804  1.500046  ...  1.500034  1.500012  5.483070  2.475049   \n",
       "4  4.805420  1.500047  5.474376  ...  1.500046  2.586990  5.440610  4.376103   \n",
       "\n",
       "       x995      x996      x997      x998      x999     x1000  \n",
       "0  3.599047  5.491461  5.486244  5.487390  5.493492  3.762523  \n",
       "1  5.493214  3.831125  5.492104  5.474811  5.492416  3.268805  \n",
       "2  1.500004  1.500019  4.113815  5.470539  5.494373  5.481754  \n",
       "3  5.493846  3.287076  3.696412  5.487583  1.500044  2.760404  \n",
       "4  1.500030  4.713223  5.491059  3.230658  1.500045  5.488727  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/regression_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x991</th>\n",
       "      <th>x992</th>\n",
       "      <th>x993</th>\n",
       "      <th>x994</th>\n",
       "      <th>x995</th>\n",
       "      <th>x996</th>\n",
       "      <th>x997</th>\n",
       "      <th>x998</th>\n",
       "      <th>x999</th>\n",
       "      <th>x1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.609926</td>\n",
       "      <td>5.491258</td>\n",
       "      <td>3.318610</td>\n",
       "      <td>5.444070</td>\n",
       "      <td>2.884154</td>\n",
       "      <td>5.486857</td>\n",
       "      <td>5.496554</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.482893</td>\n",
       "      <td>1.824835</td>\n",
       "      <td>...</td>\n",
       "      <td>4.478641</td>\n",
       "      <td>5.485122</td>\n",
       "      <td>4.915985</td>\n",
       "      <td>4.073239</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.492295</td>\n",
       "      <td>1.500005</td>\n",
       "      <td>1.559586</td>\n",
       "      <td>5.496415</td>\n",
       "      <td>4.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.488959</td>\n",
       "      <td>3.739806</td>\n",
       "      <td>5.489474</td>\n",
       "      <td>1.500021</td>\n",
       "      <td>5.492632</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>5.484813</td>\n",
       "      <td>5.467055</td>\n",
       "      <td>5.491282</td>\n",
       "      <td>1.874777</td>\n",
       "      <td>...</td>\n",
       "      <td>5.498820</td>\n",
       "      <td>5.493926</td>\n",
       "      <td>5.487404</td>\n",
       "      <td>3.162812</td>\n",
       "      <td>1.846298</td>\n",
       "      <td>5.492417</td>\n",
       "      <td>1.919107</td>\n",
       "      <td>5.480324</td>\n",
       "      <td>5.467765</td>\n",
       "      <td>5.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.498418</td>\n",
       "      <td>4.250451</td>\n",
       "      <td>5.488116</td>\n",
       "      <td>4.162031</td>\n",
       "      <td>5.494052</td>\n",
       "      <td>5.472900</td>\n",
       "      <td>1.500057</td>\n",
       "      <td>5.491497</td>\n",
       "      <td>5.491935</td>\n",
       "      <td>1.500033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.966474</td>\n",
       "      <td>5.475258</td>\n",
       "      <td>3.848034</td>\n",
       "      <td>2.863883</td>\n",
       "      <td>4.370685</td>\n",
       "      <td>5.494647</td>\n",
       "      <td>5.478855</td>\n",
       "      <td>2.465739</td>\n",
       "      <td>1.500018</td>\n",
       "      <td>5.486403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.486107</td>\n",
       "      <td>1.917414</td>\n",
       "      <td>5.414975</td>\n",
       "      <td>5.492364</td>\n",
       "      <td>2.027914</td>\n",
       "      <td>5.491349</td>\n",
       "      <td>5.494135</td>\n",
       "      <td>5.491245</td>\n",
       "      <td>1.500039</td>\n",
       "      <td>1.500019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.556995</td>\n",
       "      <td>5.457072</td>\n",
       "      <td>2.071106</td>\n",
       "      <td>5.417333</td>\n",
       "      <td>5.491818</td>\n",
       "      <td>5.473390</td>\n",
       "      <td>4.374154</td>\n",
       "      <td>5.489109</td>\n",
       "      <td>4.515340</td>\n",
       "      <td>1.500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.319623</td>\n",
       "      <td>5.482776</td>\n",
       "      <td>1.500035</td>\n",
       "      <td>5.485141</td>\n",
       "      <td>5.491019</td>\n",
       "      <td>3.733982</td>\n",
       "      <td>5.494374</td>\n",
       "      <td>3.077159</td>\n",
       "      <td>5.493188</td>\n",
       "      <td>1.500001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485356</td>\n",
       "      <td>1.500059</td>\n",
       "      <td>5.400762</td>\n",
       "      <td>5.489606</td>\n",
       "      <td>5.494583</td>\n",
       "      <td>5.490943</td>\n",
       "      <td>5.123794</td>\n",
       "      <td>5.473465</td>\n",
       "      <td>3.274979</td>\n",
       "      <td>3.700653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "995  2.609926  5.491258  3.318610  5.444070  2.884154  5.486857  5.496554   \n",
       "996  5.488959  3.739806  5.489474  1.500021  5.492632  1.500019  5.484813   \n",
       "997  3.498418  4.250451  5.488116  4.162031  5.494052  5.472900  1.500057   \n",
       "998  5.486107  1.917414  5.414975  5.492364  2.027914  5.491349  5.494135   \n",
       "999  5.319623  5.482776  1.500035  5.485141  5.491019  3.733982  5.494374   \n",
       "\n",
       "           x8        x9       x10  ...      x991      x992      x993  \\\n",
       "995  1.500019  5.482893  1.824835  ...  4.478641  5.485122  4.915985   \n",
       "996  5.467055  5.491282  1.874777  ...  5.498820  5.493926  5.487404   \n",
       "997  5.491497  5.491935  1.500033  ...  1.966474  5.475258  3.848034   \n",
       "998  5.491245  1.500039  1.500019  ...  4.556995  5.457072  2.071106   \n",
       "999  3.077159  5.493188  1.500001  ...  5.485356  1.500059  5.400762   \n",
       "\n",
       "         x994      x995      x996      x997      x998      x999     x1000  \n",
       "995  4.073239  1.500019  5.492295  1.500005  1.559586  5.496415  4.171127  \n",
       "996  3.162812  1.846298  5.492417  1.919107  5.480324  5.467765  5.457627  \n",
       "997  2.863883  4.370685  5.494647  5.478855  2.465739  1.500018  5.486403  \n",
       "998  5.417333  5.491818  5.473390  4.374154  5.489109  4.515340  1.500020  \n",
       "999  5.489606  5.494583  5.490943  5.123794  5.473465  3.274979  3.700653  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repeatition, the deepbiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.997270\n",
       "1    5.004092\n",
       "2    5.485126\n",
       "3    5.489590\n",
       "4    1.500001\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    2.609926\n",
       "996    5.488959\n",
       "997    3.498418\n",
       "998    5.486107\n",
       "999    5.319623\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (classification)\n",
    "\n",
    "This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetitions in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  ...   1.0   1.0   0.0   \n",
       "1  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   1.0   1.0   1.0   \n",
       "2  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   0.0   1.0   1.0   \n",
       "3  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...   1.0   1.0   0.0   \n",
       "4  1.0  1.0  0.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "\n",
       "   V994  V995  V996  V997  V998  V999  V1000  \n",
       "0   0.0   1.0   0.0   0.0   0.0   0.0    1.0  \n",
       "1   1.0   0.0   1.0   0.0   1.0   0.0    1.0  \n",
       "2   1.0   1.0   1.0   1.0   1.0   0.0    0.0  \n",
       "3   1.0   0.0   1.0   1.0   0.0   1.0    1.0  \n",
       "4   1.0   1.0   1.0   0.0   1.0   1.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/classification_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "995  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "996  0.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  ...   0.0   0.0   0.0   \n",
       "997  1.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  ...   1.0   1.0   1.0   \n",
       "998  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "999  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  ...   0.0   1.0   1.0   \n",
       "\n",
       "     V994  V995  V996  V997  V998  V999  V1000  \n",
       "995   1.0   1.0   0.0   1.0   1.0   0.0    1.0  \n",
       "996   1.0   1.0   0.0   1.0   0.0   1.0    1.0  \n",
       "997   1.0   1.0   0.0   1.0   1.0   1.0    0.0  \n",
       "998   1.0   0.0   1.0   1.0   0.0   1.0    1.0  \n",
       "999   0.0   0.0   0.0   1.0   1.0   1.0    1.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repeatition, the deepbiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    1.0\n",
       "996    0.0\n",
       "997    1.0\n",
       "998    0.0\n",
       "999    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exmple of the training index file for repetition\n",
    "\n",
    "For each repeatition, we have to set the training and test set. If the index file is given, the deepbiome library set the training set and test set based on the index file. Below is the example of the index file. Each column has the training indexs for each repeatition. The deepbiome will only use the samples in this index set for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>690</td>\n",
       "      <td>62</td>\n",
       "      <td>703</td>\n",
       "      <td>690</td>\n",
       "      <td>845</td>\n",
       "      <td>150</td>\n",
       "      <td>268</td>\n",
       "      <td>488</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>675</td>\n",
       "      <td>886</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>781</td>\n",
       "      <td>778</td>\n",
       "      <td>603</td>\n",
       "      <td>222</td>\n",
       "      <td>254</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498</td>\n",
       "      <td>968</td>\n",
       "      <td>123</td>\n",
       "      <td>913</td>\n",
       "      <td>348</td>\n",
       "      <td>262</td>\n",
       "      <td>705</td>\n",
       "      <td>239</td>\n",
       "      <td>632</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>636</td>\n",
       "      <td>216</td>\n",
       "      <td>495</td>\n",
       "      <td>557</td>\n",
       "      <td>196</td>\n",
       "      <td>516</td>\n",
       "      <td>23</td>\n",
       "      <td>351</td>\n",
       "      <td>472</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389</td>\n",
       "      <td>999</td>\n",
       "      <td>335</td>\n",
       "      <td>947</td>\n",
       "      <td>215</td>\n",
       "      <td>696</td>\n",
       "      <td>793</td>\n",
       "      <td>349</td>\n",
       "      <td>734</td>\n",
       "      <td>624</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>230</td>\n",
       "      <td>26</td>\n",
       "      <td>330</td>\n",
       "      <td>470</td>\n",
       "      <td>992</td>\n",
       "      <td>329</td>\n",
       "      <td>532</td>\n",
       "      <td>655</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>139</td>\n",
       "      <td>843</td>\n",
       "      <td>491</td>\n",
       "      <td>47</td>\n",
       "      <td>421</td>\n",
       "      <td>892</td>\n",
       "      <td>32</td>\n",
       "      <td>438</td>\n",
       "      <td>996</td>\n",
       "      <td>...</td>\n",
       "      <td>956</td>\n",
       "      <td>706</td>\n",
       "      <td>836</td>\n",
       "      <td>151</td>\n",
       "      <td>80</td>\n",
       "      <td>409</td>\n",
       "      <td>671</td>\n",
       "      <td>772</td>\n",
       "      <td>882</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>83</td>\n",
       "      <td>204</td>\n",
       "      <td>810</td>\n",
       "      <td>198</td>\n",
       "      <td>955</td>\n",
       "      <td>357</td>\n",
       "      <td>125</td>\n",
       "      <td>190</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>542</td>\n",
       "      <td>108</td>\n",
       "      <td>959</td>\n",
       "      <td>311</td>\n",
       "      <td>771</td>\n",
       "      <td>902</td>\n",
       "      <td>986</td>\n",
       "      <td>481</td>\n",
       "      <td>922</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "0  490  690   62  703  690  845  150  268  488  179  ...   675   886   225   \n",
       "1  498  968  123  913  348  262  705  239  632   44  ...   636   216   495   \n",
       "2  389  999  335  947  215  696  793  349  734  624  ...   626   230    26   \n",
       "3   51  139  843  491   47  421  892   32  438  996  ...   956   706   836   \n",
       "4  592   83  204  810  198  955  357  125  190  162  ...   542   108   959   \n",
       "\n",
       "   V994  V995  V996  V997  V998  V999  V1000  \n",
       "0   222   781   778   603   222   254    407  \n",
       "1   557   196   516    23   351   472    945  \n",
       "2   330   470   992   329   532   655    426  \n",
       "3   151    80   409   671   772   882    181  \n",
       "4   311   771   902   986   481   922    305  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = pd.read_csv(resource_filename('deepbiome', 'tests/data/regression_idx.csv'), dtype=np.int)\n",
    "idxs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V991</th>\n",
       "      <th>V992</th>\n",
       "      <th>V993</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>599</td>\n",
       "      <td>824</td>\n",
       "      <td>997</td>\n",
       "      <td>216</td>\n",
       "      <td>586</td>\n",
       "      <td>796</td>\n",
       "      <td>806</td>\n",
       "      <td>39</td>\n",
       "      <td>483</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>573</td>\n",
       "      <td>861</td>\n",
       "      <td>366</td>\n",
       "      <td>374</td>\n",
       "      <td>585</td>\n",
       "      <td>871</td>\n",
       "      <td>140</td>\n",
       "      <td>597</td>\n",
       "      <td>795</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>720</td>\n",
       "      <td>633</td>\n",
       "      <td>821</td>\n",
       "      <td>149</td>\n",
       "      <td>339</td>\n",
       "      <td>461</td>\n",
       "      <td>750</td>\n",
       "      <td>194</td>\n",
       "      <td>769</td>\n",
       "      <td>699</td>\n",
       "      <td>...</td>\n",
       "      <td>913</td>\n",
       "      <td>570</td>\n",
       "      <td>670</td>\n",
       "      <td>249</td>\n",
       "      <td>840</td>\n",
       "      <td>889</td>\n",
       "      <td>242</td>\n",
       "      <td>959</td>\n",
       "      <td>791</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>80</td>\n",
       "      <td>268</td>\n",
       "      <td>661</td>\n",
       "      <td>187</td>\n",
       "      <td>929</td>\n",
       "      <td>469</td>\n",
       "      <td>481</td>\n",
       "      <td>332</td>\n",
       "      <td>781</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>985</td>\n",
       "      <td>459</td>\n",
       "      <td>965</td>\n",
       "      <td>888</td>\n",
       "      <td>461</td>\n",
       "      <td>551</td>\n",
       "      <td>465</td>\n",
       "      <td>827</td>\n",
       "      <td>557</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>570</td>\n",
       "      <td>32</td>\n",
       "      <td>750</td>\n",
       "      <td>332</td>\n",
       "      <td>902</td>\n",
       "      <td>107</td>\n",
       "      <td>281</td>\n",
       "      <td>667</td>\n",
       "      <td>917</td>\n",
       "      <td>793</td>\n",
       "      <td>...</td>\n",
       "      <td>924</td>\n",
       "      <td>662</td>\n",
       "      <td>975</td>\n",
       "      <td>199</td>\n",
       "      <td>32</td>\n",
       "      <td>715</td>\n",
       "      <td>668</td>\n",
       "      <td>241</td>\n",
       "      <td>299</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>440</td>\n",
       "      <td>589</td>\n",
       "      <td>607</td>\n",
       "      <td>597</td>\n",
       "      <td>380</td>\n",
       "      <td>961</td>\n",
       "      <td>747</td>\n",
       "      <td>396</td>\n",
       "      <td>649</td>\n",
       "      <td>974</td>\n",
       "      <td>...</td>\n",
       "      <td>867</td>\n",
       "      <td>839</td>\n",
       "      <td>234</td>\n",
       "      <td>99</td>\n",
       "      <td>901</td>\n",
       "      <td>19</td>\n",
       "      <td>821</td>\n",
       "      <td>450</td>\n",
       "      <td>780</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V991  V992  V993  \\\n",
       "745  599  824  997  216  586  796  806   39  483  518  ...   573   861   366   \n",
       "746  720  633  821  149  339  461  750  194  769  699  ...   913   570   670   \n",
       "747   80  268  661  187  929  469  481  332  781  615  ...   985   459   965   \n",
       "748  570   32  750  332  902  107  281  667  917  793  ...   924   662   975   \n",
       "749  440  589  607  597  380  961  747  396  649  974  ...   867   839   234   \n",
       "\n",
       "     V994  V995  V996  V997  V998  V999  V1000  \n",
       "745   374   585   871   140   597   795    743  \n",
       "746   249   840   889   242   959   791    954  \n",
       "747   888   461   551   465   827   557    662  \n",
       "748   199    32   715   668   241   299    518  \n",
       "749    99   901    19   821   450   780    326  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the index set for 1st repetition. From 1000 samples above, it uses 750 samples for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    490\n",
       "1    498\n",
       "2    389\n",
       "3     51\n",
       "4    592\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745    599\n",
       "746    720\n",
       "747     80\n",
       "748    570\n",
       "749    440\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the configuration\n",
    "\n",
    "For detailed configuration, we used python dictionary as inputs for the main training function.\n",
    "You can build the configuration information for the network training by:\n",
    "1. the python dictionary format\n",
    "1. the configufation file (.cfg).\n",
    "\n",
    "In this notebook, we showed the dictionary python dictionary format configuration.\n",
    "\n",
    "Please check the detailed information about each options in the [documantation](https://young-won.github.io/deepbiome/prerequisites.html#configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the network information (`network_info`)\n",
    "\n",
    "For giving the information about the training hyper-parameter, you have to provide the dictionary for configuration to the `netowrk_info` field.\n",
    "Your configuration for the network training should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'training_info': {\n",
    "        'batch_size': '50', \n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the path information (`path_info`)\n",
    "\n",
    "To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, we provide the dictionary for configuration to the `path_info` feild.\n",
    "Your configuration for the path information should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/classification_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'history': 'hist.json',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepBiome Training\n",
    "\n",
    "Now we can train the DeepBiome network based on the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logging, we use the python logging library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.\n",
    "\n",
    "If we set `number_of_fold`, then the deepbiome package do the cross-validation based on that value. If not, the deepbiome package do the cross-validation based on the index file. If both `number_of_fold` option and the index file is not given, then the library do leave-one-out-cross-validation (LOOCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6651 - binary_accuracy: 0.6617 - sensitivity: 0.9192 - specificity: 0.0784 - gmeasure: 0.0141 - auc: 0.4752 - val_loss: 0.6395 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4818\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.6291 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5025 - val_loss: 0.6128 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5015\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.6227 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5128 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5415\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.6216 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5220 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5661\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6216 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5483 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5894\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 228us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5746 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6174\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 238us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6052 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6448\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6142 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6593\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6346 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6821\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6439 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7055\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6662 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7214\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6774 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7362\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6829 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7487\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6943 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7565\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6210 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7138 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7634\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7195 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7681\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 229us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7319 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7685\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7329 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7716\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7373 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7727\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7478 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7709\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7451 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7621\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7507 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7556\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7601 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7520 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 192us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7581 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7484\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 176us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7647 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7440\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 195us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7671 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7442\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7668 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7400\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7615 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7387\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7537 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7358\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7663 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7344\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7767 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7319\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7689 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7283\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 230us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7673 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7254\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 225us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7756 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7245\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 235us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7764 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7260\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7665 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7280\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 232us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7737 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7314\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7811 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7323\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7879 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7316\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7809 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7329\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7814 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7353\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7867 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7351\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7899 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6204 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7958 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7413\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 191us/step - loss: 0.6201 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7932 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7418\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8006 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7466\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 187us/step - loss: 0.6205 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8017 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8020 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7525\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6198 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8096 - val_loss: 0.6108 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7549\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.6192 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8026 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7569\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 188us/step - loss: 0.6191 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8086 - val_loss: 0.6107 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7581\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6186 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8008 - val_loss: 0.6105 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7589\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.6184 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8034 - val_loss: 0.6106 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7607\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.6177 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8122 - val_loss: 0.6103 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7627\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.6169 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8069 - val_loss: 0.6099 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7640\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.6163 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8155 - val_loss: 0.6097 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7635\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6156 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8180 - val_loss: 0.6096 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7668\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.6146 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8081 - val_loss: 0.6090 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7674\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6134 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8184 - val_loss: 0.6086 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7700\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.6124 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8119 - val_loss: 0.6082 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7725\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6114 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8207 - val_loss: 0.6077 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7779\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.6100 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8239 - val_loss: 0.6066 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7808\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.6101 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8216 - val_loss: 0.6055 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7805\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6067 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8326 - val_loss: 0.6057 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7850\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6050 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8201 - val_loss: 0.6035 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7851\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6029 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8177 - val_loss: 0.6019 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7874\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.6003 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8281 - val_loss: 0.6013 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7898\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.5976 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8286 - val_loss: 0.5983 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7905\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.5969 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8185 - val_loss: 0.5965 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7936\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5943 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8229 - val_loss: 0.5936 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7962\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.5883 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8342 - val_loss: 0.5939 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.5852 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.5879 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7988\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 230us/step - loss: 0.5805 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8295 - val_loss: 0.5846 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8012\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.5761 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.5810 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7992\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.5697 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8335 - val_loss: 0.5751 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8016\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.5642 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8394 - val_loss: 0.5694 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8011\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.5574 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8354 - val_loss: 0.5642 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8017\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.5510 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8491 - val_loss: 0.5573 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8024\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5421 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8387 - val_loss: 0.5508 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8030\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5345 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8400 - val_loss: 0.5443 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8057\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.5306 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8428 - val_loss: 0.5440 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8117\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.5232 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8464 - val_loss: 0.5315 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8161\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.5131 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8504 - val_loss: 0.5254 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8177\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.5048 - binary_accuracy: 0.7200 - sensitivity: 0.9955 - specificity: 0.1057 - gmeasure: 0.2500 - auc: 0.8515 - val_loss: 0.5186 - val_binary_accuracy: 0.7333 - val_sensitivity: 1.0000 - val_specificity: 0.0976 - val_gmeasure: 0.2551 - val_auc: 0.8242\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.5012 - binary_accuracy: 0.7517 - sensitivity: 0.9910 - specificity: 0.2461 - gmeasure: 0.4659 - auc: 0.8606 - val_loss: 0.5135 - val_binary_accuracy: 0.7333 - val_sensitivity: 1.0000 - val_specificity: 0.0976 - val_gmeasure: 0.2551 - val_auc: 0.8284\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 181us/step - loss: 0.4956 - binary_accuracy: 0.7400 - sensitivity: 0.9918 - specificity: 0.2088 - gmeasure: 0.4155 - auc: 0.8671 - val_loss: 0.5054 - val_binary_accuracy: 0.7267 - val_sensitivity: 0.9822 - val_specificity: 0.1279 - val_gmeasure: 0.3525 - val_auc: 0.8312\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 193us/step - loss: 0.4871 - binary_accuracy: 0.7683 - sensitivity: 0.9899 - specificity: 0.2817 - gmeasure: 0.5075 - auc: 0.8613 - val_loss: 0.5031 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9822 - val_specificity: 0.0976 - val_gmeasure: 0.2533 - val_auc: 0.8366\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 236us/step - loss: 0.4839 - binary_accuracy: 0.7933 - sensitivity: 0.9806 - specificity: 0.3988 - gmeasure: 0.6113 - auc: 0.8724 - val_loss: 0.4977 - val_binary_accuracy: 0.7200 - val_sensitivity: 0.9822 - val_specificity: 0.0976 - val_gmeasure: 0.2533 - val_auc: 0.8415\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.4783 - binary_accuracy: 0.7567 - sensitivity: 0.9851 - specificity: 0.2609 - gmeasure: 0.4939 - auc: 0.8695 - val_loss: 0.4901 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9540 - val_specificity: 0.3736 - val_gmeasure: 0.5968 - val_auc: 0.8483\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.4704 - binary_accuracy: 0.7817 - sensitivity: 0.9783 - specificity: 0.3452 - gmeasure: 0.5624 - auc: 0.8748 - val_loss: 0.4802 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9822 - val_specificity: 0.1517 - val_gmeasure: 0.3805 - val_auc: 0.8510\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 183us/step - loss: 0.4698 - binary_accuracy: 0.7783 - sensitivity: 0.9721 - specificity: 0.3707 - gmeasure: 0.5897 - auc: 0.8821 - val_loss: 0.4745 - val_binary_accuracy: 0.7333 - val_sensitivity: 0.9822 - val_specificity: 0.1517 - val_gmeasure: 0.3805 - val_auc: 0.8580\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 193us/step - loss: 0.4562 - binary_accuracy: 0.8033 - sensitivity: 0.9812 - specificity: 0.4105 - gmeasure: 0.6272 - auc: 0.8825 - val_loss: 0.4647 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8628\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.4508 - binary_accuracy: 0.7933 - sensitivity: 0.9812 - specificity: 0.3669 - gmeasure: 0.5877 - auc: 0.8836 - val_loss: 0.4619 - val_binary_accuracy: 0.7400 - val_sensitivity: 0.9822 - val_specificity: 0.1684 - val_gmeasure: 0.4004 - val_auc: 0.8656\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.4452 - binary_accuracy: 0.8017 - sensitivity: 0.9701 - specificity: 0.4256 - gmeasure: 0.6353 - auc: 0.8864 - val_loss: 0.4534 - val_binary_accuracy: 0.7667 - val_sensitivity: 0.9822 - val_specificity: 0.2558 - val_gmeasure: 0.4986 - val_auc: 0.8711\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 187us/step - loss: 0.4410 - binary_accuracy: 0.7983 - sensitivity: 0.9789 - specificity: 0.3986 - gmeasure: 0.6091 - auc: 0.8902 - val_loss: 0.4662 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.8631 - val_specificity: 0.7543 - val_gmeasure: 0.8065 - val_auc: 0.8705\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 195us/step - loss: 0.4399 - binary_accuracy: 0.8133 - sensitivity: 0.9500 - specificity: 0.5210 - gmeasure: 0.6972 - auc: 0.8834 - val_loss: 0.4409 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8828\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 192us/step - loss: 0.4285 - binary_accuracy: 0.8067 - sensitivity: 0.9689 - specificity: 0.4458 - gmeasure: 0.6529 - auc: 0.8951 - val_loss: 0.4333 - val_binary_accuracy: 0.7733 - val_sensitivity: 0.9822 - val_specificity: 0.2797 - val_gmeasure: 0.5193 - val_auc: 0.8860\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.4228 - binary_accuracy: 0.8167 - sensitivity: 0.9685 - specificity: 0.4798 - gmeasure: 0.6778 - auc: 0.8987 - val_loss: 0.4275 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9822 - val_specificity: 0.3266 - val_gmeasure: 0.5655 - val_auc: 0.8932\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.4198 - binary_accuracy: 0.8200 - sensitivity: 0.9723 - specificity: 0.4830 - gmeasure: 0.6754 - auc: 0.8974 - val_loss: 0.4197 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9343 - val_specificity: 0.4645 - val_gmeasure: 0.6520 - val_auc: 0.8957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 15.849582433700562!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.014268636703491211!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.41470539569854736, 0.8173333406448364, 0.9498069286346436, 0.5215517282485962, 0.7038277387619019, 0.8984614014625549]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 24us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.013792037963867188!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.42274555563926697, 0.8399999737739563, 0.9822485446929932, 0.5432098507881165, 0.7304567694664001, 0.9060559868812561]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 19.22468662261963\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 996us/step - loss: 0.6800 - binary_accuracy: 0.6850 - sensitivity: 0.9167 - specificity: 0.0833 - gmeasure: 0.0000e+00 - auc: 0.4414 - val_loss: 0.6638 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4313\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.6502 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3866 - val_loss: 0.6346 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3529\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.6238 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3297 - val_loss: 0.6102 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3699\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.6043 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.3850 - val_loss: 0.5935 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4587\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5887 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4778 - val_loss: 0.5874 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5618\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6223 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6338\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6806 - val_loss: 0.5867 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6594\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.5852 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7092 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6800\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.5852 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7232 - val_loss: 0.5866 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6816\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.5850 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7266 - val_loss: 0.5865 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6797\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.5851 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7252 - val_loss: 0.5865 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6735\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5849 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7290 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6697\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7145 - val_loss: 0.5864 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6695\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.5851 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7051 - val_loss: 0.5863 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6605\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 191us/step - loss: 0.5848 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7161 - val_loss: 0.5861 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6626\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.5843 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7168 - val_loss: 0.5859 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6634\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5842 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7188 - val_loss: 0.5857 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6643\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.5838 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7278 - val_loss: 0.5854 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6659\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.5833 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7203 - val_loss: 0.5850 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6673\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.5827 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7212 - val_loss: 0.5845 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6701\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.5821 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7270 - val_loss: 0.5839 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6713\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5818 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7361 - val_loss: 0.5831 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6709\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.5798 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7321 - val_loss: 0.5823 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6763\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5790 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7289 - val_loss: 0.5813 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.5767 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7407 - val_loss: 0.5795 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6837\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 198us/step - loss: 0.5747 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7296 - val_loss: 0.5776 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6879\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5718 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7269 - val_loss: 0.5752 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6905\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.5683 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7446 - val_loss: 0.5722 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6933\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5643 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7355 - val_loss: 0.5688 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6948\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.5592 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7442 - val_loss: 0.5646 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6978\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 183us/step - loss: 0.5536 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7566 - val_loss: 0.5598 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7029\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 160us/step - loss: 0.5470 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7420 - val_loss: 0.5547 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7070\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.5421 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7593 - val_loss: 0.5502 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7056\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 191us/step - loss: 0.5356 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7634 - val_loss: 0.5441 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7141\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.5295 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7597 - val_loss: 0.5386 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7244\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5201 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7683 - val_loss: 0.5314 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7302\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.5113 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7817 - val_loss: 0.5232 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7599\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.5026 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8343 - val_loss: 0.5139 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7776\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.4929 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8272 - val_loss: 0.5056 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7736\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.4808 - binary_accuracy: 0.7283 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8253 - val_loss: 0.4942 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7869\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 186us/step - loss: 0.4700 - binary_accuracy: 0.7633 - sensitivity: 1.0000 - specificity: 0.1461 - gmeasure: 0.2394 - auc: 0.8511 - val_loss: 0.4897 - val_binary_accuracy: 0.7267 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8059\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.4687 - binary_accuracy: 0.7533 - sensitivity: 0.9779 - specificity: 0.1591 - gmeasure: 0.2528 - auc: 0.8636 - val_loss: 0.4786 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9632 - val_specificity: 0.5037 - val_gmeasure: 0.6888 - val_auc: 0.8257\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.4476 - binary_accuracy: 0.7900 - sensitivity: 0.9893 - specificity: 0.2573 - gmeasure: 0.4202 - auc: 0.8729 - val_loss: 0.4647 - val_binary_accuracy: 0.7667 - val_sensitivity: 1.0000 - val_specificity: 0.1533 - val_gmeasure: 0.3795 - val_auc: 0.8285\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.4331 - binary_accuracy: 0.7817 - sensitivity: 1.0000 - specificity: 0.1890 - gmeasure: 0.4234 - auc: 0.8709 - val_loss: 0.4532 - val_binary_accuracy: 0.7867 - val_sensitivity: 1.0000 - val_specificity: 0.2324 - val_gmeasure: 0.4567 - val_auc: 0.8344\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.4226 - binary_accuracy: 0.8133 - sensitivity: 1.0000 - specificity: 0.3156 - gmeasure: 0.5398 - auc: 0.8873 - val_loss: 0.4420 - val_binary_accuracy: 0.8267 - val_sensitivity: 1.0000 - val_specificity: 0.3739 - val_gmeasure: 0.6037 - val_auc: 0.8440\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.4124 - binary_accuracy: 0.8183 - sensitivity: 1.0000 - specificity: 0.3367 - gmeasure: 0.5687 - auc: 0.8872 - val_loss: 0.4326 - val_binary_accuracy: 0.8200 - val_sensitivity: 1.0000 - val_specificity: 0.3462 - val_gmeasure: 0.5779 - val_auc: 0.8499\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.4019 - binary_accuracy: 0.8350 - sensitivity: 1.0000 - specificity: 0.3918 - gmeasure: 0.6093 - auc: 0.8899 - val_loss: 0.4152 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9910 - val_specificity: 0.4712 - val_gmeasure: 0.6811 - val_auc: 0.8710\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 206us/step - loss: 0.3869 - binary_accuracy: 0.8400 - sensitivity: 0.9978 - specificity: 0.4293 - gmeasure: 0.6445 - auc: 0.9162 - val_loss: 0.3956 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.4017 - val_gmeasure: 0.6264 - val_auc: 0.8849\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 201us/step - loss: 0.3745 - binary_accuracy: 0.8250 - sensitivity: 0.9835 - specificity: 0.4014 - gmeasure: 0.6069 - auc: 0.9236 - val_loss: 0.3891 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9714 - val_specificity: 0.6474 - val_gmeasure: 0.7909 - val_auc: 0.8963\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.3602 - binary_accuracy: 0.8483 - sensitivity: 0.9831 - specificity: 0.4749 - gmeasure: 0.6686 - auc: 0.9335 - val_loss: 0.3733 - val_binary_accuracy: 0.8467 - val_sensitivity: 1.0000 - val_specificity: 0.4503 - val_gmeasure: 0.6666 - val_auc: 0.9017\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 174us/step - loss: 0.3492 - binary_accuracy: 0.8717 - sensitivity: 0.9841 - specificity: 0.5543 - gmeasure: 0.7121 - auc: 0.9450 - val_loss: 0.3963 - val_binary_accuracy: 0.8000 - val_sensitivity: 1.0000 - val_specificity: 0.2740 - val_gmeasure: 0.5177 - val_auc: 0.9097\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.3446 - binary_accuracy: 0.8600 - sensitivity: 0.9853 - specificity: 0.5315 - gmeasure: 0.7115 - auc: 0.9448 - val_loss: 0.3628 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.4017 - val_gmeasure: 0.6264 - val_auc: 0.9110\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 188us/step - loss: 0.3262 - binary_accuracy: 0.8733 - sensitivity: 0.9975 - specificity: 0.5399 - gmeasure: 0.7287 - auc: 0.9520 - val_loss: 0.3569 - val_binary_accuracy: 0.8333 - val_sensitivity: 1.0000 - val_specificity: 0.3948 - val_gmeasure: 0.6234 - val_auc: 0.9143\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.3158 - binary_accuracy: 0.8700 - sensitivity: 0.9929 - specificity: 0.5319 - gmeasure: 0.7217 - auc: 0.9472 - val_loss: 0.3380 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9722 - val_specificity: 0.5871 - val_gmeasure: 0.7552 - val_auc: 0.9163\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.3113 - binary_accuracy: 0.8967 - sensitivity: 0.9777 - specificity: 0.6923 - gmeasure: 0.8123 - auc: 0.9572 - val_loss: 0.3967 - val_binary_accuracy: 0.8067 - val_sensitivity: 1.0000 - val_specificity: 0.3018 - val_gmeasure: 0.5435 - val_auc: 0.9169\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.3352 - binary_accuracy: 0.8400 - sensitivity: 0.9349 - specificity: 0.6039 - gmeasure: 0.7207 - auc: 0.9520 - val_loss: 0.3468 - val_binary_accuracy: 0.8600 - val_sensitivity: 1.0000 - val_specificity: 0.4968 - val_gmeasure: 0.7013 - val_auc: 0.9182\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.3088 - binary_accuracy: 0.8850 - sensitivity: 0.9917 - specificity: 0.6003 - gmeasure: 0.7578 - auc: 0.9563 - val_loss: 0.3274 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9722 - val_specificity: 0.5871 - val_gmeasure: 0.7552 - val_auc: 0.9188\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.2893 - binary_accuracy: 0.8900 - sensitivity: 0.9978 - specificity: 0.6112 - gmeasure: 0.7722 - auc: 0.9558 - val_loss: 0.3283 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9910 - val_specificity: 0.5662 - val_gmeasure: 0.7482 - val_auc: 0.9235\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2923 - binary_accuracy: 0.8850 - sensitivity: 0.9712 - specificity: 0.6592 - gmeasure: 0.7927 - auc: 0.9545 - val_loss: 0.3471 - val_binary_accuracy: 0.8600 - val_sensitivity: 1.0000 - val_specificity: 0.4968 - val_gmeasure: 0.7013 - val_auc: 0.9234\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2891 - binary_accuracy: 0.8850 - sensitivity: 0.9567 - specificity: 0.6734 - gmeasure: 0.7887 - auc: 0.9566 - val_loss: 0.3720 - val_binary_accuracy: 0.8467 - val_sensitivity: 1.0000 - val_specificity: 0.4482 - val_gmeasure: 0.6630 - val_auc: 0.9234\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.2888 - binary_accuracy: 0.8767 - sensitivity: 0.9589 - specificity: 0.6550 - gmeasure: 0.7766 - auc: 0.9568 - val_loss: 0.3311 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9820 - val_specificity: 0.5454 - val_gmeasure: 0.7294 - val_auc: 0.9241\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.2723 - binary_accuracy: 0.8933 - sensitivity: 0.9815 - specificity: 0.6355 - gmeasure: 0.7818 - auc: 0.9627 - val_loss: 0.3156 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6939 - val_gmeasure: 0.8152 - val_auc: 0.9240\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2663 - binary_accuracy: 0.9017 - sensitivity: 0.9909 - specificity: 0.6554 - gmeasure: 0.7987 - auc: 0.9660 - val_loss: 0.3139 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9246\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.2582 - binary_accuracy: 0.9033 - sensitivity: 0.9864 - specificity: 0.6921 - gmeasure: 0.8226 - auc: 0.9662 - val_loss: 0.3262 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9820 - val_specificity: 0.5454 - val_gmeasure: 0.7294 - val_auc: 0.9233\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.2573 - binary_accuracy: 0.9017 - sensitivity: 0.9827 - specificity: 0.6990 - gmeasure: 0.8247 - auc: 0.9674 - val_loss: 0.3178 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9730 - val_specificity: 0.5871 - val_gmeasure: 0.7553 - val_auc: 0.9228\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.2540 - binary_accuracy: 0.9017 - sensitivity: 0.9849 - specificity: 0.6823 - gmeasure: 0.8133 - auc: 0.9620 - val_loss: 0.3109 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9227\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 232us/step - loss: 0.2496 - binary_accuracy: 0.9167 - sensitivity: 0.9713 - specificity: 0.7572 - gmeasure: 0.8510 - auc: 0.9637 - val_loss: 0.3269 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9240\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.2458 - binary_accuracy: 0.9000 - sensitivity: 0.9775 - specificity: 0.6943 - gmeasure: 0.8152 - auc: 0.9692 - val_loss: 0.3173 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9730 - val_specificity: 0.5871 - val_gmeasure: 0.7553 - val_auc: 0.9240\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 186us/step - loss: 0.2404 - binary_accuracy: 0.9167 - sensitivity: 0.9775 - specificity: 0.7612 - gmeasure: 0.8609 - auc: 0.9626 - val_loss: 0.3271 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9253\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 228us/step - loss: 0.2414 - binary_accuracy: 0.9083 - sensitivity: 0.9778 - specificity: 0.7196 - gmeasure: 0.8349 - auc: 0.9642 - val_loss: 0.3292 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9820 - val_specificity: 0.5662 - val_gmeasure: 0.7446 - val_auc: 0.9241\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2414 - binary_accuracy: 0.9067 - sensitivity: 0.9802 - specificity: 0.7183 - gmeasure: 0.8319 - auc: 0.9715 - val_loss: 0.3149 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9632 - val_specificity: 0.6127 - val_gmeasure: 0.7668 - val_auc: 0.9254\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.2352 - binary_accuracy: 0.9100 - sensitivity: 0.9861 - specificity: 0.7078 - gmeasure: 0.8312 - auc: 0.9655 - val_loss: 0.3100 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9534 - val_specificity: 0.7473 - val_gmeasure: 0.8408 - val_auc: 0.9292\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 225us/step - loss: 0.2409 - binary_accuracy: 0.9067 - sensitivity: 0.9778 - specificity: 0.7117 - gmeasure: 0.8264 - auc: 0.9673 - val_loss: 0.3042 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 228us/step - loss: 0.2274 - binary_accuracy: 0.9167 - sensitivity: 0.9799 - specificity: 0.7378 - gmeasure: 0.8462 - auc: 0.9676 - val_loss: 0.3146 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9632 - val_specificity: 0.6127 - val_gmeasure: 0.7668 - val_auc: 0.9266\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.2225 - binary_accuracy: 0.9200 - sensitivity: 0.9817 - specificity: 0.7530 - gmeasure: 0.8537 - auc: 0.9670 - val_loss: 0.3159 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9632 - val_specificity: 0.6384 - val_gmeasure: 0.7811 - val_auc: 0.9284\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 193us/step - loss: 0.2263 - binary_accuracy: 0.9050 - sensitivity: 0.9849 - specificity: 0.7036 - gmeasure: 0.8293 - auc: 0.9697 - val_loss: 0.3039 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9304\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2231 - binary_accuracy: 0.9100 - sensitivity: 0.9797 - specificity: 0.7370 - gmeasure: 0.8444 - auc: 0.9698 - val_loss: 0.3005 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9310\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2290 - binary_accuracy: 0.9133 - sensitivity: 0.9757 - specificity: 0.7577 - gmeasure: 0.8511 - auc: 0.9735 - val_loss: 0.3003 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9297\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.2234 - binary_accuracy: 0.9100 - sensitivity: 0.9796 - specificity: 0.7292 - gmeasure: 0.8409 - auc: 0.9724 - val_loss: 0.2980 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9311\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 187us/step - loss: 0.2217 - binary_accuracy: 0.9217 - sensitivity: 0.9716 - specificity: 0.8000 - gmeasure: 0.8789 - auc: 0.9727 - val_loss: 0.3101 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9317\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2111 - binary_accuracy: 0.9300 - sensitivity: 0.9736 - specificity: 0.8183 - gmeasure: 0.8901 - auc: 0.9760 - val_loss: 0.3228 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9820 - val_specificity: 0.6127 - val_gmeasure: 0.7743 - val_auc: 0.9317\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2172 - binary_accuracy: 0.9150 - sensitivity: 0.9801 - specificity: 0.7462 - gmeasure: 0.8497 - auc: 0.9725 - val_loss: 0.2996 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9632 - val_specificity: 0.6918 - val_gmeasure: 0.8124 - val_auc: 0.9337\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.2088 - binary_accuracy: 0.9200 - sensitivity: 0.9800 - specificity: 0.7658 - gmeasure: 0.8632 - auc: 0.9727 - val_loss: 0.3098 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9337\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.2046 - binary_accuracy: 0.9167 - sensitivity: 0.9813 - specificity: 0.7344 - gmeasure: 0.8473 - auc: 0.9734 - val_loss: 0.2930 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9632 - val_specificity: 0.7473 - val_gmeasure: 0.8445 - val_auc: 0.9364\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.2099 - binary_accuracy: 0.9250 - sensitivity: 0.9781 - specificity: 0.7824 - gmeasure: 0.8680 - auc: 0.9744 - val_loss: 0.3045 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9351\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.2035 - binary_accuracy: 0.9367 - sensitivity: 0.9786 - specificity: 0.8270 - gmeasure: 0.8971 - auc: 0.9740 - val_loss: 0.3237 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9820 - val_specificity: 0.6384 - val_gmeasure: 0.7889 - val_auc: 0.9338\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2094 - binary_accuracy: 0.9300 - sensitivity: 0.9801 - specificity: 0.8021 - gmeasure: 0.8829 - auc: 0.9753 - val_loss: 0.3018 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9370\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2025 - binary_accuracy: 0.9217 - sensitivity: 0.9890 - specificity: 0.7374 - gmeasure: 0.8492 - auc: 0.9730 - val_loss: 0.2899 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9365\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.1975 - binary_accuracy: 0.9283 - sensitivity: 0.9846 - specificity: 0.7858 - gmeasure: 0.8780 - auc: 0.9758 - val_loss: 0.3224 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9820 - val_specificity: 0.6384 - val_gmeasure: 0.7889 - val_auc: 0.9377\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.1968 - binary_accuracy: 0.9367 - sensitivity: 0.9816 - specificity: 0.8091 - gmeasure: 0.8862 - auc: 0.9790 - val_loss: 0.2986 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9390\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 189us/step - loss: 0.1943 - binary_accuracy: 0.9333 - sensitivity: 0.9812 - specificity: 0.8027 - gmeasure: 0.8832 - auc: 0.9786 - val_loss: 0.2893 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9390\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.1987 - binary_accuracy: 0.9133 - sensitivity: 0.9755 - specificity: 0.7540 - gmeasure: 0.8546 - auc: 0.9755 - val_loss: 0.2846 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9416\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.1963 - binary_accuracy: 0.9250 - sensitivity: 0.9677 - specificity: 0.8048 - gmeasure: 0.8785 - auc: 0.9762 - val_loss: 0.2889 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9409\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1976 - binary_accuracy: 0.9233 - sensitivity: 0.9775 - specificity: 0.7753 - gmeasure: 0.8645 - auc: 0.9777 - val_loss: 0.3090 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9722 - val_specificity: 0.6640 - val_gmeasure: 0.7991 - val_auc: 0.9409\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.1925 - binary_accuracy: 0.9283 - sensitivity: 0.9749 - specificity: 0.8072 - gmeasure: 0.8846 - auc: 0.9781 - val_loss: 0.2945 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9430\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.1872 - binary_accuracy: 0.9433 - sensitivity: 0.9792 - specificity: 0.8467 - gmeasure: 0.9082 - auc: 0.9787 - val_loss: 0.3010 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9632 - val_specificity: 0.6640 - val_gmeasure: 0.7948 - val_auc: 0.9423\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 194us/step - loss: 0.1848 - binary_accuracy: 0.9367 - sensitivity: 0.9773 - specificity: 0.8238 - gmeasure: 0.8965 - auc: 0.9767 - val_loss: 0.2921 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9423\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.1854 - binary_accuracy: 0.9333 - sensitivity: 0.9844 - specificity: 0.7979 - gmeasure: 0.8833 - auc: 0.9833 - val_loss: 0.2809 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.1956 - binary_accuracy: 0.9183 - sensitivity: 0.9730 - specificity: 0.7771 - gmeasure: 0.8631 - auc: 0.9801 - val_loss: 0.2804 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9632 - val_specificity: 0.7682 - val_gmeasure: 0.8578 - val_auc: 0.9436\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 188us/step - loss: 0.1999 - binary_accuracy: 0.9083 - sensitivity: 0.9625 - specificity: 0.7556 - gmeasure: 0.8467 - auc: 0.9830 - val_loss: 0.2903 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9632 - val_specificity: 0.7196 - val_gmeasure: 0.8289 - val_auc: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 14.82160210609436!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 6us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.01217961311340332!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2018193006515503, 0.9279999732971191, 0.976190447807312, 0.7990196347236633, 0.8831734657287598, 0.9702919721603394]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.012906551361083984!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.3040628135204315, 0.8880000114440918, 0.954023003578186, 0.7368420958518982, 0.8384296894073486, 0.932773768901825]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 16.38786482810974\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6701 - binary_accuracy: 0.6700 - sensitivity: 0.9495 - specificity: 0.0441 - gmeasure: 0.0381 - auc: 0.5415 - val_loss: 0.6565 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5673\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 236us/step - loss: 0.6304 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6214 - val_loss: 0.6471 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6013\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 253us/step - loss: 0.6211 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6069 - val_loss: 0.6543 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5432\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 220us/step - loss: 0.6212 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6443 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5826\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6426 - val_loss: 0.6463 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6066\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.6208 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6942 - val_loss: 0.6475 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6527\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6203 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7211 - val_loss: 0.6492 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6842\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 227us/step - loss: 0.6209 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7423 - val_loss: 0.6485 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7172\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.6200 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7710 - val_loss: 0.6482 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7442\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6207 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7863 - val_loss: 0.6483 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7656\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 190us/step - loss: 0.6206 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8093 - val_loss: 0.6454 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7805\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6189 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8163 - val_loss: 0.6472 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7938\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 248us/step - loss: 0.6185 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8233 - val_loss: 0.6459 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8113\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6168 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8323 - val_loss: 0.6444 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8237\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.6145 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8369 - val_loss: 0.6417 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8353\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.6113 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8398 - val_loss: 0.6408 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8447\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.6073 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8547 - val_loss: 0.6327 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8544\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 233us/step - loss: 0.6007 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8553 - val_loss: 0.6230 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8644\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5920 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8570 - val_loss: 0.6164 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8659\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.5805 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8598 - val_loss: 0.6035 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8777\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.5662 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8644 - val_loss: 0.5845 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8895\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.5501 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8627 - val_loss: 0.5640 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8969\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.5308 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8761 - val_loss: 0.5423 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8942\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5121 - binary_accuracy: 0.6883 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8786 - val_loss: 0.5288 - val_binary_accuracy: 0.6533 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.8845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.4999 - binary_accuracy: 0.7183 - sensitivity: 0.9690 - specificity: 0.1727 - gmeasure: 0.3474 - auc: 0.8792 - val_loss: 0.5249 - val_binary_accuracy: 0.6800 - val_sensitivity: 1.0000 - val_specificity: 0.0657 - val_gmeasure: 0.2065 - val_auc: 0.8963\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.5027 - binary_accuracy: 0.7400 - sensitivity: 0.9573 - specificity: 0.2724 - gmeasure: 0.4810 - auc: 0.8869 - val_loss: 0.4997 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9691 - val_specificity: 0.4433 - val_gmeasure: 0.6555 - val_auc: 0.9087\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.4697 - binary_accuracy: 0.7450 - sensitivity: 0.9427 - specificity: 0.3038 - gmeasure: 0.5255 - auc: 0.8864 - val_loss: 0.4848 - val_binary_accuracy: 0.7533 - val_sensitivity: 0.9907 - val_specificity: 0.3171 - val_gmeasure: 0.5591 - val_auc: 0.9104\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.4539 - binary_accuracy: 0.7683 - sensitivity: 0.9320 - specificity: 0.4046 - gmeasure: 0.5962 - auc: 0.8952 - val_loss: 0.4677 - val_binary_accuracy: 0.7600 - val_sensitivity: 0.9691 - val_specificity: 0.3776 - val_gmeasure: 0.6033 - val_auc: 0.9136\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 227us/step - loss: 0.4388 - binary_accuracy: 0.7617 - sensitivity: 0.9292 - specificity: 0.4119 - gmeasure: 0.6088 - auc: 0.9041 - val_loss: 0.4554 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9473 - val_specificity: 0.5329 - val_gmeasure: 0.7101 - val_auc: 0.9117\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.4269 - binary_accuracy: 0.7867 - sensitivity: 0.9190 - specificity: 0.4834 - gmeasure: 0.6559 - auc: 0.8998 - val_loss: 0.4438 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9691 - val_specificity: 0.4894 - val_gmeasure: 0.6882 - val_auc: 0.9141\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.4131 - binary_accuracy: 0.8100 - sensitivity: 0.9051 - specificity: 0.5909 - gmeasure: 0.7257 - auc: 0.9041 - val_loss: 0.4461 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9691 - val_specificity: 0.4433 - val_gmeasure: 0.6555 - val_auc: 0.9139\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.4061 - binary_accuracy: 0.8083 - sensitivity: 0.9184 - specificity: 0.5890 - gmeasure: 0.7278 - auc: 0.9089 - val_loss: 0.4207 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9380 - val_specificity: 0.5329 - val_gmeasure: 0.7067 - val_auc: 0.9126\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.3921 - binary_accuracy: 0.8150 - sensitivity: 0.9053 - specificity: 0.6055 - gmeasure: 0.7370 - auc: 0.9094 - val_loss: 0.4071 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9190 - val_specificity: 0.6156 - val_gmeasure: 0.7517 - val_auc: 0.9197\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.3812 - binary_accuracy: 0.8183 - sensitivity: 0.9027 - specificity: 0.6327 - gmeasure: 0.7534 - auc: 0.9110 - val_loss: 0.4077 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9285 - val_specificity: 0.5329 - val_gmeasure: 0.7032 - val_auc: 0.9167\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.3754 - binary_accuracy: 0.8183 - sensitivity: 0.8997 - specificity: 0.6469 - gmeasure: 0.7545 - auc: 0.9180 - val_loss: 0.3946 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9097 - val_specificity: 0.6922 - val_gmeasure: 0.7934 - val_auc: 0.9145\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.3668 - binary_accuracy: 0.8283 - sensitivity: 0.8920 - specificity: 0.6817 - gmeasure: 0.7747 - auc: 0.9159 - val_loss: 0.4043 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9190 - val_specificity: 0.5551 - val_gmeasure: 0.7137 - val_auc: 0.9198\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 195us/step - loss: 0.3599 - binary_accuracy: 0.8233 - sensitivity: 0.8896 - specificity: 0.6792 - gmeasure: 0.7724 - auc: 0.9155 - val_loss: 0.3774 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9097 - val_specificity: 0.7305 - val_gmeasure: 0.8146 - val_auc: 0.9179\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 203us/step - loss: 0.3557 - binary_accuracy: 0.8267 - sensitivity: 0.8895 - specificity: 0.7094 - gmeasure: 0.7903 - auc: 0.9217 - val_loss: 0.3706 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9004 - val_specificity: 0.7833 - val_gmeasure: 0.8381 - val_auc: 0.9193\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 200us/step - loss: 0.3477 - binary_accuracy: 0.8283 - sensitivity: 0.8791 - specificity: 0.7152 - gmeasure: 0.7905 - auc: 0.9178 - val_loss: 0.3719 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9097 - val_specificity: 0.6156 - val_gmeasure: 0.7481 - val_auc: 0.9252\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 222us/step - loss: 0.3415 - binary_accuracy: 0.8383 - sensitivity: 0.8777 - specificity: 0.7366 - gmeasure: 0.7999 - auc: 0.9179 - val_loss: 0.3649 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7253 - val_gmeasure: 0.8102 - val_auc: 0.9182\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 217us/step - loss: 0.3369 - binary_accuracy: 0.8300 - sensitivity: 0.8762 - specificity: 0.7304 - gmeasure: 0.7961 - auc: 0.9216 - val_loss: 0.3613 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9097 - val_specificity: 0.6777 - val_gmeasure: 0.7849 - val_auc: 0.9258\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.3296 - binary_accuracy: 0.8450 - sensitivity: 0.8733 - specificity: 0.7717 - gmeasure: 0.8170 - auc: 0.9249 - val_loss: 0.3625 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9097 - val_specificity: 0.6777 - val_gmeasure: 0.7849 - val_auc: 0.9237\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.3266 - binary_accuracy: 0.8500 - sensitivity: 0.8731 - specificity: 0.8126 - gmeasure: 0.8390 - auc: 0.9258 - val_loss: 0.3535 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7160 - val_gmeasure: 0.8063 - val_auc: 0.9243\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.3228 - binary_accuracy: 0.8350 - sensitivity: 0.8720 - specificity: 0.7586 - gmeasure: 0.8098 - auc: 0.9277 - val_loss: 0.3432 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9097 - val_specificity: 0.7305 - val_gmeasure: 0.8146 - val_auc: 0.9267\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 230us/step - loss: 0.3150 - binary_accuracy: 0.8583 - sensitivity: 0.8722 - specificity: 0.8242 - gmeasure: 0.8468 - auc: 0.9259 - val_loss: 0.3399 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9097 - val_specificity: 0.7672 - val_gmeasure: 0.8353 - val_auc: 0.9283\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 240us/step - loss: 0.3135 - binary_accuracy: 0.8517 - sensitivity: 0.8662 - specificity: 0.8167 - gmeasure: 0.8393 - auc: 0.9261 - val_loss: 0.3463 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9097 - val_specificity: 0.7160 - val_gmeasure: 0.8063 - val_auc: 0.9256\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 221us/step - loss: 0.3125 - binary_accuracy: 0.8567 - sensitivity: 0.8712 - specificity: 0.8223 - gmeasure: 0.8416 - auc: 0.9270 - val_loss: 0.3345 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9192 - val_specificity: 0.7894 - val_gmeasure: 0.8518 - val_auc: 0.9316\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.3065 - binary_accuracy: 0.8600 - sensitivity: 0.8706 - specificity: 0.8456 - gmeasure: 0.8560 - auc: 0.9297 - val_loss: 0.3223 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9284\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2978 - binary_accuracy: 0.8650 - sensitivity: 0.8809 - specificity: 0.8216 - gmeasure: 0.8496 - auc: 0.9276 - val_loss: 0.3177 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.3007 - binary_accuracy: 0.8617 - sensitivity: 0.8717 - specificity: 0.8372 - gmeasure: 0.8495 - auc: 0.9353 - val_loss: 0.3245 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9192 - val_specificity: 0.7817 - val_gmeasure: 0.8473 - val_auc: 0.9382\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.2933 - binary_accuracy: 0.8750 - sensitivity: 0.8851 - specificity: 0.8515 - gmeasure: 0.8658 - auc: 0.9370 - val_loss: 0.3136 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9097 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9402\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.2896 - binary_accuracy: 0.8767 - sensitivity: 0.8792 - specificity: 0.8750 - gmeasure: 0.8737 - auc: 0.9423 - val_loss: 0.3202 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9445\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 202us/step - loss: 0.2837 - binary_accuracy: 0.8800 - sensitivity: 0.8857 - specificity: 0.8656 - gmeasure: 0.8745 - auc: 0.9385 - val_loss: 0.3095 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9423\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 209us/step - loss: 0.2833 - binary_accuracy: 0.8733 - sensitivity: 0.8803 - specificity: 0.8519 - gmeasure: 0.8630 - auc: 0.9424 - val_loss: 0.3113 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9398\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 237us/step - loss: 0.2769 - binary_accuracy: 0.8817 - sensitivity: 0.8846 - specificity: 0.8789 - gmeasure: 0.8804 - auc: 0.9426 - val_loss: 0.3131 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9192 - val_specificity: 0.8039 - val_gmeasure: 0.8596 - val_auc: 0.9409\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.2786 - binary_accuracy: 0.8833 - sensitivity: 0.8956 - specificity: 0.8649 - gmeasure: 0.8785 - auc: 0.9446 - val_loss: 0.3170 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9192 - val_specificity: 0.7341 - val_gmeasure: 0.8207 - val_auc: 0.9469\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.2759 - binary_accuracy: 0.8833 - sensitivity: 0.8916 - specificity: 0.8775 - gmeasure: 0.8825 - auc: 0.9458 - val_loss: 0.3046 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9454\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2705 - binary_accuracy: 0.8900 - sensitivity: 0.8913 - specificity: 0.8877 - gmeasure: 0.8882 - auc: 0.9437 - val_loss: 0.3028 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9457\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.2653 - binary_accuracy: 0.8867 - sensitivity: 0.8887 - specificity: 0.8785 - gmeasure: 0.8818 - auc: 0.9444 - val_loss: 0.2939 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8912 - val_specificity: 0.8422 - val_gmeasure: 0.8659 - val_auc: 0.9431\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2648 - binary_accuracy: 0.8833 - sensitivity: 0.8982 - specificity: 0.8460 - gmeasure: 0.8701 - auc: 0.9441 - val_loss: 0.2960 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8631 - val_specificity: 0.9028 - val_gmeasure: 0.8818 - val_auc: 0.9437\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 211us/step - loss: 0.2670 - binary_accuracy: 0.8883 - sensitivity: 0.8859 - specificity: 0.8975 - gmeasure: 0.8905 - auc: 0.9464 - val_loss: 0.2929 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9007 - val_specificity: 0.8422 - val_gmeasure: 0.8703 - val_auc: 0.9458\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.2566 - binary_accuracy: 0.8967 - sensitivity: 0.8962 - specificity: 0.8939 - gmeasure: 0.8937 - auc: 0.9507 - val_loss: 0.3089 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9192 - val_specificity: 0.7511 - val_gmeasure: 0.8309 - val_auc: 0.9483\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.2572 - binary_accuracy: 0.8950 - sensitivity: 0.8952 - specificity: 0.8985 - gmeasure: 0.8959 - auc: 0.9494 - val_loss: 0.3095 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9445\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.2560 - binary_accuracy: 0.8900 - sensitivity: 0.8951 - specificity: 0.8849 - gmeasure: 0.8891 - auc: 0.9517 - val_loss: 0.3284 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9285 - val_specificity: 0.6455 - val_gmeasure: 0.7719 - val_auc: 0.9490\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 235us/step - loss: 0.2533 - binary_accuracy: 0.8983 - sensitivity: 0.8990 - specificity: 0.8894 - gmeasure: 0.8920 - auc: 0.9495 - val_loss: 0.2952 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8422 - val_gmeasure: 0.8796 - val_auc: 0.9492\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 219us/step - loss: 0.2478 - binary_accuracy: 0.8967 - sensitivity: 0.8986 - specificity: 0.8976 - gmeasure: 0.8973 - auc: 0.9538 - val_loss: 0.3252 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9408 - val_specificity: 0.6600 - val_gmeasure: 0.7859 - val_auc: 0.9502\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.2529 - binary_accuracy: 0.9017 - sensitivity: 0.8891 - specificity: 0.9315 - gmeasure: 0.9089 - auc: 0.9456 - val_loss: 0.3004 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8277 - val_gmeasure: 0.8720 - val_auc: 0.9464\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.2529 - binary_accuracy: 0.8900 - sensitivity: 0.8878 - specificity: 0.8942 - gmeasure: 0.8897 - auc: 0.9472 - val_loss: 0.2792 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9489\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 246us/step - loss: 0.2446 - binary_accuracy: 0.8933 - sensitivity: 0.8974 - specificity: 0.8813 - gmeasure: 0.8875 - auc: 0.9480 - val_loss: 0.2867 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9007 - val_specificity: 0.8422 - val_gmeasure: 0.8703 - val_auc: 0.9460\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 230us/step - loss: 0.2402 - binary_accuracy: 0.9017 - sensitivity: 0.9114 - specificity: 0.8733 - gmeasure: 0.8906 - auc: 0.9491 - val_loss: 0.2779 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9426\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 207us/step - loss: 0.2409 - binary_accuracy: 0.8983 - sensitivity: 0.9116 - specificity: 0.8835 - gmeasure: 0.8952 - auc: 0.9552 - val_loss: 0.2793 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8727 - val_specificity: 0.8883 - val_gmeasure: 0.8791 - val_auc: 0.9407\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 0.2780 - binary_accuracy: 0.8783 - sensitivity: 0.8735 - specificity: 0.8927 - gmeasure: 0.8789 - auc: 0.9448 - val_loss: 0.3059 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9285 - val_specificity: 0.8039 - val_gmeasure: 0.8639 - val_auc: 0.9535\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2394 - binary_accuracy: 0.9083 - sensitivity: 0.8950 - specificity: 0.9323 - gmeasure: 0.9130 - auc: 0.9485 - val_loss: 0.2898 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9192 - val_specificity: 0.7656 - val_gmeasure: 0.8389 - val_auc: 0.9507\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.2373 - binary_accuracy: 0.8933 - sensitivity: 0.9025 - specificity: 0.8828 - gmeasure: 0.8894 - auc: 0.9553 - val_loss: 0.2881 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9100 - val_specificity: 0.8039 - val_gmeasure: 0.8552 - val_auc: 0.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2320 - binary_accuracy: 0.9117 - sensitivity: 0.9049 - specificity: 0.9278 - gmeasure: 0.9150 - auc: 0.9587 - val_loss: 0.2748 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9007 - val_specificity: 0.8883 - val_gmeasure: 0.8936 - val_auc: 0.9517\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 224us/step - loss: 0.2293 - binary_accuracy: 0.9133 - sensitivity: 0.9057 - specificity: 0.9343 - gmeasure: 0.9186 - auc: 0.9591 - val_loss: 0.2913 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9192 - val_specificity: 0.7656 - val_gmeasure: 0.8389 - val_auc: 0.9549\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2241 - binary_accuracy: 0.9067 - sensitivity: 0.9132 - specificity: 0.8917 - gmeasure: 0.9019 - auc: 0.9577 - val_loss: 0.2697 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8822 - val_specificity: 0.8883 - val_gmeasure: 0.8837 - val_auc: 0.9494\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.2401 - binary_accuracy: 0.8850 - sensitivity: 0.8974 - specificity: 0.8656 - gmeasure: 0.8787 - auc: 0.9588 - val_loss: 0.2753 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9007 - val_specificity: 0.8660 - val_gmeasure: 0.8818 - val_auc: 0.9547\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.2431 - binary_accuracy: 0.9000 - sensitivity: 0.8981 - specificity: 0.9177 - gmeasure: 0.9051 - auc: 0.9580 - val_loss: 0.3159 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9285 - val_specificity: 0.6983 - val_gmeasure: 0.8044 - val_auc: 0.9533\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 236us/step - loss: 0.2325 - binary_accuracy: 0.9050 - sensitivity: 0.8899 - specificity: 0.9272 - gmeasure: 0.9072 - auc: 0.9538 - val_loss: 0.3196 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9408 - val_specificity: 0.6839 - val_gmeasure: 0.8006 - val_auc: 0.9551\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 223us/step - loss: 0.2267 - binary_accuracy: 0.9100 - sensitivity: 0.9068 - specificity: 0.9092 - gmeasure: 0.9065 - auc: 0.9582 - val_loss: 0.2697 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9531\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 216us/step - loss: 0.2243 - binary_accuracy: 0.9100 - sensitivity: 0.9190 - specificity: 0.8964 - gmeasure: 0.9063 - auc: 0.9593 - val_loss: 0.2639 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8914 - val_specificity: 0.8883 - val_gmeasure: 0.8887 - val_auc: 0.9471\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 193us/step - loss: 0.2349 - binary_accuracy: 0.9017 - sensitivity: 0.8999 - specificity: 0.9122 - gmeasure: 0.9041 - auc: 0.9591 - val_loss: 0.2732 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9100 - val_specificity: 0.8660 - val_gmeasure: 0.8867 - val_auc: 0.9561\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 213us/step - loss: 0.2246 - binary_accuracy: 0.9100 - sensitivity: 0.9094 - specificity: 0.9203 - gmeasure: 0.9136 - auc: 0.9596 - val_loss: 0.2673 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9100 - val_specificity: 0.8500 - val_gmeasure: 0.8792 - val_auc: 0.9554\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 235us/step - loss: 0.2260 - binary_accuracy: 0.9100 - sensitivity: 0.9048 - specificity: 0.9342 - gmeasure: 0.9176 - auc: 0.9638 - val_loss: 0.2687 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9100 - val_specificity: 0.8660 - val_gmeasure: 0.8867 - val_auc: 0.9534\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 201us/step - loss: 0.2201 - binary_accuracy: 0.9083 - sensitivity: 0.9108 - specificity: 0.9022 - gmeasure: 0.9054 - auc: 0.9577 - val_loss: 0.2584 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9498\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 212us/step - loss: 0.2229 - binary_accuracy: 0.9117 - sensitivity: 0.9106 - specificity: 0.9263 - gmeasure: 0.9169 - auc: 0.9641 - val_loss: 0.2670 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9100 - val_specificity: 0.8500 - val_gmeasure: 0.8792 - val_auc: 0.9554\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2152 - binary_accuracy: 0.9150 - sensitivity: 0.9132 - specificity: 0.9190 - gmeasure: 0.9155 - auc: 0.9590 - val_loss: 0.2587 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9584\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 0.2217 - binary_accuracy: 0.9067 - sensitivity: 0.9008 - specificity: 0.9284 - gmeasure: 0.9123 - auc: 0.9606 - val_loss: 0.2658 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9192 - val_specificity: 0.8262 - val_gmeasure: 0.8714 - val_auc: 0.9566\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 196us/step - loss: 0.2152 - binary_accuracy: 0.9117 - sensitivity: 0.9161 - specificity: 0.9073 - gmeasure: 0.9097 - auc: 0.9676 - val_loss: 0.2587 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9100 - val_specificity: 0.8883 - val_gmeasure: 0.8985 - val_auc: 0.9575\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2103 - binary_accuracy: 0.9083 - sensitivity: 0.9105 - specificity: 0.9023 - gmeasure: 0.9053 - auc: 0.9627 - val_loss: 0.2939 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9408 - val_specificity: 0.7128 - val_gmeasure: 0.8182 - val_auc: 0.9624\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 215us/step - loss: 0.2201 - binary_accuracy: 0.9033 - sensitivity: 0.9075 - specificity: 0.9065 - gmeasure: 0.9049 - auc: 0.9657 - val_loss: 0.2851 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9408 - val_specificity: 0.7366 - val_gmeasure: 0.8320 - val_auc: 0.9630\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 197us/step - loss: 0.2105 - binary_accuracy: 0.9217 - sensitivity: 0.9101 - specificity: 0.9412 - gmeasure: 0.9250 - auc: 0.9638 - val_loss: 0.2887 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9408 - val_specificity: 0.7128 - val_gmeasure: 0.8182 - val_auc: 0.9630\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 210us/step - loss: 0.2089 - binary_accuracy: 0.9100 - sensitivity: 0.9064 - specificity: 0.9211 - gmeasure: 0.9131 - auc: 0.9641 - val_loss: 0.2924 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9408 - val_specificity: 0.6983 - val_gmeasure: 0.8095 - val_auc: 0.9642\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.2072 - binary_accuracy: 0.9167 - sensitivity: 0.9177 - specificity: 0.9190 - gmeasure: 0.9178 - auc: 0.9640 - val_loss: 0.2752 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9408 - val_specificity: 0.7827 - val_gmeasure: 0.8570 - val_auc: 0.9635\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 0.2045 - binary_accuracy: 0.9200 - sensitivity: 0.9161 - specificity: 0.9293 - gmeasure: 0.9213 - auc: 0.9645 - val_loss: 0.2603 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9192 - val_specificity: 0.8500 - val_gmeasure: 0.8838 - val_auc: 0.9642\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 214us/step - loss: 0.2021 - binary_accuracy: 0.9233 - sensitivity: 0.9114 - specificity: 0.9502 - gmeasure: 0.9299 - auc: 0.9651 - val_loss: 0.2660 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9408 - val_specificity: 0.8039 - val_gmeasure: 0.8697 - val_auc: 0.9642\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 205us/step - loss: 0.1998 - binary_accuracy: 0.9200 - sensitivity: 0.9186 - specificity: 0.9269 - gmeasure: 0.9214 - auc: 0.9701 - val_loss: 0.2627 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9316 - val_specificity: 0.8117 - val_gmeasure: 0.8693 - val_auc: 0.9654\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 208us/step - loss: 0.2021 - binary_accuracy: 0.9183 - sensitivity: 0.9061 - specificity: 0.9396 - gmeasure: 0.9218 - auc: 0.9621 - val_loss: 0.2604 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9192 - val_specificity: 0.8660 - val_gmeasure: 0.8914 - val_auc: 0.9652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 218us/step - loss: 0.2014 - binary_accuracy: 0.9267 - sensitivity: 0.9228 - specificity: 0.9360 - gmeasure: 0.9292 - auc: 0.9649 - val_loss: 0.2488 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9316 - val_specificity: 0.8738 - val_gmeasure: 0.9015 - val_auc: 0.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 15.262919902801514!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.014128923416137695!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2123630940914154, 0.9173333048820496, 0.9041095972061157, 0.9456067085266113, 0.9246253967285156, 0.967468798160553]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.012145757675170898!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.24281755089759827, 0.9039999842643738, 0.9269663095474243, 0.8472222089767456, 0.8861977458000183, 0.9503355026245117]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 16.86178183555603\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.27629593 0.88755554 0.94336899 0.75539269 0.83720887 0.94540739]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.09796488 0.04984518 0.02977692 0.17584679 0.09582087 0.03321583]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.32320864 0.87733332 0.95441262 0.70909139 0.8183614  0.92972175]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.07469245 0.02719478 0.02257056 0.12565417 0.0651453  0.0182054 ]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, network_info, path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deepbiome_train` saves the trained model weights, evaluation results and history based on the path information from the configuration.\n",
    "\n",
    "From the example above, we can check that `hist_*.json`, `weight_*.h5`, `test_eval.npy`, `train_eval.npy` files were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hist_0.json',\n",
       " 'weight_2.h5',\n",
       " 'test_eval.npy',\n",
       " 'weight_0.h5',\n",
       " 'train_eval.npy',\n",
       " 'hist_2.json',\n",
       " 'weight_1.h5',\n",
       " 'hist_1.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_info['model_info']['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the history files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8V7pPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3e0dfacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42274556, 0.83999997, 0.98224854, 0.54320985, 0.73045677,\n",
       "        0.90605599],\n",
       "       [0.30406281, 0.88800001, 0.954023  , 0.7368421 , 0.83842969,\n",
       "        0.93277377],\n",
       "       [0.24281755, 0.90399998, 0.92696631, 0.84722221, 0.88619775,\n",
       "        0.9503355 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4147054 , 0.81733334, 0.94980693, 0.52155173, 0.70382774,\n",
       "        0.8984614 ],\n",
       "       [0.2018193 , 0.92799997, 0.97619045, 0.79901963, 0.88317347,\n",
       "        0.97029197],\n",
       "       [0.21236309, 0.9173333 , 0.9041096 , 0.94560671, 0.9246254 ,\n",
       "        0.9674688 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the pre-trained network for training\n",
    "\n",
    "If you have pre-trianed model, you can use the pre-trained weight for next training. For using pre-trained weights, you have to use `warm_start` option in `training_inro` with addding the file path of the pre-trained weights in the `warm_start_model` option. Below is the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warm_start_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'training_info': {\n",
    "        'warm_start':'True',\n",
    "        'warm_start_model':'./example_result/weight.h5',\n",
    "        'batch_size': '200',\n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 798us/step - loss: 0.4161 - binary_accuracy: 0.8133 - sensitivity: 0.9660 - specificity: 0.4726 - gmeasure: 0.6735 - auc: 0.9011 - val_loss: 0.4189 - val_binary_accuracy: 0.8133 - val_sensitivity: 0.9333 - val_specificity: 0.5333 - val_gmeasure: 0.7055 - val_auc: 0.8899\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.4156 - binary_accuracy: 0.8400 - sensitivity: 0.9351 - specificity: 0.6339 - gmeasure: 0.7691 - auc: 0.9019 - val_loss: 0.4145 - val_binary_accuracy: 0.7867 - val_sensitivity: 0.9333 - val_specificity: 0.4444 - val_gmeasure: 0.6441 - val_auc: 0.8912\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4073 - binary_accuracy: 0.8133 - sensitivity: 0.9659 - specificity: 0.4756 - gmeasure: 0.6775 - auc: 0.9035 - val_loss: 0.4166 - val_binary_accuracy: 0.7800 - val_sensitivity: 0.9714 - val_specificity: 0.3333 - val_gmeasure: 0.5690 - val_auc: 0.8912\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4078 - binary_accuracy: 0.8133 - sensitivity: 0.9642 - specificity: 0.4830 - gmeasure: 0.6788 - auc: 0.9045 - val_loss: 0.4088 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9333 - val_specificity: 0.4667 - val_gmeasure: 0.6600 - val_auc: 0.8931\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4031 - binary_accuracy: 0.8350 - sensitivity: 0.9490 - specificity: 0.5833 - gmeasure: 0.7434 - auc: 0.9039 - val_loss: 0.4063 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.8954\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.4008 - binary_accuracy: 0.8267 - sensitivity: 0.9541 - specificity: 0.5476 - gmeasure: 0.7209 - auc: 0.9049 - val_loss: 0.4048 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9714 - val_specificity: 0.4000 - val_gmeasure: 0.6234 - val_auc: 0.8963\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3978 - binary_accuracy: 0.8233 - sensitivity: 0.9637 - specificity: 0.5146 - gmeasure: 0.7036 - auc: 0.9061 - val_loss: 0.4002 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9429 - val_specificity: 0.4444 - val_gmeasure: 0.6473 - val_auc: 0.8984\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.3939 - binary_accuracy: 0.8400 - sensitivity: 0.9520 - specificity: 0.5880 - gmeasure: 0.7470 - auc: 0.9066 - val_loss: 0.3985 - val_binary_accuracy: 0.8200 - val_sensitivity: 0.9048 - val_specificity: 0.6222 - val_gmeasure: 0.7503 - val_auc: 0.9005\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3922 - binary_accuracy: 0.8433 - sensitivity: 0.9468 - specificity: 0.6178 - gmeasure: 0.7635 - auc: 0.9069 - val_loss: 0.3941 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9333 - val_specificity: 0.4889 - val_gmeasure: 0.6755 - val_auc: 0.9018\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3886 - binary_accuracy: 0.8350 - sensitivity: 0.9561 - specificity: 0.5646 - gmeasure: 0.7345 - auc: 0.9071 - val_loss: 0.3918 - val_binary_accuracy: 0.7933 - val_sensitivity: 0.9429 - val_specificity: 0.4444 - val_gmeasure: 0.6473 - val_auc: 0.9035\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.3860 - binary_accuracy: 0.8350 - sensitivity: 0.9587 - specificity: 0.5593 - gmeasure: 0.7312 - auc: 0.9108 - val_loss: 0.3882 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.9048\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3840 - binary_accuracy: 0.8483 - sensitivity: 0.9522 - specificity: 0.6200 - gmeasure: 0.7680 - auc: 0.9108 - val_loss: 0.3857 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9060\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3804 - binary_accuracy: 0.8450 - sensitivity: 0.9515 - specificity: 0.6083 - gmeasure: 0.7599 - auc: 0.9101 - val_loss: 0.3827 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9333 - val_specificity: 0.4889 - val_gmeasure: 0.6755 - val_auc: 0.9067\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.3786 - binary_accuracy: 0.8433 - sensitivity: 0.9567 - specificity: 0.5939 - gmeasure: 0.7535 - auc: 0.9127 - val_loss: 0.3799 - val_binary_accuracy: 0.8067 - val_sensitivity: 0.9333 - val_specificity: 0.5111 - val_gmeasure: 0.6907 - val_auc: 0.9073\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.3750 - binary_accuracy: 0.8450 - sensitivity: 0.9491 - specificity: 0.6152 - gmeasure: 0.7630 - auc: 0.9127 - val_loss: 0.3778 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9143 - val_specificity: 0.6444 - val_gmeasure: 0.7676 - val_auc: 0.9090\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3732 - binary_accuracy: 0.8433 - sensitivity: 0.9417 - specificity: 0.6266 - gmeasure: 0.7680 - auc: 0.9141 - val_loss: 0.3744 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9096\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.3714 - binary_accuracy: 0.8467 - sensitivity: 0.9565 - specificity: 0.6010 - gmeasure: 0.7564 - auc: 0.9176 - val_loss: 0.3719 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9109\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3680 - binary_accuracy: 0.8433 - sensitivity: 0.9486 - specificity: 0.6070 - gmeasure: 0.7577 - auc: 0.9152 - val_loss: 0.3699 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9143 - val_specificity: 0.6444 - val_gmeasure: 0.7676 - val_auc: 0.9117\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3673 - binary_accuracy: 0.8483 - sensitivity: 0.9442 - specificity: 0.6390 - gmeasure: 0.7746 - auc: 0.9177 - val_loss: 0.3670 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9333 - val_specificity: 0.5778 - val_gmeasure: 0.7343 - val_auc: 0.9128\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3632 - binary_accuracy: 0.8483 - sensitivity: 0.9446 - specificity: 0.6366 - gmeasure: 0.7753 - auc: 0.9174 - val_loss: 0.3654 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9143\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3615 - binary_accuracy: 0.8467 - sensitivity: 0.9397 - specificity: 0.6420 - gmeasure: 0.7761 - auc: 0.9191 - val_loss: 0.3627 - val_binary_accuracy: 0.8267 - val_sensitivity: 0.9048 - val_specificity: 0.6444 - val_gmeasure: 0.7636 - val_auc: 0.9147\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3587 - binary_accuracy: 0.8483 - sensitivity: 0.9424 - specificity: 0.6433 - gmeasure: 0.7781 - auc: 0.9205 - val_loss: 0.3609 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9151\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3565 - binary_accuracy: 0.8483 - sensitivity: 0.9394 - specificity: 0.6471 - gmeasure: 0.7796 - auc: 0.9198 - val_loss: 0.3587 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9156\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3542 - binary_accuracy: 0.8467 - sensitivity: 0.9420 - specificity: 0.6307 - gmeasure: 0.7692 - auc: 0.9204 - val_loss: 0.3567 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9158\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3526 - binary_accuracy: 0.8483 - sensitivity: 0.9395 - specificity: 0.6460 - gmeasure: 0.7790 - auc: 0.9211 - val_loss: 0.3547 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9048 - val_specificity: 0.6667 - val_gmeasure: 0.7766 - val_auc: 0.9164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.3506 - binary_accuracy: 0.8467 - sensitivity: 0.9449 - specificity: 0.6263 - gmeasure: 0.7678 - auc: 0.9208 - val_loss: 0.3533 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.9048 - val_specificity: 0.7333 - val_gmeasure: 0.8146 - val_auc: 0.9157\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3492 - binary_accuracy: 0.8500 - sensitivity: 0.9352 - specificity: 0.6637 - gmeasure: 0.7876 - auc: 0.9225 - val_loss: 0.3508 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9048 - val_specificity: 0.6889 - val_gmeasure: 0.7895 - val_auc: 0.9168\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.3482 - binary_accuracy: 0.8533 - sensitivity: 0.9469 - specificity: 0.6480 - gmeasure: 0.7831 - auc: 0.9234 - val_loss: 0.3490 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.9048 - val_specificity: 0.6889 - val_gmeasure: 0.7895 - val_auc: 0.9178\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3470 - binary_accuracy: 0.8533 - sensitivity: 0.9282 - specificity: 0.6864 - gmeasure: 0.7970 - auc: 0.9226 - val_loss: 0.3525 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8667 - val_specificity: 0.8222 - val_gmeasure: 0.8442 - val_auc: 0.9184\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3440 - binary_accuracy: 0.8600 - sensitivity: 0.9371 - specificity: 0.6873 - gmeasure: 0.8018 - auc: 0.9253 - val_loss: 0.3479 - val_binary_accuracy: 0.8333 - val_sensitivity: 0.9333 - val_specificity: 0.6000 - val_gmeasure: 0.7483 - val_auc: 0.9189\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.3448 - binary_accuracy: 0.8433 - sensitivity: 0.9405 - specificity: 0.6322 - gmeasure: 0.7699 - auc: 0.9287 - val_loss: 0.3460 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8762 - val_specificity: 0.7778 - val_gmeasure: 0.8255 - val_auc: 0.9186\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3418 - binary_accuracy: 0.8567 - sensitivity: 0.9365 - specificity: 0.6803 - gmeasure: 0.7969 - auc: 0.9259 - val_loss: 0.3430 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9048 - val_specificity: 0.7111 - val_gmeasure: 0.8021 - val_auc: 0.9188\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3399 - binary_accuracy: 0.8550 - sensitivity: 0.9272 - specificity: 0.7004 - gmeasure: 0.8045 - auc: 0.9258 - val_loss: 0.3453 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9203\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.3345 - binary_accuracy: 0.8600 - sensitivity: 0.9322 - specificity: 0.7052 - gmeasure: 0.8106 - auc: 0.9277 - val_loss: 0.3405 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9238 - val_specificity: 0.7111 - val_gmeasure: 0.8105 - val_auc: 0.9194\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3343 - binary_accuracy: 0.8533 - sensitivity: 0.9487 - specificity: 0.6406 - gmeasure: 0.7793 - auc: 0.9256 - val_loss: 0.3387 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.9048 - val_specificity: 0.7111 - val_gmeasure: 0.8021 - val_auc: 0.9212\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.3308 - binary_accuracy: 0.8650 - sensitivity: 0.9400 - specificity: 0.6971 - gmeasure: 0.8086 - auc: 0.9273 - val_loss: 0.3402 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8667 - val_specificity: 0.8222 - val_gmeasure: 0.8442 - val_auc: 0.9224\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3308 - binary_accuracy: 0.8550 - sensitivity: 0.9254 - specificity: 0.6997 - gmeasure: 0.8046 - auc: 0.9280 - val_loss: 0.3364 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9226\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3282 - binary_accuracy: 0.8600 - sensitivity: 0.9336 - specificity: 0.6934 - gmeasure: 0.8035 - auc: 0.9294 - val_loss: 0.3353 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9233\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.3267 - binary_accuracy: 0.8617 - sensitivity: 0.9374 - specificity: 0.6917 - gmeasure: 0.8046 - auc: 0.9300 - val_loss: 0.3340 - val_binary_accuracy: 0.8400 - val_sensitivity: 0.8857 - val_specificity: 0.7333 - val_gmeasure: 0.8059 - val_auc: 0.9230\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.3254 - binary_accuracy: 0.8600 - sensitivity: 0.9352 - specificity: 0.6952 - gmeasure: 0.8055 - auc: 0.9323 - val_loss: 0.3325 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8952 - val_specificity: 0.7333 - val_gmeasure: 0.8103 - val_auc: 0.9222\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3238 - binary_accuracy: 0.8583 - sensitivity: 0.9396 - specificity: 0.6814 - gmeasure: 0.8000 - auc: 0.9297 - val_loss: 0.3318 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9221\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 0.3228 - binary_accuracy: 0.8617 - sensitivity: 0.9225 - specificity: 0.7277 - gmeasure: 0.8191 - auc: 0.9316 - val_loss: 0.3324 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9238\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.3210 - binary_accuracy: 0.8633 - sensitivity: 0.9321 - specificity: 0.7130 - gmeasure: 0.8145 - auc: 0.9321 - val_loss: 0.3296 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9333 - val_specificity: 0.7111 - val_gmeasure: 0.8147 - val_auc: 0.9243\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.3210 - binary_accuracy: 0.8583 - sensitivity: 0.9488 - specificity: 0.6593 - gmeasure: 0.7908 - auc: 0.9303 - val_loss: 0.3281 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8857 - val_specificity: 0.8222 - val_gmeasure: 0.8534 - val_auc: 0.9244\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.3197 - binary_accuracy: 0.8650 - sensitivity: 0.9181 - specificity: 0.7495 - gmeasure: 0.8293 - auc: 0.9322 - val_loss: 0.3280 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8571 - val_specificity: 0.8222 - val_gmeasure: 0.8395 - val_auc: 0.9255\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3195 - binary_accuracy: 0.8583 - sensitivity: 0.9356 - specificity: 0.6931 - gmeasure: 0.8041 - auc: 0.9326 - val_loss: 0.3255 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9333 - val_specificity: 0.7556 - val_gmeasure: 0.8398 - val_auc: 0.9244\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3187 - binary_accuracy: 0.8650 - sensitivity: 0.9283 - specificity: 0.7343 - gmeasure: 0.8244 - auc: 0.9355 - val_loss: 0.3271 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8571 - val_specificity: 0.8444 - val_gmeasure: 0.8508 - val_auc: 0.9259\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.3133 - binary_accuracy: 0.8683 - sensitivity: 0.9177 - specificity: 0.7593 - gmeasure: 0.8345 - auc: 0.9339 - val_loss: 0.3224 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8952 - val_specificity: 0.7556 - val_gmeasure: 0.8224 - val_auc: 0.9268\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3132 - binary_accuracy: 0.8617 - sensitivity: 0.9438 - specificity: 0.6811 - gmeasure: 0.8014 - auc: 0.9345 - val_loss: 0.3214 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9270\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3117 - binary_accuracy: 0.8667 - sensitivity: 0.9269 - specificity: 0.7361 - gmeasure: 0.8257 - auc: 0.9343 - val_loss: 0.3223 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3110 - binary_accuracy: 0.8600 - sensitivity: 0.9298 - specificity: 0.7065 - gmeasure: 0.8084 - auc: 0.9351 - val_loss: 0.3193 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9266\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.3082 - binary_accuracy: 0.8683 - sensitivity: 0.9323 - specificity: 0.7269 - gmeasure: 0.8225 - auc: 0.9360 - val_loss: 0.3195 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9268\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3065 - binary_accuracy: 0.8667 - sensitivity: 0.9199 - specificity: 0.7479 - gmeasure: 0.8290 - auc: 0.9370 - val_loss: 0.3173 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9261\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.3071 - binary_accuracy: 0.8667 - sensitivity: 0.9444 - specificity: 0.6953 - gmeasure: 0.8091 - auc: 0.9370 - val_loss: 0.3166 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8857 - val_specificity: 0.8000 - val_gmeasure: 0.8418 - val_auc: 0.9272\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.3039 - binary_accuracy: 0.8650 - sensitivity: 0.9321 - specificity: 0.7202 - gmeasure: 0.8189 - auc: 0.9384 - val_loss: 0.3185 - val_binary_accuracy: 0.8533 - val_sensitivity: 0.8571 - val_specificity: 0.8444 - val_gmeasure: 0.8508 - val_auc: 0.9278\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.3042 - binary_accuracy: 0.8650 - sensitivity: 0.9130 - specificity: 0.7628 - gmeasure: 0.8334 - auc: 0.9397 - val_loss: 0.3165 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9266\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3019 - binary_accuracy: 0.8633 - sensitivity: 0.9082 - specificity: 0.7643 - gmeasure: 0.8331 - auc: 0.9363 - val_loss: 0.3146 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9268\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.3006 - binary_accuracy: 0.8650 - sensitivity: 0.9275 - specificity: 0.7269 - gmeasure: 0.8204 - auc: 0.9363 - val_loss: 0.3129 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9048 - val_specificity: 0.7778 - val_gmeasure: 0.8389 - val_auc: 0.9270\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2992 - binary_accuracy: 0.8633 - sensitivity: 0.9317 - specificity: 0.7089 - gmeasure: 0.8126 - auc: 0.9389 - val_loss: 0.3142 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9270\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.2981 - binary_accuracy: 0.8700 - sensitivity: 0.9178 - specificity: 0.7649 - gmeasure: 0.8377 - auc: 0.9384 - val_loss: 0.3117 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9280\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.2988 - binary_accuracy: 0.8683 - sensitivity: 0.9350 - specificity: 0.7239 - gmeasure: 0.8219 - auc: 0.9397 - val_loss: 0.3106 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9283\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2950 - binary_accuracy: 0.8733 - sensitivity: 0.9276 - specificity: 0.7534 - gmeasure: 0.8358 - auc: 0.9394 - val_loss: 0.3132 - val_binary_accuracy: 0.8467 - val_sensitivity: 0.8476 - val_specificity: 0.8444 - val_gmeasure: 0.8460 - val_auc: 0.9291\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.2954 - binary_accuracy: 0.8717 - sensitivity: 0.9079 - specificity: 0.7937 - gmeasure: 0.8485 - auc: 0.9404 - val_loss: 0.3086 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9285\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2935 - binary_accuracy: 0.8700 - sensitivity: 0.9350 - specificity: 0.7286 - gmeasure: 0.8245 - auc: 0.9413 - val_loss: 0.3075 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9048 - val_specificity: 0.8000 - val_gmeasure: 0.8508 - val_auc: 0.9280\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.2932 - binary_accuracy: 0.8750 - sensitivity: 0.9318 - specificity: 0.7448 - gmeasure: 0.8317 - auc: 0.9392 - val_loss: 0.3090 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.8667 - val_specificity: 0.8444 - val_gmeasure: 0.8555 - val_auc: 0.9283\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.2913 - binary_accuracy: 0.8717 - sensitivity: 0.9225 - specificity: 0.7579 - gmeasure: 0.8356 - auc: 0.9425 - val_loss: 0.3060 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9295\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2899 - binary_accuracy: 0.8750 - sensitivity: 0.9277 - specificity: 0.7580 - gmeasure: 0.8385 - auc: 0.9418 - val_loss: 0.3071 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9287\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2891 - binary_accuracy: 0.8733 - sensitivity: 0.9225 - specificity: 0.7648 - gmeasure: 0.8399 - auc: 0.9423 - val_loss: 0.3047 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9291\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2880 - binary_accuracy: 0.8750 - sensitivity: 0.9322 - specificity: 0.7482 - gmeasure: 0.8350 - auc: 0.9443 - val_loss: 0.3054 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9297\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2877 - binary_accuracy: 0.8717 - sensitivity: 0.9153 - specificity: 0.7777 - gmeasure: 0.8427 - auc: 0.9446 - val_loss: 0.3048 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9306\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2868 - binary_accuracy: 0.8800 - sensitivity: 0.9354 - specificity: 0.7615 - gmeasure: 0.8436 - auc: 0.9440 - val_loss: 0.3021 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9299\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2847 - binary_accuracy: 0.8733 - sensitivity: 0.9226 - specificity: 0.7643 - gmeasure: 0.8397 - auc: 0.9430 - val_loss: 0.3027 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9308\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2845 - binary_accuracy: 0.8767 - sensitivity: 0.9273 - specificity: 0.7601 - gmeasure: 0.8384 - auc: 0.9444 - val_loss: 0.3006 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9299\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.2828 - binary_accuracy: 0.8767 - sensitivity: 0.9175 - specificity: 0.7855 - gmeasure: 0.8488 - auc: 0.9452 - val_loss: 0.3015 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9310\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2840 - binary_accuracy: 0.8733 - sensitivity: 0.9297 - specificity: 0.7499 - gmeasure: 0.8334 - auc: 0.9449 - val_loss: 0.2998 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8857 - val_specificity: 0.8444 - val_gmeasure: 0.8648 - val_auc: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2849 - binary_accuracy: 0.8683 - sensitivity: 0.9091 - specificity: 0.7837 - gmeasure: 0.8437 - auc: 0.9462 - val_loss: 0.3021 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9319\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 0.2785 - binary_accuracy: 0.8800 - sensitivity: 0.9294 - specificity: 0.7682 - gmeasure: 0.8449 - auc: 0.9456 - val_loss: 0.2988 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9238 - val_specificity: 0.8222 - val_gmeasure: 0.8715 - val_auc: 0.9319\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2814 - binary_accuracy: 0.8717 - sensitivity: 0.9419 - specificity: 0.7165 - gmeasure: 0.8215 - auc: 0.9460 - val_loss: 0.3012 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9321\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2821 - binary_accuracy: 0.8783 - sensitivity: 0.9042 - specificity: 0.8226 - gmeasure: 0.8623 - auc: 0.9457 - val_loss: 0.2994 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8762 - val_specificity: 0.8444 - val_gmeasure: 0.8602 - val_auc: 0.9312\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2787 - binary_accuracy: 0.8700 - sensitivity: 0.9222 - specificity: 0.7523 - gmeasure: 0.8321 - auc: 0.9463 - val_loss: 0.2957 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9048 - val_specificity: 0.8222 - val_gmeasure: 0.8625 - val_auc: 0.9319\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2862 - binary_accuracy: 0.8783 - sensitivity: 0.9164 - specificity: 0.7968 - gmeasure: 0.8518 - auc: 0.9494 - val_loss: 0.3032 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9325\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.2783 - binary_accuracy: 0.8733 - sensitivity: 0.9301 - specificity: 0.7477 - gmeasure: 0.8331 - auc: 0.9480 - val_loss: 0.2971 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.9238 - val_specificity: 0.7333 - val_gmeasure: 0.8231 - val_auc: 0.9314\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.2755 - binary_accuracy: 0.8783 - sensitivity: 0.9371 - specificity: 0.7480 - gmeasure: 0.8367 - auc: 0.9468 - val_loss: 0.3026 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9325\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2768 - binary_accuracy: 0.8850 - sensitivity: 0.9068 - specificity: 0.8349 - gmeasure: 0.8695 - auc: 0.9464 - val_loss: 0.2946 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9325\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.2758 - binary_accuracy: 0.8750 - sensitivity: 0.9324 - specificity: 0.7502 - gmeasure: 0.8353 - auc: 0.9469 - val_loss: 0.2930 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9048 - val_specificity: 0.8444 - val_gmeasure: 0.8741 - val_auc: 0.9319\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.2721 - binary_accuracy: 0.8850 - sensitivity: 0.9255 - specificity: 0.7976 - gmeasure: 0.8590 - auc: 0.9491 - val_loss: 0.3022 - val_binary_accuracy: 0.8667 - val_sensitivity: 0.8571 - val_specificity: 0.8889 - val_gmeasure: 0.8729 - val_auc: 0.9335\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2725 - binary_accuracy: 0.8850 - sensitivity: 0.9152 - specificity: 0.8171 - gmeasure: 0.8636 - auc: 0.9490 - val_loss: 0.2924 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9143 - val_specificity: 0.8444 - val_gmeasure: 0.8787 - val_auc: 0.9323\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.2722 - binary_accuracy: 0.8850 - sensitivity: 0.9342 - specificity: 0.7765 - gmeasure: 0.8509 - auc: 0.9490 - val_loss: 0.2938 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9331\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.2690 - binary_accuracy: 0.8850 - sensitivity: 0.9225 - specificity: 0.8002 - gmeasure: 0.8583 - auc: 0.9486 - val_loss: 0.2916 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9333\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.2696 - binary_accuracy: 0.8833 - sensitivity: 0.9325 - specificity: 0.7728 - gmeasure: 0.8472 - auc: 0.9525 - val_loss: 0.2914 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9340\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.2668 - binary_accuracy: 0.8867 - sensitivity: 0.9347 - specificity: 0.7823 - gmeasure: 0.8548 - auc: 0.9502 - val_loss: 0.2902 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9329\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2662 - binary_accuracy: 0.8850 - sensitivity: 0.9324 - specificity: 0.7790 - gmeasure: 0.8519 - auc: 0.9494 - val_loss: 0.2932 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9327\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.2661 - binary_accuracy: 0.8850 - sensitivity: 0.9273 - specificity: 0.7941 - gmeasure: 0.8573 - auc: 0.9490 - val_loss: 0.2917 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.8952 - val_specificity: 0.8667 - val_gmeasure: 0.8808 - val_auc: 0.9333\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2650 - binary_accuracy: 0.8867 - sensitivity: 0.9211 - specificity: 0.8122 - gmeasure: 0.8649 - auc: 0.9512 - val_loss: 0.2894 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9335\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.2657 - binary_accuracy: 0.8850 - sensitivity: 0.9362 - specificity: 0.7670 - gmeasure: 0.8470 - auc: 0.9516 - val_loss: 0.2879 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9338\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.2621 - binary_accuracy: 0.8900 - sensitivity: 0.9274 - specificity: 0.8024 - gmeasure: 0.8621 - auc: 0.9504 - val_loss: 0.2961 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.8667 - val_specificity: 0.8889 - val_gmeasure: 0.8777 - val_auc: 0.9335\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.2632 - binary_accuracy: 0.8867 - sensitivity: 0.9177 - specificity: 0.8184 - gmeasure: 0.8666 - auc: 0.9510 - val_loss: 0.2869 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8952 - val_specificity: 0.8444 - val_gmeasure: 0.8695 - val_auc: 0.9344\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2661 - binary_accuracy: 0.8817 - sensitivity: 0.9368 - specificity: 0.7626 - gmeasure: 0.8450 - auc: 0.9505 - val_loss: 0.2898 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9348\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.2269 - binary_accuracy: 0.9200 - sensitivity: 0.9424 - specificity: 0.8689 - gmeasure: 0.9049 - auc: 0.96 - 0s 68us/step - loss: 0.2658 - binary_accuracy: 0.8967 - sensitivity: 0.9005 - specificity: 0.8876 - gmeasure: 0.8937 - auc: 0.9522 - val_loss: 0.2922 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.8857 - val_specificity: 0.8667 - val_gmeasure: 0.8761 - val_auc: 0.9337\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.2647 - binary_accuracy: 0.8850 - sensitivity: 0.9303 - specificity: 0.7891 - gmeasure: 0.8550 - auc: 0.9525 - val_loss: 0.2868 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9143 - val_specificity: 0.8000 - val_gmeasure: 0.8552 - val_auc: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 6.324186563491821!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 9us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.014736413955688477!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2681126594543457, 0.8786666393280029, 0.9343629479408264, 0.7543103694915771, 0.8395234942436218, 0.9488583207130432]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.012296676635742188!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2787688076496124, 0.8759999871253967, 0.9585798978805542, 0.7037037014961243, 0.8213136792182922, 0.9507268667221069]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.100970029830933\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 776us/step - loss: 0.1934 - binary_accuracy: 0.9283 - sensitivity: 0.9886 - specificity: 0.7692 - gmeasure: 0.8714 - auc: 0.9791 - val_loss: 0.2795 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9541 - val_specificity: 0.7561 - val_gmeasure: 0.8494 - val_auc: 0.9403\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1960 - binary_accuracy: 0.9350 - sensitivity: 0.9378 - specificity: 0.9263 - gmeasure: 0.9319 - auc: 0.9784 - val_loss: 0.2953 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9389\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1838 - binary_accuracy: 0.9200 - sensitivity: 0.9860 - specificity: 0.7399 - gmeasure: 0.8531 - auc: 0.9789 - val_loss: 0.3213 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9817 - val_specificity: 0.6341 - val_gmeasure: 0.7890 - val_auc: 0.9387\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1841 - binary_accuracy: 0.9267 - sensitivity: 0.9886 - specificity: 0.7627 - gmeasure: 0.8669 - auc: 0.9789 - val_loss: 0.2810 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9403\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1819 - binary_accuracy: 0.9483 - sensitivity: 0.9725 - specificity: 0.8844 - gmeasure: 0.9274 - auc: 0.9807 - val_loss: 0.2850 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9403\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1795 - binary_accuracy: 0.9350 - sensitivity: 0.9772 - specificity: 0.8229 - gmeasure: 0.8958 - auc: 0.9794 - val_loss: 0.3089 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9725 - val_specificity: 0.6585 - val_gmeasure: 0.8003 - val_auc: 0.9403\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1787 - binary_accuracy: 0.9217 - sensitivity: 0.9840 - specificity: 0.7521 - gmeasure: 0.8591 - auc: 0.9803 - val_loss: 0.2835 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9414\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1755 - binary_accuracy: 0.9433 - sensitivity: 0.9749 - specificity: 0.8587 - gmeasure: 0.9148 - auc: 0.9814 - val_loss: 0.2803 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9414\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1752 - binary_accuracy: 0.9367 - sensitivity: 0.9746 - specificity: 0.8369 - gmeasure: 0.9030 - auc: 0.9815 - val_loss: 0.2911 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9633 - val_specificity: 0.6829 - val_gmeasure: 0.8111 - val_auc: 0.9420\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1764 - binary_accuracy: 0.9300 - sensitivity: 0.9842 - specificity: 0.7870 - gmeasure: 0.8799 - auc: 0.9819 - val_loss: 0.2892 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9423\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1720 - binary_accuracy: 0.9417 - sensitivity: 0.9765 - specificity: 0.8434 - gmeasure: 0.9071 - auc: 0.9810 - val_loss: 0.2762 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9434\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1735 - binary_accuracy: 0.9450 - sensitivity: 0.9749 - specificity: 0.8623 - gmeasure: 0.9164 - auc: 0.9786 - val_loss: 0.2845 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9436\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1712 - binary_accuracy: 0.9400 - sensitivity: 0.9817 - specificity: 0.8289 - gmeasure: 0.9020 - auc: 0.9825 - val_loss: 0.2879 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9633 - val_specificity: 0.6829 - val_gmeasure: 0.8111 - val_auc: 0.9438\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1703 - binary_accuracy: 0.9400 - sensitivity: 0.9819 - specificity: 0.8273 - gmeasure: 0.9013 - auc: 0.9825 - val_loss: 0.2827 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1698 - binary_accuracy: 0.9367 - sensitivity: 0.9748 - specificity: 0.8359 - gmeasure: 0.9026 - auc: 0.9825 - val_loss: 0.2786 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1699 - binary_accuracy: 0.9350 - sensitivity: 0.9772 - specificity: 0.8221 - gmeasure: 0.8958 - auc: 0.9826 - val_loss: 0.2841 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9438\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1669 - binary_accuracy: 0.9367 - sensitivity: 0.9772 - specificity: 0.8261 - gmeasure: 0.8983 - auc: 0.9818 - val_loss: 0.2766 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9454\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1666 - binary_accuracy: 0.9417 - sensitivity: 0.9749 - specificity: 0.8496 - gmeasure: 0.9099 - auc: 0.9821 - val_loss: 0.2791 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9463\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 0.1671 - binary_accuracy: 0.9400 - sensitivity: 0.9778 - specificity: 0.8432 - gmeasure: 0.9079 - auc: 0.9838 - val_loss: 0.2791 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9467\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1645 - binary_accuracy: 0.9383 - sensitivity: 0.9772 - specificity: 0.8347 - gmeasure: 0.9031 - auc: 0.9821 - val_loss: 0.2854 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9458\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1662 - binary_accuracy: 0.9383 - sensitivity: 0.9801 - specificity: 0.8293 - gmeasure: 0.9015 - auc: 0.9824 - val_loss: 0.2750 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9465\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1630 - binary_accuracy: 0.9500 - sensitivity: 0.9747 - specificity: 0.8788 - gmeasure: 0.9253 - auc: 0.9833 - val_loss: 0.2795 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9467\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1622 - binary_accuracy: 0.9417 - sensitivity: 0.9818 - specificity: 0.8271 - gmeasure: 0.9003 - auc: 0.9820 - val_loss: 0.2842 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9474\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1609 - binary_accuracy: 0.9467 - sensitivity: 0.9789 - specificity: 0.8614 - gmeasure: 0.9183 - auc: 0.9843 - val_loss: 0.2722 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9483\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 0.1607 - binary_accuracy: 0.9467 - sensitivity: 0.9774 - specificity: 0.8655 - gmeasure: 0.9196 - auc: 0.9841 - val_loss: 0.2813 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.1597 - binary_accuracy: 0.9400 - sensitivity: 0.9770 - specificity: 0.8413 - gmeasure: 0.9062 - auc: 0.9837 - val_loss: 0.2759 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9633 - val_specificity: 0.7073 - val_gmeasure: 0.8254 - val_auc: 0.9488\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1594 - binary_accuracy: 0.9450 - sensitivity: 0.9748 - specificity: 0.8652 - gmeasure: 0.9182 - auc: 0.9841 - val_loss: 0.2703 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9497\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1582 - binary_accuracy: 0.9450 - sensitivity: 0.9749 - specificity: 0.8696 - gmeasure: 0.9204 - auc: 0.9853 - val_loss: 0.2787 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9499\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1568 - binary_accuracy: 0.9417 - sensitivity: 0.9795 - specificity: 0.8393 - gmeasure: 0.9065 - auc: 0.9839 - val_loss: 0.2750 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9497\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1551 - binary_accuracy: 0.9467 - sensitivity: 0.9757 - specificity: 0.8648 - gmeasure: 0.9185 - auc: 0.9862 - val_loss: 0.2679 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9505\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 0.1549 - binary_accuracy: 0.9517 - sensitivity: 0.9726 - specificity: 0.8931 - gmeasure: 0.9318 - auc: 0.9846 - val_loss: 0.2760 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9503\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1536 - binary_accuracy: 0.9433 - sensitivity: 0.9796 - specificity: 0.8452 - gmeasure: 0.9099 - auc: 0.9850 - val_loss: 0.2781 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9508\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1546 - binary_accuracy: 0.9467 - sensitivity: 0.9772 - specificity: 0.8660 - gmeasure: 0.9198 - auc: 0.9845 - val_loss: 0.2668 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9517\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1516 - binary_accuracy: 0.9550 - sensitivity: 0.9794 - specificity: 0.8846 - gmeasure: 0.9302 - auc: 0.9869 - val_loss: 0.2767 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9510\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1543 - binary_accuracy: 0.9433 - sensitivity: 0.9814 - specificity: 0.8438 - gmeasure: 0.9097 - auc: 0.9865 - val_loss: 0.2711 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9521\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1502 - binary_accuracy: 0.9517 - sensitivity: 0.9770 - specificity: 0.8874 - gmeasure: 0.9309 - auc: 0.9855 - val_loss: 0.2612 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9633 - val_specificity: 0.7317 - val_gmeasure: 0.8396 - val_auc: 0.9535\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 0.1496 - binary_accuracy: 0.9567 - sensitivity: 0.9796 - specificity: 0.8870 - gmeasure: 0.9317 - auc: 0.9855 - val_loss: 0.2788 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9725 - val_specificity: 0.7073 - val_gmeasure: 0.8294 - val_auc: 0.9526\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 0.1503 - binary_accuracy: 0.9450 - sensitivity: 0.9822 - specificity: 0.8434 - gmeasure: 0.9101 - auc: 0.9854 - val_loss: 0.2736 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9532\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1473 - binary_accuracy: 0.9550 - sensitivity: 0.9814 - specificity: 0.8816 - gmeasure: 0.9296 - auc: 0.9852 - val_loss: 0.2570 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9633 - val_specificity: 0.7561 - val_gmeasure: 0.8534 - val_auc: 0.9535\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1531 - binary_accuracy: 0.9467 - sensitivity: 0.9791 - specificity: 0.8593 - gmeasure: 0.9160 - auc: 0.9874 - val_loss: 0.2768 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9523\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1487 - binary_accuracy: 0.9467 - sensitivity: 0.9723 - specificity: 0.8782 - gmeasure: 0.9237 - auc: 0.9879 - val_loss: 0.2581 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9539\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1512 - binary_accuracy: 0.9467 - sensitivity: 0.9749 - specificity: 0.8771 - gmeasure: 0.9244 - auc: 0.9881 - val_loss: 0.2732 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9530\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1427 - binary_accuracy: 0.9467 - sensitivity: 0.9763 - specificity: 0.8665 - gmeasure: 0.9197 - auc: 0.9859 - val_loss: 0.2518 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9550\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1461 - binary_accuracy: 0.9533 - sensitivity: 0.9678 - specificity: 0.9129 - gmeasure: 0.9398 - auc: 0.9874 - val_loss: 0.2635 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9546\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1467 - binary_accuracy: 0.9500 - sensitivity: 0.9856 - specificity: 0.8507 - gmeasure: 0.9144 - auc: 0.9858 - val_loss: 0.2750 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9817 - val_specificity: 0.7073 - val_gmeasure: 0.8333 - val_auc: 0.9537\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1435 - binary_accuracy: 0.9517 - sensitivity: 0.9796 - specificity: 0.8668 - gmeasure: 0.9206 - auc: 0.9856 - val_loss: 0.2456 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9633 - val_specificity: 0.8049 - val_gmeasure: 0.8805 - val_auc: 0.9561\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1449 - binary_accuracy: 0.9500 - sensitivity: 0.9625 - specificity: 0.9125 - gmeasure: 0.9370 - auc: 0.9878 - val_loss: 0.2740 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9817 - val_specificity: 0.7073 - val_gmeasure: 0.8333 - val_auc: 0.9544\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1426 - binary_accuracy: 0.9450 - sensitivity: 0.9862 - specificity: 0.8330 - gmeasure: 0.9061 - auc: 0.9869 - val_loss: 0.2589 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9725 - val_specificity: 0.7317 - val_gmeasure: 0.8435 - val_auc: 0.9559\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1390 - binary_accuracy: 0.9600 - sensitivity: 0.9781 - specificity: 0.9164 - gmeasure: 0.9464 - auc: 0.9880 - val_loss: 0.2492 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9570\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1401 - binary_accuracy: 0.9483 - sensitivity: 0.9793 - specificity: 0.8655 - gmeasure: 0.9206 - auc: 0.9870 - val_loss: 0.2672 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1361 - binary_accuracy: 0.9550 - sensitivity: 0.9841 - specificity: 0.8817 - gmeasure: 0.9309 - auc: 0.9883 - val_loss: 0.2478 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9575\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1368 - binary_accuracy: 0.9600 - sensitivity: 0.9746 - specificity: 0.9152 - gmeasure: 0.9442 - auc: 0.9895 - val_loss: 0.2476 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9579\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1363 - binary_accuracy: 0.9583 - sensitivity: 0.9864 - specificity: 0.8849 - gmeasure: 0.9340 - auc: 0.9876 - val_loss: 0.2665 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9817 - val_specificity: 0.7317 - val_gmeasure: 0.8475 - val_auc: 0.9573\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1336 - binary_accuracy: 0.9550 - sensitivity: 0.9863 - specificity: 0.8702 - gmeasure: 0.9263 - auc: 0.9877 - val_loss: 0.2429 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1346 - binary_accuracy: 0.9633 - sensitivity: 0.9722 - specificity: 0.9385 - gmeasure: 0.9551 - auc: 0.9883 - val_loss: 0.2508 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1339 - binary_accuracy: 0.9550 - sensitivity: 0.9864 - specificity: 0.8719 - gmeasure: 0.9269 - auc: 0.9889 - val_loss: 0.2592 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9575\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1304 - binary_accuracy: 0.9600 - sensitivity: 0.9864 - specificity: 0.8903 - gmeasure: 0.9367 - auc: 0.9894 - val_loss: 0.2392 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9584\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1315 - binary_accuracy: 0.9633 - sensitivity: 0.9748 - specificity: 0.9333 - gmeasure: 0.9537 - auc: 0.9893 - val_loss: 0.2513 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9582\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1319 - binary_accuracy: 0.9583 - sensitivity: 0.9863 - specificity: 0.8844 - gmeasure: 0.9338 - auc: 0.9891 - val_loss: 0.2540 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9579\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1273 - binary_accuracy: 0.9600 - sensitivity: 0.9814 - specificity: 0.9007 - gmeasure: 0.9401 - auc: 0.9895 - val_loss: 0.2390 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1295 - binary_accuracy: 0.9617 - sensitivity: 0.9819 - specificity: 0.9118 - gmeasure: 0.9450 - auc: 0.9893 - val_loss: 0.2518 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9584\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1268 - binary_accuracy: 0.9600 - sensitivity: 0.9840 - specificity: 0.8955 - gmeasure: 0.9384 - auc: 0.9889 - val_loss: 0.2437 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9586\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1260 - binary_accuracy: 0.9633 - sensitivity: 0.9840 - specificity: 0.9072 - gmeasure: 0.9445 - auc: 0.9891 - val_loss: 0.2449 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9588\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1256 - binary_accuracy: 0.9600 - sensitivity: 0.9839 - specificity: 0.9024 - gmeasure: 0.9418 - auc: 0.9894 - val_loss: 0.2421 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9591\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1254 - binary_accuracy: 0.9617 - sensitivity: 0.9864 - specificity: 0.8983 - gmeasure: 0.9409 - auc: 0.9901 - val_loss: 0.2447 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9591\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1229 - binary_accuracy: 0.9600 - sensitivity: 0.9793 - specificity: 0.9110 - gmeasure: 0.9444 - auc: 0.9898 - val_loss: 0.2375 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9593\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1227 - binary_accuracy: 0.9683 - sensitivity: 0.9794 - specificity: 0.9377 - gmeasure: 0.9583 - auc: 0.9897 - val_loss: 0.2462 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9593\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1240 - binary_accuracy: 0.9600 - sensitivity: 0.9865 - specificity: 0.8930 - gmeasure: 0.9382 - auc: 0.9899 - val_loss: 0.2423 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9593\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1206 - binary_accuracy: 0.9667 - sensitivity: 0.9816 - specificity: 0.9274 - gmeasure: 0.9540 - auc: 0.9897 - val_loss: 0.2347 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9599\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1208 - binary_accuracy: 0.9683 - sensitivity: 0.9795 - specificity: 0.9417 - gmeasure: 0.9603 - auc: 0.9897 - val_loss: 0.2439 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9599\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1252 - binary_accuracy: 0.9550 - sensitivity: 0.9865 - specificity: 0.8785 - gmeasure: 0.9304 - auc: 0.9907 - val_loss: 0.2431 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9599\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1220 - binary_accuracy: 0.9633 - sensitivity: 0.9749 - specificity: 0.9338 - gmeasure: 0.9540 - auc: 0.9905 - val_loss: 0.2312 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9602\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1204 - binary_accuracy: 0.9617 - sensitivity: 0.9794 - specificity: 0.9148 - gmeasure: 0.9462 - auc: 0.9903 - val_loss: 0.2503 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9597\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1176 - binary_accuracy: 0.9650 - sensitivity: 0.9885 - specificity: 0.9019 - gmeasure: 0.9441 - auc: 0.9900 - val_loss: 0.2335 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9725 - val_specificity: 0.7561 - val_gmeasure: 0.8575 - val_auc: 0.9599\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1202 - binary_accuracy: 0.9650 - sensitivity: 0.9746 - specificity: 0.9387 - gmeasure: 0.9565 - auc: 0.9900 - val_loss: 0.2382 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1248 - binary_accuracy: 0.9617 - sensitivity: 0.9909 - specificity: 0.8839 - gmeasure: 0.9355 - auc: 0.9907 - val_loss: 0.2476 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1237 - binary_accuracy: 0.9617 - sensitivity: 0.9710 - specificity: 0.9383 - gmeasure: 0.9539 - auc: 0.9908 - val_loss: 0.2245 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9611\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1163 - binary_accuracy: 0.9683 - sensitivity: 0.9822 - specificity: 0.9322 - gmeasure: 0.9568 - auc: 0.9903 - val_loss: 0.2657 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9595\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1260 - binary_accuracy: 0.9583 - sensitivity: 0.9953 - specificity: 0.8647 - gmeasure: 0.9266 - auc: 0.9915 - val_loss: 0.2325 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9602\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1280 - binary_accuracy: 0.9567 - sensitivity: 0.9587 - specificity: 0.9502 - gmeasure: 0.9542 - auc: 0.9904 - val_loss: 0.2232 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9633 - val_specificity: 0.8293 - val_gmeasure: 0.8938 - val_auc: 0.9613\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1224 - binary_accuracy: 0.9583 - sensitivity: 0.9841 - specificity: 0.8913 - gmeasure: 0.9362 - auc: 0.9908 - val_loss: 0.2714 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9595\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1171 - binary_accuracy: 0.9683 - sensitivity: 0.9933 - specificity: 0.9041 - gmeasure: 0.9475 - auc: 0.9917 - val_loss: 0.2228 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9725 - val_specificity: 0.8293 - val_gmeasure: 0.8980 - val_auc: 0.9620\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1203 - binary_accuracy: 0.9633 - sensitivity: 0.9634 - specificity: 0.9622 - gmeasure: 0.9628 - auc: 0.9909 - val_loss: 0.2275 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9617\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1166 - binary_accuracy: 0.9617 - sensitivity: 0.9886 - specificity: 0.8876 - gmeasure: 0.9360 - auc: 0.9914 - val_loss: 0.2597 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9908 - val_specificity: 0.7317 - val_gmeasure: 0.8515 - val_auc: 0.9613\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1147 - binary_accuracy: 0.9683 - sensitivity: 0.9886 - specificity: 0.9138 - gmeasure: 0.9502 - auc: 0.9910 - val_loss: 0.2221 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9725 - val_specificity: 0.8293 - val_gmeasure: 0.8980 - val_auc: 0.9622\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1145 - binary_accuracy: 0.9717 - sensitivity: 0.9817 - specificity: 0.9455 - gmeasure: 0.9632 - auc: 0.9910 - val_loss: 0.2378 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9617\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1100 - binary_accuracy: 0.9683 - sensitivity: 0.9887 - specificity: 0.9168 - gmeasure: 0.9520 - auc: 0.9901 - val_loss: 0.2325 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1092 - binary_accuracy: 0.9700 - sensitivity: 0.9793 - specificity: 0.9458 - gmeasure: 0.9624 - auc: 0.9914 - val_loss: 0.2246 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9725 - val_specificity: 0.7805 - val_gmeasure: 0.8712 - val_auc: 0.9626\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1085 - binary_accuracy: 0.9750 - sensitivity: 0.9861 - specificity: 0.9445 - gmeasure: 0.9651 - auc: 0.9914 - val_loss: 0.2365 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9622\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1081 - binary_accuracy: 0.9750 - sensitivity: 0.9919 - specificity: 0.9301 - gmeasure: 0.9605 - auc: 0.9920 - val_loss: 0.2343 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1070 - binary_accuracy: 0.9733 - sensitivity: 0.9886 - specificity: 0.9319 - gmeasure: 0.9598 - auc: 0.9914 - val_loss: 0.2317 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9620\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1066 - binary_accuracy: 0.9717 - sensitivity: 0.9857 - specificity: 0.9397 - gmeasure: 0.9623 - auc: 0.9910 - val_loss: 0.2289 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9624\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1057 - binary_accuracy: 0.9717 - sensitivity: 0.9865 - specificity: 0.9304 - gmeasure: 0.9578 - auc: 0.9914 - val_loss: 0.2312 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9622\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1056 - binary_accuracy: 0.9717 - sensitivity: 0.9863 - specificity: 0.9336 - gmeasure: 0.9594 - auc: 0.9925 - val_loss: 0.2324 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9629\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1069 - binary_accuracy: 0.9683 - sensitivity: 0.9909 - specificity: 0.9101 - gmeasure: 0.9493 - auc: 0.9916 - val_loss: 0.2317 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9626\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1040 - binary_accuracy: 0.9733 - sensitivity: 0.9864 - specificity: 0.9402 - gmeasure: 0.9628 - auc: 0.9921 - val_loss: 0.2238 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9631\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1049 - binary_accuracy: 0.9733 - sensitivity: 0.9862 - specificity: 0.9389 - gmeasure: 0.9623 - auc: 0.9915 - val_loss: 0.2334 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9629\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1039 - binary_accuracy: 0.9700 - sensitivity: 0.9840 - specificity: 0.9327 - gmeasure: 0.9579 - auc: 0.9923 - val_loss: 0.2266 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9633\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1027 - binary_accuracy: 0.9717 - sensitivity: 0.9863 - specificity: 0.9302 - gmeasure: 0.9577 - auc: 0.9919 - val_loss: 0.2338 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9817 - val_specificity: 0.7561 - val_gmeasure: 0.8615 - val_auc: 0.9633\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1036 - binary_accuracy: 0.9750 - sensitivity: 0.9862 - specificity: 0.9423 - gmeasure: 0.9636 - auc: 0.9921 - val_loss: 0.2230 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9817 - val_specificity: 0.7805 - val_gmeasure: 0.8753 - val_auc: 0.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 6.270015716552734!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 9us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.014514684677124023!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.12617357075214386, 0.9653333425521851, 0.9853479862213135, 0.9117646813392639, 0.947842538356781, 0.985859751701355]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.012951135635375977!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2848759889602661, 0.9079999923706055, 0.959770143032074, 0.7894737124443054, 0.8704673051834106, 0.9521324634552002]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.087581872940063\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:141] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 760us/step - loss: 0.2191 - binary_accuracy: 0.9033 - sensitivity: 0.9142 - specificity: 0.8903 - gmeasure: 0.9003 - auc: 0.9679 - val_loss: 0.2551 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9286 - val_specificity: 0.8462 - val_gmeasure: 0.8864 - val_auc: 0.9628\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.2087 - binary_accuracy: 0.9217 - sensitivity: 0.9017 - specificity: 0.9673 - gmeasure: 0.9334 - auc: 0.9702 - val_loss: 0.2460 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9082 - val_specificity: 0.8846 - val_gmeasure: 0.8963 - val_auc: 0.9625\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.2047 - binary_accuracy: 0.9183 - sensitivity: 0.9121 - specificity: 0.9312 - gmeasure: 0.9212 - auc: 0.9650 - val_loss: 0.2914 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9623\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1999 - binary_accuracy: 0.9133 - sensitivity: 0.9199 - specificity: 0.8990 - gmeasure: 0.9094 - auc: 0.9646 - val_loss: 0.2553 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9657\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 0.1950 - binary_accuracy: 0.9217 - sensitivity: 0.9132 - specificity: 0.9387 - gmeasure: 0.9258 - auc: 0.9690 - val_loss: 0.2467 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9286 - val_specificity: 0.8462 - val_gmeasure: 0.8864 - val_auc: 0.9657\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.2000 - binary_accuracy: 0.9183 - sensitivity: 0.9081 - specificity: 0.9430 - gmeasure: 0.9247 - auc: 0.9706 - val_loss: 0.2754 - val_binary_accuracy: 0.8600 - val_sensitivity: 0.9388 - val_specificity: 0.7115 - val_gmeasure: 0.8173 - val_auc: 0.9645\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1930 - binary_accuracy: 0.9250 - sensitivity: 0.9326 - specificity: 0.9080 - gmeasure: 0.9202 - auc: 0.9669 - val_loss: 0.2578 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9659\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1955 - binary_accuracy: 0.9233 - sensitivity: 0.9110 - specificity: 0.9523 - gmeasure: 0.9312 - auc: 0.9704 - val_loss: 0.2451 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9184 - val_specificity: 0.8846 - val_gmeasure: 0.9013 - val_auc: 0.9645\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1921 - binary_accuracy: 0.9250 - sensitivity: 0.9156 - specificity: 0.9460 - gmeasure: 0.9306 - auc: 0.9675 - val_loss: 0.2712 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9657\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1911 - binary_accuracy: 0.9200 - sensitivity: 0.9178 - specificity: 0.9244 - gmeasure: 0.9210 - auc: 0.9680 - val_loss: 0.2588 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9661\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1886 - binary_accuracy: 0.9233 - sensitivity: 0.9139 - specificity: 0.9465 - gmeasure: 0.9300 - auc: 0.9712 - val_loss: 0.2521 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9664\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1869 - binary_accuracy: 0.9250 - sensitivity: 0.9225 - specificity: 0.9301 - gmeasure: 0.9263 - auc: 0.9698 - val_loss: 0.2663 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9661\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1878 - binary_accuracy: 0.9267 - sensitivity: 0.9275 - specificity: 0.9262 - gmeasure: 0.9262 - auc: 0.9685 - val_loss: 0.2536 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9666\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1862 - binary_accuracy: 0.9250 - sensitivity: 0.9139 - specificity: 0.9527 - gmeasure: 0.9330 - auc: 0.9720 - val_loss: 0.2521 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9670\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1843 - binary_accuracy: 0.9233 - sensitivity: 0.9152 - specificity: 0.9422 - gmeasure: 0.9285 - auc: 0.9705 - val_loss: 0.2632 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9388 - val_specificity: 0.7692 - val_gmeasure: 0.8498 - val_auc: 0.9670\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1847 - binary_accuracy: 0.9250 - sensitivity: 0.9205 - specificity: 0.9346 - gmeasure: 0.9274 - auc: 0.9698 - val_loss: 0.2559 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9670\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1826 - binary_accuracy: 0.9300 - sensitivity: 0.9226 - specificity: 0.9441 - gmeasure: 0.9331 - auc: 0.9709 - val_loss: 0.2539 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9672\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1824 - binary_accuracy: 0.9267 - sensitivity: 0.9157 - specificity: 0.9522 - gmeasure: 0.9336 - auc: 0.9713 - val_loss: 0.2603 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9676\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1813 - binary_accuracy: 0.9300 - sensitivity: 0.9281 - specificity: 0.9345 - gmeasure: 0.9310 - auc: 0.9706 - val_loss: 0.2541 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9676\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1799 - binary_accuracy: 0.9233 - sensitivity: 0.9160 - specificity: 0.9399 - gmeasure: 0.9279 - auc: 0.9717 - val_loss: 0.2505 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9388 - val_specificity: 0.8269 - val_gmeasure: 0.8811 - val_auc: 0.9680\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1796 - binary_accuracy: 0.9250 - sensitivity: 0.9157 - specificity: 0.9488 - gmeasure: 0.9320 - auc: 0.9719 - val_loss: 0.2576 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9678\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1794 - binary_accuracy: 0.9250 - sensitivity: 0.9186 - specificity: 0.9465 - gmeasure: 0.9320 - auc: 0.9732 - val_loss: 0.2644 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9674\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1796 - binary_accuracy: 0.9300 - sensitivity: 0.9346 - specificity: 0.9199 - gmeasure: 0.9271 - auc: 0.9708 - val_loss: 0.2565 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9680\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1758 - binary_accuracy: 0.9317 - sensitivity: 0.9220 - specificity: 0.9509 - gmeasure: 0.9362 - auc: 0.9719 - val_loss: 0.2386 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9667\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1769 - binary_accuracy: 0.9250 - sensitivity: 0.9152 - specificity: 0.9456 - gmeasure: 0.9302 - auc: 0.9719 - val_loss: 0.2634 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9388 - val_specificity: 0.7692 - val_gmeasure: 0.8498 - val_auc: 0.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1759 - binary_accuracy: 0.9300 - sensitivity: 0.9270 - specificity: 0.9341 - gmeasure: 0.9303 - auc: 0.9714 - val_loss: 0.2445 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9670\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1741 - binary_accuracy: 0.9333 - sensitivity: 0.9265 - specificity: 0.9453 - gmeasure: 0.9358 - auc: 0.9728 - val_loss: 0.2512 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9694\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1734 - binary_accuracy: 0.9333 - sensitivity: 0.9297 - specificity: 0.9420 - gmeasure: 0.9358 - auc: 0.9727 - val_loss: 0.2545 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9690\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1728 - binary_accuracy: 0.9300 - sensitivity: 0.9185 - specificity: 0.9581 - gmeasure: 0.9379 - auc: 0.9737 - val_loss: 0.2424 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9698\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1721 - binary_accuracy: 0.9283 - sensitivity: 0.9258 - specificity: 0.9371 - gmeasure: 0.9312 - auc: 0.9737 - val_loss: 0.2650 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9696\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1735 - binary_accuracy: 0.9250 - sensitivity: 0.9234 - specificity: 0.9339 - gmeasure: 0.9281 - auc: 0.9741 - val_loss: 0.2468 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9676\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.1703 - binary_accuracy: 0.9317 - sensitivity: 0.9273 - specificity: 0.9422 - gmeasure: 0.9345 - auc: 0.9737 - val_loss: 0.2521 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9677\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1682 - binary_accuracy: 0.9333 - sensitivity: 0.9273 - specificity: 0.9467 - gmeasure: 0.9369 - auc: 0.9754 - val_loss: 0.2436 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9710\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1703 - binary_accuracy: 0.9300 - sensitivity: 0.9157 - specificity: 0.9640 - gmeasure: 0.9394 - auc: 0.9752 - val_loss: 0.2475 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9712\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1687 - binary_accuracy: 0.9283 - sensitivity: 0.9348 - specificity: 0.9120 - gmeasure: 0.9232 - auc: 0.9733 - val_loss: 0.2618 - val_binary_accuracy: 0.8733 - val_sensitivity: 0.9388 - val_specificity: 0.7500 - val_gmeasure: 0.8391 - val_auc: 0.9704\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1657 - binary_accuracy: 0.9300 - sensitivity: 0.9201 - specificity: 0.9517 - gmeasure: 0.9357 - auc: 0.9753 - val_loss: 0.2276 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9688\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1665 - binary_accuracy: 0.9350 - sensitivity: 0.9154 - specificity: 0.9786 - gmeasure: 0.9464 - auc: 0.9751 - val_loss: 0.2744 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9490 - val_specificity: 0.7500 - val_gmeasure: 0.8436 - val_auc: 0.9698\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.1656 - binary_accuracy: 0.9283 - sensitivity: 0.9323 - specificity: 0.9196 - gmeasure: 0.9259 - auc: 0.9741 - val_loss: 0.2280 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9692\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1662 - binary_accuracy: 0.9333 - sensitivity: 0.9125 - specificity: 0.9782 - gmeasure: 0.9447 - auc: 0.9746 - val_loss: 0.2442 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9717\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1662 - binary_accuracy: 0.9383 - sensitivity: 0.9435 - specificity: 0.9303 - gmeasure: 0.9368 - auc: 0.9737 - val_loss: 0.2510 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9714\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1630 - binary_accuracy: 0.9317 - sensitivity: 0.9206 - specificity: 0.9574 - gmeasure: 0.9388 - auc: 0.9750 - val_loss: 0.2245 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9707\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1644 - binary_accuracy: 0.9317 - sensitivity: 0.9249 - specificity: 0.9570 - gmeasure: 0.9405 - auc: 0.9771 - val_loss: 0.2589 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9714\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1601 - binary_accuracy: 0.9350 - sensitivity: 0.9354 - specificity: 0.9316 - gmeasure: 0.9335 - auc: 0.9772 - val_loss: 0.2366 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9388 - val_specificity: 0.8077 - val_gmeasure: 0.8708 - val_auc: 0.9731\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1587 - binary_accuracy: 0.9383 - sensitivity: 0.9298 - specificity: 0.9570 - gmeasure: 0.9433 - auc: 0.9770 - val_loss: 0.2455 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9731\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1607 - binary_accuracy: 0.9383 - sensitivity: 0.9429 - specificity: 0.9346 - gmeasure: 0.9384 - auc: 0.9769 - val_loss: 0.2512 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9388 - val_specificity: 0.7885 - val_gmeasure: 0.8603 - val_auc: 0.9731\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1592 - binary_accuracy: 0.9400 - sensitivity: 0.9300 - specificity: 0.9628 - gmeasure: 0.9462 - auc: 0.9783 - val_loss: 0.2226 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9723\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1615 - binary_accuracy: 0.9367 - sensitivity: 0.9328 - specificity: 0.9475 - gmeasure: 0.9396 - auc: 0.9774 - val_loss: 0.2606 - val_binary_accuracy: 0.8800 - val_sensitivity: 0.9490 - val_specificity: 0.7500 - val_gmeasure: 0.8436 - val_auc: 0.9725\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1563 - binary_accuracy: 0.9433 - sensitivity: 0.9395 - specificity: 0.9493 - gmeasure: 0.9442 - auc: 0.9773 - val_loss: 0.2242 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9717\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1582 - binary_accuracy: 0.9417 - sensitivity: 0.9391 - specificity: 0.9455 - gmeasure: 0.9417 - auc: 0.9773 - val_loss: 0.2562 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9727\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1526 - binary_accuracy: 0.9433 - sensitivity: 0.9395 - specificity: 0.9508 - gmeasure: 0.9451 - auc: 0.9774 - val_loss: 0.2265 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1534 - binary_accuracy: 0.9400 - sensitivity: 0.9274 - specificity: 0.9671 - gmeasure: 0.9470 - auc: 0.9785 - val_loss: 0.2547 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9739\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1522 - binary_accuracy: 0.9467 - sensitivity: 0.9491 - specificity: 0.9395 - gmeasure: 0.9442 - auc: 0.9767 - val_loss: 0.2427 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9741\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 54us/step - loss: 0.1525 - binary_accuracy: 0.9467 - sensitivity: 0.9419 - specificity: 0.9586 - gmeasure: 0.9500 - auc: 0.9779 - val_loss: 0.2353 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9749\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.1504 - binary_accuracy: 0.9467 - sensitivity: 0.9492 - specificity: 0.9413 - gmeasure: 0.9453 - auc: 0.9776 - val_loss: 0.2477 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9735\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.1486 - binary_accuracy: 0.9467 - sensitivity: 0.9421 - specificity: 0.9565 - gmeasure: 0.9492 - auc: 0.9787 - val_loss: 0.2328 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9388 - val_specificity: 0.8462 - val_gmeasure: 0.8913 - val_auc: 0.9721\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1481 - binary_accuracy: 0.9483 - sensitivity: 0.9393 - specificity: 0.9649 - gmeasure: 0.9520 - auc: 0.9779 - val_loss: 0.2497 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9490 - val_specificity: 0.7885 - val_gmeasure: 0.8650 - val_auc: 0.9745\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.1466 - binary_accuracy: 0.9483 - sensitivity: 0.9489 - specificity: 0.9437 - gmeasure: 0.9460 - auc: 0.9781 - val_loss: 0.2311 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9490 - val_specificity: 0.8269 - val_gmeasure: 0.8859 - val_auc: 0.9728\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1510 - binary_accuracy: 0.9417 - sensitivity: 0.9306 - specificity: 0.9703 - gmeasure: 0.9499 - auc: 0.9802 - val_loss: 0.2373 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9753\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1472 - binary_accuracy: 0.9483 - sensitivity: 0.9513 - specificity: 0.9409 - gmeasure: 0.9460 - auc: 0.9778 - val_loss: 0.2657 - val_binary_accuracy: 0.9000 - val_sensitivity: 0.9796 - val_specificity: 0.7500 - val_gmeasure: 0.8571 - val_auc: 0.9751\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1428 - binary_accuracy: 0.9500 - sensitivity: 0.9493 - specificity: 0.9524 - gmeasure: 0.9508 - auc: 0.9791 - val_loss: 0.2131 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9746\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 0.1442 - binary_accuracy: 0.9517 - sensitivity: 0.9419 - specificity: 0.9727 - gmeasure: 0.9571 - auc: 0.9799 - val_loss: 0.2418 - val_binary_accuracy: 0.9067 - val_sensitivity: 0.9490 - val_specificity: 0.8269 - val_gmeasure: 0.8859 - val_auc: 0.9755\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1439 - binary_accuracy: 0.9483 - sensitivity: 0.9538 - specificity: 0.9364 - gmeasure: 0.9450 - auc: 0.9782 - val_loss: 0.2295 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9774\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1414 - binary_accuracy: 0.9550 - sensitivity: 0.9470 - specificity: 0.9741 - gmeasure: 0.9604 - auc: 0.9803 - val_loss: 0.2280 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9490 - val_specificity: 0.8462 - val_gmeasure: 0.8961 - val_auc: 0.9772\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1432 - binary_accuracy: 0.9533 - sensitivity: 0.9561 - specificity: 0.9445 - gmeasure: 0.9494 - auc: 0.9788 - val_loss: 0.2273 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9772\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.1446 - binary_accuracy: 0.9483 - sensitivity: 0.9353 - specificity: 0.9807 - gmeasure: 0.9576 - auc: 0.9806 - val_loss: 0.2212 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9764\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1390 - binary_accuracy: 0.9517 - sensitivity: 0.9492 - specificity: 0.9565 - gmeasure: 0.9528 - auc: 0.9797 - val_loss: 0.2647 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9788\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.1379 - binary_accuracy: 0.9567 - sensitivity: 0.9535 - specificity: 0.9622 - gmeasure: 0.9578 - auc: 0.9800 - val_loss: 0.1952 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9723\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1423 - binary_accuracy: 0.9500 - sensitivity: 0.9394 - specificity: 0.9736 - gmeasure: 0.9561 - auc: 0.9812 - val_loss: 0.2752 - val_binary_accuracy: 0.8933 - val_sensitivity: 0.9796 - val_specificity: 0.7308 - val_gmeasure: 0.8461 - val_auc: 0.9788\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1424 - binary_accuracy: 0.9500 - sensitivity: 0.9637 - specificity: 0.9203 - gmeasure: 0.9417 - auc: 0.9796 - val_loss: 0.2077 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9388 - val_specificity: 0.8654 - val_gmeasure: 0.9013 - val_auc: 0.9775\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1422 - binary_accuracy: 0.9500 - sensitivity: 0.9349 - specificity: 0.9844 - gmeasure: 0.9592 - auc: 0.9820 - val_loss: 0.2318 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9763\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 0.1495 - binary_accuracy: 0.9450 - sensitivity: 0.9599 - specificity: 0.9210 - gmeasure: 0.9395 - auc: 0.9810 - val_loss: 0.2199 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9490 - val_specificity: 0.8654 - val_gmeasure: 0.9062 - val_auc: 0.9766\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 0.1467 - binary_accuracy: 0.9450 - sensitivity: 0.9302 - specificity: 0.9788 - gmeasure: 0.9541 - auc: 0.9820 - val_loss: 0.2181 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9592 - val_specificity: 0.8654 - val_gmeasure: 0.9111 - val_auc: 0.9769\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1377 - binary_accuracy: 0.9550 - sensitivity: 0.9617 - specificity: 0.9391 - gmeasure: 0.9503 - auc: 0.9804 - val_loss: 0.2586 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9794\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1377 - binary_accuracy: 0.9583 - sensitivity: 0.9495 - specificity: 0.9800 - gmeasure: 0.9645 - auc: 0.9813 - val_loss: 0.2009 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9388 - val_specificity: 0.9038 - val_gmeasure: 0.9211 - val_auc: 0.9755\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1337 - binary_accuracy: 0.9517 - sensitivity: 0.9442 - specificity: 0.9688 - gmeasure: 0.9562 - auc: 0.9819 - val_loss: 0.2704 - val_binary_accuracy: 0.9133 - val_sensitivity: 0.9796 - val_specificity: 0.7885 - val_gmeasure: 0.8788 - val_auc: 0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.1328 - binary_accuracy: 0.9583 - sensitivity: 0.9659 - specificity: 0.9407 - gmeasure: 0.9532 - auc: 0.9808 - val_loss: 0.2123 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9592 - val_specificity: 0.8654 - val_gmeasure: 0.9111 - val_auc: 0.9778\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1314 - binary_accuracy: 0.9600 - sensitivity: 0.9515 - specificity: 0.9780 - gmeasure: 0.9646 - auc: 0.9838 - val_loss: 0.2120 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9694 - val_specificity: 0.8654 - val_gmeasure: 0.9159 - val_auc: 0.9810\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1295 - binary_accuracy: 0.9600 - sensitivity: 0.9637 - specificity: 0.9522 - gmeasure: 0.9577 - auc: 0.9819 - val_loss: 0.2566 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9796 - val_specificity: 0.8077 - val_gmeasure: 0.8895 - val_auc: 0.9798\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1270 - binary_accuracy: 0.9567 - sensitivity: 0.9589 - specificity: 0.9520 - gmeasure: 0.9553 - auc: 0.9823 - val_loss: 0.2073 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9388 - val_specificity: 0.8846 - val_gmeasure: 0.9113 - val_auc: 0.9789\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1283 - binary_accuracy: 0.9617 - sensitivity: 0.9487 - specificity: 0.9883 - gmeasure: 0.9681 - auc: 0.9830 - val_loss: 0.2412 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9804\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1255 - binary_accuracy: 0.9600 - sensitivity: 0.9637 - specificity: 0.9533 - gmeasure: 0.9584 - auc: 0.9827 - val_loss: 0.2322 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9806\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1243 - binary_accuracy: 0.9667 - sensitivity: 0.9664 - specificity: 0.9686 - gmeasure: 0.9673 - auc: 0.9831 - val_loss: 0.2003 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9818\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1244 - binary_accuracy: 0.9650 - sensitivity: 0.9564 - specificity: 0.9840 - gmeasure: 0.9701 - auc: 0.9841 - val_loss: 0.2379 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9808\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1233 - binary_accuracy: 0.9617 - sensitivity: 0.9610 - specificity: 0.9635 - gmeasure: 0.9622 - auc: 0.9832 - val_loss: 0.2172 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9814\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.1230 - binary_accuracy: 0.9650 - sensitivity: 0.9537 - specificity: 0.9887 - gmeasure: 0.9710 - auc: 0.9848 - val_loss: 0.2331 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9796 - val_specificity: 0.8462 - val_gmeasure: 0.9104 - val_auc: 0.9810\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.1231 - binary_accuracy: 0.9600 - sensitivity: 0.9662 - specificity: 0.9492 - gmeasure: 0.9576 - auc: 0.9842 - val_loss: 0.2140 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9812\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1200 - binary_accuracy: 0.9650 - sensitivity: 0.9567 - specificity: 0.9839 - gmeasure: 0.9702 - auc: 0.9845 - val_loss: 0.2099 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9816\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 0.1175 - binary_accuracy: 0.9650 - sensitivity: 0.9611 - specificity: 0.9728 - gmeasure: 0.9669 - auc: 0.9836 - val_loss: 0.2519 - val_binary_accuracy: 0.9200 - val_sensitivity: 0.9796 - val_specificity: 0.8077 - val_gmeasure: 0.8895 - val_auc: 0.9804\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1189 - binary_accuracy: 0.9617 - sensitivity: 0.9637 - specificity: 0.9587 - gmeasure: 0.9611 - auc: 0.9845 - val_loss: 0.1993 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9785\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 0.1196 - binary_accuracy: 0.9650 - sensitivity: 0.9593 - specificity: 0.9799 - gmeasure: 0.9694 - auc: 0.9849 - val_loss: 0.2416 - val_binary_accuracy: 0.9267 - val_sensitivity: 0.9796 - val_specificity: 0.8269 - val_gmeasure: 0.9000 - val_auc: 0.9810\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.1166 - binary_accuracy: 0.9650 - sensitivity: 0.9690 - specificity: 0.9601 - gmeasure: 0.9644 - auc: 0.9853 - val_loss: 0.2114 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.1191 - binary_accuracy: 0.9617 - sensitivity: 0.9545 - specificity: 0.9797 - gmeasure: 0.9669 - auc: 0.9853 - val_loss: 0.2206 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9812\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.1150 - binary_accuracy: 0.9667 - sensitivity: 0.9659 - specificity: 0.9638 - gmeasure: 0.9644 - auc: 0.9862 - val_loss: 0.2429 - val_binary_accuracy: 0.9333 - val_sensitivity: 0.9796 - val_specificity: 0.8462 - val_gmeasure: 0.9104 - val_auc: 0.9808\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1138 - binary_accuracy: 0.9683 - sensitivity: 0.9668 - specificity: 0.9752 - gmeasure: 0.9708 - auc: 0.9872 - val_loss: 0.1867 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9694 - val_specificity: 0.8846 - val_gmeasure: 0.9260 - val_auc: 0.9816\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1158 - binary_accuracy: 0.9700 - sensitivity: 0.9613 - specificity: 0.9896 - gmeasure: 0.9753 - auc: 0.9857 - val_loss: 0.2352 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9796 - val_specificity: 0.8654 - val_gmeasure: 0.9207 - val_auc: 0.9806\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1157 - binary_accuracy: 0.9617 - sensitivity: 0.9685 - specificity: 0.9459 - gmeasure: 0.9570 - auc: 0.9865 - val_loss: 0.2102 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.1193 - binary_accuracy: 0.9617 - sensitivity: 0.9490 - specificity: 0.9894 - gmeasure: 0.9689 - auc: 0.9860 - val_loss: 0.2064 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9812\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.1119 - binary_accuracy: 0.9683 - sensitivity: 0.9683 - specificity: 0.9671 - gmeasure: 0.9675 - auc: 0.9878 - val_loss: 0.2911 - val_binary_accuracy: 0.8867 - val_sensitivity: 0.9796 - val_specificity: 0.7115 - val_gmeasure: 0.8349 - val_auc: 0.9808\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.1097 - binary_accuracy: 0.9633 - sensitivity: 0.9678 - specificity: 0.9515 - gmeasure: 0.9596 - auc: 0.9888 - val_loss: 0.1809 - val_binary_accuracy: 0.9400 - val_sensitivity: 0.9592 - val_specificity: 0.9038 - val_gmeasure: 0.9311 - val_auc: 0.9831\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.1148 - binary_accuracy: 0.9650 - sensitivity: 0.9540 - specificity: 0.9896 - gmeasure: 0.9716 - auc: 0.9877 - val_loss: 0.2218 - val_binary_accuracy: 0.9467 - val_sensitivity: 0.9796 - val_specificity: 0.8846 - val_gmeasure: 0.9309 - val_auc: 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:151] Training end with time 6.227388858795166!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "750/750 [==============================] - 0s 6us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.011963129043579102!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.13018378615379333, 0.9639999866485596, 0.9686888456344604, 0.9539749026298523, 0.9613037109375, 0.9872716665267944]\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.011726856231689453!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2259432077407837, 0.9279999732971191, 0.9606741666793823, 0.8472222089767456, 0.9021665453910828, 0.9655118584632874]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.126851081848145\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.17482334 0.93599999 0.96279993 0.87334998 0.91622325 0.97399658]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.06598582 0.04054445 0.021227   0.08591953 0.05451263 0.01778478]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.263196   0.90399998 0.95967474 0.78013321 0.86464918 0.95612373]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.02645943 0.0214165  0.00085764 0.05896227 0.03326344 0.00666316]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, warm_start_network_info, path_info, \n",
    "                                                                       number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the history plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wDtYOiVdKQ64AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3e123ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load the pre-trained network for testing\n",
    "\n",
    "If you want to test the trained model, you can use the `deepbiome_test` function. If you use the index file, this function provide the evaluation using test index (index set not included in the index file) for each fold. If not, this function provide the evaluation using the whole samples. If `number_of_fold` is setted as `k`, the function will test the model only with first `k` folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/classification_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:294] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 283us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.22127509117126465!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2787688076496124, 0.8759999871253967, 0.9585798978805542, 0.7037037014961243, 0.8213136792182922, 0.9507268667221069]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.6310412883758545\n",
      "[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 457us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.31082844734191895!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2848759889602661, 0.9079999923706055, 0.959770143032074, 0.7894737124443054, 0.8704673051834106, 0.9521324634552002]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.7521309852600098\n",
      "[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:177] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "250/250 [==============================] - 0s 336us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:182] Evaluation end with time 0.26335835456848145!\n",
      "[root    |INFO|build_network.py:183] Evaluation: [0.2259432077407837, 0.9279999732971191, 0.9606741666793823, 0.8472222089767456, 0.9021665453910828, 0.9655118584632874]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.9530818462371826\n",
      "[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:328] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:331]       mean : [0.263196   0.90399998 0.95967474 0.78013321 0.86464918 0.95612373]\n",
      "[root    |INFO|deepbiome.py:332]        std : [0.02645943 0.0214165  0.00085764 0.05896227 0.03326344 0.00666316]\n",
      "[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:336] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluation = deepbiome.deepbiome_test(log, test_network_info, test_path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function provides the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc\n",
      "Mean:           0.2632          0.9040          0.9597          0.7801          0.8646          0.9561\n",
      "Std :           0.0265          0.0214          0.0009          0.0590          0.0333          0.0067\n"
     ]
    }
   ],
   "source": [
    "print('      %s' % ''.join(['%16s'%'loss']+ ['%16s'%s.strip() for s in network_info['model_info']['metrics'].split(',')]))\n",
    "print('Mean: %s' % ''.join(['%16.4f'%v for v in np.mean(evaluation, axis=0)]))\n",
    "print('Std : %s' % ''.join(['%16.4f'%v for v in np.std(evaluation, axis=0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load the pre-trained network for prediction\n",
    "\n",
    "For prediction using the pre-trained model, we can use the `deepbiome_prediction` function. If `number_of_fold` is set to `k`, the function will predict only with first `k` folds sample's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_path_info = {\n",
    "    'data_info': {\n",
    "        'count_list_path': resource_filename('deepbiome', 'tests/data/gcount_list.csv'),\n",
    "        'count_path': resource_filename('deepbiome', 'tests/data/count'),\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': '',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight_0.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:197] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:202] Prediction end with time 0.050612688064575195!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 1.2163026332855225\n",
      "[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:197] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:202] Prediction end with time 0.050907135009765625!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 1.1867918968200684\n",
      "[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:518] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:526]      Genus: 48\n",
      "[root    |INFO|build_network.py:526]     Family: 40\n",
      "[root    |INFO|build_network.py:526]      Order: 23\n",
      "[root    |INFO|build_network.py:526]      Class: 17\n",
      "[root    |INFO|build_network.py:526]     Phylum: 9\n",
      "[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: ['Phylum', 'Family', 'Order', 'Class', 'Genus', 'Number']\n",
      "[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:197] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:202] Prediction end with time 0.02785348892211914!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 1.1357481479644775\n",
      "[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:449] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prediction = deepbiome.deepbiome_prediction(log, prediction_network_info, prediction_path_info,\n",
    "                                            num_classes = 1, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78799784],\n",
       "       [0.9245996 ],\n",
       "       [0.1545347 ],\n",
       "       [0.14412734],\n",
       "       [0.9911699 ],\n",
       "       [0.98303807],\n",
       "       [0.1934169 ],\n",
       "       [0.14412734],\n",
       "       [0.979736  ],\n",
       "       [0.9812544 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0,:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}