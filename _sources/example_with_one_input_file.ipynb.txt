{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : k fold cross-validation with an input file \n",
    "\n",
    "DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.\n",
    "\n",
    "To use DeepBiome, you can experiment (1) __k times repetition__ or (2) __k fold cross-validation__.\n",
    "For each experiment, we asuume that the dataset is given by\n",
    "- __A list of k input files for k times repetition.__\n",
    "- __One input file for k fold cross-validation.__\n",
    "\n",
    "This notebook contains an example of (2) __k fold cross-validation__ for the deep neural netowrk using deepbiome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load library\n",
    "\n",
    "First, we load the DeepBiome package. The DeepBiome package is built on the tensorflow and keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepbiome import deepbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset\n",
    "\n",
    "In this example, we assume that we have __one input file for k times repetition.__\n",
    "\n",
    "DeepBiome needs 3 data files as follows:\n",
    "1. **the tree information**\n",
    "1. **the input file**\n",
    "1. **y**\n",
    "\n",
    "For `k` fold cross-validation, we can use an input file.\n",
    "In addition, we can set **the training index for each fold**. If we set the index file, DeepBiome build the training set for each fold based on each fold index in the index file. If not, DeepBiome will generate the index file locally.\n",
    "        \n",
    "Eath data should have the csv format as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the tree information\n",
    "\n",
    "First we need a file about the phylogenetic tree information. This tree information file should have the format below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genus</th>\n",
       "      <th>Family</th>\n",
       "      <th>Order</th>\n",
       "      <th>Class</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Streptococcus</td>\n",
       "      <td>Streptococcaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tropheryma</td>\n",
       "      <td>Cellulomonadaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veillonella</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actinomyces</td>\n",
       "      <td>Actinomycetaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flavobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prevotella</td>\n",
       "      <td>Prevotellaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Porphyromonas</td>\n",
       "      <td>Porphyromonadaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parvimonas</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fusobacterium</td>\n",
       "      <td>Fusobacteriaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Propionibacterium</td>\n",
       "      <td>Propionibacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gemella</td>\n",
       "      <td>Bacillales_Incertae_Sedis_XI</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rothia</td>\n",
       "      <td>Micrococcaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Granulicatella</td>\n",
       "      <td>Carnobacteriaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Neisseria</td>\n",
       "      <td>Neisseriaceae</td>\n",
       "      <td>Neisseriales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lactobacillus</td>\n",
       "      <td>Lactobacillaceae</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Megasphaera</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Catonella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atopobium</td>\n",
       "      <td>Coriobacteriaceae</td>\n",
       "      <td>Coriobacteriales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>Campylobacteraceae</td>\n",
       "      <td>Campylobacterales</td>\n",
       "      <td>Epsilonproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Capnocytophaga</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solobacterium</td>\n",
       "      <td>Erysipelotrichaceae</td>\n",
       "      <td>Erysipelotrichales</td>\n",
       "      <td>Erysipelotrichia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Moryella</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7_genera_incertae_sedis</td>\n",
       "      <td>TM7</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Staphylococcus</td>\n",
       "      <td>Staphylococcaceae</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Filifactor</td>\n",
       "      <td>Peptostreptococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oribacterium</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Burkholderia</td>\n",
       "      <td>Burkholderiaceae</td>\n",
       "      <td>Burkholderiales</td>\n",
       "      <td>Betaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sneathia</td>\n",
       "      <td>Leptotrichiaceae</td>\n",
       "      <td>Fusobacteriales</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Fusobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Treponema</td>\n",
       "      <td>Spirochaetaceae</td>\n",
       "      <td>Spirochaetales</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Spirochaetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Moraxella</td>\n",
       "      <td>Moraxellaceae</td>\n",
       "      <td>Pseudomonadales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Haemophilus</td>\n",
       "      <td>Pasteurellaceae</td>\n",
       "      <td>Pasteurellales</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Selenomonas</td>\n",
       "      <td>Veillonellaceae</td>\n",
       "      <td>Selenomonadales</td>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Corynebacterium</td>\n",
       "      <td>Corynebacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rhizobium</td>\n",
       "      <td>Rhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bradyrhizobium</td>\n",
       "      <td>Bradyrhizobiaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Methylobacterium</td>\n",
       "      <td>Methylobacteriaceae</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1_genera_incertae_sedis</td>\n",
       "      <td>OD1</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Finegoldia</td>\n",
       "      <td>Clostridiales_Incertae_Sedis_XI</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Microbacterium</td>\n",
       "      <td>Microbacteriaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sphingomonas</td>\n",
       "      <td>Sphingomonadaceae</td>\n",
       "      <td>Sphingomonadales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Chryseobacterium</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteria</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bacteroides</td>\n",
       "      <td>Bacteroidaceae</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidetes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bdellovibrio</td>\n",
       "      <td>Bdellovibrionaceae</td>\n",
       "      <td>Bdellovibrionales</td>\n",
       "      <td>Deltaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Streptophyta</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>Cyanobacteria_Chloroplast</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Lachnospiracea_incertae_sedis</td>\n",
       "      <td>Lachnospiraceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Paracoccus</td>\n",
       "      <td>Rhodobacteraceae</td>\n",
       "      <td>Rhodobacterales</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fastidiosipila</td>\n",
       "      <td>Ruminococcaceae</td>\n",
       "      <td>Clostridiales</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pseudonocardia</td>\n",
       "      <td>Pseudonocardiaceae</td>\n",
       "      <td>Actinomycetales</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Bacteria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Genus                           Family  \\\n",
       "0                   Streptococcus                 Streptococcaceae   \n",
       "1                      Tropheryma                Cellulomonadaceae   \n",
       "2                     Veillonella                  Veillonellaceae   \n",
       "3                     Actinomyces                 Actinomycetaceae   \n",
       "4                  Flavobacterium                Flavobacteriaceae   \n",
       "5                      Prevotella                   Prevotellaceae   \n",
       "6                   Porphyromonas               Porphyromonadaceae   \n",
       "7                      Parvimonas  Clostridiales_Incertae_Sedis_XI   \n",
       "8                   Fusobacterium                 Fusobacteriaceae   \n",
       "9               Propionibacterium             Propionibacteriaceae   \n",
       "10                        Gemella     Bacillales_Incertae_Sedis_XI   \n",
       "11                         Rothia                   Micrococcaceae   \n",
       "12                 Granulicatella                Carnobacteriaceae   \n",
       "13                      Neisseria                    Neisseriaceae   \n",
       "14                  Lactobacillus                 Lactobacillaceae   \n",
       "15                    Megasphaera                  Veillonellaceae   \n",
       "16                      Catonella                  Lachnospiraceae   \n",
       "17                      Atopobium                Coriobacteriaceae   \n",
       "18                  Campylobacter               Campylobacteraceae   \n",
       "19                 Capnocytophaga                Flavobacteriaceae   \n",
       "20                  Solobacterium              Erysipelotrichaceae   \n",
       "21                       Moryella                  Lachnospiraceae   \n",
       "22      TM7_genera_incertae_sedis        TM7_genera_incertae_sedis   \n",
       "23                 Staphylococcus                Staphylococcaceae   \n",
       "24                     Filifactor            Peptostreptococcaceae   \n",
       "25                   Oribacterium                  Lachnospiraceae   \n",
       "26                   Burkholderia                 Burkholderiaceae   \n",
       "27                       Sneathia                 Leptotrichiaceae   \n",
       "28                      Treponema                  Spirochaetaceae   \n",
       "29                      Moraxella                    Moraxellaceae   \n",
       "30                    Haemophilus                  Pasteurellaceae   \n",
       "31                    Selenomonas                  Veillonellaceae   \n",
       "32                Corynebacterium               Corynebacteriaceae   \n",
       "33                      Rhizobium                     Rhizobiaceae   \n",
       "34                 Bradyrhizobium                Bradyrhizobiaceae   \n",
       "35               Methylobacterium              Methylobacteriaceae   \n",
       "36      OD1_genera_incertae_sedis        OD1_genera_incertae_sedis   \n",
       "37                     Finegoldia  Clostridiales_Incertae_Sedis_XI   \n",
       "38                 Microbacterium                Microbacteriaceae   \n",
       "39                   Sphingomonas                Sphingomonadaceae   \n",
       "40               Chryseobacterium                Flavobacteriaceae   \n",
       "41                    Bacteroides                   Bacteroidaceae   \n",
       "42                   Bdellovibrio               Bdellovibrionaceae   \n",
       "43                   Streptophyta                      Chloroplast   \n",
       "44  Lachnospiracea_incertae_sedis                  Lachnospiraceae   \n",
       "45                     Paracoccus                 Rhodobacteraceae   \n",
       "46                 Fastidiosipila                  Ruminococcaceae   \n",
       "47                 Pseudonocardia               Pseudonocardiaceae   \n",
       "\n",
       "                        Order                      Class  \\\n",
       "0             Lactobacillales                    Bacilli   \n",
       "1             Actinomycetales             Actinobacteria   \n",
       "2             Selenomonadales              Negativicutes   \n",
       "3             Actinomycetales             Actinobacteria   \n",
       "4            Flavobacteriales              Flavobacteria   \n",
       "5               Bacteroidales                Bacteroidia   \n",
       "6               Bacteroidales                Bacteroidia   \n",
       "7               Clostridiales                 Clostridia   \n",
       "8             Fusobacteriales               Fusobacteria   \n",
       "9             Actinomycetales             Actinobacteria   \n",
       "10                 Bacillales                    Bacilli   \n",
       "11            Actinomycetales             Actinobacteria   \n",
       "12            Lactobacillales                    Bacilli   \n",
       "13               Neisseriales         Betaproteobacteria   \n",
       "14            Lactobacillales                    Bacilli   \n",
       "15            Selenomonadales              Negativicutes   \n",
       "16              Clostridiales                 Clostridia   \n",
       "17           Coriobacteriales             Actinobacteria   \n",
       "18          Campylobacterales      Epsilonproteobacteria   \n",
       "19           Flavobacteriales              Flavobacteria   \n",
       "20         Erysipelotrichales           Erysipelotrichia   \n",
       "21              Clostridiales                 Clostridia   \n",
       "22  TM7_genera_incertae_sedis  TM7_genera_incertae_sedis   \n",
       "23                 Bacillales                    Bacilli   \n",
       "24              Clostridiales                 Clostridia   \n",
       "25              Clostridiales                 Clostridia   \n",
       "26            Burkholderiales         Betaproteobacteria   \n",
       "27            Fusobacteriales               Fusobacteria   \n",
       "28             Spirochaetales               Spirochaetes   \n",
       "29            Pseudomonadales        Gammaproteobacteria   \n",
       "30             Pasteurellales        Gammaproteobacteria   \n",
       "31            Selenomonadales              Negativicutes   \n",
       "32            Actinomycetales             Actinobacteria   \n",
       "33                Rhizobiales        Alphaproteobacteria   \n",
       "34                Rhizobiales        Alphaproteobacteria   \n",
       "35                Rhizobiales        Alphaproteobacteria   \n",
       "36  OD1_genera_incertae_sedis  OD1_genera_incertae_sedis   \n",
       "37              Clostridiales                 Clostridia   \n",
       "38            Actinomycetales             Actinobacteria   \n",
       "39           Sphingomonadales        Alphaproteobacteria   \n",
       "40           Flavobacteriales              Flavobacteria   \n",
       "41              Bacteroidales                Bacteroidia   \n",
       "42          Bdellovibrionales        Deltaproteobacteria   \n",
       "43                Chloroplast                Chloroplast   \n",
       "44              Clostridiales                 Clostridia   \n",
       "45            Rhodobacterales        Alphaproteobacteria   \n",
       "46              Clostridiales                 Clostridia   \n",
       "47            Actinomycetales             Actinobacteria   \n",
       "\n",
       "                       Phylum    Domain  \n",
       "0                  Firmicutes  Bacteria  \n",
       "1              Actinobacteria  Bacteria  \n",
       "2                  Firmicutes  Bacteria  \n",
       "3              Actinobacteria  Bacteria  \n",
       "4               Bacteroidetes  Bacteria  \n",
       "5               Bacteroidetes  Bacteria  \n",
       "6               Bacteroidetes  Bacteria  \n",
       "7                  Firmicutes  Bacteria  \n",
       "8                Fusobacteria  Bacteria  \n",
       "9              Actinobacteria  Bacteria  \n",
       "10                 Firmicutes  Bacteria  \n",
       "11             Actinobacteria  Bacteria  \n",
       "12                 Firmicutes  Bacteria  \n",
       "13             Proteobacteria  Bacteria  \n",
       "14                 Firmicutes  Bacteria  \n",
       "15                 Firmicutes  Bacteria  \n",
       "16                 Firmicutes  Bacteria  \n",
       "17             Actinobacteria  Bacteria  \n",
       "18             Proteobacteria  Bacteria  \n",
       "19              Bacteroidetes  Bacteria  \n",
       "20                 Firmicutes  Bacteria  \n",
       "21                 Firmicutes  Bacteria  \n",
       "22                        TM7  Bacteria  \n",
       "23                 Firmicutes  Bacteria  \n",
       "24                 Firmicutes  Bacteria  \n",
       "25                 Firmicutes  Bacteria  \n",
       "26             Proteobacteria  Bacteria  \n",
       "27               Fusobacteria  Bacteria  \n",
       "28               Spirochaetes  Bacteria  \n",
       "29             Proteobacteria  Bacteria  \n",
       "30             Proteobacteria  Bacteria  \n",
       "31                 Firmicutes  Bacteria  \n",
       "32             Actinobacteria  Bacteria  \n",
       "33             Proteobacteria  Bacteria  \n",
       "34             Proteobacteria  Bacteria  \n",
       "35             Proteobacteria  Bacteria  \n",
       "36                        OD1  Bacteria  \n",
       "37                 Firmicutes  Bacteria  \n",
       "38             Actinobacteria  Bacteria  \n",
       "39             Proteobacteria  Bacteria  \n",
       "40              Bacteroidetes  Bacteria  \n",
       "41              Bacteroidetes  Bacteria  \n",
       "42             Proteobacteria  Bacteria  \n",
       "43  Cyanobacteria_Chloroplast  Bacteria  \n",
       "44                 Firmicutes  Bacteria  \n",
       "45             Proteobacteria  Bacteria  \n",
       "46                 Firmicutes  Bacteria  \n",
       "47             Actinobacteria  Bacteria  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_information = pd.read_csv(resource_filename('deepbiome', 'tests/data/genus48_dic.csv'))\n",
    "tree_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has `.csv` format below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genus,Family,Order,Class,Phylum,Domain\n",
      "Streptococcus,Streptococcaceae,Lactobacillales,Bacilli,Firmicutes,Bacteria\n",
      "Tropheryma,Cellulomonadaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Veillonella,Veillonellaceae,Selenomonadales,Negativicutes,Firmicutes,Bacteria\n",
      "Actinomyces,Actinomycetaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Flavobacterium,Flavobacteriaceae,Flavobacteriales,Flavobacteria,Bacteroidetes,Bacteria\n",
      "Prevotella,Prevotellaceae,Bacteroidales,Bacteroidia,Bacteroidetes,Bacteria\n",
      "Porphyromonas,Porphyromonadaceae,Bacteroidales,Bacteroidia,Bacteroidetes,Bacteria\n",
      "Parvimonas,Clostridiales_Incertae_Sedis_XI,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Fusobacterium,Fusobacteriaceae,Fusobacteriales,Fusobacteria,Fusobacteria,Bacteria\n",
      "Propionibacterium,Propionibacteriaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Gemella,Bacillales_Incertae_Sedis_XI,Bacillales,Bacilli,Firmicutes,Bacteria\n",
      "Rothia,Micrococcaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Granulicatella,Carnobacteriaceae,Lactobacillales,Bacilli,Firmicutes,Bacteria\n",
      "Neisseria,Neisseriaceae,Neisseriales,Betaproteobacteria,Proteobacteria,Bacteria\n",
      "Lactobacillus,Lactobacillaceae,Lactobacillales,Bacilli,Firmicutes,Bacteria\n",
      "Megasphaera,Veillonellaceae,Selenomonadales,Negativicutes,Firmicutes,Bacteria\n",
      "Catonella,Lachnospiraceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Atopobium,Coriobacteriaceae,Coriobacteriales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Campylobacter,Campylobacteraceae,Campylobacterales,Epsilonproteobacteria,Proteobacteria,Bacteria\n",
      "Capnocytophaga,Flavobacteriaceae,Flavobacteriales,Flavobacteria,Bacteroidetes,Bacteria\n",
      "Solobacterium,Erysipelotrichaceae,Erysipelotrichales,Erysipelotrichia,Firmicutes,Bacteria\n",
      "Moryella,Lachnospiraceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "TM7_genera_incertae_sedis,TM7_genera_incertae_sedis,TM7_genera_incertae_sedis,TM7_genera_incertae_sedis,TM7,Bacteria\n",
      "Staphylococcus,Staphylococcaceae,Bacillales,Bacilli,Firmicutes,Bacteria\n",
      "Filifactor,Peptostreptococcaceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Oribacterium,Lachnospiraceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Burkholderia,Burkholderiaceae,Burkholderiales,Betaproteobacteria,Proteobacteria,Bacteria\n",
      "Sneathia,Leptotrichiaceae,Fusobacteriales,Fusobacteria,Fusobacteria,Bacteria\n",
      "Treponema,Spirochaetaceae,Spirochaetales,Spirochaetes,Spirochaetes,Bacteria\n",
      "Moraxella,Moraxellaceae,Pseudomonadales,Gammaproteobacteria,Proteobacteria,Bacteria\n",
      "Haemophilus,Pasteurellaceae,Pasteurellales,Gammaproteobacteria,Proteobacteria,Bacteria\n",
      "Selenomonas,Veillonellaceae,Selenomonadales,Negativicutes,Firmicutes,Bacteria\n",
      "Corynebacterium,Corynebacteriaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Rhizobium,Rhizobiaceae,Rhizobiales,Alphaproteobacteria,Proteobacteria,Bacteria\n",
      "Bradyrhizobium,Bradyrhizobiaceae,Rhizobiales,Alphaproteobacteria,Proteobacteria,Bacteria\n",
      "Methylobacterium,Methylobacteriaceae,Rhizobiales,Alphaproteobacteria,Proteobacteria,Bacteria\n",
      "OD1_genera_incertae_sedis,OD1_genera_incertae_sedis,OD1_genera_incertae_sedis,OD1_genera_incertae_sedis,OD1,Bacteria\n",
      "Finegoldia,Clostridiales_Incertae_Sedis_XI,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Microbacterium,Microbacteriaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "Sphingomonas,Sphingomonadaceae,Sphingomonadales,Alphaproteobacteria,Proteobacteria,Bacteria\n",
      "Chryseobacterium,Flavobacteriaceae,Flavobacteriales,Flavobacteria,Bacteroidetes,Bacteria\n",
      "Bacteroides,Bacteroidaceae,Bacteroidales,Bacteroidia,Bacteroidetes,Bacteria\n",
      "Bdellovibrio,Bdellovibrionaceae,Bdellovibrionales,Deltaproteobacteria,Proteobacteria,Bacteria\n",
      "Streptophyta,Chloroplast,Chloroplast,Chloroplast,Cyanobacteria_Chloroplast,Bacteria\n",
      "Lachnospiracea_incertae_sedis,Lachnospiraceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Paracoccus,Rhodobacteraceae,Rhodobacterales,Alphaproteobacteria,Proteobacteria,Bacteria\n",
      "Fastidiosipila,Ruminococcaceae,Clostridiales,Clostridia,Firmicutes,Bacteria\n",
      "Pseudonocardia,Pseudonocardiaceae,Actinomycetales,Actinobacteria,Actinobacteria,Bacteria\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(resource_filename('deepbiome', 'tests/data/genus48_dic.csv')) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the input file\n",
    "\n",
    "Below is an example of the input file.\n",
    "This example has 1000 samples' microbiome abandunce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>3224</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>1278</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1259</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>969</td>\n",
       "      <td>163</td>\n",
       "      <td>1515</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "0            841           0          813          505               5   \n",
       "1           1445           0            1          573               0   \n",
       "2           1259           0          805          650               0   \n",
       "3            982           0          327          594               0   \n",
       "4           1162           0          130          969             163   \n",
       "\n",
       "   Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "0        3224              0         362             11                 65   \n",
       "1        1278             82          85             69                154   \n",
       "2        1088              0           0             74                  0   \n",
       "3         960             81          19              9                  0   \n",
       "4        1515            167           4            162                  3   \n",
       "\n",
       "   ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "0  ...               0            87                 0            0   \n",
       "1  ...               0             1                 2            0   \n",
       "2  ...               0             2                 8            1   \n",
       "3  ...             157             1                 0            4   \n",
       "4  ...               0             9                 0            0   \n",
       "\n",
       "   Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "0             0             0                              0           0   \n",
       "1             0             0                              0           0   \n",
       "2            39             0                              0           0   \n",
       "3            60             0                              0           0   \n",
       "4             0             0                             60           0   \n",
       "\n",
       "   Fastidiosipila  Pseudonocardia  \n",
       "0               0            2133  \n",
       "1               0            3638  \n",
       "2               0            3445  \n",
       "3               0            3507  \n",
       "4               0            3945  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(resource_filename('deepbiome', 'tests/data/onefile_x.csv'))\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Streptococcus</th>\n",
       "      <th>Tropheryma</th>\n",
       "      <th>Veillonella</th>\n",
       "      <th>Actinomyces</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Prevotella</th>\n",
       "      <th>Porphyromonas</th>\n",
       "      <th>Parvimonas</th>\n",
       "      <th>Fusobacterium</th>\n",
       "      <th>Propionibacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Microbacterium</th>\n",
       "      <th>Sphingomonas</th>\n",
       "      <th>Chryseobacterium</th>\n",
       "      <th>Bacteroides</th>\n",
       "      <th>Bdellovibrio</th>\n",
       "      <th>Streptophyta</th>\n",
       "      <th>Lachnospiracea_incertae_sedis</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Fastidiosipila</th>\n",
       "      <th>Pseudonocardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1401</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2655</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>259</td>\n",
       "      <td>67</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>649</td>\n",
       "      <td>69</td>\n",
       "      <td>966</td>\n",
       "      <td>1227</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>2348</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Streptococcus  Tropheryma  Veillonella  Actinomyces  Flavobacterium  \\\n",
       "995           1401           4           30          526               0   \n",
       "996           2655           6          106           74               0   \n",
       "997            335           0           71          259              67   \n",
       "998            649          69          966         1227               0   \n",
       "999           1258           0            0         1119               0   \n",
       "\n",
       "     Prevotella  Porphyromonas  Parvimonas  Fusobacterium  Propionibacterium  \\\n",
       "995         923             25           0            127                  0   \n",
       "996         952             76          13            158                125   \n",
       "997         718              1           4              4                167   \n",
       "998         508              2          30            550                  0   \n",
       "999        2348             25           0            137                176   \n",
       "\n",
       "     ...  Microbacterium  Sphingomonas  Chryseobacterium  Bacteroides  \\\n",
       "995  ...               0             0                 7            0   \n",
       "996  ...               0             2                 0            0   \n",
       "997  ...               0           246                 0            0   \n",
       "998  ...               0             0                 0            0   \n",
       "999  ...               0             2                 0            0   \n",
       "\n",
       "     Bdellovibrio  Streptophyta  Lachnospiracea_incertae_sedis  Paracoccus  \\\n",
       "995             0             0                              0           0   \n",
       "996             0             0                              0           0   \n",
       "997             6             0                              0           0   \n",
       "998             0             6                              0           0   \n",
       "999             0             0                              0           0   \n",
       "\n",
       "     Fastidiosipila  Pseudonocardia  \n",
       "995               0            4470  \n",
       "996               0            2826  \n",
       "997               0            6527  \n",
       "998               0            4402  \n",
       "999               0            2585  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has `.csv` format below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Streptococcus\",\"Tropheryma\",\"Veillonella\",\"Actinomyces\",\"Flavobacterium\",\"Prevotella\",\"Porphyromonas\",\"Parvimonas\",\"Fusobacterium\",\"Propionibacterium\",\"Gemella\",\"Rothia\",\"Granulicatella\",\"Neisseria\",\"Lactobacillus\",\"Megasphaera\",\"Catonella\",\"Atopobium\",\"Campylobacter\",\"Capnocytophaga\",\"Solobacterium\",\"Moryella\",\"TM7_genera_incertae_sedis\",\"Staphylococcus\",\"Filifactor\",\"Oribacterium\",\"Burkholderia\",\"Sneathia\",\"Treponema\",\"Moraxella\",\"Haemophilus\",\"Selenomonas\",\"Corynebacterium\",\"Rhizobium\",\"Bradyrhizobium\",\"Methylobacterium\",\"OD1_genera_incertae_sedis\",\"Finegoldia\",\"Microbacterium\",\"Sphingomonas\",\"Chryseobacterium\",\"Bacteroides\",\"Bdellovibrio\",\"Streptophyta\",\"Lachnospiracea_incertae_sedis\",\"Paracoccus\",\"Fastidiosipila\",\"Pseudonocardia\"\n",
      "841,0,813,505,5,3224,0,362,11,65,156,1,55,0,1,20,382,1,333,24,80,43,309,2,3,4,0,1,32,0,2,4,382,0,0,96,23,0,0,87,0,0,0,0,0,0,0,2133\n",
      "1445,0,1,573,0,1278,82,85,69,154,436,3,0,61,440,0,394,83,33,123,0,49,414,0,0,37,0,0,42,0,0,384,27,0,0,0,146,0,0,1,2,0,0,0,0,0,0,3638\n",
      "1259,0,805,650,0,1088,0,0,74,0,155,228,430,765,0,0,11,102,68,90,77,83,322,10,0,7,0,122,76,0,1,25,0,0,0,44,13,0,0,2,8,1,39,0,0,0,0,3445\n",
      "982,0,327,594,0,960,81,19,9,0,45,457,1049,0,3,450,19,170,388,147,0,0,41,63,0,1,0,0,121,0,0,1,0,0,0,0,344,0,157,1,0,4,60,0,0,0,0,3507\n",
      "1162,0,130,969,163,1515,167,4,162,3,12,0,48,73,93,259,52,0,201,85,14,14,434,2,0,0,0,0,187,0,0,188,45,0,0,0,4,0,0,9,0,0,0,0,60,0,0,3945\n",
      "1956,37,41,661,47,1555,374,7,142,19,61,226,0,30,52,0,6,480,142,148,9,575,12,0,0,0,0,3,168,0,56,50,0,0,0,98,989,0,0,12,0,0,0,0,0,0,0,2044\n",
      "1037,14,83,1595,132,305,103,174,1195,0,410,224,1,320,26,0,476,0,7,37,46,61,20,0,0,0,0,0,226,0,239,8,1,0,0,0,0,188,0,20,4,0,4,0,0,0,0,3044\n",
      "641,0,172,179,0,1312,84,9,81,376,128,223,160,0,532,155,89,355,1,282,0,0,25,0,0,43,0,9,311,0,0,0,0,0,0,0,845,0,0,8,0,0,0,0,0,0,0,3980\n",
      "852,146,504,99,2,376,116,152,67,0,120,3,23,2,34,0,127,75,240,60,42,0,9,0,15,0,62,0,13,0,197,187,396,0,0,20,51,0,0,3,0,0,0,0,0,0,0,6007\n",
      "901,3,187,1214,0,1508,675,0,107,49,318,2,393,5,3,65,4,285,79,11,0,0,4,3,0,0,1,0,729,0,0,173,0,0,0,0,254,0,0,0,0,0,1,0,29,0,0,2997\n",
      "677,60,635,45,268,2461,466,9,338,0,97,63,45,82,128,1,139,4,323,6,0,0,58,0,0,0,0,0,36,0,646,29,0,0,0,0,120,0,0,41,0,0,0,0,0,0,0,3223\n",
      "413,0,355,1258,0,583,48,107,250,5,102,204,287,4,0,18,2,145,454,11,0,79,104,25,164,1,0,100,55,0,1,33,206,0,0,10,81,0,0,0,0,0,0,0,0,0,0,4895\n",
      "351,99,17,268,0,912,4,96,847,472,67,8,440,16,0,0,247,0,165,83,0,0,0,0,4,0,0,0,275,0,21,1968,3,0,0,0,173,0,0,1,37,0,0,0,0,0,53,3373\n",
      "1829,0,32,77,0,1971,8,6,319,1,8,140,302,165,177,0,166,27,857,19,0,0,155,0,0,579,127,112,54,0,1,19,0,0,0,0,143,0,0,8,51,0,0,0,0,0,0,2647\n",
      "1089,0,4,30,0,847,51,42,48,0,211,1,24,0,81,1,687,494,758,27,0,0,123,7,0,0,0,1,310,0,6,4,780,0,0,4,1,0,0,0,0,0,2,0,0,0,0,4367\n",
      "1761,0,60,517,4,576,63,0,169,0,12,437,0,7,130,0,2,7,47,346,115,0,539,0,2,0,0,0,515,0,0,68,5,0,0,0,315,0,0,16,0,0,0,0,0,0,0,4287\n",
      "938,0,601,794,0,1836,52,6,10,0,1104,8,219,168,174,3,0,12,425,885,0,15,268,34,0,141,2,0,8,0,0,5,8,0,0,0,2,0,0,0,0,0,0,0,0,0,0,2282\n",
      "882,8,110,975,0,1042,11,3,211,0,15,22,56,0,47,140,5,4,194,109,0,403,129,6,0,10,0,3,19,0,1,591,2,2,0,6,0,0,0,1,0,0,0,0,0,0,0,4993\n",
      "1395,0,76,60,0,916,2,466,353,13,1,159,369,0,92,2,14,528,103,133,100,4,17,0,0,0,0,0,7,0,0,6,48,0,0,44,578,0,0,0,0,0,0,0,0,0,0,4514\n",
      "1150,3,168,1265,0,1328,14,0,432,14,140,0,1,179,77,0,92,55,33,123,0,8,844,0,0,82,34,113,14,0,0,99,26,0,0,0,14,14,0,24,49,0,0,0,0,0,0,3605\n",
      "352,0,20,48,0,1035,269,1,1,53,122,1,0,0,107,0,12,414,253,483,335,3,117,0,0,1,21,37,7,0,8,13,15,0,0,186,0,0,0,18,0,57,0,0,0,0,0,6011\n",
      "1120,0,124,1198,0,2161,795,1,483,0,0,5,8,16,78,7,22,3,62,203,0,0,148,0,0,68,0,2,22,0,0,23,148,0,0,0,127,0,0,2,0,0,0,0,0,0,0,3174\n",
      "406,5,6,1191,0,2582,239,155,81,0,2,183,4,7,483,0,190,0,10,8,0,0,447,4,226,0,59,4,146,0,22,225,0,0,0,0,34,0,0,1,0,0,0,0,0,0,0,3280\n",
      "439,133,130,108,0,1511,50,180,33,0,110,86,539,0,88,145,7,11,745,487,0,40,176,43,8,103,0,6,193,0,4,306,6,0,0,0,2,1,0,0,0,0,0,0,0,0,0,4310\n",
      "513,0,130,583,2,781,3,34,201,84,3,1358,59,3,343,117,148,278,0,335,0,51,80,47,0,5,63,775,35,0,16,562,0,0,0,0,62,0,0,5,0,0,18,1,0,2,0,3303\n",
      "229,0,126,179,0,1581,61,26,1018,25,27,73,289,25,9,2,4,150,32,130,0,84,78,102,0,29,1,11,143,0,1,15,0,0,0,471,179,0,0,398,0,0,0,0,0,0,0,4502\n",
      "1378,3,327,351,3,1129,103,35,140,245,23,1,251,0,13,1128,0,0,81,16,0,0,193,31,0,0,0,255,273,0,1,15,8,0,0,0,29,0,6,0,0,0,1,0,0,0,2,3959\n",
      "701,0,402,918,0,1518,116,234,881,252,144,14,4,0,18,374,22,8,0,363,1,0,37,0,0,0,0,0,187,0,0,7,5,0,0,0,0,0,0,2,120,0,0,1,0,0,0,3671\n",
      "1116,1,630,232,0,1291,318,93,423,0,166,122,432,0,13,0,6,54,5,3,0,11,2019,0,0,51,0,0,88,0,0,91,1,0,0,34,0,0,0,0,0,0,0,1,0,0,0,2799\n",
      "1356,813,40,210,0,1337,628,0,134,0,145,203,247,1,28,5,25,0,1,373,58,0,93,2,0,80,260,0,18,0,0,196,0,2,0,0,0,0,4,0,4,0,0,0,0,0,0,3737\n",
      "470,0,167,18,41,882,318,820,189,38,521,65,58,132,25,257,43,6,973,46,132,114,17,48,0,0,51,0,4,0,0,131,76,0,0,0,106,0,0,0,2,0,0,0,0,0,0,4250\n",
      "487,16,412,945,1,535,1,0,122,0,530,392,1,182,167,1,1,44,374,61,73,9,33,0,8,0,0,9,484,0,52,66,4,0,0,0,571,0,0,1,0,0,21,0,0,0,0,4397\n",
      "994,0,1190,98,0,917,16,9,357,0,101,15,0,0,48,2,8,0,25,40,0,286,27,0,0,75,243,0,1610,0,0,387,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3477\n",
      "383,6,1452,690,4,775,2,58,287,0,833,0,83,1,5,0,50,400,28,120,0,16,6,0,3,274,0,0,313,0,0,0,0,0,0,4,27,0,0,0,0,0,72,0,0,0,0,4108\n",
      "179,101,59,491,0,1902,59,0,150,0,11,75,131,461,112,0,0,462,0,6,0,225,78,50,96,21,1,1,35,0,0,0,79,162,172,0,250,0,0,0,19,0,0,0,0,0,0,4612\n",
      "822,0,168,475,0,1640,600,6,247,13,138,2,51,2,64,169,24,55,360,126,0,841,94,158,0,0,0,27,448,0,0,190,0,0,0,0,5,0,0,0,22,0,0,0,0,0,0,3253\n",
      "525,50,142,278,1,1005,148,26,905,5,256,9,1536,37,6,116,48,13,116,14,23,0,0,0,0,1,1,1,8,0,0,48,7,0,0,0,289,0,0,0,0,0,0,9,0,0,0,4377\n",
      "660,14,132,252,64,597,0,206,13,23,12,233,160,0,212,21,281,160,45,102,4,133,44,0,0,88,53,0,204,0,20,127,13,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6126\n",
      "480,22,72,170,222,1481,6,2,585,211,448,503,11,48,14,527,832,0,9,192,341,272,2,0,0,50,2,0,52,0,0,86,192,0,0,0,14,0,0,0,0,0,0,1,0,0,0,3153\n",
      "741,23,189,143,3,2487,35,201,312,0,3,233,0,1,150,12,495,0,1,102,285,0,507,26,7,62,0,1,41,0,0,0,588,0,0,29,18,0,0,0,0,0,0,0,0,0,0,3305\n",
      "623,168,18,1993,0,1829,157,0,146,0,177,1,86,8,1232,0,6,0,5,14,3,0,59,0,5,0,122,8,25,0,2,202,265,0,0,0,201,0,0,0,12,0,0,0,0,0,0,2633\n",
      "835,0,79,117,17,1140,559,59,350,262,242,178,6,178,0,0,59,133,27,62,39,20,5,0,69,3,0,13,449,0,0,0,0,0,0,0,178,0,13,0,0,0,0,0,0,0,0,4908\n",
      "2196,0,614,328,0,1809,467,70,470,3,131,0,2,1,1,4,3,172,417,14,14,0,231,0,0,1,4,47,258,0,0,73,133,0,0,0,0,0,3,5,0,0,0,0,0,0,0,2529\n",
      "618,0,73,740,0,1253,21,115,508,8,124,15,221,0,88,14,33,304,733,10,258,177,305,0,0,46,0,0,342,0,13,512,0,0,0,0,117,0,0,0,0,0,0,0,0,0,0,3352\n",
      "835,7,94,769,1,1235,65,97,629,0,115,436,42,0,265,31,70,15,396,99,0,611,66,26,0,0,32,1,86,0,0,395,935,0,0,0,18,0,0,140,0,0,0,0,0,0,0,2489\n",
      "587,24,12,1374,0,2272,96,109,789,26,238,1,1,46,1,2,10,6,120,80,19,0,13,10,0,5,0,8,175,0,0,83,0,0,0,0,17,0,3,0,0,0,0,0,0,0,0,3873\n",
      "750,0,261,235,5,592,30,0,704,579,0,12,61,2,64,576,0,100,0,44,26,0,343,0,0,13,12,4,32,0,0,451,16,0,0,440,186,0,0,22,12,7,1,0,0,21,0,4399\n",
      "940,1,12,2219,2,447,203,35,451,10,76,22,183,5,78,16,0,0,194,394,68,0,14,0,0,305,7,0,567,0,1,183,410,0,0,1,27,0,0,0,0,0,0,0,0,0,0,3129\n",
      "516,2,300,127,0,831,494,18,798,0,0,589,342,53,86,922,140,5,118,207,0,2,37,31,5,77,144,0,113,0,169,34,195,0,0,0,5,0,0,60,37,216,0,0,0,0,0,3327\n",
      "449,8,130,731,8,1533,220,0,147,3,253,248,6,20,77,50,9,0,6,255,0,0,138,0,0,0,10,390,43,0,0,56,3,0,0,0,278,0,0,0,0,0,141,1,0,0,0,4787\n",
      "429,0,0,460,0,937,899,222,58,0,38,62,3,6,657,0,130,20,81,552,41,4,184,72,38,3,12,0,489,0,14,317,307,0,0,0,101,0,0,0,0,0,0,0,0,0,0,3864\n",
      "1453,368,215,377,2,1464,1,22,346,0,473,114,16,0,1,24,47,0,458,349,208,0,79,117,6,199,0,28,542,0,11,46,3,0,0,0,290,0,0,1,0,0,0,0,0,0,0,2740\n",
      "946,200,7,506,183,366,5,124,152,571,302,47,70,5,6,55,5,42,272,470,13,367,3,161,31,0,0,2,599,21,0,3,0,0,0,0,263,0,0,104,0,0,0,7,0,0,0,4092\n",
      "2039,1,288,1033,302,562,313,1,50,0,4,3,2,3,41,209,151,0,637,1031,43,5,0,0,0,1,6,101,318,0,1,20,0,0,0,0,13,0,0,7,0,0,0,0,0,0,0,2815\n",
      "707,81,332,103,436,1272,0,87,1262,0,102,69,12,22,2,2,436,507,425,177,0,0,425,0,0,0,0,0,90,2,207,272,487,0,0,477,4,0,0,0,0,0,1,0,0,0,0,2001\n",
      "534,0,94,1573,0,1752,75,0,830,7,35,0,3,5,135,16,502,65,121,4,0,0,17,1,0,314,0,262,16,0,2,274,47,0,0,162,5,4,0,3,0,185,0,0,0,0,0,2957\n",
      "1160,9,122,189,14,1479,305,158,291,9,39,4,301,0,376,0,85,0,532,32,6,621,990,0,71,61,1,4,24,0,0,160,104,0,0,0,33,0,0,58,0,0,0,27,0,7,0,2728\n",
      "564,2,31,423,0,2131,604,1,224,2,4,69,0,0,371,0,62,573,3,0,0,0,52,0,0,0,0,42,210,0,1,258,27,0,0,0,0,0,0,312,10,0,0,0,0,15,0,4009\n",
      "779,0,11,47,0,1710,568,2,188,0,255,4,2,88,75,95,786,421,698,72,7,0,31,0,21,137,0,10,354,8,0,379,103,0,0,0,126,0,0,0,0,0,0,0,0,0,0,3023\n",
      "1015,353,145,58,127,1030,47,0,39,0,410,64,22,104,212,1,260,51,86,30,8,146,78,2,0,22,22,0,19,0,43,982,382,0,0,10,0,0,26,0,154,0,0,61,0,0,0,3991\n",
      "1123,0,188,483,0,649,72,19,386,43,4,35,3,150,10,66,46,4,36,0,169,445,0,0,57,2,9,132,1286,0,0,38,12,0,0,16,22,0,0,15,0,0,0,0,0,0,0,4480\n",
      "902,0,336,744,0,1350,10,0,109,397,0,968,53,0,0,1,18,0,560,0,12,0,256,92,237,8,272,4,81,78,34,11,78,0,0,0,13,0,0,0,22,5,0,0,0,0,0,3349\n",
      "1586,0,11,473,0,2151,138,373,6,0,13,482,175,16,1,222,8,13,32,362,0,2,29,0,29,86,0,0,12,0,84,582,24,0,0,0,201,0,0,0,0,3,29,0,0,0,0,2857\n",
      "965,0,142,930,0,510,332,282,9,0,109,1,51,2,120,0,0,542,439,0,0,0,148,247,0,0,0,304,146,0,123,0,0,0,0,0,97,0,0,0,0,0,0,0,0,0,0,4501\n",
      "922,0,900,203,0,1362,21,384,26,0,523,16,42,10,42,3,29,3,9,204,0,0,13,2,57,65,0,6,108,0,140,33,43,0,0,0,70,0,0,0,0,0,0,0,0,0,0,4764\n",
      "826,0,61,84,6,1248,112,7,365,1071,193,45,0,0,1698,0,2,15,0,692,5,88,0,17,40,18,19,0,433,0,0,1,28,0,0,0,36,0,0,43,0,0,0,0,0,0,0,2847\n",
      "1138,0,504,573,3,1529,346,72,166,0,190,0,131,38,18,0,261,142,10,17,149,0,726,0,20,12,4,0,32,0,0,58,0,0,0,2,37,0,0,0,0,0,0,0,0,0,0,3822\n",
      "1610,0,17,35,0,721,597,2,588,24,32,6,187,15,31,0,15,3,531,190,34,75,10,0,0,6,0,0,250,0,0,177,44,0,0,0,78,0,0,0,0,0,25,0,0,0,0,4697\n",
      "1351,0,202,492,34,1607,639,28,197,0,55,0,155,0,174,0,10,0,158,494,47,70,32,227,0,0,0,0,445,0,0,120,1,0,0,0,42,0,0,12,0,0,0,0,0,0,0,3408\n",
      "1255,0,181,78,0,855,33,0,394,0,300,2,18,54,163,4,146,1,171,173,0,3,183,1093,0,274,288,0,336,0,0,201,13,0,0,12,24,1,0,0,0,0,0,0,0,0,0,3744\n",
      "1430,253,2,485,0,54,99,0,122,21,40,0,12,0,0,0,5,116,469,17,969,0,31,173,0,41,39,0,661,0,288,0,934,0,0,43,46,0,0,20,0,0,0,0,0,0,0,3630\n",
      "266,0,60,414,0,668,88,55,71,0,88,38,3,72,0,4,499,101,78,7,8,558,0,40,0,44,154,109,241,0,292,494,23,0,0,0,850,0,0,0,0,0,0,0,0,0,0,4675\n",
      "974,402,252,441,0,1557,40,0,188,1,231,0,2,57,1,0,655,462,468,143,239,0,60,0,0,0,0,0,56,0,0,35,10,4,0,0,254,0,0,0,0,0,0,0,0,0,173,3295\n",
      "710,503,53,94,0,1490,2,5,269,1,24,0,12,0,97,108,285,152,329,2,59,8,99,40,0,0,0,0,91,11,183,374,2,0,20,0,0,0,0,0,461,0,0,0,0,0,0,4516\n",
      "2075,309,141,83,19,1424,184,27,97,85,180,0,10,70,34,4,266,0,488,145,0,17,78,1,0,0,53,243,177,0,0,12,130,0,0,0,76,0,0,3,4,0,0,0,0,0,0,3565\n",
      "1319,3,1019,4,0,1102,1136,18,436,0,85,139,129,0,132,6,2,1,0,1,0,244,73,1,0,9,0,0,4,0,0,0,67,0,0,0,0,0,94,0,0,0,0,0,0,0,0,3976\n",
      "262,0,46,421,0,1027,501,62,377,1114,5,18,0,15,56,0,447,313,0,734,69,0,14,16,0,2,2,79,222,0,0,60,11,0,0,241,12,0,5,0,0,0,0,0,0,6,0,3863\n",
      "964,0,132,214,32,1532,130,11,1138,0,20,0,0,0,166,0,359,25,110,11,0,221,111,0,0,0,15,0,11,3,1,98,154,0,0,0,6,0,0,1,0,0,70,0,0,0,0,4465\n",
      "1813,0,110,549,20,428,1,177,131,111,0,0,5,0,3,0,0,0,318,4,7,0,52,0,0,305,0,23,441,5,124,8,829,0,0,5,10,0,4,25,0,0,0,0,0,0,0,4492\n",
      "942,3,424,292,0,658,191,37,147,0,419,50,1,542,13,0,11,6,1090,4,45,1,122,95,4,0,242,349,148,0,537,113,0,0,11,0,12,0,0,0,0,0,0,7,0,0,0,3484\n",
      "298,0,672,366,0,1176,3,8,304,253,18,432,31,0,2,50,299,6,3,32,1,618,16,258,0,0,0,0,182,0,0,1893,13,0,0,75,30,0,0,1,0,0,0,0,0,0,0,2960\n",
      "412,0,33,663,0,678,300,308,347,46,122,220,1,0,143,1,7,0,68,40,3,4,521,0,0,0,0,0,12,0,407,120,0,0,0,0,389,0,0,17,44,0,14,0,0,3,0,5077\n",
      "931,6,138,452,0,511,47,0,60,21,0,0,317,4,0,5,31,177,4,22,14,0,40,0,0,72,50,0,645,0,0,308,11,0,0,0,36,0,0,0,0,176,1,0,0,0,0,5921\n",
      "1836,605,11,72,0,2037,155,50,505,34,255,0,0,0,100,0,643,52,164,46,0,0,62,0,83,22,0,0,81,0,0,374,0,4,0,0,41,0,0,11,0,0,0,0,0,0,0,2757\n",
      "1304,2,37,119,76,1263,278,148,18,0,202,3,62,28,330,0,117,33,271,0,0,0,302,0,0,496,0,0,394,0,0,135,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,4381\n",
      "1283,90,350,408,0,764,453,4,66,0,30,0,0,60,0,12,5,30,59,225,0,25,45,0,2,0,105,5,361,0,300,259,244,0,0,115,17,0,0,7,0,0,0,0,0,0,0,4676\n",
      "675,72,166,372,27,1507,8,73,720,0,4,1,0,0,8,19,108,0,746,44,0,0,140,0,0,100,0,0,191,104,1,604,3,0,134,47,126,0,0,1008,34,0,0,0,50,0,0,2908\n",
      "2130,168,163,154,244,1733,192,19,3,57,58,1,97,0,104,34,2,8,1195,23,288,114,77,214,0,27,19,0,10,0,0,479,0,0,0,0,159,0,0,155,0,0,0,0,0,0,0,2073\n",
      "488,0,608,808,0,621,0,35,427,0,319,522,0,0,320,13,292,0,67,21,0,1,520,0,0,18,0,0,281,0,19,8,0,0,10,0,17,0,0,0,0,0,30,0,0,0,0,4555\n",
      "793,60,872,436,28,1153,0,28,18,1,0,4,145,50,216,0,4,1,93,318,44,30,22,81,0,0,0,467,72,4,0,3,0,0,0,53,99,0,0,0,413,0,0,0,0,0,0,4492\n",
      "556,0,343,804,4,1317,60,39,644,1,94,148,0,0,50,0,2,530,45,70,0,0,135,0,0,325,6,0,25,0,13,166,82,0,0,0,0,0,83,0,18,0,0,0,0,0,0,4440\n",
      "422,1433,55,365,0,513,45,9,251,10,17,31,3,400,387,0,3,88,338,4,0,95,7,8,192,180,3,6,118,0,0,369,30,0,0,240,886,0,69,11,0,0,0,0,0,5,0,3407\n",
      "818,0,411,362,332,654,174,47,137,0,223,515,15,312,614,0,255,117,58,275,0,99,159,0,0,0,83,506,380,0,1,371,48,0,0,83,108,0,0,0,7,1,0,0,0,0,0,2835\n",
      "875,0,323,50,13,1542,11,84,40,3,937,0,19,0,453,149,138,1,199,391,129,2,6,0,132,0,0,1251,75,0,0,10,0,0,0,0,2,0,15,39,0,0,1,0,0,0,0,3110\n",
      "1029,224,830,561,109,1795,17,182,40,11,1,8,2,47,88,0,516,0,4,18,5,62,0,713,0,148,0,15,204,0,3,489,1100,0,0,2,122,0,2,0,0,0,0,0,0,0,0,1653\n",
      "635,59,392,622,0,2423,4,11,294,148,60,27,164,15,38,0,7,56,572,127,5,0,922,107,5,2,0,0,232,0,172,220,62,0,0,14,0,0,0,0,0,0,0,0,0,0,0,2605\n",
      "673,13,268,526,0,2855,549,0,245,2,1,30,3,0,2,24,15,1,108,2,0,0,352,0,0,244,22,1,22,0,0,18,8,0,0,23,108,4,0,0,0,0,0,0,0,0,0,3881\n",
      "1239,7,60,1294,1,643,16,129,799,0,86,11,10,0,398,11,91,1,28,101,4,271,1,316,0,0,0,6,70,0,0,14,0,0,0,4,3,0,0,0,0,0,0,0,0,0,0,4386\n",
      "1470,0,334,281,0,975,2,225,12,0,22,631,23,0,127,7,12,334,2,36,0,0,644,27,12,5,1,0,683,0,1,276,26,0,0,5,75,0,0,1,0,0,18,0,0,0,0,3733\n",
      "641,1,135,649,0,1211,849,10,496,5,8,0,0,0,10,3,5,11,10,999,137,39,375,0,0,0,19,0,7,1,364,88,72,5,0,0,2,0,1,0,0,0,2,0,0,0,0,3845\n",
      "1163,0,786,861,0,785,86,599,291,0,239,205,3,0,47,0,37,2,4,141,158,0,240,40,0,0,7,9,39,0,0,57,20,1,0,0,364,0,0,0,0,0,0,0,0,0,0,3816\n",
      "568,2,523,348,0,1221,22,75,361,20,3,172,280,117,59,90,583,0,203,35,0,6,6,243,0,553,0,0,742,0,0,19,0,0,0,4,110,0,0,163,0,0,7,0,0,0,0,3465\n",
      "493,0,96,79,0,2091,238,72,258,0,422,146,0,36,8,104,1,5,42,49,0,1,138,0,40,0,0,2,419,0,0,56,506,0,0,0,4,0,0,7,0,0,5,0,0,0,0,4682\n",
      "395,0,46,1373,0,1394,55,0,48,34,48,0,24,124,123,336,40,23,17,1,638,0,63,7,0,0,0,0,5,0,0,109,243,0,0,0,3,0,0,2,0,0,0,0,0,0,0,4849\n",
      "694,0,6,414,0,1196,168,122,22,0,83,83,180,0,21,21,28,7,142,75,8,116,5,8,0,5,41,3,816,0,0,5,279,0,0,253,44,0,0,0,48,0,0,0,0,13,0,5094\n",
      "855,110,367,662,0,1401,4,107,29,2,20,7,101,0,108,29,358,2,53,18,7,9,639,2,0,1,4,0,202,0,0,53,8,0,0,0,244,0,0,14,0,0,0,0,0,0,0,4584\n",
      "600,0,1,148,0,1042,423,3,15,3,30,995,47,0,744,1,0,0,263,53,0,115,206,0,0,0,0,0,22,0,0,0,12,0,0,0,22,0,0,0,0,0,0,0,0,0,0,5255\n",
      "312,0,93,1111,0,1802,227,30,0,0,6,25,9,0,60,47,178,0,270,864,1,1,383,0,0,50,0,73,199,0,0,17,419,0,0,0,83,0,0,0,0,0,0,0,0,0,0,3740\n",
      "523,0,98,197,497,2342,15,0,662,0,52,222,10,12,23,37,203,0,423,444,1,0,61,39,0,18,109,2,148,0,1,32,15,0,0,0,14,0,0,177,0,0,0,0,0,0,0,3623\n",
      "297,0,175,232,0,484,0,170,35,0,358,31,2,0,2,0,6,0,104,22,168,150,42,1,0,57,0,2,409,0,1,511,551,0,0,0,16,0,53,6,0,0,13,0,0,0,0,6102\n",
      "936,26,35,73,1,958,4,0,1274,0,219,5,170,1,17,1,103,437,168,124,105,437,141,0,0,3,0,139,361,0,0,229,2,0,0,0,36,0,0,0,0,0,0,0,0,0,0,3995\n",
      "2003,0,304,329,0,852,121,9,209,5,95,135,693,0,216,0,33,6,2,1,0,2,416,38,0,111,3,0,122,0,0,43,134,0,0,0,1,0,0,0,0,0,0,17,0,0,0,4100\n",
      "724,190,18,877,0,1560,1002,725,429,75,0,0,49,17,103,0,25,0,15,52,0,0,638,0,0,24,0,0,267,15,0,146,2,0,0,1,0,33,0,0,0,0,0,0,0,0,0,3013\n",
      "646,4,332,674,0,861,381,6,897,4,145,149,38,36,108,3,1072,1,16,0,0,0,84,0,0,7,0,261,491,0,24,273,2,0,0,23,0,0,0,0,23,10,7,0,0,0,0,3422\n",
      "261,0,11,213,24,2144,35,337,178,45,423,0,127,13,72,0,0,0,2,11,196,0,13,0,0,0,0,111,261,0,0,597,284,0,0,47,10,0,0,0,1,0,0,0,2,0,0,4582\n",
      "1387,5,154,44,0,893,0,80,234,117,418,196,0,1,269,0,203,75,45,0,10,0,142,12,0,16,5,0,58,2,266,159,0,0,0,160,2,261,0,0,0,0,0,0,0,0,0,4786\n",
      "1154,31,13,1332,0,654,504,13,127,428,191,39,15,0,1,0,0,0,62,23,0,0,1,1,0,0,1,0,307,0,0,336,366,0,0,0,236,0,0,0,0,0,0,0,0,0,0,4165\n",
      "1315,5,309,698,0,759,31,8,110,26,69,245,622,232,74,0,22,0,17,7,4,0,6,6,0,2,1,272,443,0,0,93,61,0,0,0,22,0,0,0,0,0,1,0,0,0,0,4540\n",
      "1196,49,1,675,0,1126,412,5,24,15,674,157,36,0,1,1,0,0,161,79,958,3,203,0,0,0,8,0,3,2,14,242,0,0,0,0,157,0,0,1,0,184,0,0,0,0,0,3613\n",
      "267,0,228,584,58,634,450,0,240,0,137,2,202,0,48,58,20,61,75,151,2,0,424,0,0,10,35,85,16,0,805,0,846,0,0,3,4,0,0,0,0,0,49,0,0,0,0,4506\n",
      "1589,7,101,23,0,3168,54,1,20,43,124,129,14,16,107,27,0,0,2,20,0,0,25,0,0,8,0,31,2,0,0,111,131,0,0,0,0,0,0,0,0,0,0,1,0,0,0,4246\n",
      "2039,17,76,177,0,1770,15,851,320,0,366,52,314,0,39,0,208,0,9,71,17,166,26,1,0,0,8,75,133,0,0,4,0,0,0,0,121,0,0,0,0,3,8,0,0,0,0,3114\n",
      "1040,21,1246,901,412,789,809,0,76,0,0,158,7,79,55,0,31,0,157,2,118,51,191,0,11,2,0,15,188,0,678,46,1,0,0,0,162,0,0,24,2,1,0,0,0,0,0,2727\n",
      "341,70,337,88,2,322,415,2,494,4,97,107,148,0,217,781,0,27,161,421,35,0,722,5,4,0,0,31,3,0,19,281,1,0,0,0,1203,0,0,0,2,0,0,0,0,0,0,3660\n",
      "633,0,505,43,220,993,55,326,270,2,375,14,68,258,88,51,28,1,4,153,12,429,386,0,0,48,294,31,129,0,2,38,147,0,0,0,293,0,13,0,0,0,0,0,0,0,0,4091\n",
      "667,109,472,85,2,998,125,66,479,161,0,9,217,0,0,0,46,1,18,37,0,0,4,6,0,48,7,81,390,0,12,52,0,0,30,0,0,0,0,0,0,0,0,0,0,0,0,5878\n",
      "1427,0,210,376,49,1506,10,33,4,10,29,350,21,62,254,14,78,0,2,211,3,0,10,35,1188,18,0,12,34,0,25,330,261,0,0,1,4,0,0,244,7,0,0,0,0,0,0,3182\n",
      "704,0,771,390,0,2541,82,27,212,13,498,244,17,161,0,12,38,0,22,533,58,62,504,0,303,30,0,1,70,0,5,11,5,5,0,0,1,0,0,0,0,0,0,33,0,0,0,2647\n",
      "1450,3,99,303,4,385,267,83,182,55,44,0,329,11,80,1,294,130,22,3,0,6,205,0,0,1,18,8,88,25,0,6,29,0,260,0,17,0,0,420,0,0,0,0,0,0,0,5172\n",
      "431,1,118,195,227,1150,579,18,77,0,16,4,275,196,0,44,16,1011,788,13,0,0,20,8,0,4,0,1,130,0,0,32,303,327,0,0,70,0,93,3,0,0,64,0,0,0,0,3786\n",
      "150,0,757,821,1,535,48,0,108,0,132,7,288,431,1,1,56,68,122,300,14,0,276,0,0,34,6,0,438,0,2,2,0,0,0,0,63,0,0,0,0,0,0,0,0,0,0,5339\n",
      "648,0,239,947,0,935,4,0,189,12,217,0,33,0,3,0,808,6,99,612,0,29,12,0,0,11,5,94,10,0,0,23,0,0,0,0,32,0,0,2,0,0,1,0,0,0,0,5029\n",
      "2104,63,4,505,0,1186,420,95,320,54,69,157,258,307,332,162,1,20,0,111,42,16,85,78,24,0,1,1,277,0,0,39,281,0,0,0,1,0,0,0,2,0,1,0,0,0,0,2984\n",
      "684,0,895,53,159,500,199,0,264,2,342,0,12,5,1,0,329,202,446,78,66,0,419,0,0,0,0,1,726,0,91,256,121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4149\n",
      "1041,96,176,378,0,2298,56,670,253,0,1,740,43,89,117,245,12,1,23,39,0,2,171,21,1,0,0,0,72,7,0,827,73,0,0,37,75,0,0,0,0,0,0,0,0,0,0,2436\n",
      "864,711,350,1101,0,2048,80,7,25,1,245,19,228,0,2,0,134,0,50,14,5,0,307,13,0,33,0,360,5,0,5,85,116,182,3,77,0,0,0,0,0,0,0,18,0,0,0,2912\n",
      "974,22,88,247,8,1109,115,13,131,0,17,130,6,40,686,0,95,296,32,9,0,284,81,338,0,0,328,0,109,0,25,78,1,0,0,0,65,0,0,1,0,0,0,0,0,0,0,4672\n",
      "37,0,344,263,0,647,73,0,12,16,424,0,47,0,113,1,402,112,14,0,225,2,47,0,1,107,88,0,1064,0,0,1066,1129,0,25,9,336,0,0,0,0,0,4,0,0,0,0,3392\n",
      "1616,9,104,493,98,676,83,0,101,126,4,0,81,0,101,0,428,0,248,181,70,16,3,7,0,0,52,0,91,3,8,219,495,0,0,0,0,0,0,0,96,0,2,0,13,0,0,4576\n",
      "765,349,441,285,78,2028,418,1,313,0,147,0,153,1,1,183,85,0,274,572,0,202,29,131,0,51,0,53,44,0,0,11,0,389,0,0,18,0,0,0,0,0,0,0,0,0,0,2978\n",
      "2120,0,23,538,0,786,130,1,535,0,67,103,19,2,0,196,14,0,212,119,14,0,242,0,43,1,12,126,191,0,0,38,161,0,0,0,0,0,0,138,0,0,0,0,0,0,0,4169\n",
      "161,206,261,787,5,1441,79,1059,14,92,22,17,17,4,98,96,14,24,131,278,15,0,0,40,3,0,7,0,227,49,52,85,25,0,0,0,4,0,0,0,0,0,0,23,0,11,0,4653\n",
      "369,0,1,240,0,2111,33,0,331,1,5,41,0,151,0,365,559,61,478,257,232,0,78,29,0,0,0,0,457,0,27,0,71,0,0,80,73,0,0,0,0,0,0,0,0,0,0,3950\n",
      "156,310,43,232,81,1570,164,10,212,0,29,6,494,25,5,255,0,89,10,1,21,9,225,0,0,0,0,6,149,0,0,1303,102,0,0,0,72,0,0,4,0,0,0,0,0,8,0,4409\n",
      "650,0,19,576,0,2185,18,89,265,0,50,14,16,61,48,0,76,0,24,751,0,77,81,192,0,0,0,0,362,0,0,167,395,0,0,2,0,0,0,12,0,0,0,1,0,5,0,3864\n",
      "2143,25,33,336,0,2094,40,1,109,0,485,26,54,0,126,251,58,30,115,89,14,0,11,479,0,60,1,75,287,0,0,385,24,0,0,0,487,0,0,0,0,0,64,0,0,0,0,2098\n",
      "773,1,562,611,7,2419,251,101,312,6,476,15,69,0,584,267,7,22,4,30,0,0,8,0,13,82,0,0,25,0,74,12,3,0,0,0,359,0,0,3,14,0,688,0,0,0,0,2202\n",
      "1238,0,8,54,0,1887,58,0,433,83,0,1435,3,104,286,0,7,14,154,4,49,1,50,2,441,0,0,102,58,0,0,98,3,0,0,0,11,0,0,24,0,0,0,407,0,0,557,2429\n",
      "870,1,147,97,27,724,130,15,274,27,199,36,2,0,933,128,24,0,202,40,10,0,23,16,0,0,0,23,905,0,81,0,518,0,0,483,66,0,0,9,0,0,0,0,0,0,0,3990\n",
      "660,225,201,1088,32,2427,395,0,92,0,16,244,61,401,5,1,91,145,122,18,0,16,50,1,0,373,0,2,326,0,34,529,167,0,0,9,2,0,0,0,0,0,3,0,0,0,0,2264\n",
      "268,0,101,450,0,595,59,0,9,2,651,177,31,10,37,72,3,153,26,2,7,68,84,0,8,255,0,0,352,0,0,322,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,6256\n",
      "1318,0,13,235,0,551,208,29,31,0,0,471,68,25,325,2,40,425,167,33,42,0,641,0,1,1,2,75,50,1,0,300,63,0,0,0,1,0,901,75,25,0,0,0,26,0,0,3855\n",
      "1801,0,35,42,1,772,1560,0,324,2,184,10,2,0,380,0,0,1,16,2,0,8,67,0,37,3,0,0,408,0,2,2,15,0,0,0,711,0,0,0,0,0,0,0,0,0,1,3614\n",
      "596,11,297,29,0,1242,102,45,11,572,18,153,0,0,87,20,107,39,7,0,0,0,166,0,0,356,0,0,89,0,162,4,163,0,0,0,184,0,0,5,0,0,19,0,0,0,0,5516\n",
      "409,0,171,481,1,2338,9,363,514,406,30,0,6,1,209,14,230,0,31,5,1,176,55,0,32,190,176,0,216,0,0,304,511,0,0,0,56,0,0,0,0,0,0,0,0,0,0,3065\n",
      "356,0,75,353,178,321,409,751,116,177,583,1,0,0,59,32,95,858,103,64,244,0,71,0,0,0,0,0,244,9,18,74,508,0,0,0,116,0,0,1,0,1,7,0,0,0,0,4176\n",
      "866,50,183,151,255,859,300,26,476,0,167,3,1,43,1,32,6,16,91,70,0,30,15,299,0,0,0,1,793,0,22,64,171,0,0,0,29,0,0,0,0,0,0,0,0,0,0,4980\n",
      "2345,285,104,216,259,1750,718,12,402,108,190,185,129,29,433,243,56,35,61,59,128,20,0,1,0,0,4,0,118,0,0,69,0,0,0,0,291,0,0,0,0,0,0,1,0,0,0,1749\n",
      "1044,0,81,413,0,254,1,474,35,50,154,151,39,60,194,0,107,0,6,1416,0,298,338,0,0,8,0,0,78,0,0,17,0,0,1,0,100,0,0,1,105,0,0,0,0,0,0,4575\n",
      "682,0,129,152,0,708,55,735,164,0,230,0,1735,3,379,11,42,12,0,0,0,15,9,1,41,88,127,2,28,0,8,11,1,0,0,1,1,0,0,3,0,0,0,0,17,0,0,4610\n",
      "1411,0,200,382,129,1289,0,1,7,2,544,135,6,0,35,0,1,47,2,360,0,62,139,9,0,0,570,247,3,0,0,10,14,0,0,0,4,0,0,0,0,0,0,0,0,0,17,4374\n",
      "435,0,510,381,0,2236,1,96,944,0,118,5,4,80,105,0,2,0,177,0,0,49,32,6,0,1,0,0,685,0,0,2,0,0,0,0,0,0,0,4,42,0,24,0,0,0,0,4061\n",
      "868,317,1,602,0,2364,20,0,308,50,366,2,0,1,45,6,9,0,320,465,0,0,95,104,0,0,0,1,120,0,9,104,66,0,0,0,0,0,0,64,0,0,0,0,0,0,0,3693\n",
      "1218,0,126,170,0,1544,94,25,224,19,100,31,0,277,397,4,618,4,102,12,0,0,103,29,0,85,0,78,112,0,1,0,41,0,0,0,0,0,0,0,0,14,0,0,0,0,0,4572\n",
      "1467,0,78,82,5,2945,320,12,805,230,160,53,0,28,41,27,41,44,9,51,2,197,12,0,0,5,0,0,127,0,0,16,116,0,0,0,1,0,2,0,0,0,207,0,0,0,0,2917\n",
      "797,0,1507,113,0,1109,180,0,211,0,121,98,414,0,11,4,13,7,11,73,6,5,385,43,0,0,38,0,0,0,7,114,12,0,0,0,16,0,0,3,0,0,229,0,0,0,0,4473\n",
      "230,230,446,687,72,899,18,18,35,580,493,4,518,0,36,0,0,42,400,737,3,0,0,2,0,0,38,1,46,375,0,81,102,0,0,1,81,0,0,0,38,0,0,0,0,0,0,3787\n",
      "177,52,0,555,0,1451,94,0,116,616,826,63,24,7,46,551,109,178,39,70,0,0,14,0,46,277,188,0,183,7,0,587,2,0,0,0,302,0,50,2,0,0,0,0,0,0,0,3368\n",
      "1749,0,112,202,0,2169,366,5,15,56,119,116,182,20,92,0,460,3,3,24,0,0,488,3,0,290,5,0,459,0,0,255,5,0,0,0,15,0,0,0,0,0,0,0,0,0,0,2787\n",
      "206,0,1130,223,4,1004,4,0,112,0,292,648,163,139,12,0,15,29,307,60,0,2,0,0,1,225,0,0,956,0,0,131,0,0,0,0,501,0,0,0,0,0,0,0,0,0,0,3836\n",
      "639,47,320,453,0,792,16,0,436,2,88,37,1,3,20,38,37,0,3,930,0,0,19,0,0,0,30,57,211,0,0,1213,275,0,0,12,1,0,0,19,0,0,0,0,0,0,0,4301\n",
      "189,35,87,1938,0,1890,98,67,65,0,584,73,3,240,1,58,8,3,249,15,156,5,4,6,0,48,0,0,26,0,0,295,12,0,133,5,33,0,0,0,0,0,0,0,0,0,0,3674\n",
      "571,0,1233,321,75,2339,14,87,227,0,185,274,0,15,2,6,297,0,54,3,28,0,107,0,0,20,0,0,259,0,0,19,29,0,0,7,26,0,0,11,0,0,0,0,0,0,0,3791\n",
      "1707,0,533,1448,0,707,1,0,9,0,11,740,3,2,46,23,22,167,653,12,0,0,68,0,0,0,0,1,375,0,0,23,39,0,0,193,0,0,0,1,0,0,0,0,0,0,0,3216\n",
      "91,55,380,480,0,1016,162,327,1271,497,23,22,239,0,31,0,21,1,22,3,1,1,0,321,0,305,0,0,700,0,0,59,77,0,0,166,9,0,0,1,0,0,0,0,0,0,0,3719\n",
      "418,9,46,911,86,541,1,41,490,0,758,0,321,23,20,1,78,84,65,338,0,1,3,41,2,634,1,7,224,0,0,93,1,0,0,0,140,0,0,19,2,0,0,0,0,0,0,4601\n",
      "609,0,453,1582,8,522,3,8,401,5,3,5,45,6,17,141,25,111,0,512,1,734,773,0,58,6,0,0,809,0,0,140,1,0,0,0,82,0,0,0,0,0,3,0,0,0,0,2937\n",
      "2642,38,69,692,1,917,73,86,223,9,15,83,98,59,532,1,0,29,19,109,2,0,46,0,0,37,0,0,446,0,73,19,1097,0,0,0,28,1,0,0,0,0,0,0,0,0,0,2556\n",
      "722,0,558,1078,112,829,448,48,1421,0,0,0,1,30,211,136,6,6,20,1,0,72,0,0,22,30,0,2,69,0,2,17,29,2,0,0,47,0,0,2,59,0,1,0,0,0,0,4019\n",
      "1312,189,7,579,0,2032,48,78,282,67,214,8,263,356,128,3,479,9,55,283,1,65,7,117,0,183,0,4,41,0,283,44,3,0,2,0,7,0,0,0,0,0,0,0,0,0,0,2851\n",
      "1065,136,0,1121,1,526,2,0,44,517,188,43,21,1,239,38,0,220,100,0,25,5,233,0,104,46,0,0,13,0,23,71,335,0,0,0,2,0,0,2,0,0,0,0,0,0,0,4879\n",
      "1512,15,63,643,22,1321,0,16,293,0,15,4,188,0,287,0,192,0,66,41,0,0,65,10,0,0,200,2,19,0,0,929,393,0,0,0,136,0,24,2,0,0,82,0,0,0,0,3460\n",
      "652,142,374,254,28,1077,145,1,286,0,12,7,0,0,31,0,20,191,35,1,342,81,34,0,0,3,3,0,58,0,18,5,2,0,0,0,67,0,29,0,0,0,1,0,0,0,0,6101\n",
      "1374,53,303,1283,352,1923,127,19,36,0,225,3,226,51,17,0,41,28,9,14,13,2,30,0,0,4,8,0,254,26,26,21,0,0,0,0,180,0,0,0,2,0,0,0,0,0,0,3350\n",
      "578,58,138,875,20,730,38,89,1694,0,170,0,0,483,0,0,280,6,235,119,0,0,0,359,0,2,0,0,324,0,0,98,22,0,0,0,3,0,0,0,0,0,41,0,0,0,0,3638\n",
      "418,0,25,1094,0,2274,14,46,300,0,14,71,15,3,251,63,155,71,557,6,0,0,342,0,0,0,0,219,623,0,0,121,119,0,0,1,421,0,39,0,1,0,0,0,109,0,0,2628\n",
      "561,0,8,419,0,858,188,239,112,22,221,188,646,0,3,205,362,6,232,44,21,9,222,0,0,0,0,2,149,0,0,269,20,0,0,0,277,0,0,0,0,0,0,0,0,0,0,4717\n",
      "533,141,2,24,0,766,20,28,135,9,31,0,17,133,466,378,6,0,93,238,0,192,13,0,19,2,207,634,978,0,0,192,43,0,6,0,102,0,0,0,0,0,0,0,0,0,0,4592\n",
      "266,0,46,293,8,2097,281,5,732,30,20,1572,2,39,12,1,567,4,33,208,0,0,209,0,0,0,0,69,40,0,0,22,1,0,0,0,5,0,0,200,0,0,0,4,0,0,0,3234\n",
      "1281,0,6,921,104,886,460,179,340,3,0,193,27,45,484,0,0,9,118,179,4,0,378,0,0,0,0,0,128,0,183,223,807,0,0,0,181,0,0,0,0,0,0,0,0,0,0,2861\n",
      "337,0,694,341,11,416,257,332,115,9,226,12,3,139,138,32,77,0,2,3,1,72,42,0,0,3,4,0,3,0,216,6,0,0,0,90,928,0,0,8,0,0,0,0,0,0,0,5483\n",
      "1131,0,1027,294,1,741,0,86,633,224,119,76,51,42,78,11,1,0,244,10,0,0,104,1,0,839,0,3,468,0,8,56,296,0,0,285,11,0,0,17,0,0,0,1,0,0,0,3142\n",
      "589,0,2,338,0,797,3,757,112,74,1,165,0,1,0,0,241,4,50,33,0,2,295,4,0,152,9,38,43,0,0,695,1,0,0,0,0,0,0,206,0,0,0,0,0,0,0,5388\n",
      "904,437,11,536,1,545,106,0,425,2,30,6,4,5,34,0,124,0,583,1,0,134,383,202,0,0,0,0,247,0,0,0,4,0,0,343,18,0,0,0,0,0,0,0,0,0,0,4915\n",
      "661,0,25,895,0,1051,57,119,602,0,9,132,448,12,83,0,107,14,259,38,0,0,179,89,12,8,0,12,394,0,40,179,806,0,0,0,16,0,1,0,0,0,0,0,0,0,0,3752\n",
      "1322,14,1216,1191,0,824,0,3,477,0,24,17,304,10,150,284,25,2,203,9,13,0,67,0,0,9,125,38,256,0,0,317,4,0,0,0,79,0,0,138,0,0,0,0,0,0,0,2879\n",
      "1034,0,106,45,0,842,23,4,347,0,37,4,44,1,77,0,72,101,687,131,547,16,282,0,3,3,956,1,71,0,0,181,0,0,0,12,96,0,0,0,0,0,35,0,0,0,0,4242\n",
      "521,0,247,68,1,618,14,1190,2232,437,57,34,6,0,0,0,126,81,1,316,20,3,118,0,61,104,0,0,30,0,0,18,334,0,0,108,6,0,0,1,0,0,0,0,0,0,0,3248\n",
      "798,0,21,242,0,1383,25,0,364,0,44,0,43,172,358,25,475,1,7,106,0,1081,347,1,0,0,2,2,5,42,0,127,1,0,0,18,31,0,0,0,11,0,0,0,0,0,0,4268\n",
      "931,2,151,750,0,843,5,4,782,21,3,143,2,17,17,0,0,0,28,41,43,75,1,0,0,10,49,0,443,0,0,856,2,39,0,11,2,0,0,6,0,0,0,0,0,0,0,4723\n",
      "373,0,128,1089,9,1176,23,139,305,12,13,2,9,0,80,0,14,55,211,8,17,256,44,3,0,0,1,0,1848,0,870,2,0,0,0,5,1,0,0,0,0,0,13,0,0,0,0,3294\n",
      "1378,24,11,877,89,1897,18,468,816,1,75,75,0,3,73,0,270,58,50,155,0,13,542,2,0,17,0,19,228,0,17,196,1,0,0,0,395,0,12,12,0,1,0,89,0,0,0,2118\n",
      "233,0,106,593,0,784,49,22,287,0,547,284,11,16,37,91,64,0,68,114,253,71,961,8,5,3,65,15,263,0,0,1,46,0,0,43,84,0,0,585,14,0,99,0,0,1,0,4177\n",
      "949,0,69,81,8,2254,127,14,14,179,93,0,514,10,441,1,37,379,0,0,0,0,0,0,0,1,0,0,16,605,354,150,281,598,322,0,4,421,0,0,0,0,3,0,0,0,0,2075\n",
      "1778,19,221,431,95,1309,282,0,663,0,0,344,51,35,727,0,24,137,192,0,0,0,85,0,0,3,0,0,139,0,0,6,0,13,0,65,125,0,0,4,0,0,0,0,0,0,0,3252\n",
      "700,88,234,1016,33,2054,40,106,72,0,27,1,40,65,106,0,133,2,0,60,485,389,468,2,0,16,80,0,73,0,0,807,26,0,0,0,61,0,0,0,0,0,0,0,0,0,0,2816\n",
      "505,1,80,3103,0,1203,17,184,160,0,285,0,371,36,8,0,113,1,225,0,0,0,91,0,67,52,11,0,323,0,226,8,0,0,0,0,0,0,0,52,0,0,0,0,0,0,0,2878\n",
      "1585,4,766,116,0,1511,8,0,0,0,9,29,107,353,27,0,428,0,121,2,224,0,202,0,2,6,1,0,263,0,0,159,11,0,0,0,3,0,0,102,0,0,0,0,0,0,0,3961\n",
      "620,0,393,239,0,1113,914,0,64,198,429,10,442,373,15,0,0,0,36,912,204,0,10,128,1,0,2,0,240,0,0,69,7,0,0,0,8,0,0,0,0,0,0,0,0,0,0,3573\n",
      "442,491,1591,408,0,1027,77,0,0,0,372,28,2,206,0,0,883,15,99,126,0,0,573,139,3,0,0,0,272,0,103,23,98,0,0,0,3,0,0,7,0,0,0,0,0,0,0,3012\n",
      "1449,8,157,82,0,496,2,6,1153,3,0,450,7,2,184,0,0,49,40,10,5,2,115,8,0,33,0,0,480,0,12,26,250,0,0,0,231,0,0,115,0,0,2,0,0,0,0,4623\n",
      "739,356,688,211,0,766,155,268,870,0,123,12,182,0,3,1,309,0,7,2,0,0,486,14,0,119,11,0,34,0,0,97,68,0,0,0,71,0,0,0,0,0,0,0,0,0,0,4408\n",
      "1214,0,125,344,195,422,44,0,1212,173,36,111,74,63,153,0,145,9,143,8,13,15,139,0,0,245,27,0,726,0,0,0,4,0,0,0,33,0,0,0,3,0,0,1,0,0,0,4323\n",
      "1497,733,24,810,0,1038,61,107,200,30,21,0,105,980,9,214,84,0,0,25,0,19,205,0,0,111,161,0,111,0,0,257,6,0,0,4,3,0,0,0,0,0,11,0,0,0,0,3174\n",
      "2074,1,843,544,0,1354,7,0,27,0,270,248,37,0,0,0,0,0,90,529,0,0,1,0,0,80,0,3,167,0,0,7,187,0,0,0,58,0,0,4,0,0,0,0,0,0,0,3469\n",
      "1332,0,495,615,0,1983,94,5,40,10,275,2,0,211,2,0,84,82,1034,42,0,4,36,0,1,0,2,0,1,270,3,953,125,0,0,0,26,0,63,0,0,0,1,0,0,0,0,2209\n",
      "751,0,727,1252,28,1183,292,713,302,0,456,28,27,0,172,23,8,31,5,23,1,1,596,37,37,2,0,0,229,0,4,142,36,0,0,0,6,0,0,13,0,0,0,0,8,0,362,2505\n",
      "1084,0,1902,687,0,504,186,621,253,2,210,0,127,211,0,1344,102,29,0,126,0,3,3,141,0,2,3,6,43,0,2,0,4,0,0,0,2,0,0,174,0,0,0,0,0,0,0,2229\n",
      "864,0,692,318,0,1083,7,41,329,362,0,73,140,2,160,0,0,0,2,4,2,0,7,0,0,0,4,128,236,0,0,0,4,0,86,495,3,0,0,10,6,0,16,0,0,4,0,4922\n",
      "918,19,0,239,0,1056,7,375,357,0,28,369,780,0,0,288,1,38,7,0,18,0,193,312,20,4,0,0,250,0,3,3,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,4709\n",
      "748,0,296,345,0,1768,36,0,16,0,616,0,759,45,114,146,60,2,466,523,1,22,228,66,3,18,750,0,50,0,0,94,31,0,0,7,24,0,0,2,1,0,9,0,0,0,0,2754\n",
      "1018,1,312,626,0,1478,229,10,205,64,49,71,0,268,195,0,810,39,53,41,131,0,208,128,0,0,0,10,191,0,0,132,66,0,0,0,0,0,0,1,0,0,0,0,1,0,0,3663\n",
      "1166,0,115,549,0,1842,0,148,221,169,433,30,314,4,22,0,42,32,74,194,16,0,21,0,0,0,0,0,256,0,0,203,183,236,0,0,0,0,0,1,0,0,0,0,0,0,0,3729\n",
      "408,0,14,855,0,377,703,286,126,234,0,7,343,151,85,0,19,126,321,697,535,3,0,0,45,1246,1,23,133,0,0,13,13,0,0,188,0,0,66,6,2,0,0,0,0,0,0,2974\n",
      "1507,0,715,90,0,1082,13,73,243,95,590,101,20,1112,237,194,0,27,316,381,0,71,27,0,0,0,0,0,203,0,0,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2865\n",
      "513,0,399,657,0,1207,241,424,355,0,596,123,7,95,0,60,45,0,158,0,784,0,568,31,0,22,97,1,162,0,2,96,97,0,16,6,0,0,16,0,0,0,0,15,0,0,0,3207\n",
      "2163,88,284,338,66,807,212,2,752,36,648,43,95,5,0,4,2,119,0,3,0,28,0,0,0,16,0,195,8,0,0,84,315,0,0,0,331,0,0,0,0,243,0,0,0,0,0,3113\n",
      "615,40,166,67,51,2187,17,6,242,14,0,61,0,2,14,10,3,2,320,51,61,0,145,0,0,0,62,0,51,0,30,16,6,0,0,0,126,0,0,0,0,84,5,261,0,0,0,5285\n",
      "619,875,82,526,19,698,209,0,314,0,113,0,127,1319,0,17,32,0,57,484,1,1,119,0,0,372,57,0,29,0,4,633,6,0,0,0,0,323,0,11,6,0,0,0,2,0,0,2945\n",
      "480,105,730,809,105,504,47,0,245,132,110,1189,3,1,119,176,262,263,2,66,0,81,48,1,0,0,177,1,343,0,3,264,8,0,0,13,129,0,0,0,1,0,0,0,0,0,0,3583\n",
      "1126,289,172,307,0,1998,134,0,12,1,66,20,119,14,60,0,0,17,48,3,0,508,34,1,0,32,0,26,106,0,25,12,30,0,0,0,114,0,0,6,0,0,0,0,5,0,0,4715\n",
      "1298,0,51,566,323,651,154,0,13,0,25,911,0,0,380,0,0,17,41,1694,0,161,28,2,5,0,205,0,1,0,14,296,160,0,0,0,10,0,0,13,0,0,0,0,0,0,0,2981\n",
      "607,2,7,233,0,2334,174,5,218,0,658,11,17,0,0,103,0,1,129,168,15,0,2,0,0,15,24,0,231,412,0,140,46,0,0,0,66,0,0,0,0,0,0,0,0,0,0,4382\n",
      "928,451,492,15,57,324,7,328,1159,0,3,7,2,0,71,7,4,158,0,70,0,0,133,0,4,1,323,0,85,0,43,73,283,0,0,0,1404,0,0,2,1,0,0,0,0,44,0,3521\n",
      "1360,0,1,118,154,894,36,564,201,24,113,105,2,5,242,32,90,51,121,284,205,74,286,216,218,0,46,54,388,7,17,1030,118,1,0,0,319,0,0,0,0,0,0,0,0,0,0,2624\n",
      "2852,0,36,578,12,376,130,176,55,0,38,1,2,65,28,0,37,0,44,61,0,5,6,4,0,0,13,14,670,0,1,101,36,0,0,525,26,0,0,1,0,0,0,0,0,0,0,4107\n",
      "1422,0,10,473,12,1085,103,21,5,1,435,0,73,9,63,179,1,4,74,149,68,94,109,13,0,20,25,0,91,0,0,118,58,0,56,17,897,0,0,0,0,0,0,0,0,26,0,4289\n",
      "2535,38,585,204,0,537,27,0,178,0,7,13,1,15,408,6,87,296,0,0,0,67,47,224,86,502,0,85,950,0,0,0,97,0,0,0,4,0,0,66,0,155,0,0,0,0,0,2780\n",
      "574,0,93,904,121,627,25,12,414,12,700,48,50,0,1045,1,66,9,14,3,9,6,40,0,186,0,0,66,0,0,0,390,0,0,0,30,112,0,19,0,2,0,0,0,0,0,0,4422\n",
      "200,46,172,135,0,2691,33,84,552,6,217,128,0,7,24,0,0,480,360,40,0,0,575,7,0,0,0,457,454,0,0,557,3,0,0,4,84,0,0,0,1,7,0,0,0,0,0,2676\n",
      "1003,0,440,265,6,225,204,51,320,35,121,3,110,15,1526,9,120,9,527,218,12,13,51,8,0,0,0,0,242,0,62,19,30,0,0,0,147,0,0,126,0,0,0,0,0,0,0,4083\n",
      "920,0,16,749,2,1117,637,53,183,0,20,0,405,1,363,0,1,0,61,61,0,3,2,1328,28,7,0,101,551,0,0,8,48,0,0,1,427,11,0,0,0,3,0,0,0,0,0,2893\n",
      "713,12,90,221,0,401,3,7,254,12,14,2,120,317,12,37,19,27,31,524,0,0,20,0,3,1,54,0,471,0,2,175,15,0,0,1,3,0,0,0,3,0,718,0,1,0,0,5717\n",
      "656,125,21,438,0,1332,72,0,89,1,306,23,26,9,30,2,1,0,2,322,773,6,716,43,0,18,0,2,69,269,71,468,1284,0,0,134,1,115,0,0,0,0,0,0,0,0,0,2576\n",
      "1637,0,91,687,0,2201,3,5,18,0,3,336,0,12,88,1,50,0,93,222,0,0,4,0,24,1,11,3,202,0,7,253,0,9,0,0,1,0,0,0,0,179,0,0,0,0,8,3851\n",
      "1271,5,178,893,0,719,61,72,342,0,61,99,58,0,7,37,3,155,12,46,0,8,86,150,0,3,125,0,13,0,55,101,201,0,0,0,1,0,0,0,531,0,0,0,0,0,0,4707\n",
      "1719,0,803,60,23,842,722,487,69,320,28,4,0,0,3,48,221,6,116,131,0,0,153,344,109,2,231,3,91,0,0,65,107,0,0,1,0,0,1,22,0,41,0,0,0,0,0,3228\n",
      "626,22,1,127,5,808,3,28,62,0,275,238,0,0,5,165,55,0,600,116,221,0,256,0,0,429,35,0,181,0,4,164,30,0,0,15,58,0,0,0,5,0,0,0,0,0,0,5466\n",
      "1289,0,0,818,0,1478,24,0,1219,0,249,0,415,1,9,0,7,0,26,168,0,67,681,143,0,5,3,5,267,0,23,349,4,0,0,0,1,0,0,2,2,0,0,0,0,0,0,2745\n",
      "296,0,473,404,139,2737,145,533,714,1,4,0,1,7,474,1,0,3,109,22,126,2,67,4,0,0,684,0,2,0,0,2,24,8,0,0,1,0,0,0,0,0,1,0,0,0,0,3016\n",
      "1014,68,12,773,129,1979,129,0,338,64,4,0,101,0,102,0,358,24,222,4,0,0,5,0,0,28,2,0,161,4,0,483,390,0,0,211,0,0,0,0,0,0,0,0,0,0,0,3395\n",
      "670,0,485,466,0,470,668,14,166,0,522,917,101,0,112,1,90,72,14,831,0,0,9,0,0,5,25,143,43,0,1,229,7,0,0,1,135,0,0,0,46,0,0,0,5,0,0,3752\n",
      "1558,1,89,253,0,865,220,0,547,1,14,0,28,0,81,5,4,280,2,232,0,32,801,0,0,65,0,0,1633,0,0,141,6,0,0,0,9,0,0,9,0,46,1,0,0,0,0,3077\n",
      "390,0,169,948,0,972,237,405,519,0,74,149,15,0,0,553,1,280,715,137,3,0,69,110,103,1,7,0,39,0,50,0,536,0,0,0,5,0,6,0,21,0,0,0,0,0,0,3486\n",
      "1011,5,1017,145,0,1484,3,19,415,42,87,27,59,195,0,59,45,1,14,0,0,0,112,0,57,94,0,146,122,0,408,77,425,0,0,0,3,0,0,0,0,0,0,0,0,0,0,3928\n",
      "683,0,775,1010,0,920,618,82,413,0,23,200,57,0,155,0,3,66,10,9,0,0,1,0,0,0,0,0,345,0,0,42,191,0,0,0,5,0,0,0,24,0,0,114,0,0,0,4254\n",
      "829,0,142,74,0,1363,21,55,267,76,30,12,374,908,970,0,103,65,3,559,852,2,144,0,0,35,0,0,124,0,272,143,4,0,0,0,13,0,0,0,0,0,105,0,1,0,0,2454\n",
      "1422,63,72,628,7,1572,38,43,42,118,85,478,0,0,5,627,77,6,100,250,0,0,0,29,0,8,0,0,844,0,0,136,155,0,0,0,41,3,0,6,0,0,0,0,0,0,0,3145\n",
      "1755,571,120,16,0,980,20,676,207,0,138,290,45,10,95,1,3,16,571,29,0,9,82,0,0,70,0,9,645,1,7,25,397,0,35,6,4,0,0,21,1,0,0,0,0,0,0,3145\n",
      "1391,0,226,493,14,1631,29,550,56,0,49,409,8,2,10,35,0,12,24,93,0,13,94,0,0,0,0,647,418,0,49,47,18,0,0,0,3,0,0,1,0,0,0,0,0,29,0,3649\n",
      "1321,5,41,1402,0,2246,6,112,370,12,24,73,3,3,525,1,93,89,24,598,0,286,584,11,18,11,1,19,199,0,11,0,298,0,0,10,31,0,0,0,58,0,3,0,0,0,0,1512\n",
      "1179,0,42,480,0,1437,210,0,27,178,5,353,25,0,1,103,7,68,126,32,0,1,313,0,0,43,14,5,246,1,0,181,41,0,0,0,477,0,72,0,0,0,0,0,0,0,0,4333\n",
      "1604,2,19,70,0,473,159,0,649,0,155,5,0,0,15,2,4,3,14,86,0,5,36,0,0,1,0,0,42,0,21,249,30,0,0,0,519,0,0,300,0,0,0,0,0,0,0,5537\n",
      "554,0,205,79,41,1768,107,4,51,0,72,453,0,0,116,0,0,852,1152,35,0,0,10,0,2,1,0,1,11,6,0,141,113,0,0,0,179,0,0,132,16,0,0,0,0,0,0,3899\n",
      "479,0,165,295,0,829,11,58,310,163,60,111,0,66,5,174,101,8,56,10,0,0,591,0,13,6,0,4,223,0,0,76,111,0,48,0,5,0,18,0,0,0,0,0,0,0,0,6004\n",
      "1061,0,165,342,0,1452,17,2,8,0,12,36,0,57,346,0,35,0,83,31,31,0,103,1007,0,0,1,1,45,0,61,608,3,12,0,0,23,0,0,0,0,0,0,0,0,92,0,4366\n",
      "203,0,620,223,0,3086,448,60,268,0,72,48,115,0,3,2,52,75,635,7,30,11,117,62,0,0,0,253,325,0,0,8,691,0,0,88,1,0,0,0,0,0,0,170,0,0,0,2327\n",
      "930,479,78,193,2,896,49,39,46,8,172,86,14,71,61,10,3,7,101,3,4,0,846,21,0,0,0,14,751,0,0,377,0,0,0,0,32,0,0,0,0,0,0,0,0,0,0,4707\n",
      "855,286,861,291,127,1157,194,0,61,81,184,0,13,0,62,109,0,0,119,338,0,181,321,0,0,0,77,0,163,0,21,37,21,0,0,0,97,0,1,0,0,67,0,0,0,0,0,4276\n",
      "306,3,315,327,20,1200,1156,0,586,258,325,9,256,56,82,0,2,54,27,101,0,7,123,0,51,2,1,4,746,0,18,3,11,0,0,0,1,0,0,0,3,0,9,0,0,4,0,3934\n",
      "1068,34,22,469,0,1756,135,0,407,32,385,9,8,59,0,2,1,5,10,11,5,0,83,66,0,0,0,0,29,0,831,2,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,4554\n",
      "336,3,875,836,43,847,384,0,379,0,1,1020,20,0,505,21,111,8,0,149,0,0,37,0,35,75,0,0,286,0,19,571,15,0,0,58,0,0,0,10,0,0,0,0,0,0,0,3356\n",
      "2123,0,1960,30,7,630,89,0,194,0,16,1,2,93,0,4,0,0,442,78,1,0,65,0,0,1,51,0,144,0,7,508,114,2,0,42,0,0,1,0,0,0,0,48,0,0,0,3347\n",
      "1347,88,1320,460,9,561,38,0,314,4,186,8,14,0,70,29,98,855,42,2,0,62,125,5,0,83,0,103,57,0,0,6,0,0,0,0,524,0,26,0,33,0,0,0,0,0,0,3531\n",
      "906,33,7,463,1,1108,19,21,0,332,30,0,10,4,295,0,56,63,103,1,10,0,0,43,0,27,186,157,168,0,132,116,11,0,0,0,228,0,0,0,0,0,1480,0,0,0,0,3990\n",
      "622,0,5,133,0,246,1,50,1678,0,1,33,107,256,22,0,25,1,15,48,4,32,1370,1,0,0,650,0,291,0,5,4,0,0,0,1,3,0,15,0,28,1458,0,112,0,0,0,2783\n",
      "1252,57,239,21,1,1367,27,349,392,88,71,8,10,2,0,10,414,475,43,53,0,0,923,9,53,0,0,25,0,0,0,204,10,0,0,0,3,0,0,2,0,0,0,0,0,0,0,3892\n",
      "1602,0,116,65,1,1050,230,0,1440,0,4,3,159,13,0,0,1,0,0,1149,0,25,373,1,0,169,0,330,74,0,4,8,1,0,0,0,2,0,0,0,0,0,0,20,0,0,0,3160\n",
      "1154,0,11,283,0,2135,275,340,8,50,0,28,265,43,73,0,159,0,130,63,5,62,939,6,345,140,0,0,18,0,1,227,59,0,0,2,52,0,0,0,0,0,0,0,0,294,0,2833\n",
      "2506,0,362,1352,0,950,1,137,239,0,0,29,133,0,9,0,269,1,84,11,2,4,540,0,0,0,0,127,44,0,31,102,33,0,0,0,46,0,0,0,0,0,0,0,0,0,0,2988\n",
      "1006,4,294,110,0,1161,34,87,1060,15,0,0,583,151,50,388,5,1,218,55,0,2,123,0,57,8,110,10,22,0,1,607,0,0,10,49,289,0,79,4,0,0,217,0,0,47,0,3143\n",
      "826,82,4,419,2,763,0,0,37,9,73,10,28,17,0,0,21,16,2,255,0,38,1027,0,12,21,0,0,487,0,3,191,311,0,0,6,651,0,0,3,0,0,2363,21,0,0,0,2302\n",
      "1125,0,278,201,0,1810,167,0,830,139,103,71,1,47,274,69,252,1,170,5,0,211,116,126,0,0,1,1,30,7,19,98,59,0,0,0,1110,0,0,0,0,0,0,0,0,0,0,2679\n",
      "807,0,307,274,1,1080,4,192,123,19,10,0,309,0,115,29,184,6,874,20,0,0,219,0,0,316,19,0,163,0,0,691,0,0,0,0,14,0,74,92,0,0,0,0,0,0,0,4058\n",
      "842,0,604,685,23,673,960,54,18,0,76,134,36,5,0,0,9,35,115,229,8,0,9,0,0,662,0,10,186,0,0,3,0,0,0,103,652,0,129,0,37,0,45,0,0,0,0,3658\n",
      "1216,0,3,1205,0,1130,276,6,569,1,3,6,0,158,260,2,11,67,46,0,0,539,120,373,0,0,0,0,4,0,0,29,152,0,0,2,1036,0,3,0,0,0,33,0,0,0,0,2750\n",
      "374,2,915,570,3,899,144,12,161,272,122,2,0,0,225,0,267,0,424,170,18,25,185,83,0,0,0,0,1639,0,21,46,0,0,0,0,49,0,0,5,0,0,0,0,0,0,0,3367\n",
      "1270,0,155,164,0,994,19,0,253,0,134,0,172,143,0,5,0,329,71,451,0,0,158,12,0,0,0,4,305,0,0,0,0,0,100,0,130,0,0,1,139,0,0,0,0,0,0,4991\n",
      "1744,7,111,494,123,378,40,0,541,6,799,419,0,0,124,42,0,2,58,89,40,7,36,0,0,0,0,2,64,0,56,15,9,0,0,0,487,0,5,0,0,0,0,0,0,0,0,4302\n",
      "563,69,137,420,493,693,14,0,58,396,364,0,35,76,17,0,31,5,154,752,111,19,268,0,0,0,0,5,6,0,454,111,76,0,0,0,1,0,0,0,0,0,17,0,0,0,0,4655\n",
      "1609,78,384,71,0,919,5,22,829,17,639,77,0,123,21,0,38,2,76,22,17,253,159,0,0,0,25,196,307,0,41,175,374,0,0,0,3,0,4,0,0,0,0,0,0,0,0,3514\n",
      "3410,17,85,151,127,633,186,31,109,0,3,13,0,21,3,63,80,1,5,0,815,524,200,0,104,29,0,0,416,167,112,1,0,0,0,44,9,0,0,0,1,0,0,0,33,0,0,2607\n",
      "2025,0,144,728,0,598,203,25,28,0,25,235,158,1,130,1,123,28,628,6,892,2,69,4,0,0,0,0,391,0,8,167,54,0,0,0,9,0,0,13,4,0,1,0,0,0,0,3300\n",
      "665,0,44,232,111,426,1128,40,51,76,51,801,255,63,1056,113,24,103,0,4,26,0,1505,354,0,9,0,55,129,0,2,24,24,0,0,0,121,0,81,0,0,0,0,12,0,0,0,2415\n",
      "614,0,64,228,0,916,144,67,306,18,0,88,19,0,93,6,58,4,137,27,0,0,50,5,54,15,0,331,1344,601,154,223,169,0,0,0,367,0,0,1,2,0,0,163,0,0,0,3732\n",
      "1440,0,158,248,0,1675,16,2,52,0,642,3,5,141,42,8,180,6,673,364,0,40,41,0,0,4,0,395,73,0,34,60,0,106,0,130,110,0,0,0,0,0,0,0,0,0,0,3352\n",
      "1203,22,126,433,94,1666,550,85,141,0,419,46,90,7,103,0,8,120,188,0,271,33,0,1,201,89,1,0,329,0,26,359,0,0,6,1,2,1,0,79,0,0,0,0,0,0,0,3300\n",
      "112,0,295,1016,0,1814,1,114,816,0,93,363,99,113,27,0,158,1,304,20,0,0,0,75,0,0,0,0,29,0,53,256,1064,1,0,3,0,0,0,81,0,0,0,0,1,0,0,3091\n",
      "496,0,7,10,0,1633,57,14,1017,0,529,1300,9,0,369,217,302,17,209,243,0,9,55,11,0,0,0,158,24,0,2,0,1030,0,0,0,8,0,0,0,0,0,0,0,0,0,0,2274\n",
      "1265,0,131,379,16,1632,27,0,307,0,227,11,106,0,254,0,419,4,13,21,0,2,105,17,0,0,0,0,1015,0,0,10,58,0,0,0,1,0,0,2,7,0,0,0,0,0,0,3971\n",
      "790,16,847,419,3,1454,82,26,1017,1,13,33,0,0,13,0,79,186,50,50,11,67,163,0,9,0,2,23,110,0,7,4,310,0,0,0,13,0,0,0,0,0,1,0,0,0,0,4201\n",
      "718,0,3,431,0,971,235,133,1,1,8,286,238,1147,125,12,57,734,150,194,0,0,344,12,0,1,0,0,447,0,0,20,418,30,0,0,141,0,0,0,0,0,0,0,0,0,0,3143\n",
      "1468,0,48,772,90,923,146,297,213,0,32,1,22,60,13,0,161,324,252,0,0,0,46,20,0,14,0,390,0,0,0,18,0,0,0,0,325,0,0,54,0,0,193,0,0,0,0,4118\n",
      "645,0,501,852,59,688,318,163,315,15,263,14,33,0,236,56,86,0,9,1,0,2,158,107,0,655,0,45,38,0,0,19,6,0,0,0,122,0,0,5,0,1,1,0,0,0,0,4587\n",
      "907,1,192,730,0,1783,144,14,900,7,46,323,27,0,171,0,19,49,426,3,1,1,31,0,0,446,221,6,266,0,0,180,4,0,0,378,27,0,0,0,0,0,0,50,0,0,0,2647\n",
      "434,63,90,1013,345,974,546,0,332,32,98,0,2,100,415,20,16,0,35,63,1,1,1231,1,0,0,0,0,13,0,15,97,313,0,0,0,0,0,0,0,0,0,54,0,0,0,0,3696\n",
      "1509,0,224,261,0,1710,639,0,153,201,872,15,0,10,20,0,48,0,1,26,4,0,0,0,0,0,51,0,323,0,0,9,3,0,0,5,1,0,0,0,0,0,0,0,0,0,0,3915\n",
      "790,484,57,60,474,1181,6,0,190,529,971,136,29,0,298,2,6,2,372,496,0,1,267,48,4,6,0,0,95,0,0,155,208,0,0,24,85,0,0,0,0,0,0,0,0,0,0,3024\n",
      "1099,15,14,66,0,2675,200,9,398,3,31,160,43,20,35,72,236,8,240,345,27,221,92,31,0,1,2,39,70,0,55,1,265,0,114,0,76,0,0,0,0,59,0,0,0,0,0,3278\n",
      "612,269,103,621,0,2229,46,239,17,0,0,114,6,136,231,98,10,2,370,17,13,459,80,8,0,127,0,0,2,0,63,6,61,0,0,231,2,12,2,0,0,0,0,0,0,0,0,3814\n",
      "440,0,612,929,6,1449,27,15,59,0,752,535,122,1,2,45,0,194,444,449,222,0,232,460,2,5,0,2,639,1,0,360,60,36,0,1,217,0,0,94,0,27,0,0,0,0,0,1561\n",
      "2452,22,178,909,0,400,88,12,100,11,51,103,0,156,57,672,335,24,33,39,12,147,374,1,26,0,0,414,27,0,0,61,289,0,0,0,46,0,0,0,0,0,0,0,0,0,0,2961\n",
      "1591,0,5,126,3,1245,175,4,472,2,2,4,0,0,491,22,4,26,0,55,0,0,5,0,46,8,0,43,60,0,0,56,227,0,0,60,670,0,0,53,181,0,0,0,0,0,0,4364\n",
      "1074,7,1387,215,5,715,15,37,313,0,131,0,318,0,25,1,7,0,117,5,31,0,551,2,0,112,0,39,369,0,2,410,3,0,0,0,3,0,0,0,25,1,0,0,0,0,0,4080\n",
      "915,2,237,280,0,1429,604,0,988,47,530,2,0,106,10,0,685,0,34,0,0,529,571,0,0,0,3,4,455,2,0,82,0,0,0,0,13,0,0,0,45,0,0,0,0,0,0,2427\n",
      "488,0,113,241,29,1266,47,14,182,0,7,102,61,101,20,6,70,169,364,116,0,1,19,97,0,0,0,5,52,0,38,1108,3,0,0,1,3,0,2,2,68,0,0,0,0,0,0,5205\n",
      "539,45,1105,1636,0,287,8,1,645,0,358,7,34,6,285,22,1,0,22,224,0,1,99,2,0,5,0,0,194,0,0,1,474,0,0,5,44,0,0,0,0,0,0,0,0,1,0,3949\n",
      "662,32,173,1973,223,684,11,13,525,0,231,4,33,1,349,101,1,20,215,27,0,56,668,26,0,0,99,0,25,0,194,201,0,1,7,0,0,0,0,0,0,0,0,0,0,0,0,3445\n",
      "753,0,29,842,44,595,39,0,345,0,24,31,0,15,174,9,499,1,1,3,218,2,35,11,272,0,0,0,176,0,0,9,87,0,0,89,13,0,0,0,0,0,0,0,0,0,0,5684\n",
      "1620,0,71,142,0,1413,828,27,433,0,781,15,0,443,23,0,0,6,128,325,28,0,157,0,2,11,0,0,148,0,5,58,136,0,0,1,12,0,211,0,0,0,0,0,0,0,0,2976\n",
      "199,1,114,971,0,1558,337,0,788,0,53,44,7,237,42,6,23,125,343,417,3,44,27,0,2,15,0,0,31,0,0,1,338,0,0,56,28,0,0,0,0,0,0,73,0,0,9,4108\n",
      "1094,0,118,477,0,1522,106,1,878,83,133,39,4,0,54,0,97,19,3,0,2,406,156,0,0,105,0,0,672,0,0,50,9,0,0,227,22,0,0,0,1,0,0,20,0,4,0,3698\n",
      "1073,0,1083,137,6,1352,81,9,78,0,52,0,0,282,13,0,404,45,58,0,0,0,310,10,0,1,0,37,436,0,0,211,200,0,0,0,0,0,0,9,0,1,0,0,0,0,0,4112\n",
      "831,0,198,97,151,1117,337,0,117,0,90,56,307,1,75,0,1,28,170,0,0,0,554,0,11,2,0,0,201,0,0,101,27,0,165,0,21,0,0,0,0,0,0,0,0,0,0,5342\n",
      "900,110,418,455,5,2035,150,49,73,0,0,178,203,0,0,0,80,4,405,110,0,221,12,22,0,0,0,779,59,0,2,777,15,0,0,0,12,0,1,0,25,0,0,0,0,0,0,2900\n",
      "636,0,608,49,7,1144,160,116,1700,48,585,37,15,0,282,7,141,77,130,2,1,0,388,17,0,9,0,69,37,0,76,133,108,0,0,8,0,0,4,0,0,0,0,0,4,0,0,3402\n",
      "1365,0,33,496,0,349,157,0,1269,2,7,4,165,202,133,0,191,9,221,0,0,0,1259,0,0,2,2,28,71,0,0,4,1460,0,0,0,23,0,0,0,60,0,1,0,0,0,0,2487\n",
      "1149,108,285,926,1,789,16,110,49,8,8,1,5,42,739,0,4,103,0,568,6,0,4,0,0,273,0,4,192,0,15,55,40,0,0,1,13,0,0,0,0,0,0,0,0,0,0,4486\n",
      "1148,15,463,463,3,1166,382,0,425,2,0,0,69,2,47,69,0,10,37,1,0,0,134,0,0,6,2,12,59,0,0,1061,7,0,0,0,33,0,0,0,0,0,0,0,0,0,0,4384\n",
      "1670,46,4,348,0,1462,42,15,110,13,1,22,230,15,16,0,1,116,31,34,521,0,210,258,0,4,144,499,340,0,83,26,0,0,0,0,0,0,4,12,0,0,0,0,0,0,0,3723\n",
      "604,0,112,266,0,917,218,7,315,1,23,922,463,0,36,1,224,0,1,40,0,83,279,42,0,0,29,0,267,0,301,645,102,0,0,1,0,0,8,16,0,0,9,0,0,0,0,4068\n",
      "1923,32,32,343,8,858,96,0,472,0,16,12,64,1,47,1,0,1,3,1398,570,175,0,0,0,0,0,1,17,0,0,44,51,0,0,30,671,0,3,3,0,108,0,1,0,0,0,3019\n",
      "465,0,852,688,0,1633,102,240,375,0,4,72,90,355,34,51,19,0,1,19,0,53,450,0,0,0,17,0,6,4,0,120,34,0,0,0,1059,0,0,0,0,0,0,0,0,14,0,3243\n",
      "886,0,186,79,1,360,0,116,256,0,316,417,87,477,11,156,108,67,93,248,0,0,13,14,0,16,3,70,18,0,0,455,91,0,0,0,183,0,0,0,0,0,0,0,0,0,0,5273\n",
      "963,0,150,776,51,977,266,0,474,0,66,9,13,5,391,0,4,13,0,5,3,244,52,0,1,0,0,0,92,144,0,12,53,0,0,0,8,0,5,0,0,0,0,0,0,0,0,5223\n",
      "2492,106,29,363,0,793,144,18,229,0,156,35,1,0,5,12,2,148,60,369,1,151,41,0,2,137,0,247,801,0,0,200,15,0,0,0,58,0,1,0,2,3,0,0,0,0,0,3379\n",
      "327,11,4,48,3,1783,949,366,38,0,20,490,95,0,25,15,40,52,9,159,0,0,3,160,0,0,32,0,208,1,11,40,16,0,0,2,44,0,13,0,0,0,73,0,0,0,0,4963\n",
      "337,0,1,455,15,1740,12,0,264,1,46,76,0,72,142,0,1,0,369,790,805,132,27,0,0,81,0,12,0,0,1,448,76,0,0,0,323,0,0,0,0,0,0,0,0,0,0,3774\n",
      "785,64,1035,215,7,1787,237,0,145,118,8,100,0,9,35,18,0,34,24,143,5,0,329,109,0,0,0,0,421,0,31,351,1,0,0,366,8,0,15,0,0,0,0,0,0,0,0,3600\n",
      "312,0,83,810,0,300,37,14,152,0,154,46,0,144,24,10,1,40,375,6,0,0,42,29,0,84,0,1,37,0,0,26,343,98,0,0,93,0,0,0,0,0,120,0,0,0,0,6619\n",
      "1111,14,439,97,1,1043,2,53,1658,35,67,56,0,18,0,0,10,29,6,60,0,0,18,1,0,0,0,0,25,0,41,46,297,0,0,0,59,0,376,2,0,0,1,0,0,0,0,4435\n",
      "1682,0,104,7,0,1791,927,0,33,0,11,0,0,57,6,24,2,73,0,242,64,72,396,0,5,0,16,2,767,0,0,1101,63,0,0,0,324,0,1,74,0,0,0,0,0,0,0,2156\n",
      "1599,348,367,93,0,1423,380,251,169,2,9,0,31,0,30,0,1,0,41,27,1,27,398,2,0,46,0,0,310,0,0,296,1,0,0,0,55,0,0,1,0,0,2,51,0,0,0,4039\n",
      "627,0,216,303,0,469,320,180,349,3,0,0,180,1,0,1,156,0,3,533,0,118,26,0,0,0,0,0,1017,0,178,54,64,0,0,0,0,0,0,0,213,0,0,0,0,0,0,4989\n",
      "630,0,440,447,117,300,86,24,237,269,127,49,106,4,372,87,0,23,1672,142,24,0,1043,68,0,4,9,0,15,0,0,319,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3380\n",
      "1299,144,273,341,0,824,560,1,185,2,423,39,1,86,5,0,12,33,10,9,2,48,68,0,0,277,7,0,73,0,413,66,35,0,0,3,1,0,0,0,0,0,0,0,0,0,0,4760\n",
      "410,0,207,198,0,2825,32,8,495,0,75,201,1,195,22,0,315,0,182,32,0,1,561,1,126,2,0,0,180,0,0,1,0,0,0,0,5,23,1,7,0,0,0,0,0,0,0,3894\n",
      "1807,0,42,30,4,1057,420,35,269,5,54,0,201,10,52,0,49,63,360,0,625,9,10,0,0,3,0,5,84,0,0,14,73,30,0,0,0,0,0,0,0,1,0,0,0,0,0,4688\n",
      "935,7,282,174,250,712,442,5,168,2,92,0,6,152,13,327,12,0,292,0,1,406,0,12,0,0,0,0,945,0,0,730,0,0,0,0,38,0,0,0,0,0,6,93,0,0,0,3898\n",
      "869,13,0,815,0,2231,0,18,91,41,0,4,143,0,7,0,4,0,98,353,0,1,0,0,24,0,0,249,335,0,217,13,4,0,0,21,212,0,0,0,0,0,0,0,0,0,0,4237\n",
      "770,110,63,30,2,655,28,0,112,0,8,190,16,96,76,0,16,0,7,191,0,201,308,0,4,18,26,0,369,0,0,262,26,0,0,0,127,0,136,0,0,0,0,0,0,0,0,6153\n",
      "833,0,628,267,41,951,189,0,348,0,43,1,2,0,128,12,0,7,24,0,4,159,17,0,0,0,0,0,41,0,322,10,0,0,0,0,55,0,0,0,0,0,0,0,0,0,0,5918\n",
      "293,436,29,1513,30,1895,38,0,41,19,11,264,46,48,96,0,140,0,45,88,0,34,24,159,106,5,0,0,421,0,4,697,61,0,0,0,0,0,0,28,35,0,0,0,0,0,0,3394\n",
      "967,0,5,387,662,2190,347,3,330,0,36,4,0,215,30,0,34,131,85,4,202,0,0,0,0,384,0,0,191,22,0,112,0,0,0,0,100,0,1,1,0,0,0,0,0,0,0,3557\n",
      "161,0,12,645,2,571,163,0,227,0,28,37,16,1,417,39,1,39,685,138,0,6,142,0,1,0,2,57,753,0,20,318,0,0,0,7,17,6,0,17,0,1,0,0,0,0,2,5469\n",
      "406,0,6,796,24,1886,22,8,153,30,885,12,19,2,345,627,274,0,415,72,0,21,172,46,33,0,21,107,17,0,0,345,185,173,0,0,0,0,1,46,0,0,15,0,0,0,0,2836\n",
      "522,1,98,78,29,1206,142,873,569,0,13,1,10,36,45,94,126,1,0,119,0,0,347,0,0,0,0,399,113,0,0,255,0,0,0,0,50,0,0,0,0,0,0,0,0,0,0,4873\n",
      "1126,0,516,125,35,2657,88,0,43,0,95,9,3,2,258,279,0,0,70,2,0,0,0,22,0,172,0,17,335,0,0,283,2,0,0,0,2,0,0,1,0,0,2,0,0,0,0,3856\n",
      "1210,0,116,724,17,827,44,248,818,0,176,375,29,0,8,37,40,2,57,151,62,0,564,16,0,2,0,1036,50,0,140,0,0,0,0,35,222,0,36,0,0,0,0,0,0,0,0,2958\n",
      "1885,7,628,651,50,1447,66,28,174,0,62,30,81,0,14,88,348,75,69,324,0,76,47,60,0,1,0,26,28,0,348,1,184,0,0,0,25,0,0,0,0,0,0,0,0,0,58,3119\n",
      "656,7,72,51,9,2707,481,12,175,6,20,17,21,283,33,563,0,1,33,20,13,0,5,261,0,0,1,4,268,0,0,240,28,4,0,0,103,0,0,4,0,0,0,0,0,0,0,3902\n",
      "1192,8,318,254,193,716,1288,2,32,0,12,3,0,63,61,0,55,7,1,138,0,0,45,7,0,19,528,0,17,0,314,61,3,56,0,0,98,0,0,0,0,0,0,0,0,0,0,4509\n",
      "394,0,95,400,2,2224,92,4,401,4,602,0,2,0,130,0,96,0,29,44,119,3,592,48,3,0,4,0,126,0,38,1,76,0,90,0,3,0,0,0,0,0,0,0,0,0,0,4378\n",
      "818,0,23,498,0,967,294,218,40,15,10,15,0,21,21,1,39,0,0,24,0,0,120,7,0,2,568,0,652,0,249,501,0,0,0,487,23,0,0,0,0,0,0,0,0,0,0,4387\n",
      "756,0,107,548,0,911,10,0,364,249,0,140,145,11,467,0,281,403,993,80,0,51,1,0,0,3,1,0,9,0,0,120,0,0,0,4,119,0,0,36,1,0,0,0,0,0,0,4190\n",
      "1690,0,5,112,0,1214,57,33,42,0,212,7,89,103,27,0,11,0,37,100,1,0,5,149,5,0,0,0,278,0,42,11,5,4,0,0,153,0,0,2,0,282,0,3,0,0,0,5321\n",
      "887,0,115,246,20,1021,12,111,103,72,52,123,0,1,263,0,135,1,556,275,250,150,661,0,0,39,487,4,71,0,1,396,519,0,0,0,681,0,99,1,0,2,0,0,0,0,0,2646\n",
      "704,16,682,532,33,929,0,2,274,12,17,0,113,23,7,9,1,195,46,1,0,0,13,0,85,2,0,0,446,0,1,191,296,0,0,0,1024,0,0,69,81,0,0,0,0,0,0,4196\n",
      "2505,0,86,46,3,1043,119,27,180,251,2,23,340,0,333,0,4,135,42,0,0,335,10,0,443,7,0,0,110,0,4,30,465,0,0,0,32,0,0,0,180,0,0,0,0,0,0,3245\n",
      "327,8,336,587,0,899,0,5,56,0,30,0,44,1,6,0,70,78,224,85,0,0,79,49,0,1,0,0,469,154,72,116,24,2,0,1,581,0,0,0,0,0,0,0,0,0,0,5696\n",
      "517,0,103,869,39,1600,40,46,100,6,119,3,7,253,145,6,36,0,4,212,0,0,17,0,0,69,0,5,7,363,0,21,413,0,0,0,262,0,0,0,0,0,0,0,0,0,0,4738\n",
      "753,0,401,300,0,954,4,237,482,0,824,480,210,0,2,324,2,0,0,6,37,21,93,186,5,0,0,0,117,0,4,503,6,0,0,0,252,0,0,0,12,0,0,0,0,0,0,3785\n",
      "729,26,497,44,10,968,16,281,270,1,315,12,3,460,19,52,59,690,46,297,8,2,154,0,944,384,0,5,147,0,0,71,1,0,0,0,343,0,0,19,0,0,36,0,0,0,1,3090\n",
      "1223,0,204,171,0,1401,437,38,281,91,284,0,55,0,4,71,138,88,2,78,0,10,10,166,0,0,0,0,66,0,0,13,21,0,0,0,132,0,0,0,0,0,5,0,0,0,0,5011\n",
      "1148,30,266,678,0,1222,526,569,1289,0,20,53,0,0,62,39,44,0,642,0,0,0,435,0,0,0,0,1,64,0,0,385,183,0,0,0,74,0,0,2,0,0,0,0,0,0,0,2268\n",
      "1087,0,97,443,0,2190,142,273,148,30,57,0,21,89,502,0,214,3,18,240,134,153,12,0,0,0,0,0,103,0,0,23,0,0,0,0,8,0,7,0,0,0,0,0,0,0,0,4006\n",
      "1384,75,1734,589,0,1332,152,1,211,697,4,3,111,58,3,40,0,0,27,67,16,39,3,0,4,79,0,8,82,0,0,84,17,0,0,0,122,0,0,0,8,0,0,0,0,0,0,3050\n",
      "661,0,981,139,0,871,27,201,66,0,389,87,198,0,286,2,190,3,13,0,0,47,471,7,0,100,676,0,113,0,0,11,5,0,0,0,152,0,0,2,0,0,0,0,0,0,0,4302\n",
      "1501,14,1029,137,29,1546,245,1,92,8,22,134,65,0,70,0,152,24,2,11,0,0,8,0,79,0,0,97,196,0,0,9,571,0,0,0,18,0,0,0,0,0,0,0,0,0,0,3940\n",
      "1423,167,74,206,0,350,244,1,140,41,10,0,19,0,9,1,482,62,82,9,91,773,73,0,0,807,0,49,11,0,14,6,0,0,0,135,353,0,0,0,0,0,733,0,0,0,0,3635\n",
      "183,0,124,272,52,1898,361,2,135,0,1,0,104,0,57,17,2,1180,322,424,0,0,84,2,0,0,0,0,258,3,7,261,112,0,0,0,188,0,0,0,0,0,0,0,0,0,0,3951\n",
      "545,8,64,1109,182,691,763,0,242,102,437,1,0,0,2,1,1222,77,606,12,1,62,123,0,0,0,0,1,496,29,0,71,34,0,0,0,134,0,278,0,0,0,0,0,0,0,0,2707\n",
      "647,0,26,435,16,3785,979,355,80,0,7,363,7,0,4,0,58,2,254,186,0,0,39,0,0,54,0,0,120,0,3,5,2,0,0,0,84,0,0,25,0,0,0,0,0,0,8,2456\n",
      "3960,45,122,388,6,921,153,41,4,11,124,0,3,64,675,1,0,0,57,35,3,0,12,0,0,0,0,14,246,0,4,5,6,0,0,0,172,0,0,0,0,0,0,0,0,0,0,2928\n",
      "1047,0,9,206,37,1013,435,134,360,228,4,0,162,0,95,159,833,35,2,301,0,0,212,0,0,478,0,0,15,0,0,30,2,7,0,0,465,0,0,214,14,0,0,0,6,0,7,3490\n",
      "1907,54,45,29,2,2607,546,1,75,0,152,198,1,92,0,0,13,4,14,2,0,0,40,253,25,5,30,0,99,0,2,6,281,0,0,192,135,0,0,0,0,0,56,0,0,0,0,3134\n",
      "1123,0,158,68,58,1290,95,66,311,734,1,298,0,2,13,1,2,0,514,0,43,0,485,0,0,53,1,0,9,0,32,8,88,0,0,0,11,0,0,0,0,0,0,0,0,0,0,4536\n",
      "1087,0,63,807,1,1786,19,3,282,1,28,268,0,0,39,1,1,190,144,20,0,37,55,0,0,1,0,0,27,0,0,20,956,0,0,0,12,0,0,0,0,0,0,0,0,0,0,4152\n",
      "477,2,196,601,12,411,249,2,540,201,140,537,21,0,906,0,0,6,449,0,0,2,136,209,0,117,0,96,1,0,0,327,1,0,0,3,49,0,0,0,0,0,0,0,0,0,0,4309\n",
      "176,0,7,775,0,2240,1,1,454,0,0,1,0,80,0,115,378,0,397,98,0,34,126,0,0,3,0,0,766,0,0,142,10,0,0,0,3,0,0,0,0,0,0,0,0,0,0,4193\n",
      "713,97,160,215,0,1594,120,3,484,19,12,129,148,2,0,0,351,1,1,0,12,77,52,20,0,0,101,0,246,0,0,71,0,0,0,33,86,0,0,0,0,0,126,14,0,0,0,5113\n",
      "820,2,382,1016,0,1176,167,42,116,76,89,31,760,0,0,106,529,0,62,273,0,0,24,0,0,0,0,20,36,0,0,296,68,0,0,0,81,0,0,1,3,0,4,0,0,0,0,3820\n",
      "1655,0,294,246,285,1009,38,59,75,0,203,29,0,1,18,16,424,294,186,259,12,0,11,44,0,44,0,0,104,0,0,9,0,0,0,25,65,0,0,0,0,0,0,0,0,0,0,4595\n",
      "1236,0,454,681,0,1265,87,0,17,3,3,27,3,112,210,0,13,131,81,1011,0,134,7,13,0,5,0,6,205,0,294,336,56,0,0,16,145,0,0,179,75,0,354,0,0,0,0,2841\n",
      "689,30,204,35,301,915,45,0,161,0,461,1,359,79,122,18,39,0,93,7,803,1,367,4,0,596,0,0,52,0,1,51,183,0,0,0,4,0,0,2,0,0,5,0,0,0,0,4372\n",
      "1305,0,1082,33,15,1163,15,0,923,861,35,23,75,38,79,0,276,40,2,221,187,46,38,0,0,0,2,24,211,0,0,224,30,0,0,75,0,0,0,0,0,21,0,0,0,0,0,2956\n",
      "710,0,764,260,0,2348,0,27,189,9,68,12,58,0,163,18,309,8,130,20,0,0,75,0,209,42,0,0,48,19,0,378,12,0,0,0,8,0,0,0,0,92,0,0,0,0,0,4024\n",
      "2452,0,92,267,321,1345,630,0,558,0,111,81,114,0,17,0,92,252,156,74,0,0,50,0,0,5,0,0,425,0,1,18,322,0,0,8,21,0,0,0,0,0,6,0,0,0,0,2582\n",
      "1650,0,185,219,0,1482,44,106,330,0,1,57,0,1,1,95,243,1,0,52,1,43,21,0,0,0,7,39,931,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,246,4241\n",
      "902,154,2,181,0,1013,1,1,1486,4,47,75,10,6,14,0,12,312,66,599,0,825,6,0,0,134,0,172,7,0,18,4,15,0,0,29,99,0,0,6,0,0,0,0,0,0,0,3800\n",
      "582,70,416,126,146,633,170,0,10,0,165,0,7,24,1162,3,32,15,29,444,147,1,195,0,0,18,0,131,89,0,0,11,12,0,0,140,1,0,3,0,0,0,6,0,0,0,0,5212\n",
      "650,76,352,73,20,1164,56,320,21,0,5,52,0,0,387,0,79,0,4,1677,5,93,185,0,0,215,0,128,194,0,0,111,227,0,0,0,41,0,0,0,0,0,0,0,0,0,0,3865\n",
      "302,0,304,470,6,1895,301,1,226,0,39,3,199,5,38,568,194,63,227,51,628,0,135,0,0,0,123,0,64,0,214,90,414,0,0,0,318,0,0,146,538,0,0,27,0,0,0,2411\n",
      "391,0,18,960,1,537,39,0,44,28,615,0,29,0,0,147,71,0,5,55,186,0,408,31,32,0,0,0,89,0,529,378,6,0,1,23,0,0,0,0,65,0,2,0,0,0,0,5310\n",
      "1105,61,315,230,0,767,102,0,201,132,371,115,65,50,35,0,0,109,177,0,0,297,412,183,0,0,1,0,34,0,1,354,80,0,0,0,539,0,0,5,0,0,0,0,0,0,0,4259\n",
      "365,47,40,394,88,3011,10,257,179,194,0,34,1,688,268,508,0,17,245,17,33,0,47,1,19,0,39,0,35,412,0,14,0,0,0,15,14,1,0,0,0,0,0,0,0,1,0,3006\n",
      "558,25,254,961,36,681,3,144,124,5,141,234,63,8,526,0,152,2,250,15,247,0,116,0,0,1,0,0,187,1134,0,2,25,0,95,0,69,0,0,0,0,60,0,0,0,0,0,3882\n",
      "343,0,573,605,8,1269,0,144,206,50,18,106,728,5,304,32,20,44,31,147,0,0,185,0,0,0,1,0,334,159,140,63,333,0,0,0,39,1,0,0,0,594,0,0,0,0,0,3518\n",
      "2667,0,17,516,221,567,115,0,789,54,206,886,88,0,143,34,130,207,30,19,1,6,27,2,0,15,0,0,496,0,0,65,0,0,0,2,112,0,0,0,0,0,0,0,0,0,0,2585\n",
      "946,0,143,636,0,1350,5,0,167,224,16,41,67,58,0,13,129,8,14,362,15,0,124,1,0,3,1,21,237,0,21,173,0,0,0,0,405,0,0,0,0,1,1,0,0,23,0,4795\n",
      "174,0,519,362,0,1349,130,16,190,13,15,0,25,33,4,12,28,20,130,66,0,169,57,152,0,0,0,292,790,0,0,108,162,0,0,0,130,0,0,0,3,0,0,0,0,0,0,5051\n",
      "1936,0,245,924,0,322,607,11,2,61,68,212,11,2,749,35,203,4,7,59,3,0,15,0,0,0,0,0,212,0,167,15,64,0,0,13,746,0,7,73,0,0,0,0,0,0,0,3227\n",
      "322,1,4,1274,0,746,221,10,805,0,20,26,0,25,113,0,11,24,274,89,89,242,110,5,0,92,0,32,27,0,0,2,17,0,0,0,67,0,16,492,0,0,0,0,0,0,0,4844\n",
      "1967,0,227,381,8,667,234,27,0,0,57,126,60,9,121,0,0,168,69,5,80,1,78,0,0,0,0,106,172,0,0,476,25,0,0,0,10,0,0,0,2,0,0,0,0,0,0,4924\n",
      "418,0,301,729,456,912,55,30,132,274,211,495,0,10,349,28,314,35,12,0,0,99,368,0,0,0,11,0,24,0,30,14,54,0,0,0,6,0,0,456,0,0,1,0,0,0,0,4176\n",
      "859,120,42,57,12,406,119,167,96,0,68,127,12,4,66,0,294,662,41,0,2,2,0,76,15,811,506,15,213,0,16,261,3,0,0,4,46,0,0,0,0,0,0,0,0,0,0,4878\n",
      "547,0,10,29,6,1856,104,0,38,11,143,82,502,122,660,43,55,4,92,43,11,189,228,0,0,0,103,2,519,0,0,38,69,0,0,0,50,0,0,0,0,0,0,0,0,0,0,4444\n",
      "2291,5,190,792,4,663,95,374,430,0,371,20,7,3,169,0,522,0,42,98,0,4,0,34,0,6,0,2,319,7,0,190,774,0,0,0,0,0,0,4,1,209,0,0,954,0,0,1420\n",
      "794,0,647,1016,0,1829,121,11,36,0,142,0,15,5,46,5,4,4,42,150,4,0,93,4,0,1,1,5,32,0,7,237,189,0,0,9,52,0,0,0,0,0,0,0,0,0,0,4499\n",
      "1770,159,10,407,0,1199,9,91,1083,0,82,1,127,1,58,28,1246,122,3,4,9,162,136,0,6,0,40,62,497,0,0,15,2,1,0,0,259,0,0,0,0,0,12,0,0,0,0,2399\n",
      "1523,0,12,664,0,965,24,171,15,593,15,56,0,90,261,13,0,3,96,91,15,3,262,0,0,51,0,15,14,0,0,15,32,0,0,0,101,0,0,383,0,0,0,0,0,0,0,4517\n",
      "652,4,459,887,2,798,77,75,258,4,268,0,0,0,206,1,8,319,18,314,45,0,13,0,0,145,54,0,502,0,14,706,13,3,0,0,99,0,0,0,0,0,0,0,0,0,0,4056\n",
      "1829,0,88,137,0,1534,27,1,145,0,81,40,7,1,843,6,272,0,224,13,12,0,490,5,0,1,0,1,722,0,0,432,47,31,0,0,50,0,0,14,0,78,0,0,0,0,0,2869\n",
      "2285,127,255,755,0,1430,2,91,30,1,122,0,222,127,6,4,133,3,192,50,0,0,83,0,0,91,31,1,6,0,0,4,0,0,0,0,23,0,0,0,0,0,57,0,0,0,0,3869\n",
      "862,0,1019,136,17,1287,36,240,98,88,149,429,148,306,0,0,1,36,443,1,60,0,89,21,4,236,148,3,367,0,0,185,12,0,0,4,91,0,0,3,93,2,0,0,0,0,0,3386\n",
      "990,51,84,230,0,2364,165,11,74,0,64,568,178,3,16,0,7,7,334,141,0,192,277,1,0,60,0,0,554,0,0,134,13,0,0,0,8,0,0,0,0,0,39,0,0,0,0,3435\n",
      "2315,5,480,752,0,1054,1,15,549,0,0,0,379,4,2,121,62,1,138,2,4,0,190,0,0,1,0,0,126,0,0,3,6,0,0,0,47,0,0,164,0,0,0,0,0,0,0,3579\n",
      "158,0,611,788,16,337,1062,18,39,89,4,174,1,0,4,396,30,0,275,225,59,0,260,105,0,0,972,183,109,0,0,140,147,0,0,2,9,0,0,0,0,0,0,0,5,0,0,3782\n",
      "998,14,145,318,82,1385,888,0,56,0,0,302,13,45,188,17,0,2,19,1,0,0,1,0,8,179,37,1,315,0,0,923,81,0,0,0,18,0,0,0,0,0,47,0,0,0,0,3917\n",
      "100,0,28,0,0,1177,42,248,93,23,147,261,14,77,29,0,10,22,120,16,0,3,295,901,5,0,121,0,247,0,32,49,57,0,0,0,475,0,719,0,0,0,0,3,0,0,0,4686\n",
      "2587,2,82,117,16,1381,88,0,166,67,364,64,0,3,3,363,118,1,32,0,0,0,75,0,0,0,0,105,628,0,7,0,2,0,0,0,39,0,0,0,40,1109,134,0,0,0,0,2407\n",
      "1136,0,703,493,0,776,119,3,4,91,0,38,0,246,114,96,115,0,298,39,0,0,157,19,0,1,4,1,864,0,0,3,211,0,0,0,83,0,0,0,2,0,0,0,0,0,0,4384\n",
      "247,28,177,76,19,1907,350,1,714,69,90,78,0,497,225,36,116,2,72,93,11,0,7,0,10,0,0,0,74,0,0,346,22,0,0,0,12,0,0,0,0,0,0,0,0,5,0,4716\n",
      "271,0,171,673,2,918,22,243,17,0,1,318,101,10,172,171,830,1,126,6,0,23,332,0,0,24,0,0,35,0,1217,61,267,0,0,0,35,0,0,15,0,0,0,0,0,0,0,3938\n",
      "1030,28,375,64,0,2046,221,2,433,0,299,120,178,157,555,14,128,326,29,111,0,0,3,0,0,1,4,0,610,0,22,19,13,0,0,0,65,0,0,0,0,0,0,0,0,0,0,3147\n",
      "421,194,32,90,0,1604,252,0,1063,113,13,0,40,295,478,41,26,0,249,4,0,0,148,0,0,2,0,0,392,0,74,4,15,0,0,0,15,0,0,0,0,0,0,0,0,0,0,4435\n",
      "658,1,16,636,0,1035,524,30,229,190,741,53,76,390,7,0,194,1,54,89,0,0,4,180,2,5,13,0,214,315,0,58,4,0,0,6,27,0,54,0,0,0,0,0,0,0,0,4194\n",
      "603,0,362,129,0,2403,91,23,22,0,261,1,108,0,93,0,72,51,3,395,0,7,14,18,0,13,0,0,40,0,0,1172,2,0,0,117,37,0,0,0,0,92,0,0,0,0,0,3871\n",
      "427,81,92,260,61,2507,285,0,38,0,269,33,931,44,0,1,58,37,22,172,1,113,82,6,0,0,0,0,584,0,0,13,216,0,0,0,8,0,0,6,0,0,0,0,0,0,0,3653\n",
      "1222,0,861,678,0,677,140,13,753,0,131,16,3,70,18,7,30,0,106,101,4,42,1,0,0,0,21,49,671,0,0,100,1,0,0,35,624,0,0,184,0,0,0,0,0,0,0,3442\n",
      "1977,10,325,1564,0,493,1292,0,570,0,46,5,141,42,256,0,191,47,196,105,0,0,7,0,0,32,40,0,7,0,315,2,2,0,0,0,28,0,0,0,1,0,0,0,0,0,0,2306\n",
      "351,10,123,9,0,2318,0,0,292,2,1196,0,0,1,1,0,298,0,1,58,0,0,99,1,0,0,1,0,457,0,0,135,164,0,0,0,81,0,0,1,0,0,0,0,0,0,0,4401\n",
      "922,0,382,1982,2,299,358,0,125,246,20,0,9,18,178,5,0,45,593,15,0,0,28,0,0,11,314,0,315,0,830,17,140,0,0,11,0,0,0,0,0,0,0,0,0,0,0,3135\n",
      "1951,0,147,381,111,1403,379,4,190,65,311,18,1,0,5,86,116,91,134,37,10,0,68,0,0,45,0,2,271,0,8,380,1,0,0,0,0,0,0,16,4,0,0,0,0,1,0,3764\n",
      "1059,0,379,348,0,420,7,90,1789,1,119,5,65,227,355,0,50,6,749,89,137,0,55,0,0,1,0,1,28,8,0,3,231,0,0,0,159,0,2,0,0,0,0,0,0,0,0,3617\n",
      "1257,237,27,224,5,406,394,0,203,0,0,0,244,9,1172,36,144,0,31,8,68,244,13,0,0,0,1,0,476,0,1,464,226,1,0,2,53,0,0,0,0,0,0,0,0,0,0,4054\n",
      "481,264,251,55,0,1560,143,356,5,5,6,0,16,12,840,0,315,4,15,193,0,0,131,1,0,45,28,0,124,0,15,401,0,0,0,0,417,0,0,0,19,0,38,0,0,173,0,4087\n",
      "788,2,190,100,0,1660,461,15,187,0,320,2,71,0,11,0,100,5,2,118,0,0,3,1,0,1,0,0,470,0,0,54,0,0,0,0,120,0,110,0,0,0,5,0,0,0,0,5204\n",
      "1266,0,367,63,1,1334,12,72,10,15,323,183,11,61,223,15,208,899,89,1,28,0,52,0,3,57,0,0,717,0,0,8,565,0,0,94,7,0,0,1,0,0,0,0,0,0,0,3315\n",
      "564,799,30,801,0,1179,603,423,26,0,3,27,0,100,8,0,77,0,158,231,3,23,920,53,0,34,0,0,176,0,0,977,9,4,0,306,0,0,0,0,0,0,0,0,0,0,0,2466\n",
      "1252,1,319,34,26,761,1,24,53,190,557,20,200,0,214,7,54,329,891,225,0,0,509,462,56,2,8,0,55,0,0,0,295,0,0,71,28,0,0,0,0,0,0,0,0,0,0,3356\n",
      "1010,0,153,366,197,1196,56,0,294,0,539,186,10,2,403,26,257,132,41,216,43,360,209,165,0,26,10,28,91,0,0,265,235,0,0,0,138,0,0,1,0,0,0,0,0,0,0,3345\n",
      "820,13,1225,34,0,1058,243,200,861,0,257,48,322,2,207,0,1,16,177,4,33,0,43,0,16,0,0,0,281,0,0,193,70,0,0,5,87,0,0,55,0,0,0,0,0,0,0,3729\n",
      "1372,3,355,1289,0,615,761,62,115,0,73,14,263,453,3,56,35,35,279,121,0,0,7,183,8,25,0,5,291,0,157,71,137,0,0,2,254,0,0,5,0,0,0,0,0,0,0,2951\n",
      "1029,0,246,175,190,508,295,34,248,1,131,15,185,1769,0,174,375,40,31,1,2,0,557,0,0,0,1,8,224,0,105,130,314,0,0,0,14,0,0,0,0,0,0,0,0,0,0,3198\n",
      "686,0,120,957,409,1118,35,0,277,1,296,29,0,10,1174,106,65,96,66,17,0,0,11,0,0,7,41,229,459,0,0,424,81,25,0,0,528,0,0,0,4,0,0,0,0,0,0,2729\n",
      "1519,6,519,747,1,469,36,0,431,3,59,163,0,0,31,265,260,7,51,524,0,4,362,0,0,0,0,4,289,0,0,14,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4226\n",
      "1343,0,573,205,46,1060,789,22,564,0,119,154,121,92,53,4,364,12,46,36,4,147,0,1,0,1,0,0,84,0,4,49,639,0,0,70,222,0,0,1,35,0,7,0,0,0,0,3133\n",
      "1458,0,234,128,0,494,182,1,1556,36,16,5,197,6,443,131,37,84,14,43,6,2,130,0,0,0,0,0,2,501,0,0,44,0,0,0,508,0,0,1,0,1,0,0,22,0,0,3718\n",
      "937,8,367,123,7,1930,298,1,652,173,0,10,157,14,95,0,98,157,261,38,4,228,4,49,175,18,1,83,59,0,0,3,168,0,4,0,106,0,0,76,6,0,0,1,0,0,0,3689\n",
      "664,0,155,480,179,1162,740,8,632,0,271,21,8,0,0,3,12,5,150,92,210,0,259,2,0,88,1,0,44,0,445,131,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4216\n",
      "289,78,763,184,264,1229,62,13,259,3,14,14,248,49,1,0,117,48,245,8,0,360,127,203,2,0,1,2,123,40,24,81,25,0,0,0,10,0,0,0,1333,0,0,0,0,0,0,3781\n",
      "861,0,66,78,0,2330,46,160,126,176,132,13,39,31,12,7,0,99,7,0,60,45,110,3,0,13,0,2,3,0,152,515,1391,0,0,267,60,0,0,8,0,0,0,0,0,0,0,3188\n",
      "410,6,477,38,0,2080,101,0,1401,27,359,23,0,26,87,4,25,9,0,0,1,0,257,0,0,0,0,0,306,0,0,251,0,0,0,0,402,0,0,0,0,0,0,0,0,0,0,3710\n",
      "1862,0,323,1605,24,1327,276,69,174,0,25,134,0,12,98,0,6,0,31,114,0,105,2,0,0,0,0,0,43,0,111,532,236,0,0,0,48,0,0,0,0,0,12,0,0,0,1,2830\n",
      "1017,0,228,724,1,1419,639,112,295,0,698,8,130,0,0,0,233,5,875,134,0,12,122,0,0,0,3,0,8,0,0,77,14,0,0,1,0,0,0,32,0,0,0,0,0,0,0,3213\n",
      "483,0,125,590,0,2091,248,279,703,1,95,6,0,16,462,1,74,5,279,112,0,243,231,7,0,3,1,74,165,0,370,16,254,0,0,0,2,14,0,0,0,1,0,1,0,0,0,3048\n",
      "743,12,88,1038,94,2390,73,5,265,73,24,274,1,0,55,303,121,11,80,9,6,0,511,145,0,0,0,14,3,0,34,6,732,0,0,0,10,0,9,0,0,0,0,0,0,0,0,2871\n",
      "865,16,130,241,0,1572,1489,156,174,14,169,12,68,88,8,0,2,0,491,307,44,55,497,7,0,5,0,0,5,0,37,2,1,0,0,34,513,0,0,0,0,0,0,0,0,0,0,2998\n",
      "1014,0,1,335,519,367,11,408,197,22,22,113,0,11,5,13,235,10,122,52,0,0,339,2,0,4,0,3,96,0,115,293,0,0,0,27,1,0,0,0,0,0,4,2,0,0,0,5657\n",
      "194,0,40,220,0,2262,43,226,2,0,10,26,54,213,7,262,0,0,393,44,0,49,142,0,0,0,0,45,43,0,0,362,367,0,0,11,118,0,0,0,0,0,0,0,0,0,0,4867\n",
      "1890,8,131,371,12,802,134,34,750,120,703,13,0,28,82,5,0,45,5,204,0,89,120,0,0,0,11,0,294,0,714,3,0,0,0,0,4,0,1,0,3,0,0,0,0,0,2,3422\n",
      "552,0,89,442,0,1793,653,12,185,18,60,88,1,23,167,0,45,42,11,264,0,11,150,32,0,0,1,13,43,0,0,1,231,0,0,3,16,0,0,3,0,0,0,0,0,0,0,5051\n",
      "447,0,728,119,0,2153,38,48,763,1,6,1,0,155,5,19,33,390,349,44,1,0,30,0,21,0,0,50,313,746,1,113,2,0,0,0,0,0,10,0,1,0,0,0,0,0,0,3413\n",
      "550,0,9,314,0,1472,2,0,463,79,0,67,4,0,10,781,56,2,369,21,0,17,182,0,0,13,0,0,154,0,13,67,612,0,0,1,110,0,0,0,0,0,0,0,10,0,0,4622\n",
      "1007,6,654,606,11,1194,3,499,49,8,14,1,53,88,15,136,16,0,39,0,1,0,10,0,0,24,253,1,254,0,0,831,25,0,0,0,3,0,10,0,0,0,545,0,0,0,0,3644\n",
      "2113,26,113,472,98,1645,204,41,30,15,78,0,843,0,0,29,0,0,140,5,6,6,929,1927,0,0,8,0,8,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1253\n",
      "920,0,200,1708,75,864,41,13,91,0,223,265,39,6,1,6,193,578,340,2,13,7,46,11,0,0,0,3,168,0,0,5,0,0,0,51,227,0,1,5,0,0,0,0,0,0,0,3898\n",
      "1443,0,55,142,0,1063,0,15,745,0,45,16,520,73,220,47,2,0,0,9,37,13,86,0,73,0,8,15,25,0,0,95,0,0,0,0,535,0,0,31,0,0,0,0,0,0,0,4687\n",
      "1886,71,415,110,18,1597,52,5,149,0,17,15,187,90,38,249,22,11,142,813,0,185,203,0,0,431,0,0,875,0,8,36,0,0,0,0,183,0,0,197,0,0,0,0,0,0,0,1995\n",
      "589,176,302,120,0,2187,25,212,295,380,75,0,358,68,64,1,0,3,110,605,0,0,0,0,0,0,0,112,33,0,0,3,75,0,0,83,24,0,0,0,0,0,58,0,0,0,0,4042\n",
      "1467,0,130,140,31,1986,0,141,237,0,245,12,0,86,272,0,104,2,401,17,289,121,3,124,0,19,0,0,637,0,0,22,0,0,0,0,0,0,1,4,0,0,13,0,0,0,0,3496\n",
      "684,3,179,493,0,1245,0,3,710,5,427,2,85,4,0,109,12,0,374,313,5,17,96,0,6,12,230,0,1099,0,65,296,27,0,0,0,441,0,0,0,0,0,0,0,0,0,0,3058\n",
      "224,27,0,940,0,858,55,0,644,161,298,0,1,0,227,1763,32,0,27,3,2,4,165,0,0,0,0,151,760,0,0,13,165,0,0,0,154,0,0,3,6,0,0,0,0,0,0,3317\n",
      "1586,0,0,70,85,1868,191,20,126,192,152,0,1,0,22,11,11,166,423,23,0,0,206,5,0,2,7,0,72,0,123,12,103,0,0,0,16,0,0,2,0,0,0,0,0,0,0,4505\n",
      "1639,0,7,381,5,1999,213,0,259,4,0,15,5,64,15,43,24,22,175,8,0,0,45,3,0,25,4,6,244,0,0,258,270,0,0,1,154,0,0,0,3,0,0,0,0,0,0,4109\n",
      "1121,0,53,111,0,1676,105,0,356,4,55,0,526,53,1322,14,25,139,551,7,250,0,78,3,0,0,61,8,6,0,0,22,147,0,0,0,36,0,0,0,0,0,0,0,0,0,0,3271\n",
      "1002,18,27,261,0,1353,51,253,112,138,368,29,6,11,83,414,5,4,4,138,97,0,190,16,0,31,0,15,17,0,1,192,17,199,0,0,1,0,1,0,0,0,0,0,0,0,0,4946\n",
      "781,0,25,513,0,500,200,29,152,237,525,889,15,0,2,0,93,54,3,639,0,191,199,0,0,47,0,0,10,0,0,2,109,0,0,6,0,0,0,0,0,0,0,0,0,0,0,4779\n",
      "569,0,1222,186,0,1389,43,53,31,0,40,0,1,0,118,0,0,0,14,287,1,0,9,0,0,6,0,0,102,298,0,367,21,0,0,0,245,0,0,12,0,3,0,0,0,0,0,4983\n",
      "1563,1,198,719,0,1408,14,9,5,9,112,686,0,0,602,238,26,0,554,15,3,0,14,7,0,15,0,1,453,124,0,345,0,0,0,34,24,0,0,3,0,0,0,0,0,0,0,2818\n",
      "961,0,162,575,0,1630,2,1175,131,13,34,0,170,184,770,0,14,30,1,59,0,0,120,0,3,142,166,6,28,0,4,0,428,0,0,0,125,0,0,0,0,0,0,0,0,0,0,3067\n",
      "143,0,42,1745,3,1036,63,0,118,108,13,39,49,54,53,21,99,0,32,0,46,0,537,351,22,0,4,0,14,0,4,900,1,0,0,0,3,1,0,0,0,0,0,0,0,0,0,4499\n",
      "2159,3,38,400,0,966,223,22,355,0,2,0,16,211,0,1,88,30,102,330,8,109,645,100,59,0,0,0,115,5,3,12,65,0,0,751,1,0,0,0,1,0,0,0,0,0,0,3180\n",
      "1260,0,7,61,0,1219,436,46,205,23,78,29,265,153,0,195,56,118,204,0,1,3,151,0,1,0,0,0,696,0,1,206,5,0,0,3,331,0,0,0,18,0,0,0,0,0,0,4229\n",
      "1028,0,0,421,5,393,213,0,794,87,106,3,23,22,0,1,427,112,13,361,10,0,204,1,0,1097,0,42,47,0,0,112,0,0,0,0,11,0,0,22,248,93,0,0,0,0,0,4104\n",
      "3366,7,333,266,0,525,259,89,1,0,66,209,319,124,254,0,91,0,134,8,158,6,439,235,0,0,0,0,95,0,0,15,183,0,0,277,84,0,0,6,0,0,0,0,0,0,0,2451\n",
      "2147,0,182,321,296,1817,15,3,188,0,1,355,115,0,287,2,0,187,10,21,35,0,106,0,147,232,0,3,125,0,25,31,0,0,0,0,128,0,132,4,57,0,0,0,0,0,0,3028\n",
      "1064,1,33,232,0,1082,825,63,762,287,145,195,281,10,5,1,54,0,170,192,77,1,6,0,3,0,280,0,57,0,26,251,250,0,0,0,0,0,0,347,0,0,0,0,0,0,0,3300\n",
      "657,536,257,809,0,662,170,376,475,0,7,1,496,474,0,4,8,3,94,121,1,0,96,224,0,19,15,126,15,0,0,227,0,0,0,0,199,0,0,0,1,0,0,0,0,0,0,3927\n",
      "1012,0,34,204,0,1049,370,42,596,7,2,0,257,630,1,8,0,216,112,2,0,9,995,0,0,127,31,83,0,0,0,124,3,0,0,0,488,0,0,0,0,0,0,0,0,0,0,3598\n",
      "1251,135,683,81,0,1248,67,0,83,56,78,0,192,13,65,451,0,86,122,203,0,515,69,0,2,54,3,50,564,0,265,13,1,0,0,0,498,0,0,0,0,0,0,0,0,0,0,3152\n",
      "1464,0,620,187,0,809,88,3,79,18,692,2,2,50,47,117,259,4,39,95,1,3,0,1,0,0,7,274,4,0,168,16,45,0,0,0,917,0,0,188,0,0,0,46,0,0,0,3755\n",
      "586,0,148,498,3,929,113,35,183,98,740,77,0,0,8,0,0,1711,276,2,0,91,9,0,16,0,0,0,895,0,0,2,389,0,0,0,35,0,0,0,99,0,214,0,0,0,0,2843\n",
      "698,15,841,1055,16,1355,2,386,6,1,0,107,55,26,32,80,4,113,60,17,166,10,277,9,0,2,105,0,4,0,0,41,29,0,0,0,138,0,0,2,3,0,0,0,0,0,0,4345\n",
      "1482,19,194,343,34,1140,98,0,566,0,126,0,67,132,2,1,182,31,95,299,0,24,606,0,1,0,0,112,491,0,0,24,1,0,0,0,1521,0,0,0,0,0,0,0,0,0,0,2409\n",
      "786,0,261,206,0,3129,43,30,43,0,22,276,83,6,38,0,32,0,43,95,0,116,15,0,0,0,0,15,51,0,0,142,53,0,0,0,25,0,0,65,146,0,1,0,0,0,0,4278\n",
      "572,0,837,197,0,611,236,42,269,571,147,197,67,258,14,0,4,2,251,931,0,0,3,10,0,0,145,1,141,0,47,0,157,0,0,0,69,0,0,0,0,0,0,161,0,0,0,4060\n",
      "955,0,321,654,1,1307,205,33,166,0,79,0,400,69,174,84,17,105,442,217,10,0,24,0,0,167,0,0,58,0,0,93,32,0,0,0,3,0,22,36,0,0,0,0,0,0,0,4326\n",
      "1452,0,309,489,0,486,113,254,211,207,22,7,691,169,161,920,431,3,173,0,0,42,285,10,0,3,0,0,162,0,61,301,377,0,0,96,0,0,0,13,0,0,0,0,0,0,3,2549\n",
      "491,0,255,555,1,1029,0,0,651,680,330,16,0,91,39,0,357,233,185,922,3,40,23,0,2,0,0,0,1181,0,54,74,37,0,0,0,4,0,0,7,0,0,151,0,0,0,0,2589\n",
      "1153,5,293,780,2,1155,18,0,83,11,209,253,3,2,380,234,32,2,479,732,1,6,787,10,0,176,0,69,140,211,5,4,0,0,0,0,33,0,0,0,0,0,1,0,0,0,0,2731\n",
      "1517,0,869,48,0,558,14,0,127,0,1,2,1,145,710,1,6,305,12,624,0,0,38,2,7,0,13,90,55,0,0,46,2,0,0,0,0,0,0,2,0,0,0,0,0,30,0,4775\n",
      "902,17,204,159,0,2635,464,1,329,0,103,19,89,0,0,0,86,362,33,88,131,0,209,72,0,5,3,483,30,0,0,2,0,0,0,9,25,0,0,0,0,0,0,0,0,0,0,3540\n",
      "2241,0,11,950,0,958,1,3,23,0,259,466,377,0,6,0,82,677,5,260,0,0,361,128,15,73,209,1,164,0,2,64,0,1,0,0,277,0,0,0,0,0,0,0,0,0,67,2319\n",
      "459,0,536,601,16,1470,420,291,518,3,340,0,85,0,0,459,63,98,60,7,0,0,98,8,0,0,460,46,157,0,1,1206,1,0,0,351,0,0,0,0,0,0,0,0,0,0,0,2246\n",
      "527,0,41,635,0,1624,529,26,161,40,51,50,147,76,191,6,17,6,24,665,0,11,828,8,0,0,0,0,182,0,0,103,4,0,0,254,757,3,0,758,0,0,0,7,0,0,0,2269\n",
      "812,96,36,589,0,1609,169,0,190,0,102,0,4,0,16,468,187,1,10,164,0,33,462,25,1,22,86,0,62,0,163,985,1,0,0,0,38,0,0,0,164,0,0,0,0,0,0,3505\n",
      "1436,0,78,230,0,2178,203,105,46,45,53,12,133,63,45,44,15,31,28,89,0,275,60,3,0,49,50,0,121,0,0,221,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4355\n",
      "1586,678,165,142,161,1427,5,0,39,0,205,38,0,183,108,1,36,105,85,75,89,158,110,0,0,164,0,0,21,0,91,333,2,0,0,0,2,4,0,0,0,0,0,0,0,0,0,3987\n",
      "874,0,176,381,83,1015,1520,10,62,0,678,27,37,45,28,72,81,74,311,93,0,0,293,6,0,0,0,0,14,0,111,1234,19,0,0,40,1,0,0,0,0,0,0,0,0,332,0,2383\n",
      "1495,0,83,1219,20,1102,1,0,787,113,35,5,4,20,289,0,22,26,315,639,0,92,121,73,4,0,7,22,302,0,29,6,99,0,0,0,29,0,0,0,0,0,8,0,0,0,0,3033\n",
      "1066,5,324,71,129,600,546,1,356,321,204,68,3,656,37,313,129,273,127,21,1,4,458,0,0,0,1,0,248,0,0,165,23,0,0,18,83,0,9,0,0,0,102,0,0,0,0,3638\n",
      "466,2,378,343,0,1591,346,825,250,0,2,196,478,51,0,27,0,157,140,4,0,0,5,8,20,10,0,0,113,0,0,0,69,0,0,824,1,0,0,51,408,8,0,0,0,0,0,3227\n",
      "537,0,122,370,2,484,340,0,488,6,30,0,39,387,46,187,116,0,207,299,25,97,594,0,0,0,14,2,234,118,5,27,227,0,0,0,94,0,0,279,0,0,0,0,0,0,0,4624\n",
      "2098,12,332,1625,59,2034,831,17,140,0,2,13,15,10,87,0,4,0,0,58,226,6,5,11,0,34,39,0,279,0,125,72,1,0,0,0,1,0,0,0,62,0,0,0,0,0,0,1802\n",
      "1297,0,302,252,0,897,95,0,66,0,119,393,143,328,23,236,172,356,321,83,0,0,1,0,0,10,0,0,792,0,0,91,22,15,0,0,0,0,0,96,0,0,0,0,0,0,0,3890\n",
      "1511,250,498,371,0,1544,184,232,338,0,135,0,60,149,453,0,21,40,87,275,0,0,92,0,0,0,0,0,11,0,0,91,0,9,0,44,2,0,0,13,109,0,27,0,0,0,0,3454\n",
      "667,0,937,126,15,1508,79,6,462,222,26,112,137,0,35,0,0,200,582,2,0,4,545,136,0,0,0,24,24,0,2,209,32,0,0,0,463,0,0,0,0,0,0,8,0,0,0,3437\n",
      "185,4,479,507,0,681,114,134,1176,0,0,0,245,0,134,6,247,0,188,186,0,0,1061,54,0,180,3,0,32,0,75,8,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4264\n",
      "1386,0,313,199,2,1334,84,63,84,47,188,222,152,6,113,0,3,4,137,8,8,0,282,0,0,115,0,142,411,0,4,1082,47,0,0,0,25,91,0,0,0,0,0,0,0,0,0,3448\n",
      "2408,30,81,781,0,967,399,7,372,0,34,0,0,8,179,23,57,371,155,223,0,3,28,0,58,0,0,0,947,22,0,15,0,0,0,13,13,0,0,247,0,0,2,0,0,8,0,2549\n",
      "2304,5,70,46,0,1625,19,1,218,21,403,19,81,106,32,0,0,0,0,0,0,124,475,0,26,162,1,356,508,0,0,168,8,0,0,0,6,0,0,0,0,0,0,0,0,0,0,3216\n",
      "1452,0,172,169,10,2880,306,0,612,0,276,7,132,0,579,78,136,77,157,22,0,11,71,14,9,318,1,27,201,0,0,82,0,0,0,0,286,0,0,2,1,0,0,0,0,0,0,1912\n",
      "523,0,295,1654,0,1613,75,339,399,0,48,0,113,19,202,0,168,364,31,210,0,2,332,0,0,1,49,0,518,0,1,30,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2992\n",
      "2657,0,246,68,0,2889,46,68,3,0,21,5,11,1,0,1,87,0,3,30,0,18,260,2,3,8,0,0,168,0,0,578,30,0,0,0,141,0,0,0,0,0,0,0,0,0,0,2656\n",
      "1948,0,45,175,0,1215,2,30,124,211,33,199,75,28,105,1,36,171,72,259,5,12,163,0,0,13,27,0,29,156,0,1271,160,0,0,0,159,0,0,0,8,0,0,0,0,0,0,3268\n",
      "1567,0,351,589,0,1250,57,3,273,54,10,21,0,33,37,0,409,1,91,90,5,516,124,1,0,11,30,0,24,0,88,78,0,75,0,0,0,0,0,0,0,0,0,0,0,8,0,4204\n",
      "1065,131,346,181,0,829,4,0,32,0,106,194,319,15,69,50,274,291,229,7,1,0,313,3,0,2,0,0,121,0,0,1,1,0,0,862,36,0,0,1,0,0,0,0,0,0,0,4517\n",
      "2441,0,98,672,0,816,8,77,66,8,375,344,18,276,40,7,64,10,4,11,23,0,165,5,85,11,0,53,375,0,326,53,62,0,0,0,337,0,0,0,0,0,21,0,0,0,0,3149\n",
      "1931,0,45,207,15,1140,53,0,35,552,188,175,41,89,37,18,12,46,113,35,137,0,136,9,0,42,3,0,313,0,29,83,552,0,0,0,0,0,0,0,4,0,0,0,0,0,0,3960\n",
      "139,0,323,115,0,1220,755,1,1148,0,27,39,90,1,90,18,0,1,183,150,7,3,854,27,0,22,0,538,13,0,0,26,2,0,0,0,216,0,0,0,0,0,0,0,0,0,0,3992\n",
      "1242,0,537,620,0,1299,52,334,64,124,1,15,58,97,758,4,286,0,29,153,0,277,1,0,4,10,72,226,189,0,0,391,45,0,4,0,26,0,0,0,0,0,244,0,0,0,0,2838\n",
      "1548,0,87,95,0,1142,787,85,288,36,14,56,370,0,41,2,0,123,68,21,0,0,198,0,0,477,0,14,41,0,0,1576,9,0,0,0,48,0,0,1,0,0,0,0,0,0,0,2873\n",
      "38,0,1421,41,321,1357,31,20,1480,0,77,4,559,1,201,0,348,0,89,0,0,1,3,80,14,131,10,50,76,0,0,102,229,0,0,262,35,0,15,1,0,1,0,0,0,0,0,3002\n",
      "1245,58,147,96,0,1985,56,74,35,0,158,33,0,86,850,0,6,1,1244,6,57,0,21,0,118,0,4,12,205,0,90,48,0,0,0,0,21,0,0,0,0,0,6,0,0,0,0,3338\n",
      "924,37,175,80,4,742,103,220,1450,0,122,19,175,20,279,0,0,63,119,0,1,1,2,121,0,0,0,0,233,0,0,6,3,0,0,541,29,0,11,0,9,441,0,0,0,0,0,4070\n",
      "1851,0,46,169,0,1270,10,296,476,1,41,2,25,3,613,271,0,12,3,9,9,0,162,0,0,6,0,59,340,0,4,64,249,0,0,14,4,0,0,6,0,35,0,17,0,0,0,3933\n",
      "460,23,116,494,0,1172,43,186,618,466,3,0,126,0,169,12,147,9,120,499,0,0,155,12,0,6,75,503,26,0,5,539,9,0,0,0,273,0,0,0,0,0,0,0,0,0,0,3734\n",
      "704,0,89,255,4,1494,0,6,10,19,2,234,87,28,2,117,5,86,170,222,675,0,549,0,35,161,9,378,7,0,0,34,41,0,0,49,6,0,0,0,0,0,0,2,0,0,0,4520\n",
      "1258,26,21,262,186,958,20,12,231,0,0,0,38,49,726,538,7,28,15,170,195,0,309,0,0,0,0,0,539,0,0,226,0,0,0,0,0,0,0,0,8,0,0,0,0,0,22,4156\n",
      "1060,114,267,609,7,443,281,7,51,5,31,0,128,207,25,30,35,2,22,19,1,6,297,0,196,1,1,10,635,1,0,131,64,0,0,34,472,0,0,0,0,0,0,0,0,0,0,4808\n",
      "487,4,5,105,18,2828,0,0,754,0,46,15,13,6,10,84,1090,163,550,146,0,65,353,1,0,3,0,0,14,0,0,120,6,0,0,0,7,0,0,1,0,0,0,0,0,0,0,3106\n",
      "647,0,12,241,0,1464,0,5,3,179,0,4,0,0,219,80,0,0,173,2,0,28,250,0,0,0,98,67,353,0,0,167,203,0,0,26,75,0,0,183,0,0,28,0,0,0,0,5493\n",
      "978,1,507,174,0,1414,34,5,193,1004,23,1,99,0,334,31,1,43,1,0,0,230,450,0,73,1,0,0,139,0,0,48,1,0,0,0,65,0,0,0,0,0,0,0,0,0,0,4150\n",
      "762,80,185,661,0,1172,422,98,81,1,3,32,0,1,7,28,26,298,1,1,0,1,212,1731,0,94,0,1,306,0,0,222,8,0,0,0,4,0,12,0,0,426,0,0,0,0,0,3124\n",
      "578,0,70,154,0,1604,123,13,598,0,644,201,204,0,105,0,0,0,0,228,155,0,1675,118,56,0,80,159,300,0,1,150,0,0,0,0,0,0,0,0,39,0,0,0,0,0,0,2745\n",
      "509,0,124,519,0,558,119,84,318,0,151,106,120,124,1,0,3,510,1153,869,14,0,140,1,1,0,0,0,29,3,37,217,11,0,0,0,149,0,0,588,0,0,0,0,0,0,0,3542\n",
      "795,329,122,469,12,1015,282,0,577,0,35,513,52,0,862,85,44,68,3,306,0,46,30,0,194,1,307,7,116,12,0,396,392,0,0,0,46,0,0,1,0,0,0,0,0,0,0,2883\n",
      "1674,0,409,1255,3,788,558,320,533,0,0,5,33,242,39,0,334,0,0,4,0,114,622,0,0,0,0,78,8,0,17,36,317,0,0,27,39,0,1,0,0,0,7,0,0,0,0,2537\n",
      "344,0,29,543,0,574,0,0,544,0,10,1,13,71,22,49,0,7,2,274,0,0,357,27,0,199,0,1,804,0,0,391,4,17,0,0,2425,0,0,0,473,0,144,0,0,0,0,2675\n",
      "2628,0,162,292,22,1374,65,336,158,1,61,1,7,0,80,12,119,93,52,9,31,75,52,48,0,5,3,0,590,0,0,60,28,0,0,0,196,0,0,0,0,0,0,0,0,0,0,3440\n",
      "1236,0,637,524,0,300,3,131,193,0,126,3,41,2,90,14,492,373,386,871,0,678,101,0,0,286,0,303,174,0,12,214,164,0,0,3,10,0,0,27,0,1,0,0,0,0,0,2605\n",
      "712,0,282,194,6,1394,118,205,128,0,94,4,11,330,53,22,88,0,98,12,0,26,865,446,1,103,4,0,351,0,9,0,7,0,0,0,0,0,0,1,0,0,0,0,0,0,0,4436\n",
      "696,0,176,389,209,893,334,352,103,0,55,0,39,12,306,7,52,124,114,27,74,1,2,0,0,0,0,0,32,0,0,377,14,0,0,4,43,0,14,0,0,0,2,0,0,0,0,5549\n",
      "1715,4,598,636,355,1199,0,122,676,0,124,97,1,252,8,30,0,0,531,7,0,0,305,36,0,0,130,0,0,0,0,162,88,0,0,0,80,0,0,0,0,107,19,0,0,0,0,2718\n",
      "412,176,211,200,0,1735,90,37,884,8,34,156,20,0,1434,0,0,121,93,11,6,0,7,1,15,1,73,0,400,0,5,114,0,0,0,6,4,0,0,0,0,0,0,0,0,0,0,3746\n",
      "697,25,32,335,0,2095,14,20,312,192,72,300,128,1,5,111,0,487,46,11,1,0,277,0,0,0,13,14,3,0,1,132,709,0,0,41,55,0,32,0,0,0,0,0,0,0,0,3839\n",
      "584,14,709,456,293,2864,81,0,219,0,25,133,5,0,121,0,59,0,68,153,1,46,226,1,0,17,0,9,9,0,3,0,8,0,0,0,1,0,0,0,0,0,0,0,0,0,0,3895\n",
      "585,0,703,236,16,1151,1,0,277,0,2,546,631,0,119,34,1448,21,115,0,0,0,44,3,0,0,0,30,15,0,0,37,86,0,0,7,136,0,0,0,0,0,0,0,0,0,0,3757\n",
      "751,0,122,276,0,1347,7,1,304,0,1,16,13,0,0,24,232,0,528,167,0,3,32,484,0,2,243,0,136,60,226,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,5015\n",
      "650,0,139,204,0,1737,43,0,168,0,460,0,5,1,244,136,505,2,152,8,0,54,78,0,0,4,32,0,28,0,17,27,82,0,0,0,72,0,0,30,0,0,0,0,0,0,0,5122\n",
      "1388,0,282,1640,0,627,233,110,39,0,27,0,0,9,15,12,0,13,20,43,2,231,304,212,0,0,0,1,0,0,3,0,0,0,0,0,187,0,0,2,0,0,0,0,0,0,0,4600\n",
      "474,31,72,283,775,1763,72,17,111,135,300,1,336,1,258,6,0,0,157,84,0,0,23,0,63,0,0,15,10,0,260,71,204,0,0,19,193,0,0,15,2,0,0,0,0,0,0,4249\n",
      "1416,0,457,521,6,881,0,514,180,0,104,21,81,391,52,125,95,0,2,0,20,0,601,0,0,6,0,0,1084,0,1,15,0,0,0,27,15,0,0,84,0,0,0,0,8,14,2,3277\n",
      "846,1,210,756,0,1352,0,0,653,3,67,7,83,0,9,65,5,0,68,5,0,0,151,0,0,384,1,0,519,0,0,660,157,0,0,75,4,0,0,60,0,0,0,0,0,0,0,3859\n",
      "1939,0,242,255,133,1423,18,1,64,22,509,7,26,82,4,41,282,3,2,196,52,23,22,136,3,62,58,0,607,0,50,22,7,0,0,0,7,0,0,1,6,0,0,0,0,0,0,3695\n",
      "1139,0,135,460,0,661,2,3,1140,0,23,11,74,15,2,65,110,0,800,0,29,2,17,156,0,0,0,0,1,0,0,108,65,0,0,0,4,0,0,0,0,6,25,0,0,0,0,4947\n",
      "1040,143,491,582,0,1348,92,28,8,0,1491,5,10,70,274,0,6,0,317,17,245,108,215,0,0,0,317,47,433,0,4,3,1,0,0,0,0,0,0,56,0,0,0,0,0,0,0,2649\n",
      "1328,0,67,357,24,895,333,0,25,8,28,92,1,0,566,0,1370,0,544,999,7,28,40,0,57,60,299,0,81,0,5,1,3,20,0,0,314,0,2,19,6,0,0,0,0,0,0,2421\n",
      "596,0,121,284,4,1226,48,42,754,0,9,825,0,32,100,124,130,0,8,18,5,84,181,3,0,547,3,0,517,0,169,8,0,0,0,0,7,1,0,0,0,7,0,0,0,0,0,4147\n",
      "1385,14,137,130,0,916,80,35,75,2,420,4,0,17,261,0,49,288,0,161,313,0,7,8,0,188,0,0,454,0,1517,5,153,0,0,0,283,0,0,8,0,0,34,0,0,0,0,3056\n",
      "1981,0,525,546,2,1176,79,26,71,48,43,0,0,45,49,3,0,21,16,117,0,0,315,0,5,0,0,3,55,0,4,372,41,1,0,0,1,0,0,0,0,0,0,0,0,0,0,4455\n",
      "2193,9,490,119,0,1573,95,2,135,0,113,26,331,0,136,10,67,22,88,212,0,0,128,0,0,2,89,34,75,0,0,498,0,0,0,0,93,0,0,0,6,0,0,0,0,0,0,3454\n",
      "830,0,178,278,0,1276,128,3,163,2,390,1120,82,15,1,68,487,133,11,21,4,5,119,3,1,1,1,0,29,0,0,168,284,0,0,0,1,0,0,97,0,0,0,0,0,5,0,4096\n",
      "780,87,26,877,238,1790,29,39,172,0,15,0,53,70,62,2,62,89,92,43,428,21,4,80,0,11,0,0,271,0,0,2386,211,0,0,0,15,0,0,2,0,0,0,0,0,0,0,2045\n",
      "417,2,1241,84,149,1151,345,61,158,0,90,129,63,145,45,6,28,295,9,69,0,16,1,0,0,0,5,0,597,0,5,356,35,0,0,0,13,21,9,0,69,0,109,1,0,0,273,4003\n",
      "264,0,241,284,322,1291,167,1,130,535,36,40,44,51,144,0,0,2,111,86,1,165,49,78,0,0,197,0,885,0,50,3,36,0,0,0,4,0,0,0,0,0,0,0,0,0,0,4783\n",
      "1109,2,138,1077,760,2069,640,168,5,0,16,0,0,0,1,123,451,0,3,1,1,2,144,0,79,1,0,0,28,0,0,14,50,0,0,0,5,0,0,14,0,0,0,0,0,0,0,3099\n",
      "1904,1,168,117,0,974,74,611,87,221,118,136,432,994,171,0,8,19,21,0,0,1,33,15,0,0,0,6,55,0,0,305,258,81,0,0,8,0,3,0,0,0,0,0,0,0,0,3179\n",
      "1068,4,213,243,1,1129,0,4,910,193,0,14,155,11,964,0,1,0,25,14,170,2,394,41,0,231,0,218,23,0,0,443,270,0,0,3,859,0,0,0,0,0,35,0,0,3,0,2359\n",
      "1927,0,8,538,0,1094,165,1218,58,107,7,414,1,108,3,414,7,5,24,45,2,115,0,152,0,1,0,3,12,31,4,303,358,0,0,0,58,0,0,35,0,0,0,0,23,0,0,2760\n",
      "1312,5,243,1086,0,922,5,162,38,30,2,375,17,20,173,7,89,183,274,6,0,31,9,146,0,457,0,0,76,0,0,21,153,68,0,0,1463,0,0,2,1,0,0,0,0,0,0,2624\n",
      "2308,0,141,120,9,1281,37,113,210,0,214,39,0,269,441,206,4,35,12,77,0,143,233,0,38,0,1,8,923,0,0,106,10,0,0,5,3,0,0,0,0,0,0,0,0,0,0,3014\n",
      "870,144,314,1615,0,751,89,0,132,113,9,0,0,0,222,108,0,29,70,4,0,0,24,0,0,75,120,5,620,0,7,374,14,0,0,0,104,0,0,73,0,0,0,0,0,0,0,4114\n",
      "144,117,0,91,0,1494,367,3,84,98,688,547,2,5,0,19,0,330,9,1,0,186,0,0,0,0,139,0,375,0,0,15,61,0,0,21,56,0,5,0,0,0,0,0,0,67,0,5076\n",
      "274,65,97,444,24,1993,45,152,146,947,1119,68,1,118,0,4,86,1,2,245,14,0,101,52,0,0,1,0,77,0,41,407,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3447\n",
      "672,2,134,1181,3,1844,67,0,770,2,527,2,117,92,50,32,81,0,5,153,10,441,122,44,0,0,0,0,49,24,0,0,110,0,0,0,6,0,2,0,0,1,0,0,0,0,0,3457\n",
      "503,109,791,415,0,836,99,463,14,0,11,15,148,43,2,6,144,0,163,0,99,1,58,104,0,0,110,0,539,0,0,15,362,0,28,1,56,0,501,0,0,0,0,0,0,0,0,4364\n",
      "619,0,612,459,72,2116,13,10,285,0,212,0,2,1,0,10,27,44,870,231,2,0,42,0,0,0,0,0,155,0,156,371,15,0,0,0,20,0,0,6,0,0,0,1,569,0,0,3080\n",
      "214,165,3,43,0,559,1180,770,316,0,46,5,1,438,788,0,76,32,189,133,0,52,1,260,0,287,363,0,75,0,6,197,553,0,0,1,1,0,0,1,0,0,0,0,0,0,0,3245\n",
      "516,0,157,359,6,1105,0,4,267,65,0,5,2,0,1135,7,8,124,118,154,0,41,16,0,0,21,0,0,100,0,0,12,32,0,0,0,710,0,0,2,0,0,2,0,0,0,0,5032\n",
      "1742,8,178,149,5,663,154,294,138,0,733,641,572,0,8,0,5,56,1,0,143,60,289,165,1,0,0,0,27,1,875,190,1,0,0,0,188,0,0,0,0,0,0,0,0,0,0,2713\n",
      "403,11,528,66,9,1232,2,18,40,0,486,272,19,725,33,163,212,51,237,819,197,0,23,0,0,1,34,0,1,0,0,7,784,0,0,85,14,0,0,361,0,244,0,0,0,0,0,2923\n",
      "1032,0,79,923,2,1913,41,1,27,0,76,7,0,0,96,0,2,2,270,180,1,0,108,102,0,28,5,0,4,0,21,192,3,0,0,0,134,364,0,5,0,15,0,0,0,0,0,4367\n",
      "686,0,4,514,142,809,71,317,1,822,3,40,6,3,121,0,106,993,7,24,0,126,141,23,144,2,0,38,194,0,10,227,234,0,0,60,71,0,0,295,0,0,0,0,0,0,0,3766\n",
      "790,0,311,722,5,1335,501,0,355,98,0,165,9,0,0,12,680,417,252,36,0,1,99,145,360,0,0,0,127,0,3,339,21,0,0,0,6,0,0,2,112,0,0,0,0,0,0,3097\n",
      "485,0,260,340,0,1539,278,59,1134,20,69,0,8,1,24,0,69,0,413,313,0,40,2,0,0,192,0,44,5,30,15,107,0,0,10,89,0,0,0,2,0,0,0,0,0,0,0,4452\n",
      "958,0,400,47,0,757,142,26,940,27,8,21,7,7,115,0,13,7,18,586,866,188,298,23,1,1,0,0,254,0,2,241,7,0,0,0,0,0,0,25,0,34,0,108,0,0,0,3873\n",
      "918,0,0,201,0,1001,96,438,398,0,53,0,44,1082,46,4,67,4,0,521,69,0,130,69,16,7,12,56,413,4,0,147,51,0,0,1,9,0,0,0,105,9,0,0,0,0,0,4029\n",
      "411,0,167,924,52,1156,262,6,36,0,0,341,0,0,5,0,3,0,22,2,13,1,9,0,0,0,0,3,54,0,97,7,0,0,0,15,0,124,0,1,0,0,0,0,0,0,0,6289\n",
      "339,0,15,411,0,2186,29,0,157,442,1430,0,1,1,79,362,20,5,232,22,0,102,269,761,0,7,0,7,635,0,1,0,43,0,0,0,146,0,0,23,5,0,0,0,0,0,0,2270\n",
      "833,0,5,668,102,1104,242,158,4,0,0,0,94,61,511,45,105,14,15,509,0,0,518,377,0,0,0,189,142,0,0,663,19,0,0,0,168,0,0,0,0,0,0,0,0,0,0,3454\n",
      "495,175,45,225,346,686,4,0,296,216,871,208,6,8,6,1,152,57,2,32,472,75,392,2,5,0,0,0,47,0,0,1,56,0,0,47,36,0,103,0,0,0,0,0,0,0,0,4933\n",
      "1712,401,927,98,602,1047,122,300,75,8,134,2,80,60,107,17,12,243,10,3,1,1,629,21,142,0,0,0,84,0,1,122,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,3022\n",
      "868,2,301,1600,0,1426,90,0,326,0,33,10,0,0,51,0,2,32,0,278,2,0,251,195,0,5,0,281,464,29,0,0,0,0,0,13,1,0,0,0,0,0,0,102,0,0,0,3638\n",
      "801,46,396,36,25,614,317,2,336,0,135,761,22,153,601,0,1,490,1,6,0,270,1,228,6,0,0,0,47,0,1,13,328,0,0,0,223,0,0,0,0,0,27,0,0,0,0,4113\n",
      "1346,0,2,1381,0,263,8,55,1540,245,8,0,0,0,397,77,95,28,1,72,0,0,194,1,0,11,3,0,160,0,4,3,31,0,17,0,1,1434,0,0,0,0,0,0,0,0,0,2623\n",
      "1284,23,18,841,0,400,3,114,156,0,8,28,128,13,982,14,1165,22,65,2,0,3,0,0,40,0,415,1,242,0,0,79,0,0,0,1098,222,0,71,0,0,0,0,0,0,11,0,2552\n",
      "607,0,576,56,84,2713,226,1,139,414,253,30,73,37,278,297,0,43,96,1,0,0,30,0,0,0,5,4,16,0,12,277,25,0,0,54,6,0,0,0,0,0,0,0,0,0,0,3647\n",
      "1352,294,105,144,5,1227,135,83,564,70,44,0,85,20,0,43,19,172,121,531,18,47,9,3,214,109,0,0,19,0,0,551,3,0,0,0,3,0,49,0,0,0,0,0,412,0,0,3549\n",
      "821,1,16,373,627,1000,0,107,17,0,32,223,20,256,234,3,0,0,201,483,0,0,98,4,0,0,0,0,454,0,79,204,71,0,0,0,71,0,6,0,0,0,0,0,0,0,0,4599\n",
      "1738,0,212,220,0,2270,46,1,115,7,0,132,11,0,2,0,0,6,58,624,65,0,85,1,0,0,41,14,236,0,0,14,0,0,0,4,3,0,0,0,47,779,7,0,0,0,0,3262\n",
      "1392,0,549,401,3,1178,0,29,543,21,14,19,407,43,0,960,519,605,82,9,0,0,173,0,0,0,0,0,9,11,0,63,1,0,0,0,7,0,0,211,10,0,0,0,0,0,0,2741\n",
      "1431,3,135,770,1,1706,83,78,49,0,15,2,132,358,755,38,0,162,241,113,0,10,11,117,0,38,8,149,117,0,0,852,4,60,0,0,0,0,6,18,68,5,0,0,0,0,0,2465\n",
      "737,0,630,579,59,882,176,67,257,8,108,170,53,101,91,0,10,0,3,153,49,568,609,42,0,0,0,0,17,45,1,1,2,7,0,0,157,0,0,1,0,0,0,0,0,0,0,4417\n",
      "856,0,61,112,0,926,31,13,244,719,41,318,13,226,30,1,0,76,2,45,1,0,119,21,0,43,3,55,33,0,2,193,88,0,0,0,284,0,226,104,5,0,0,0,0,0,0,5109\n",
      "1278,0,202,11,0,466,585,34,42,15,3,766,0,0,51,74,8,6,88,213,0,77,412,1,0,0,0,35,1026,254,0,340,0,0,0,22,43,0,0,0,0,2,0,0,0,0,0,3946\n",
      "1416,0,262,206,2,1344,79,0,267,0,0,9,265,0,381,4,1,0,92,66,18,454,37,4,0,36,0,31,64,0,45,47,0,0,0,1,47,278,1,0,0,0,0,0,0,0,0,4543\n",
      "474,257,445,354,1,782,362,883,517,192,0,179,16,11,284,0,502,0,14,112,0,3,171,0,0,262,0,0,152,0,0,27,10,0,0,0,0,0,0,18,0,0,0,0,0,0,0,3972\n",
      "1770,1,457,176,0,1569,22,43,6,76,91,37,41,0,405,3,1,4,121,1,0,0,837,1,1,0,206,2,147,0,0,10,1,0,0,1,232,0,0,0,1,0,0,0,0,6,0,3731\n",
      "985,0,117,12,0,2989,45,101,259,0,143,0,12,91,170,35,316,11,194,73,0,6,220,1,116,145,19,1,26,0,0,284,289,0,0,0,99,0,0,0,0,0,0,0,0,0,0,3241\n",
      "515,0,14,793,0,934,34,148,52,40,257,5,4,1,172,0,25,18,316,232,749,0,20,2,0,151,0,0,238,4,3,443,100,0,0,0,12,0,0,0,0,0,0,23,0,0,0,4695\n",
      "781,2,203,80,303,2262,13,289,211,2,11,0,11,1,12,257,0,0,119,23,7,4,1,1,0,0,0,0,174,0,6,129,8,0,0,63,727,0,0,0,1,0,0,0,0,0,0,4299\n",
      "1298,0,201,1111,0,1798,494,37,246,26,516,117,22,106,103,8,64,109,200,59,0,23,381,8,0,0,0,0,6,0,0,47,9,0,0,0,6,0,0,0,0,0,0,158,0,0,0,2847\n",
      "567,9,3,691,8,2506,363,0,690,0,0,55,47,53,7,58,758,86,35,10,64,6,22,270,7,16,0,0,108,0,1,4,232,40,0,0,142,0,1,0,0,2,0,0,0,0,0,3139\n",
      "739,7,2126,10,1,1043,1,1,299,0,15,5,15,21,13,0,40,315,11,0,73,68,1,0,0,0,1,0,218,0,44,0,1,0,0,0,67,0,0,28,0,0,0,0,0,0,0,4837\n",
      "872,66,22,547,0,1893,6,0,145,0,596,0,73,0,6,106,8,88,16,0,2,6,1,0,5,85,5,0,318,0,0,647,0,0,0,9,7,0,0,17,0,1,0,37,0,0,0,4416\n",
      "713,0,49,735,0,1435,32,116,2,27,10,1,1,0,27,4,201,2,9,278,163,254,0,1,7,211,0,0,776,0,0,366,2,0,0,0,34,0,0,3,0,0,401,0,0,0,0,4140\n",
      "771,0,12,39,28,1187,196,0,134,55,335,625,2,3,410,90,229,0,707,8,1,1,157,24,87,0,5,0,113,0,0,785,21,0,0,4,120,0,0,2,194,174,125,0,0,0,0,3356\n",
      "1481,14,179,39,2,2218,67,5,161,566,172,135,51,0,3,111,12,63,5,2,4,0,262,4,26,2,1,0,0,0,0,59,0,0,0,51,0,0,25,1,0,0,0,0,0,0,0,4279\n",
      "1519,0,16,895,3,1688,8,0,17,0,18,1,18,0,162,33,428,0,755,0,0,0,9,0,0,242,0,0,178,0,109,82,0,0,7,0,24,0,0,150,0,0,0,0,0,0,0,3638\n",
      "433,15,551,1771,0,1665,82,24,39,1,38,0,12,203,1,2,4,15,346,2,0,299,296,127,57,0,0,0,27,0,0,7,26,0,0,0,147,0,0,13,0,0,0,114,0,0,0,3683\n",
      "453,6,855,102,6,401,14,39,165,111,14,0,30,196,873,741,12,2,91,466,11,268,383,38,0,0,0,350,4,0,296,0,3,0,0,56,2,150,155,0,1,0,1,0,0,0,0,3705\n",
      "333,0,74,306,0,1686,314,0,18,0,188,5,93,260,757,7,52,120,331,368,48,105,0,12,311,2,19,0,81,0,27,771,3,0,1,0,856,0,0,0,0,0,6,0,0,4,0,2842\n",
      "556,0,522,390,116,2173,423,5,8,0,10,1,435,0,59,0,0,19,160,250,32,5,125,25,0,0,0,0,4,0,286,84,95,0,0,39,67,0,0,0,0,1,0,0,0,0,0,4110\n",
      "414,49,474,719,0,511,227,2,582,348,0,3,63,36,27,542,109,1,26,374,30,71,0,37,0,42,0,88,79,0,0,1186,90,0,0,0,136,0,0,0,0,0,100,0,0,0,0,3634\n",
      "1373,4,568,563,271,1931,108,0,91,10,87,8,45,52,20,34,4,160,13,49,39,0,6,1,0,13,23,0,4,55,35,393,4,0,0,135,130,0,0,0,0,0,123,0,0,0,0,3648\n",
      "301,899,12,416,0,2128,742,514,4,0,122,300,45,10,24,1,514,322,563,72,0,191,62,0,0,0,0,0,553,0,39,0,0,0,0,6,356,0,0,15,0,0,0,0,0,0,0,1789\n",
      "1567,0,90,89,0,1502,234,3,84,0,97,1,54,31,66,0,262,0,47,260,0,0,2,0,0,0,8,0,261,0,0,372,295,0,0,2,3,0,0,0,0,35,0,0,0,0,0,4635\n",
      "600,0,2,134,66,1859,237,1349,369,15,117,2,16,167,40,88,122,1,170,8,302,0,224,145,2,1,204,0,0,0,13,57,0,0,0,42,69,0,0,65,0,0,0,0,0,0,0,3514\n",
      "1194,5,60,625,2,767,28,6,993,0,2,21,20,78,57,95,36,1,5,0,0,12,649,0,1,0,1,9,214,563,0,76,35,60,0,0,3,0,0,0,1,45,0,90,0,0,0,4246\n",
      "1132,0,55,319,13,1916,347,0,1433,5,0,0,4,0,8,28,4,39,92,0,4,0,304,0,0,4,0,0,67,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4226\n",
      "1612,0,567,31,15,1688,122,5,914,44,17,10,1,0,0,5,1,40,308,39,4,15,191,3,0,130,0,206,0,0,0,1037,4,0,0,0,16,0,0,0,0,0,0,0,0,0,0,2975\n",
      "590,0,1063,572,0,1369,49,0,464,19,0,10,0,3,7,135,15,8,631,6,2,71,113,0,0,41,0,214,98,36,0,0,254,0,0,0,110,0,0,9,40,0,0,0,0,0,0,4071\n",
      "893,0,808,66,0,1693,68,0,49,3,5,1,0,0,1098,3,0,0,1,1245,0,102,121,0,319,0,0,0,27,0,0,95,0,0,0,0,3,0,0,0,0,13,44,0,0,3,0,3340\n",
      "1506,107,458,203,0,927,291,0,7,27,325,66,182,260,333,12,22,239,41,27,0,4,14,0,0,0,1,1,876,0,0,19,111,2,0,3,4,0,3,8,0,0,0,0,0,0,0,3921\n",
      "1477,337,68,64,0,883,349,1,433,0,97,8,2,0,148,0,6,44,737,89,14,21,343,0,0,34,16,197,188,0,225,10,6,0,0,165,273,0,0,0,0,0,486,0,0,0,0,3279\n",
      "1104,0,400,477,0,2141,778,11,175,1,0,33,13,8,8,334,0,8,375,79,0,19,1,26,0,0,2,34,1,0,0,264,0,0,0,0,242,0,0,0,0,0,7,0,0,0,0,3459\n",
      "558,0,71,135,115,1696,64,5,13,51,0,58,0,409,4,0,362,326,34,18,14,0,362,24,0,0,9,0,39,1,5,130,2838,0,0,0,0,0,0,0,0,0,8,0,0,0,0,2651\n",
      "1975,0,260,521,0,1104,9,33,865,0,152,117,19,102,191,75,259,8,675,0,0,15,116,5,0,0,137,37,242,1,0,559,8,0,26,0,58,0,0,1,0,0,249,0,0,0,0,2181\n",
      "1645,0,69,57,0,1124,171,2,10,9,85,14,48,214,23,0,260,36,41,236,0,101,21,2,0,49,47,25,765,0,6,469,2020,1,0,1,223,0,0,0,0,0,0,0,0,0,0,2226\n",
      "613,1,118,702,61,1103,84,23,903,0,267,36,0,19,128,15,4,35,168,343,0,0,576,38,0,28,0,261,21,1,246,52,21,0,0,6,0,0,0,49,0,1433,0,0,0,0,0,2645\n",
      "1087,0,13,196,4,779,0,22,111,73,182,0,111,0,90,11,28,0,5,0,0,86,37,215,88,4,411,0,158,0,1,986,34,0,0,0,1,0,0,0,51,0,0,0,0,0,0,5216\n",
      "362,0,765,207,0,947,1,31,1,23,483,0,31,1,133,93,371,2,326,142,123,0,821,59,0,14,0,17,1029,0,323,128,0,0,0,373,46,0,32,0,2,0,0,0,0,0,0,3114\n",
      "452,0,884,58,31,2294,4,7,352,0,2,2,113,0,122,40,401,0,0,63,0,6,123,14,0,20,16,31,839,0,5,715,0,0,0,0,17,0,0,1,0,0,3,0,0,0,0,3385\n",
      "492,0,7,314,0,525,108,14,158,0,36,0,32,0,77,90,746,427,275,329,0,0,1349,7,0,791,52,66,124,0,0,2,2,0,0,2,83,0,0,0,0,0,0,0,0,0,0,3892\n",
      "1667,32,88,1600,1,919,3,0,2,190,427,0,0,2,18,0,2,94,64,131,0,0,2,2,0,0,0,0,207,14,417,550,1,0,0,0,95,0,0,6,0,0,0,0,0,0,0,3466\n",
      "416,2,131,438,12,453,33,2,291,7,21,48,346,18,219,4,20,786,189,37,4,3,0,1,0,0,0,1010,827,0,89,633,198,0,0,3,2,0,0,2,0,0,0,73,0,0,0,3682\n",
      "909,0,24,963,62,507,2,274,32,0,0,10,1,9,18,125,172,356,7,0,0,0,96,0,0,397,0,0,6,1,15,33,241,0,0,20,90,0,0,11,0,0,0,0,0,0,0,5619\n",
      "907,0,217,226,0,2147,64,1,88,2,3,0,743,19,3,3,0,18,417,1,0,0,65,0,0,465,35,0,109,0,9,182,8,0,0,0,169,0,0,0,0,0,2,0,0,0,0,4097\n",
      "1136,0,733,122,0,984,3,17,166,31,34,64,3,577,21,0,447,44,401,146,0,0,16,0,0,0,493,35,474,0,0,59,152,0,0,2,54,0,0,144,0,0,0,0,0,0,0,3642\n",
      "406,546,178,890,0,1139,9,7,536,2,82,66,0,13,21,16,3,0,6,11,742,42,4,356,0,42,69,21,14,0,206,176,119,0,0,0,151,0,0,214,0,0,0,0,0,0,0,3913\n",
      "796,2,130,562,2,2172,328,33,249,48,0,49,0,18,299,7,3,48,12,399,0,0,339,0,4,0,0,120,184,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,4192\n",
      "1220,0,6,251,3,1346,40,1,82,0,29,5,1,0,274,0,1,271,10,539,94,30,42,4,331,0,0,25,234,74,2,318,0,0,0,3,293,0,0,0,0,0,84,0,0,0,0,4387\n",
      "566,0,311,516,54,2134,9,0,464,0,410,86,0,3,0,1,1,334,358,3,75,112,1029,0,15,0,12,0,61,0,100,55,55,0,0,0,0,75,0,0,0,0,0,0,0,0,0,3161\n",
      "1459,655,158,840,88,755,5,3,85,167,16,11,10,349,0,30,1059,0,59,1,108,248,154,0,0,0,0,24,985,0,3,537,12,0,0,0,9,0,0,37,0,0,0,0,0,2,0,2131\n",
      "3792,189,164,134,18,579,32,30,169,7,289,2,1272,0,1,6,0,0,2,0,0,0,49,2,0,49,234,39,216,0,0,52,16,4,0,0,4,0,0,4,0,1,0,0,0,0,0,2644\n",
      "927,0,69,321,0,2055,67,0,488,64,12,0,124,1,639,1,26,27,1,255,0,1,124,0,0,46,0,0,87,0,1709,424,139,0,0,0,0,0,0,92,186,1,0,0,0,0,0,2114\n",
      "620,50,7,194,0,1378,238,2,729,734,86,0,0,11,9,39,410,184,81,355,222,0,391,0,0,0,0,17,30,0,0,77,149,0,0,104,433,0,146,4,0,0,0,0,150,0,0,3150\n",
      "588,14,542,753,0,496,48,67,392,95,137,330,205,454,161,0,0,10,158,25,12,18,26,22,0,0,1,0,595,0,0,599,7,0,0,0,28,0,0,139,0,0,0,0,0,0,0,4078\n",
      "699,0,493,733,0,1161,0,0,231,32,234,38,12,2,513,3,5,32,1353,1,6,13,0,0,0,0,116,24,44,26,0,633,3,0,0,0,124,0,0,138,0,0,0,0,0,0,0,3331\n",
      "658,228,329,144,130,543,289,41,127,0,552,71,6,6,31,0,123,0,109,10,0,2,780,0,1,36,0,74,572,0,0,131,41,0,0,0,0,0,0,0,0,0,0,0,0,81,0,4885\n",
      "1887,0,84,241,0,1164,450,0,102,0,0,13,2,0,183,45,0,0,266,4,0,0,0,0,89,0,0,0,196,0,1,68,53,0,0,0,207,0,0,0,0,0,0,0,0,0,0,4945\n",
      "986,35,125,227,56,2076,285,5,35,340,94,6,1,2,322,0,255,399,72,80,0,154,36,0,0,0,32,3,390,0,0,0,287,0,0,19,155,6,347,121,7,0,3,0,0,0,0,3039\n",
      "1893,0,93,27,0,1110,556,3,86,37,415,13,137,0,280,0,12,19,625,111,81,77,274,0,47,0,0,5,489,0,0,127,33,0,0,0,75,0,0,22,0,0,0,0,0,0,0,3353\n",
      "3284,0,190,93,0,1281,240,20,788,2,128,94,28,3,93,0,19,26,3,1,0,142,935,2,17,8,0,24,353,0,0,314,1,0,0,0,22,0,0,2,0,0,0,0,0,0,0,1887\n",
      "1466,56,283,271,0,1237,45,23,1231,0,24,1,186,495,47,456,459,4,0,68,0,0,82,53,0,61,1,6,142,0,207,331,1,0,0,0,49,0,0,0,4,31,0,91,1,0,0,2588\n",
      "575,0,527,951,540,1564,512,140,225,30,64,5,0,292,20,31,8,8,41,27,1,70,713,60,0,1,162,0,160,0,0,4,18,0,2,0,209,0,0,0,0,0,56,0,0,0,0,2984\n",
      "348,5,20,383,0,2484,145,36,1552,7,20,34,358,4,63,4,0,1,38,9,1,33,17,16,0,2,16,4,900,0,506,87,0,0,634,0,82,0,0,0,39,0,0,12,0,0,0,2140\n",
      "688,23,34,472,0,1130,199,0,95,55,4,336,519,107,83,910,100,199,443,0,0,1,98,0,7,16,37,9,367,0,0,107,299,0,0,0,39,0,0,114,0,0,0,0,0,0,0,3509\n",
      "1064,34,497,480,0,917,189,0,135,0,72,70,94,177,36,3,288,0,561,65,1,119,38,17,0,0,0,44,14,0,0,983,0,0,0,0,193,0,0,0,550,12,0,159,0,0,0,3188\n",
      "281,7,248,68,0,1303,7,21,1307,0,55,34,407,188,32,0,272,2,188,242,0,3,467,0,0,109,0,0,739,0,0,47,0,0,10,0,5,0,0,0,2,0,0,0,0,0,0,3956\n",
      "698,34,61,443,15,1225,526,21,209,1,53,0,972,9,2,70,78,0,27,13,0,1,21,9,0,42,55,46,36,366,3,1536,6,0,0,308,830,0,0,0,1,0,0,0,0,0,0,2283\n",
      "941,3,92,478,85,1584,118,66,366,0,163,0,4,0,6,8,4,745,3,40,0,0,0,0,0,0,17,0,278,0,0,227,92,0,0,0,0,0,191,808,0,0,0,0,0,0,0,3681\n",
      "1036,0,336,1014,390,1206,8,175,448,11,552,760,110,4,27,26,10,0,1159,61,14,277,7,0,0,0,0,63,20,0,16,89,16,0,0,3,94,0,0,0,5,0,0,0,0,0,0,2063\n",
      "1644,143,417,92,0,1004,0,0,212,0,4,6,52,0,1,16,1508,2,0,71,1,321,144,209,1,33,0,0,7,0,0,31,0,0,0,0,761,0,0,0,0,31,0,0,0,0,0,3289\n",
      "848,0,495,336,0,897,93,14,402,10,41,0,537,32,122,0,55,2,678,95,0,3,124,4,0,0,0,0,58,0,15,1,5,0,0,1,145,0,0,0,0,0,0,0,0,0,0,4987\n",
      "574,0,317,214,274,1495,4,42,136,44,270,248,0,17,54,2,565,226,423,561,0,97,94,0,0,0,0,1,4,0,0,47,128,0,0,0,0,0,0,0,363,0,0,0,0,0,0,3800\n",
      "425,0,70,509,0,630,1010,4,42,0,564,28,464,0,883,47,30,161,16,1,15,43,150,0,0,11,0,0,299,0,38,9,16,0,0,138,0,0,0,0,0,0,0,0,0,0,11,4386\n",
      "224,14,81,992,26,1298,11,3,447,23,3,0,0,10,61,290,5,38,226,612,12,160,2,0,0,103,0,0,6,0,0,60,0,0,0,0,220,0,0,0,9,0,0,0,0,0,0,5064\n",
      "365,41,430,90,13,2312,737,105,81,0,118,287,0,44,80,7,20,0,105,228,0,0,348,507,1,2,573,0,5,0,0,80,88,0,0,1,115,0,0,0,0,0,0,0,0,0,0,3217\n",
      "502,0,575,76,0,2389,9,0,6,18,179,0,3,282,17,0,288,74,212,400,89,2,33,0,0,0,112,229,244,0,36,91,1,0,0,0,214,0,0,574,0,0,0,0,0,19,0,3326\n",
      "1114,0,29,287,0,997,247,0,119,0,10,58,178,1,155,62,21,259,106,16,0,0,10,0,0,89,0,17,2707,0,16,9,486,0,0,0,12,0,0,0,0,0,1,0,0,0,0,2994\n",
      "1347,94,98,386,30,1258,42,3,583,4,114,5,2,407,50,0,5,2,62,0,0,0,721,58,0,0,2,3,54,0,0,29,23,0,0,0,413,0,0,0,5,0,0,0,0,0,0,4200\n",
      "1773,0,1120,908,0,1288,537,0,398,0,59,0,0,0,12,0,374,3,41,553,2,18,82,0,0,0,14,0,43,0,0,49,108,0,0,0,2,0,0,1,0,0,0,0,0,0,0,2615\n",
      "218,7,1069,72,0,2185,50,10,761,28,1,0,76,14,55,35,5,0,199,163,500,8,0,0,0,6,0,0,414,0,0,508,0,0,0,0,43,0,0,4,1,55,17,0,0,0,0,3496\n",
      "374,0,739,61,102,1229,18,157,313,0,33,0,4,3,480,183,25,3,135,7,0,379,185,0,0,156,43,0,143,0,0,33,0,0,0,0,116,0,0,1,0,0,416,0,0,0,0,4662\n",
      "1292,13,139,600,0,942,49,14,160,19,27,802,0,1,0,0,96,0,0,251,0,0,88,0,12,0,1,4,721,0,132,245,278,0,0,5,0,0,0,91,0,1,0,0,0,0,0,4017\n",
      "1139,0,162,109,248,1633,35,174,69,0,43,15,3,252,5,3,82,3,3,0,158,12,268,20,160,0,1,0,761,7,20,1048,38,0,0,47,215,0,0,0,0,0,36,0,0,0,0,3231\n",
      "305,2,831,444,0,829,271,0,100,0,2,16,32,102,32,23,177,0,40,1,37,0,773,0,1,214,7,0,119,40,0,0,0,0,0,0,8,0,0,11,0,1,0,0,0,8,0,5574\n",
      "1332,0,75,457,0,1422,5,6,400,336,92,11,117,24,9,3,32,21,22,72,2,0,19,0,24,61,0,6,421,0,0,38,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,4991\n",
      "1153,62,423,313,130,335,569,51,527,16,59,1,339,0,98,3,590,0,52,129,0,78,308,8,0,131,0,1,74,0,107,124,97,0,0,0,0,0,0,2,0,0,0,0,0,0,0,4220\n",
      "1211,0,696,262,223,667,40,0,20,0,192,11,0,0,41,134,3,82,349,98,0,0,226,0,0,10,0,99,167,0,0,194,44,0,0,0,39,0,626,18,0,7,0,0,0,0,0,4541\n",
      "516,29,4,758,0,257,9,6,229,0,142,129,12,0,331,1,101,3,12,0,29,27,12,2,10,0,0,2299,20,0,0,71,0,0,0,10,1,0,0,0,0,0,0,0,0,0,0,4980\n",
      "1419,1,80,366,0,1020,277,37,61,47,88,9,0,0,215,123,3,102,54,1,2,0,136,8,202,9,0,11,226,36,0,32,1200,543,0,161,0,0,0,0,0,0,0,0,0,0,0,3531\n",
      "1633,0,469,187,458,863,107,549,23,6,85,23,2,123,1,52,662,19,62,231,0,44,689,0,0,4,0,26,865,0,0,18,30,0,0,0,2,10,60,0,82,0,0,0,0,0,0,2615\n",
      "1190,0,1,795,0,2127,0,7,264,0,1,3,22,0,6,4,763,83,253,90,0,16,136,0,0,309,0,0,363,0,0,334,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3233\n",
      "218,1,288,945,1,1264,91,0,7,16,557,584,1,94,11,0,1,0,314,15,84,30,54,112,0,11,0,44,248,0,0,675,27,0,0,0,55,0,0,13,0,0,0,0,0,0,0,4239\n",
      "1554,148,19,489,0,807,155,0,741,1,384,22,0,320,175,29,0,0,75,9,0,372,4,2,0,0,8,0,127,0,136,66,50,0,0,0,104,0,0,0,37,0,51,0,0,0,0,4115\n",
      "1282,217,48,193,5,1234,59,0,575,0,154,711,204,56,0,2,323,2,11,7,0,1,1306,4,0,365,1,1,397,0,64,11,173,0,0,0,60,0,0,0,0,0,0,0,0,0,0,2534\n",
      "422,0,1009,401,0,853,124,4,214,2,830,41,23,1,369,301,5,0,417,9,86,0,460,0,5,336,0,0,52,0,0,746,0,0,0,0,49,0,0,0,0,0,0,0,99,0,0,3142\n",
      "620,0,36,376,0,1487,173,0,30,135,522,7,88,1,13,3,0,147,395,41,137,0,235,15,0,22,0,5,380,0,0,2,42,0,0,54,226,0,0,694,0,0,0,0,0,0,0,4114\n",
      "1481,0,2,129,13,1399,301,6,334,40,133,701,6,19,4,8,615,99,204,52,25,3,109,0,1267,2,0,0,193,4,18,222,1,0,0,0,85,0,0,11,0,0,0,0,0,0,0,2514\n",
      "667,0,104,1446,1,1492,299,20,435,0,39,11,22,1,57,51,329,4,11,32,0,0,6,2,0,0,46,23,27,0,0,35,2,0,0,0,1151,0,0,0,0,2,0,0,0,0,0,3685\n",
      "3059,0,239,96,0,766,524,0,449,0,10,0,28,148,14,6,218,153,766,1,1,0,671,0,0,0,0,0,7,0,10,92,12,0,0,0,180,0,0,0,0,0,0,0,0,0,0,2550\n",
      "308,6,310,704,41,1370,32,0,135,0,29,71,4,0,388,3,91,0,239,291,3,0,34,1,0,21,0,0,630,0,0,0,2,0,1430,0,78,0,0,0,0,0,0,0,0,0,0,3779\n",
      "477,0,1432,677,0,2066,2,0,46,0,17,9,0,24,102,0,314,5,269,944,666,156,23,95,6,4,21,0,17,0,0,5,39,0,0,0,294,0,0,0,0,0,0,0,0,0,222,2068\n",
      "2427,0,392,921,0,657,159,8,182,3,65,0,16,80,9,105,162,0,41,366,0,0,5,1,0,0,0,11,388,46,0,37,5,0,0,0,118,0,0,0,0,0,0,0,0,0,0,3796\n",
      "1718,1,54,496,105,996,0,772,658,0,8,13,21,1,583,660,24,10,114,17,52,0,88,0,0,1,2,3,31,0,0,307,42,0,0,0,133,0,0,1,0,0,5,0,0,0,0,3084\n",
      "767,1,19,9,198,1551,85,0,663,18,10,69,38,18,205,46,73,88,327,12,0,0,242,1,1,7,0,0,47,0,0,1075,2,0,0,0,2,0,0,0,0,37,0,0,0,0,0,4389\n",
      "89,0,886,744,11,1267,426,35,26,0,492,227,120,340,63,1,346,540,14,0,0,31,0,0,0,1,0,0,52,0,0,624,3,0,0,87,115,0,0,0,0,0,0,0,0,0,0,3460\n",
      "1278,4,633,31,0,721,112,3,93,0,188,3,192,0,0,282,1076,1,180,446,0,0,511,10,1,0,0,92,578,0,69,6,104,0,0,0,11,0,225,0,0,0,0,0,0,0,0,3150\n",
      "919,0,57,44,114,1197,0,0,79,4,19,370,30,60,15,0,1,0,90,393,352,1,1831,442,7,0,0,175,25,0,0,25,82,0,0,1,10,0,0,76,0,0,0,7,0,0,0,3574\n",
      "834,3,44,213,12,1528,25,0,301,0,1621,270,17,2,10,230,28,6,74,596,63,119,0,0,0,0,23,0,92,0,447,29,291,0,0,0,17,0,1,8,0,0,0,0,0,0,0,3096\n",
      "771,429,1032,46,0,1951,61,467,168,0,30,0,1,0,625,0,18,49,14,197,190,0,50,13,0,59,0,0,555,0,3,0,141,0,0,0,45,0,0,17,0,0,0,0,0,0,0,3068\n",
      "1653,0,270,134,0,931,60,81,294,2,0,85,0,427,2,4,37,6,221,94,0,11,125,86,37,0,578,0,213,0,6,15,66,0,0,0,256,0,0,2,0,0,10,0,0,0,0,4294\n",
      "1223,0,101,327,361,1377,1270,12,832,0,57,0,498,510,78,17,4,0,36,61,1,1,119,740,3,0,0,0,44,0,0,79,47,0,0,0,184,0,0,0,0,0,0,0,0,23,0,1995\n",
      "1353,274,322,83,0,1332,21,7,94,2,828,60,718,0,142,143,22,17,151,194,0,0,123,0,0,158,4,4,43,0,0,58,56,0,0,1,118,0,0,0,0,0,0,0,0,0,0,3672\n",
      "664,0,300,970,0,2394,949,192,232,0,3,0,0,36,12,5,0,0,4,92,0,1,50,44,0,0,79,8,118,0,9,57,75,0,0,3,455,0,0,0,13,0,0,0,0,340,0,2895\n",
      "350,40,59,876,436,352,47,6,212,0,4,103,1,139,0,2,345,164,67,3,3,0,38,0,0,0,0,3,22,0,0,376,2044,33,0,107,4,0,2,0,0,0,1,0,0,0,0,4161\n",
      "606,1,80,473,0,2120,35,0,77,0,17,0,124,0,621,263,102,125,224,59,0,1,60,0,2,11,0,0,225,0,0,71,49,0,0,45,65,0,0,2,0,0,8,0,0,0,0,4534\n",
      "1649,0,698,211,0,1057,586,696,198,0,0,165,0,6,59,217,34,0,0,236,2,0,803,0,0,1,13,65,358,0,0,19,36,0,0,0,73,0,0,34,0,0,706,0,0,0,0,2078\n",
      "785,15,265,1620,0,1371,9,109,0,11,254,2,0,0,10,0,174,1,591,46,12,1,595,0,0,47,0,0,294,0,0,115,25,0,0,0,39,0,0,0,1,0,0,0,0,0,0,3608\n",
      "2242,163,49,411,268,907,78,1,73,2,51,8,0,161,0,107,3,5,11,381,14,1,30,0,0,0,0,2,22,0,0,384,24,0,0,0,374,0,0,6,0,0,35,0,0,0,0,4187\n",
      "539,0,185,283,0,1077,662,0,89,0,262,177,5,1,294,5,91,644,125,3,2,0,100,5,31,5,2,0,3,0,1,47,134,0,0,0,1,0,0,345,0,0,0,0,0,0,0,4882\n",
      "498,0,15,430,7,2210,14,7,447,0,51,89,23,41,8,72,6,0,1098,64,3,16,28,0,80,130,0,0,106,0,5,229,122,0,0,12,0,0,0,412,0,0,0,0,0,0,0,3777\n",
      "2077,64,122,145,4,234,238,0,62,0,180,0,11,162,69,41,68,4,54,627,0,21,270,23,0,8,5,18,210,0,65,464,31,0,0,0,0,0,0,70,0,0,0,0,0,0,0,4653\n",
      "336,137,300,131,0,1477,0,336,175,43,23,73,97,0,49,12,62,3,1023,248,0,564,42,0,0,43,0,95,13,0,0,281,4,0,0,5,132,0,610,4,0,0,0,0,0,0,0,3682\n",
      "675,17,257,1364,4,1092,192,1,28,100,122,853,1,1,159,110,0,3,12,2,244,25,6,0,0,0,11,0,337,0,0,171,540,0,0,0,75,0,0,6,55,0,0,0,0,0,0,3537\n",
      "370,168,100,509,0,1800,68,88,94,21,0,206,37,1,554,0,68,210,9,123,47,0,300,0,0,10,18,1,269,0,0,0,1,0,0,0,7,3,32,0,0,0,0,0,0,0,0,4886\n",
      "1317,0,70,140,0,1820,91,11,239,0,2,0,4,2,100,0,15,0,435,677,58,0,0,0,0,0,0,92,568,0,0,308,672,0,0,1,21,0,0,0,2,0,5,0,0,0,0,3350\n",
      "579,386,234,538,0,504,276,4,510,23,388,19,3,1091,523,13,128,153,24,109,266,0,45,0,0,1500,39,6,41,14,0,0,3,4,0,0,99,0,2,2,0,49,0,0,0,83,0,2342\n",
      "1682,456,1,282,0,2567,178,1,24,0,149,0,17,2,94,6,1,1,1,34,0,0,119,21,0,219,0,0,161,0,13,43,17,0,0,0,16,0,191,0,0,0,0,0,0,0,0,3704\n",
      "141,0,216,386,3,2963,63,139,531,0,391,25,108,57,57,0,8,35,296,344,0,0,516,550,0,645,4,0,152,0,0,78,18,0,0,356,18,0,0,16,0,1,0,0,0,0,0,1883\n",
      "889,0,114,41,0,1047,86,0,237,33,295,0,1084,0,151,10,1,1,18,197,804,0,12,0,1,0,0,0,306,0,0,488,25,0,0,6,153,0,0,267,37,0,0,0,0,0,0,3697\n",
      "651,19,3,239,21,1139,124,0,237,1,153,13,107,180,89,2,1,0,808,311,0,11,754,107,0,1,0,124,94,0,1,294,519,0,0,0,1,0,0,10,0,0,21,0,0,0,0,3965\n",
      "1772,1,73,124,0,1448,29,5,216,0,75,223,23,2,1,45,2,46,169,172,3,0,324,468,572,36,0,3,120,0,0,17,0,0,0,0,32,0,0,0,0,0,840,0,0,0,0,3159\n",
      "404,69,667,359,18,2233,315,48,346,3,7,0,111,0,22,0,5,85,627,91,8,0,258,0,6,0,386,0,20,0,0,190,0,0,0,3,19,0,0,22,1,0,0,0,0,0,0,3677\n",
      "1213,0,0,691,5,802,146,342,122,3,8,82,27,6,1,0,0,30,86,22,0,3,57,134,426,67,0,36,31,0,194,11,118,0,0,0,189,0,0,0,9,0,0,0,0,0,0,5139\n",
      "512,0,163,736,33,644,504,5,1133,0,2,248,0,119,2,24,948,193,76,185,0,0,152,56,0,0,1,0,95,0,0,11,211,0,0,0,29,0,0,0,0,0,0,0,0,0,0,3918\n",
      "824,0,784,149,0,1054,315,8,274,0,706,0,234,2,2,2,105,59,107,136,0,118,22,19,0,59,140,359,29,0,152,11,0,0,0,0,9,0,0,2,0,0,0,0,0,0,0,4319\n",
      "1266,6,111,19,0,402,8,8,85,0,125,14,699,0,21,70,154,0,873,119,0,133,108,0,17,16,0,7,136,0,4,1,0,0,0,0,30,0,0,0,0,0,0,0,0,0,7,5561\n",
      "1285,9,291,151,2,585,881,144,255,110,140,5,2,0,113,4,1,304,257,11,118,0,304,0,0,0,6,7,149,11,0,53,351,0,0,16,316,0,370,0,0,0,0,0,0,0,0,3749\n",
      "642,47,275,1277,0,1960,56,31,844,36,14,61,648,1,0,0,5,0,282,149,0,13,59,0,0,3,0,0,535,0,0,439,52,0,0,0,55,0,0,0,0,0,0,0,0,0,0,2516\n",
      "837,1,45,474,2,2891,342,0,257,0,26,227,0,20,88,0,1,40,164,521,0,154,66,0,0,0,7,397,21,0,2,17,0,20,0,2,165,0,0,0,16,0,0,0,0,0,0,3197\n",
      "455,37,141,1268,17,1874,5,14,470,2,37,15,0,1,592,120,4,0,161,120,9,1,9,0,0,2,0,0,6,0,1,817,2,0,0,0,311,0,0,11,0,0,0,0,0,0,0,3498\n",
      "340,196,33,399,0,1463,1,1,291,63,32,2,0,0,193,7,12,48,81,151,3,71,0,0,0,1,0,0,8,0,381,574,362,0,0,0,365,0,0,0,0,0,0,0,0,0,0,4922\n",
      "619,0,195,195,0,162,40,45,1162,0,1769,57,254,0,849,0,406,32,7,327,0,90,116,0,0,93,3,0,103,28,0,24,0,0,0,53,48,0,0,0,0,0,0,0,0,0,0,3323\n",
      "1393,242,421,428,0,421,0,2,126,0,12,0,1560,106,3,417,1,3,79,730,0,187,46,0,0,0,0,1033,227,0,0,7,5,0,0,113,2,0,0,0,0,11,1,0,0,0,0,2424\n",
      "309,1,205,1287,36,407,27,11,354,0,44,24,393,123,116,0,0,37,335,3,0,262,403,0,0,73,0,1,41,0,0,104,192,0,0,0,55,0,0,113,0,0,0,3,0,0,0,5041\n",
      "806,1,364,21,14,2121,301,5,242,0,69,9,73,0,38,0,4,59,0,128,27,6,181,0,0,37,0,0,76,0,2,106,0,0,0,3,219,0,0,0,0,0,0,0,0,0,0,5088\n",
      "417,23,35,162,218,1829,15,72,661,1,535,39,71,14,1,54,75,85,83,29,378,271,114,34,0,2,0,15,576,0,105,149,459,0,0,0,194,0,0,0,0,0,30,0,0,0,0,3254\n",
      "476,0,731,456,2,753,64,6,320,169,21,326,90,0,82,1,9,0,190,63,113,2,0,228,0,52,0,0,5,0,1,20,7,0,0,0,135,0,0,0,2,0,0,0,0,0,0,5676\n",
      "654,0,350,359,9,3490,185,128,52,0,0,1,62,18,25,0,270,8,13,31,4,0,14,0,0,22,0,738,193,0,26,282,2,0,0,0,3,0,5,8,0,0,0,0,0,0,0,3048\n",
      "1968,0,158,87,136,1509,400,9,514,0,215,105,9,0,0,5,3,0,3,6,0,0,224,6,0,4,0,0,71,0,1,2,516,0,0,0,358,0,0,12,1,0,0,0,0,0,0,3678\n",
      "916,0,461,93,4,948,198,2,696,36,37,22,1,114,403,0,121,406,262,145,6,7,270,178,0,0,91,12,164,0,0,289,204,6,0,0,16,0,0,0,0,0,0,0,0,0,0,3892\n",
      "582,8,154,648,0,1592,86,0,328,16,72,0,2,0,149,172,0,38,411,1131,0,0,154,0,0,5,0,0,407,0,0,1163,31,0,0,0,1,2,0,0,0,0,8,0,0,0,0,2840\n",
      "2567,0,18,552,0,636,1,22,92,3,104,12,0,0,34,50,71,222,117,61,0,287,130,0,0,0,0,10,334,0,0,705,6,0,0,0,0,0,0,3,0,0,0,0,0,0,0,3963\n",
      "2108,360,303,392,38,675,67,0,242,2,1,19,92,214,171,0,151,55,13,44,11,0,37,37,0,0,0,2,512,0,0,82,61,0,0,0,0,0,0,3,3,0,0,0,0,0,0,4305\n",
      "330,48,33,473,0,1585,3,22,544,0,14,360,303,0,98,5,0,0,158,3,14,68,310,17,0,27,0,427,81,344,2,61,0,0,0,0,248,0,0,23,0,0,5,0,0,0,0,4394\n",
      "1329,0,83,35,0,549,11,12,581,42,110,0,20,0,3,8,645,414,38,164,2,0,216,356,0,3,4,1185,81,0,0,245,2,0,0,1,239,0,0,4,0,1,0,0,0,0,0,3617\n",
      "1427,13,693,601,0,1213,386,6,625,132,239,0,83,0,1,1,1,14,24,102,0,0,2,0,12,139,0,16,737,420,0,91,0,0,0,2,19,0,0,0,0,0,7,0,0,0,0,2994\n",
      "342,0,443,126,0,1407,279,2,23,136,49,29,69,0,155,466,54,0,1524,380,0,0,15,30,0,0,0,0,539,0,0,31,0,0,0,23,87,0,0,3,0,0,0,0,0,0,0,3788\n",
      "1715,45,316,74,0,1104,621,3,3,585,4,11,19,2,164,0,78,0,5,4,0,0,329,0,35,186,3,0,109,144,0,632,21,0,0,0,345,0,0,0,428,1,0,0,0,0,0,3014\n",
      "1954,7,208,411,67,408,74,484,3,0,964,0,13,37,762,5,0,0,252,2,69,0,794,0,14,394,0,0,81,0,29,586,66,0,0,4,2,0,27,0,0,0,0,0,0,0,0,2283\n",
      "1653,6,734,542,0,1336,14,0,168,117,215,15,83,0,2,22,10,0,0,414,43,0,4,27,0,452,345,0,5,0,39,8,146,342,0,0,2,0,0,0,2,0,0,0,0,0,0,3254\n",
      "193,0,165,159,1,1135,17,0,299,8,267,14,404,47,74,4,168,140,0,333,0,3,37,0,0,0,0,0,24,0,34,118,0,0,0,0,1,0,113,21,0,0,0,0,0,0,0,6221\n",
      "634,256,1116,380,0,1302,276,124,625,0,69,2,34,0,0,10,6,84,349,5,34,134,38,0,0,0,0,0,8,0,95,12,41,0,0,1,27,0,0,1,0,0,1,0,0,0,0,4336\n",
      "3030,198,284,1115,0,882,108,1,994,0,148,60,309,0,2,0,1,204,64,0,1,210,170,7,0,0,0,33,400,0,60,11,7,0,0,0,0,0,0,0,20,5,0,0,0,0,0,1676\n",
      "1446,1,4,31,112,2389,128,8,749,1,365,10,0,0,15,0,4,5,87,347,166,165,405,0,45,157,0,26,98,0,31,5,31,0,0,0,2,0,0,0,0,5,0,0,0,0,0,3162\n",
      "286,184,262,1199,47,1230,254,72,153,0,236,1,4,0,149,59,3,0,19,0,124,0,221,3,1,0,0,430,152,0,71,311,234,0,0,4,251,0,0,0,2,0,0,0,0,0,0,4038\n",
      "1747,0,315,71,0,1212,70,811,219,7,153,4,0,0,50,1,83,74,24,639,1,0,10,0,0,1,4,0,2,43,1,333,0,52,0,1,62,0,0,0,0,0,0,0,0,0,0,4010\n",
      "332,2,90,180,118,2442,339,0,346,0,194,556,0,334,6,11,116,59,14,13,7,2,27,0,0,18,0,0,29,0,3,10,1,0,0,0,1,0,0,6,0,0,0,0,0,0,0,4744\n",
      "1975,0,384,214,0,1099,88,1,61,0,1262,2,0,301,115,4,0,38,44,466,0,0,279,22,42,0,3,33,120,1,11,147,0,401,0,0,578,0,1,0,0,0,26,0,0,0,0,2282\n",
      "1491,1,386,48,187,2005,279,50,344,0,20,14,22,84,565,45,11,8,0,257,0,1,759,1,0,139,0,16,44,0,0,98,0,0,0,0,2,10,0,0,0,0,0,41,0,0,0,3072\n",
      "1190,0,8,519,0,1760,28,0,410,0,46,59,255,27,16,0,3,0,405,292,18,0,216,1,0,52,90,12,395,4,13,109,304,0,0,0,12,0,0,6,0,0,52,0,0,0,0,3698\n",
      "262,0,14,280,19,1518,29,5,202,0,29,118,20,60,0,107,0,9,182,344,0,26,473,6,3,0,0,55,161,27,75,138,16,2,0,3,1620,0,0,5,0,0,0,0,0,0,0,4192\n",
      "211,128,564,598,15,406,596,17,220,0,9,323,446,6,100,1,5,39,50,2,0,1,47,17,405,1,17,0,184,0,0,310,0,0,0,18,152,0,0,278,0,0,0,0,0,0,0,4834\n",
      "619,0,143,1248,0,965,76,150,1133,0,437,697,24,0,400,0,0,28,272,317,6,0,832,0,50,144,0,1,64,0,10,296,84,0,0,0,137,0,0,0,0,0,0,0,0,0,0,1867\n",
      "1270,2,372,1320,0,658,18,0,26,1,699,0,199,199,319,38,111,209,34,11,0,0,223,27,0,638,0,100,175,0,0,40,0,0,0,0,93,0,0,25,0,0,0,0,0,0,0,3193\n",
      "2936,0,69,1476,0,500,369,0,254,0,56,17,88,0,353,0,11,0,32,306,16,0,153,1,0,0,1,104,29,0,27,157,1,0,0,0,24,0,0,0,0,0,0,0,0,3,23,2994\n",
      "518,0,113,218,0,2277,276,0,10,16,637,1,35,1,0,12,102,58,0,1,1,1,414,0,0,0,427,9,231,0,0,415,0,0,0,0,86,0,0,11,0,0,0,0,0,0,18,4112\n",
      "413,14,30,1246,0,927,543,151,11,23,437,114,6,12,32,0,0,16,2,3,1,0,240,32,21,0,0,14,1,0,1,7,0,0,0,0,5,0,22,6,0,0,0,0,41,0,256,5373\n",
      "2618,118,32,86,1,574,15,6,24,37,8,3,0,0,311,185,64,310,325,42,0,4,49,0,0,47,9,26,460,0,166,24,11,0,0,0,206,0,0,41,0,0,0,0,0,0,0,4198\n",
      "1221,0,534,223,0,919,60,148,661,2,266,36,12,0,23,0,18,8,1,26,0,75,895,0,1,725,26,268,111,0,0,376,46,0,0,0,47,0,0,0,1,48,0,0,0,0,0,3223\n",
      "534,1,305,520,0,3251,42,8,310,0,504,15,2,0,103,4,340,1,131,36,0,0,15,0,0,0,6,0,510,0,63,45,477,0,0,0,1,0,0,11,0,0,0,0,0,0,0,2765\n",
      "636,0,194,568,13,1510,201,0,38,2,258,127,41,22,117,4,110,244,229,401,97,735,322,0,21,0,0,0,198,16,0,19,60,0,0,0,39,0,0,0,0,168,0,0,0,0,0,3610\n",
      "880,74,793,282,21,1175,4,5,799,9,350,161,1,46,19,3,5,1,21,53,0,14,1249,15,0,193,0,14,231,0,0,78,2,0,0,0,29,0,0,0,0,2,0,0,0,0,0,3471\n",
      "2231,101,457,647,38,937,90,1,58,11,2,197,16,9,468,28,213,56,9,53,15,0,56,11,0,744,1,1,24,0,0,474,2,0,0,0,2,0,0,0,0,0,0,0,0,0,0,3048\n",
      "1744,69,18,1661,8,293,48,0,2,28,806,66,0,92,76,114,10,1,283,54,0,315,92,0,0,716,11,0,448,94,0,53,4,0,0,0,191,0,0,0,0,0,10,0,0,0,0,2693\n",
      "714,46,372,888,0,1356,78,24,49,0,27,6,0,10,624,15,556,261,74,60,0,130,281,0,0,96,28,90,228,0,0,903,13,0,0,44,238,0,0,0,0,0,0,0,0,0,0,2789\n",
      "803,0,440,198,0,692,150,0,25,0,208,267,735,1,420,10,4,28,352,68,80,0,2,0,330,104,0,0,125,0,20,124,2,0,0,4,0,0,0,0,0,0,0,0,0,0,1,4807\n",
      "1021,0,799,188,0,1135,2,0,1311,1,67,1,3,2,134,43,3,0,356,50,0,0,150,30,0,9,13,14,55,0,0,221,35,0,0,0,357,0,0,0,0,0,0,0,0,0,0,4000\n",
      "2491,0,576,160,0,990,263,34,121,0,25,49,46,0,0,344,0,0,19,15,0,26,197,1,0,152,0,1,139,0,67,7,7,0,0,0,289,0,0,0,0,0,0,0,0,0,0,3981\n",
      "1664,0,26,341,32,1197,337,0,239,12,6,0,2,93,91,0,1,0,368,52,0,0,118,0,0,26,152,201,916,0,0,24,128,0,0,0,7,0,124,0,0,0,4,0,0,0,0,3839\n",
      "1780,1,72,397,12,348,67,0,1311,0,4,0,3,0,400,118,236,44,0,0,85,1,3,143,0,719,0,0,381,0,5,5,7,0,0,0,32,0,0,1,5,0,0,0,0,0,0,3820\n",
      "1516,14,167,226,0,1873,10,0,62,18,124,0,112,2,43,542,13,20,178,13,0,0,228,178,51,5,0,0,374,0,54,43,36,0,0,4,99,0,0,9,0,0,0,0,0,0,0,3986\n",
      "1419,19,201,160,0,1740,1150,13,32,13,162,49,81,116,2,1,0,10,0,65,0,0,21,0,64,11,0,253,87,0,0,211,0,0,0,0,42,0,0,0,426,0,0,0,0,0,0,3652\n",
      "1643,0,98,170,4,1326,113,150,523,233,42,3,0,16,3,0,27,11,31,108,0,0,306,171,0,28,0,63,94,0,49,285,0,0,0,3,97,0,0,0,0,0,0,0,0,0,0,4403\n",
      "600,0,197,841,0,969,254,249,497,0,146,103,208,0,103,173,7,97,86,2,0,1,917,0,0,11,206,23,565,0,0,213,299,0,0,0,17,0,0,0,0,0,0,0,0,0,0,3216\n",
      "687,0,618,443,0,1188,443,405,909,6,206,414,148,0,0,0,21,207,67,111,0,16,209,129,0,6,0,0,152,0,0,489,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,3123\n",
      "856,146,107,2011,2,1399,16,1,63,0,15,0,0,5,27,34,701,0,210,179,0,112,552,1,0,0,0,0,15,0,0,227,204,0,0,0,111,0,258,0,0,0,0,0,0,0,0,2748\n",
      "666,0,178,600,11,689,24,6,10,0,26,15,867,0,93,8,1,215,254,1,0,175,28,365,0,0,2,6,193,0,0,28,5,0,0,6,7,0,0,7,0,0,0,0,0,0,0,5514\n",
      "741,63,499,442,0,3143,496,35,20,0,0,1,180,22,33,37,1,11,124,27,5,2,24,0,0,0,0,0,199,0,0,44,12,0,0,0,467,0,0,222,0,0,0,0,0,0,0,3150\n",
      "1599,6,43,158,9,1533,16,302,139,5,0,137,14,0,543,0,181,0,45,7,0,3,13,12,81,0,0,507,998,0,3,264,14,0,0,0,149,0,262,0,4,0,0,0,0,0,0,2953\n",
      "730,9,0,176,0,3437,234,0,9,1,22,305,0,0,30,0,292,0,0,60,94,0,818,0,2,40,0,0,36,1,221,96,279,0,0,0,149,0,0,0,0,0,0,0,0,7,0,2952\n",
      "971,0,103,120,12,651,3,0,223,86,2,1,120,684,189,12,47,0,116,4,0,0,408,10,960,0,0,0,168,0,39,129,217,0,0,0,147,0,0,0,0,0,0,0,2,0,0,4576\n",
      "596,224,51,134,0,2384,242,292,416,42,17,92,1,6,135,1,76,2,0,151,16,0,5,0,0,312,34,66,425,0,31,8,219,0,0,450,185,0,55,19,0,0,1,0,0,0,0,3312\n",
      "1067,5,238,670,253,796,774,70,456,5,270,757,209,4,2,1,289,125,4,6,15,11,45,2,0,223,0,1,37,0,0,47,3,0,0,1,162,0,106,0,4,0,0,0,0,0,0,3342\n",
      "188,32,1599,1665,0,347,593,23,66,3,590,13,12,24,84,38,10,198,169,289,104,21,138,0,1,14,0,95,524,0,0,41,41,0,0,0,98,0,0,0,0,0,0,0,0,0,0,2980\n",
      "811,66,229,164,0,1616,182,38,159,0,18,63,1,0,63,1,38,176,207,1062,0,0,8,8,0,0,199,79,39,0,219,37,114,0,0,0,6,0,0,0,0,0,0,0,0,0,0,4397\n",
      "657,67,140,52,0,1639,15,148,239,0,891,50,15,83,3,42,24,585,20,17,75,66,422,0,0,109,172,274,13,151,0,10,0,0,0,0,399,0,0,34,0,0,0,0,0,0,0,3588\n",
      "1634,193,459,500,33,1594,90,7,151,0,19,3,642,17,598,0,0,146,29,14,0,38,25,1,0,34,0,2,41,0,54,1,15,0,0,0,131,0,164,1,0,0,0,0,0,0,0,3364\n",
      "1053,0,434,640,0,2345,187,42,270,0,76,43,0,110,52,0,11,5,20,37,68,93,7,0,0,2,0,0,19,0,25,239,416,0,0,1,341,0,7,105,0,0,0,0,0,0,0,3352\n",
      "1566,148,1,381,33,906,86,48,131,0,4,0,21,128,11,0,13,23,12,316,59,255,218,0,0,102,3,0,178,0,262,2,11,0,0,0,50,0,0,0,0,0,0,0,0,0,0,5032\n",
      "238,8,176,74,10,926,338,41,296,0,17,0,143,0,0,8,114,266,121,261,0,56,207,273,3,7,0,11,987,0,0,82,17,0,127,0,154,1,17,0,12,0,283,0,0,0,0,4726\n",
      "271,0,248,1006,10,685,9,218,200,0,3,75,788,0,169,1235,1,88,45,10,5,1,114,0,0,0,5,0,7,0,3,156,349,0,0,0,18,0,0,0,3,0,0,0,94,0,0,4184\n",
      "1090,1,398,267,0,1444,24,0,143,21,455,0,4,0,44,0,1,0,245,1,11,1,19,2,0,64,3,24,42,0,281,51,94,0,0,1,6,0,0,0,0,47,0,0,0,0,0,5216\n",
      "1050,493,1470,105,12,648,6,335,84,0,8,19,0,23,143,181,54,0,35,34,9,0,240,2,0,237,0,27,1,0,0,7,48,0,86,0,262,0,0,0,0,0,0,18,0,0,0,4363\n",
      "641,1,91,186,2,2168,405,93,176,64,16,81,3,5,50,0,23,142,46,39,144,0,5,1,0,149,1,3,6,0,53,0,0,0,0,0,114,0,0,0,23,0,0,0,0,0,0,5269\n",
      "1148,7,30,602,1,1035,368,0,387,18,180,47,85,61,327,105,108,848,1588,139,18,2,329,0,0,273,0,2,14,0,0,37,109,0,0,0,744,0,8,16,0,0,0,0,0,0,0,1364\n",
      "837,0,244,306,2,1325,33,6,654,0,155,81,135,285,24,11,64,2,396,329,152,0,71,382,0,15,0,0,23,0,0,541,39,0,0,0,0,940,0,321,0,0,0,0,0,0,0,2627\n",
      "410,0,1128,136,13,1181,153,44,43,90,313,1,441,283,28,15,255,3,368,244,0,610,72,0,0,9,0,67,129,334,0,48,1,0,0,32,30,0,0,1,11,0,16,0,0,0,0,3491\n",
      "2673,0,145,704,73,1328,246,58,315,44,70,0,0,14,25,4,310,8,11,429,0,4,222,0,0,0,0,0,122,0,0,30,205,0,0,0,851,0,0,0,0,0,0,0,0,0,0,2109\n",
      "471,0,59,25,17,1289,347,4,1155,414,162,0,64,450,341,0,17,2,540,38,347,349,184,0,0,1,85,82,9,0,0,829,3,0,0,3,652,0,0,0,0,0,0,0,0,0,0,2061\n",
      "493,0,300,208,1,1248,8,238,187,0,38,482,135,4,144,0,173,12,130,1296,5,0,480,0,0,0,279,0,38,7,0,160,183,0,0,405,128,18,46,21,0,0,0,0,0,0,0,3133\n",
      "746,25,312,226,0,1392,33,0,469,10,174,212,61,0,47,3,25,0,1,212,0,0,29,110,157,0,103,0,62,0,173,6,0,0,0,0,10,0,0,59,0,0,205,0,0,152,0,4986\n",
      "879,0,47,416,1,1464,335,0,254,0,0,66,29,15,191,0,116,88,35,31,409,40,1,0,0,0,0,0,237,0,165,145,11,0,0,0,121,0,0,1,0,0,0,0,0,0,0,4903\n",
      "1350,0,57,703,29,744,83,3,133,22,55,6,19,24,54,187,8,6,59,38,3,186,23,0,0,25,0,35,55,0,0,0,0,0,0,0,1293,0,0,0,27,0,0,0,0,0,0,4773\n",
      "1826,7,28,372,0,1970,157,0,224,18,14,162,38,0,241,12,5,34,81,70,0,11,1085,5,0,0,58,46,111,0,21,222,10,0,0,0,153,0,0,0,0,0,0,0,0,0,0,3019\n",
      "2550,4,44,45,52,616,289,151,488,179,350,85,305,1,88,30,471,4,241,59,5,0,34,0,155,0,26,1,54,0,11,247,0,0,0,0,0,0,0,0,1,248,2,0,0,0,0,3164\n",
      "297,0,173,326,0,272,165,0,601,77,302,0,2,0,62,435,490,632,9,1132,321,0,123,0,0,83,0,0,12,35,0,16,216,0,0,0,15,0,0,0,0,0,0,0,0,0,0,4204\n",
      "376,13,302,368,140,969,659,2,169,0,0,49,314,58,295,150,70,85,82,1,124,0,199,293,0,0,0,0,1,0,0,1,76,0,0,207,0,0,115,0,0,0,0,0,0,0,0,4882\n",
      "754,5,425,90,1,1455,9,532,84,3,4,41,2,0,990,30,35,579,200,3,0,0,69,0,0,0,0,0,370,0,0,178,23,0,0,1,1,0,0,0,1023,2,0,0,0,0,0,3091\n",
      "1191,18,11,405,0,810,40,461,605,406,217,0,185,10,30,14,250,124,4,513,14,109,10,9,1,0,0,0,441,0,0,102,0,0,0,0,140,0,0,0,0,0,0,0,0,0,0,3880\n",
      "276,150,394,131,0,839,0,0,93,367,0,47,151,221,71,22,289,0,25,1,6,22,217,32,0,14,145,0,394,0,26,8,95,2,0,0,289,0,0,14,0,0,0,0,0,0,0,5659\n",
      "1111,70,412,112,102,656,1063,176,93,0,2,16,0,0,270,0,40,1,130,26,92,0,30,84,0,0,0,0,1065,0,0,0,10,0,0,0,370,0,0,0,216,219,0,10,0,0,0,3624\n",
      "945,0,327,596,14,438,544,0,77,16,12,565,34,4,0,6,0,0,14,18,0,75,80,9,0,0,1,7,1,0,0,35,0,0,0,0,188,0,0,0,0,0,0,0,0,0,0,5994\n",
      "1285,0,870,146,0,1128,65,67,188,5,458,0,17,18,157,217,223,31,94,0,0,3,93,174,0,97,0,2,844,0,0,329,400,0,0,0,2,0,0,0,0,17,12,0,0,0,0,3058\n",
      "1221,0,146,1219,0,1414,407,1,246,6,51,88,1,11,8,29,21,6,3,350,69,0,34,72,0,0,0,0,8,0,0,1,386,0,0,0,1,2,0,0,0,0,0,0,0,0,0,4199\n",
      "1094,0,246,129,0,1689,322,279,218,78,54,5,189,44,64,76,50,8,700,154,3,5,1,0,2,64,172,16,292,0,0,163,11,0,0,0,3,0,11,0,5,0,0,0,0,0,129,3724\n",
      "645,1,308,407,0,3564,138,6,3,246,151,213,13,36,10,212,1,66,5,470,0,0,206,351,0,35,0,42,296,0,30,62,39,0,0,0,23,0,0,1,0,0,0,0,0,0,0,2420\n",
      "344,0,790,465,1,768,15,0,365,202,623,7,145,12,0,0,2,55,9,2,0,7,712,824,0,4,0,44,123,0,0,102,5,0,0,0,487,0,0,0,94,0,68,0,0,0,0,3725\n",
      "822,319,315,90,2,2118,571,0,265,5,952,0,0,275,17,36,163,36,216,245,69,0,736,0,0,26,0,1,344,2,226,44,48,0,0,0,2,0,35,0,8,0,2,0,191,0,0,1819\n",
      "2206,21,363,367,1,1084,466,58,172,105,94,130,5,106,9,0,7,14,8,17,75,0,8,1235,0,0,1,98,252,0,0,155,659,0,0,0,40,0,0,0,0,0,0,0,0,4,0,2240\n",
      "707,0,186,265,0,859,1486,204,216,0,558,0,21,30,17,32,0,21,1,274,12,0,241,13,29,0,10,9,19,0,6,2683,45,0,13,0,13,0,0,0,0,0,0,0,0,0,0,2030\n",
      "527,0,830,327,0,1421,162,25,153,24,85,31,1,12,8,51,17,219,7,16,0,0,944,0,0,1,37,0,12,0,0,199,1,0,0,0,39,0,0,0,0,0,0,0,0,0,0,4851\n",
      "383,60,43,1073,0,1130,1559,0,329,133,1,94,63,0,53,0,0,2,215,463,28,122,204,0,0,0,0,0,178,0,0,25,42,0,1,0,13,0,0,2,0,0,108,0,0,0,0,3676\n",
      "924,0,221,567,0,529,0,185,427,3,584,422,28,971,17,0,0,0,569,8,4,21,138,0,0,4,0,35,56,0,0,29,0,0,0,0,74,0,0,0,0,0,0,0,0,0,0,4184\n",
      "1208,0,35,876,85,1369,307,7,25,1,81,248,49,350,27,313,207,9,6,203,8,209,284,0,9,0,1,715,12,0,32,11,20,0,0,35,211,0,0,0,0,0,0,0,0,0,0,3047\n",
      "1147,36,444,178,0,1143,0,9,264,2,9,159,12,327,13,42,178,1563,2,271,156,224,134,4,0,0,522,0,2,0,0,1,0,0,0,0,139,0,0,0,0,0,0,0,0,16,0,3003\n",
      "920,0,4,677,3,660,261,3,0,5,498,6,7,58,2,194,18,2,47,658,0,0,480,26,0,6,0,101,130,0,0,30,548,0,0,0,12,0,0,0,0,5,0,12,0,0,0,4627\n",
      "1148,3,92,120,129,695,7,48,238,473,16,0,34,0,331,660,107,1,21,0,0,0,95,192,593,0,0,2,414,0,0,0,88,0,0,0,9,0,0,0,112,0,0,12,0,0,0,4360\n",
      "987,0,1022,32,28,398,837,301,298,25,31,0,0,12,27,65,0,12,156,1,467,0,2,0,0,0,0,0,324,0,0,984,259,0,0,0,390,0,0,0,0,0,0,0,0,0,0,3342\n",
      "944,0,77,128,442,1377,103,0,229,0,70,0,113,0,489,56,2,0,175,37,6,0,527,0,0,1,11,87,170,1515,0,0,140,0,0,0,424,0,1,27,24,0,0,35,0,0,0,2790\n",
      "703,0,174,751,316,1933,15,0,0,4,0,46,405,0,35,0,14,53,33,9,10,0,639,0,0,1195,47,0,39,0,0,197,5,0,0,0,529,0,0,0,0,0,0,0,0,0,0,2848\n",
      "1345,11,46,179,280,1583,570,4,7,0,2,0,146,92,15,3,315,58,88,42,48,0,66,0,0,0,600,0,48,0,2,4,203,0,0,2,0,0,3,0,0,0,1,0,0,0,0,4237\n",
      "594,0,557,1297,0,1118,0,380,114,2,22,81,3,1,6,0,282,400,74,52,1,8,29,78,0,142,91,0,299,0,194,4,57,0,0,0,128,0,27,0,0,0,7,0,0,0,0,3952\n",
      "1453,0,103,111,0,1689,541,3,291,2,367,0,362,2,24,11,524,0,11,4,1,53,208,2,0,1,0,0,254,0,42,59,16,0,0,2,175,0,0,49,9,0,0,0,0,0,0,3631\n",
      "2326,91,6,47,13,943,1,0,142,0,450,3,13,0,562,2,983,0,243,0,100,2,8,0,0,1,0,0,370,411,0,42,9,139,0,2,11,0,0,27,0,0,0,0,0,0,0,3053\n",
      "301,1,112,419,0,566,193,0,463,225,27,30,131,63,236,275,512,0,0,108,0,0,373,1,0,22,0,19,426,0,0,350,2,0,0,0,2,0,138,2,0,0,0,0,0,0,0,5003\n",
      "2169,4,63,184,0,760,587,26,709,0,10,29,0,0,82,0,3,0,2007,176,178,0,225,0,4,0,1,0,466,0,0,23,1,0,0,178,178,0,0,21,14,0,0,0,0,0,0,1902\n",
      "1578,0,54,819,2,1143,77,4,158,0,4,335,17,4,38,26,475,34,3,17,4,316,23,0,0,39,11,0,67,0,7,16,110,0,0,29,33,0,0,0,0,0,0,10,0,0,0,4547\n",
      "872,14,60,289,7,1575,28,1070,140,0,465,3,0,2,51,0,141,6,29,19,26,0,31,0,0,5,130,3,315,0,0,464,64,0,0,5,883,0,4,75,6,0,0,0,0,0,0,3218\n",
      "819,0,696,1519,4,1654,59,0,1018,0,139,48,156,0,195,89,397,15,134,285,43,34,0,3,8,0,0,0,274,0,7,10,41,1,0,6,2,0,0,0,0,0,0,0,0,0,0,2344\n",
      "1441,153,526,1565,0,1609,306,253,209,0,1,167,12,0,15,0,0,139,59,13,0,1,75,80,7,43,13,1,341,0,127,6,443,0,0,0,113,0,0,1,0,0,0,0,0,0,0,2281\n",
      "1108,11,119,443,0,827,61,13,161,0,163,26,48,145,108,2,11,7,121,543,706,201,104,14,0,570,0,0,151,0,3,41,54,0,0,1,66,0,0,0,0,0,79,0,0,7,4,4082\n",
      "1188,21,113,182,0,2158,12,63,881,0,0,38,0,14,40,0,21,8,7,94,131,0,209,42,0,4,0,5,527,0,0,27,8,0,0,93,457,0,5,0,0,0,0,0,0,0,0,3652\n",
      "774,108,144,1634,271,329,52,113,206,0,37,14,0,12,23,2,27,36,2,356,19,0,159,9,0,74,0,0,1,0,33,992,412,0,0,0,0,0,0,4,0,0,57,0,0,0,0,4100\n",
      "1366,12,107,1433,15,530,156,14,13,214,9,310,345,1,4,0,563,62,217,0,59,1,114,138,10,0,0,0,1635,12,0,839,37,0,0,0,319,0,0,0,6,0,0,0,0,0,0,1459\n",
      "2022,43,293,123,0,693,342,11,429,3,31,6,16,16,449,0,22,22,314,241,0,0,88,0,0,0,1,0,131,0,0,2,22,0,0,3,0,0,0,5,0,0,208,9,0,0,0,4455\n",
      "1811,0,245,376,0,1257,7,431,450,99,405,0,0,39,843,4,7,0,122,1,326,4,311,0,0,0,4,15,485,0,7,241,107,0,0,7,46,0,10,0,0,0,0,0,0,0,0,2340\n",
      "741,29,311,621,87,1690,0,66,821,4,811,160,85,165,41,207,4,1,3,278,5,188,104,1187,0,0,0,135,0,0,0,23,0,0,0,0,186,0,23,0,2,0,0,0,0,0,0,2022\n",
      "1657,0,574,268,325,1334,27,0,573,0,6,82,11,6,290,7,211,36,41,77,0,2,72,2,409,0,0,257,5,0,0,7,19,10,0,406,64,0,0,92,0,0,0,0,0,0,0,3130\n",
      "762,4,675,508,0,1660,18,21,60,0,0,4,0,592,56,281,2,118,824,4,0,278,317,1,15,0,285,141,518,0,4,311,1,0,0,107,108,0,2,0,0,0,0,0,0,0,0,2323\n",
      "328,0,417,597,4,988,119,0,625,15,38,0,28,0,382,44,358,224,3,0,679,0,0,103,0,0,18,0,82,0,6,39,865,0,0,0,42,0,0,62,0,0,0,0,0,0,0,3934\n",
      "1417,78,70,1352,0,1514,259,201,6,18,10,2,3,294,38,244,269,10,37,16,0,2,243,0,251,512,390,31,31,7,0,1,18,0,0,0,42,0,0,2,53,0,0,0,201,0,0,2378\n",
      "1398,0,335,617,25,1712,8,0,2,9,1,207,1,412,51,44,2,3,45,67,0,5,469,33,0,20,0,0,16,0,6,45,238,0,0,0,2,0,0,31,0,0,0,0,0,0,0,4196\n",
      "1005,136,148,516,0,1840,273,66,445,0,41,45,4,82,15,216,861,103,978,15,0,0,5,11,0,0,0,82,295,0,0,55,0,0,0,12,56,0,0,0,0,0,0,0,0,0,0,2695\n",
      "2703,6,1,732,4,690,186,0,308,194,488,12,81,51,8,0,69,127,462,3,0,384,0,0,0,0,0,0,5,0,0,233,105,0,0,31,258,0,153,198,0,0,0,0,0,0,0,2508\n",
      "463,0,204,373,3,1343,79,77,456,2,96,92,73,468,1,0,5,336,66,180,0,67,115,29,0,0,527,0,369,0,0,21,37,0,0,24,165,0,0,0,0,0,47,0,0,0,1490,2792\n",
      "615,23,102,696,0,910,8,27,156,0,8,0,0,672,10,0,2,4,93,0,0,0,40,277,0,96,0,1,415,0,28,10,23,0,0,0,1245,0,0,330,0,0,0,55,0,0,0,4154\n",
      "1357,112,32,477,11,677,35,16,163,5,33,37,31,0,99,10,126,399,16,0,214,0,96,0,0,4,0,11,201,0,76,7,7,0,0,0,322,0,3,1,0,0,0,0,0,0,0,5422\n",
      "2114,1,580,99,0,863,118,2,151,13,10,3,182,25,1,164,760,19,212,168,0,0,63,0,52,0,0,16,114,0,307,113,31,0,0,0,897,0,0,1,0,0,0,0,0,0,0,2921\n",
      "1018,0,396,485,26,615,118,285,73,13,27,0,394,7,1595,116,157,0,10,4,0,0,71,0,0,512,0,0,42,0,62,284,8,0,0,0,1108,0,0,0,99,0,0,0,0,0,0,2475\n",
      "1516,0,221,81,82,1713,493,636,19,6,3,21,5,0,321,0,61,0,9,24,33,0,12,16,0,0,0,1,145,0,12,370,152,0,0,6,146,0,0,34,0,0,0,0,0,0,0,3862\n",
      "432,2,222,595,369,1777,439,0,209,0,579,87,3,0,44,2,343,0,556,37,0,180,32,286,0,0,14,11,43,0,0,464,143,0,0,0,0,0,0,3,40,0,0,0,0,0,0,3088\n",
      "2786,20,100,37,0,845,453,2,286,16,70,1,0,13,102,26,1,5,0,14,0,0,36,176,0,0,12,0,295,0,252,118,147,0,0,194,27,0,3,0,0,46,0,0,0,0,0,3917\n",
      "586,5,63,63,3,975,146,13,65,178,40,148,546,2,126,0,0,163,124,1,0,9,51,0,0,80,0,1,171,0,0,233,4,0,0,8,4,0,0,0,0,0,7,0,0,0,0,6185\n",
      "816,1,489,140,4,1176,498,117,50,298,140,210,0,12,979,6,0,3,88,2,0,0,45,17,0,7,66,0,709,0,0,10,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,4093\n",
      "933,0,48,84,0,2237,724,18,336,0,47,0,0,563,148,141,49,7,0,347,23,240,115,0,0,0,0,351,49,0,3,64,671,0,0,0,6,0,0,2,0,0,7,0,0,0,0,2787\n",
      "447,150,98,1565,0,986,301,70,118,0,711,193,43,20,17,1,0,0,68,0,0,0,20,0,0,1,0,463,74,0,0,1,114,0,0,6,11,0,0,0,1,0,0,0,0,0,0,4521\n",
      "1398,0,34,110,99,1279,395,1,255,0,213,181,12,377,3,6,266,21,93,150,0,284,73,8,0,37,3,9,9,0,0,263,0,0,0,15,1,0,6,20,5,0,0,0,0,0,0,4374\n",
      "2109,0,129,946,0,1759,1,83,4,2,111,40,0,64,651,31,412,11,147,0,205,2,227,47,0,4,81,59,81,0,20,20,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,2752\n",
      "1111,0,528,468,1,981,145,3,1137,42,17,8,129,0,23,0,0,2,59,160,280,5,10,0,0,185,0,0,385,0,0,104,81,0,0,0,370,0,0,0,0,0,0,0,0,0,0,3766\n",
      "2097,97,58,647,0,579,52,112,944,0,19,457,147,47,471,21,257,0,9,209,3,142,180,0,0,0,4,1,255,0,0,21,16,0,0,0,470,0,0,0,0,0,0,0,0,0,0,2685\n",
      "1051,0,84,65,11,1438,180,85,615,0,201,24,57,566,69,0,18,272,73,53,168,106,161,0,0,21,0,0,982,0,0,152,8,0,0,0,240,0,0,0,1,0,0,0,0,0,0,3299\n",
      "597,0,317,2091,158,1529,279,33,507,2,1401,0,0,0,21,0,10,104,30,79,234,1,112,0,0,0,1,0,141,0,0,65,63,0,0,0,0,0,11,0,0,0,0,0,0,0,0,2214\n",
      "490,0,29,60,0,638,118,9,762,0,537,40,96,171,1,6,142,1,526,396,0,0,758,6,27,40,0,188,83,0,0,7,0,0,0,0,156,0,0,0,0,0,0,283,0,0,0,4430\n",
      "2445,0,81,680,415,939,123,375,397,3,0,53,96,0,0,2,285,22,41,132,16,0,5,0,5,0,0,7,258,0,0,25,52,0,0,19,103,0,0,0,0,0,0,0,0,0,0,3421\n",
      "890,114,208,367,475,1095,59,0,66,150,4,8,120,10,615,374,2,0,160,55,2,127,184,15,0,0,0,0,350,0,13,7,5,0,0,0,763,0,0,0,0,0,0,0,0,0,0,3762\n",
      "725,120,7,250,226,1035,552,441,4,51,21,1,52,0,280,0,0,4,11,15,0,9,5,0,0,0,131,0,167,384,50,13,53,0,0,0,180,0,0,254,0,0,1,0,0,0,0,4958\n",
      "545,2,55,210,0,420,348,0,300,10,804,23,0,0,4,1,76,150,77,5,768,0,412,2,76,4,570,0,556,0,0,17,62,0,0,2,59,0,0,0,416,0,0,0,0,0,0,4026\n",
      "1941,0,313,741,0,574,25,3,388,4,565,61,22,12,24,0,20,205,0,24,134,1190,154,1,5,14,106,239,10,0,0,27,59,0,0,453,0,0,104,0,0,0,0,0,0,0,0,2582\n",
      "922,2,18,140,24,2011,71,167,19,0,637,71,325,502,253,185,35,226,51,22,0,310,83,1,0,0,0,0,51,2,4,210,509,0,1,0,7,0,0,0,0,0,0,8,0,0,0,3133\n",
      "229,0,49,806,77,1393,337,41,391,5,3,45,4,0,14,0,49,15,58,94,21,0,92,0,0,0,75,0,251,0,12,208,0,0,0,0,88,0,0,0,0,0,181,0,0,0,0,5462\n",
      "1131,0,344,334,0,1528,45,23,182,37,272,0,0,1,0,1748,1,0,2,175,204,0,60,31,0,0,153,0,648,0,0,42,61,0,0,76,44,0,0,2,0,0,0,0,0,0,0,2856\n",
      "417,626,375,141,0,1513,78,0,174,460,478,37,112,0,69,95,69,0,140,1050,0,0,126,39,0,27,14,0,32,0,0,194,0,0,0,0,329,0,0,6,0,0,0,0,0,0,0,3399\n",
      "1195,81,66,103,23,739,39,0,570,7,1045,151,0,10,140,110,7,24,532,1,0,10,436,190,0,46,0,109,91,0,1,449,329,0,0,0,246,0,0,0,5,0,0,0,0,0,0,3245\n",
      "882,0,231,992,8,848,210,42,645,0,1,150,0,167,99,42,155,252,100,4,0,0,1,561,2,3,45,0,121,0,0,29,63,0,0,0,55,627,0,0,0,0,0,0,0,0,0,3665\n",
      "399,0,5,206,0,2685,133,0,617,105,15,479,90,34,5,0,314,26,5,39,4,558,230,0,0,37,0,0,465,0,2,100,14,0,0,0,85,2,1,370,0,0,9,0,2,0,0,2964\n",
      "1096,0,119,191,2,1807,47,17,365,0,2,2,46,91,11,36,34,1,999,230,0,27,228,0,0,2,0,188,828,0,56,110,5,0,0,0,136,0,0,96,52,0,2,0,0,0,0,3174\n",
      "974,479,1491,7,133,553,55,1,104,9,0,4,0,0,252,6,1,100,242,17,969,0,50,0,0,146,111,2,161,45,145,553,0,0,0,0,151,0,0,0,0,0,0,0,0,0,0,3239\n",
      "1207,77,287,759,215,1312,371,30,222,9,908,71,222,97,2,0,209,0,17,115,0,69,690,0,0,0,1,0,118,0,0,845,43,19,0,0,11,0,0,2,0,0,0,0,0,0,0,2072\n",
      "1453,0,2,323,1,1403,44,10,85,64,10,10,0,407,7,0,3,193,3,1,8,4,129,0,0,205,2,0,534,0,0,376,0,0,0,60,2,0,1,0,2,0,3,0,0,0,0,4655\n",
      "999,6,17,290,256,1555,64,18,542,0,45,1,36,40,1,115,659,635,361,4,1,0,323,405,0,4,0,82,9,0,0,15,4,0,0,0,9,0,0,9,0,3,0,0,0,0,0,3492\n",
      "330,0,88,222,9,1092,517,2,21,69,424,0,60,0,469,42,631,0,126,164,156,262,74,0,0,0,0,0,461,0,68,6,318,0,0,0,1,0,0,0,93,0,0,0,0,0,0,4295\n",
      "481,0,316,431,0,576,197,8,487,129,645,90,8,2,568,20,0,1,29,23,0,152,8,173,0,0,0,0,153,0,2,8,76,0,0,0,120,0,0,0,0,0,0,0,0,0,0,5297\n",
      "1574,329,464,1217,0,1010,91,191,63,0,165,448,0,0,2,4,1,0,12,218,0,0,9,568,0,0,0,0,582,0,120,8,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,2900\n",
      "568,217,460,918,0,794,219,0,273,0,126,786,0,0,1,16,84,7,31,34,137,0,70,1,0,6,0,29,9,0,10,700,54,0,0,0,5,0,0,0,0,0,0,0,0,73,1,4371\n",
      "347,2,363,207,2,2514,488,4,27,42,99,0,0,98,11,7,0,0,472,5,78,23,70,1,1,2,10,0,16,0,13,232,23,0,0,0,2,4,0,0,0,0,0,60,0,0,0,4777\n",
      "591,0,300,351,0,742,31,0,737,2,770,2,1,4,16,0,57,0,21,29,434,0,584,286,17,29,57,98,209,0,126,1,0,0,0,0,576,0,6,0,0,0,0,0,2,0,0,3921\n",
      "642,139,150,1043,77,1074,0,636,56,169,0,1,22,10,30,0,6,0,0,11,89,0,3,36,0,117,265,0,566,0,830,59,2,0,0,3,106,0,0,0,0,0,0,0,0,0,0,3858\n",
      "507,16,816,39,49,900,16,102,1457,67,6,150,23,194,75,0,6,0,3,272,261,41,83,0,0,11,0,35,330,30,0,535,104,0,0,0,317,0,0,0,354,8,0,0,1,0,0,3192\n",
      "857,0,366,581,0,955,29,224,362,0,8,454,33,361,143,4,117,0,1071,312,758,0,23,188,0,0,0,2,176,16,204,68,29,0,0,51,68,0,0,19,0,0,0,0,0,0,2,2519\n",
      "545,1,851,421,0,1743,310,0,42,2,2,559,0,233,0,11,224,349,53,371,1,35,489,0,37,62,0,0,285,0,0,54,2,0,0,13,29,0,0,0,0,0,10,0,0,0,0,3266\n",
      "1846,0,136,121,0,1580,44,77,301,0,46,0,2,12,4,294,135,190,33,242,35,0,33,0,0,0,49,1168,78,0,0,5,0,0,0,39,1,0,0,0,0,0,0,0,0,0,0,3529\n",
      "1027,4,997,1038,17,1472,573,85,85,101,0,150,109,23,246,78,28,0,183,1,1,0,207,103,0,0,98,40,270,0,13,595,185,0,0,0,103,128,0,0,0,0,0,0,0,3,0,2037\n",
      "1711,1,231,1923,0,337,0,22,718,49,3,9,336,0,24,35,11,215,576,0,121,0,108,0,0,0,221,0,48,0,57,23,0,0,0,0,77,0,0,0,0,0,0,0,0,0,0,3144\n",
      "1727,0,30,1315,0,416,252,0,110,9,360,0,0,13,0,81,89,0,833,140,0,1,11,0,0,1,19,234,18,0,0,125,1,0,0,0,15,0,0,0,1,0,0,0,0,0,0,4199\n",
      "1367,0,490,933,0,791,0,0,424,3,81,9,16,45,120,0,3,43,257,1,0,440,1,14,0,1,13,0,176,0,0,152,36,98,0,0,390,0,6,0,39,0,0,0,0,0,0,4051\n",
      "936,5,85,102,85,2309,908,6,385,160,15,0,0,0,5,0,9,0,1,225,652,1,0,195,0,1,107,1,1,0,0,157,115,0,0,0,16,0,0,5,294,0,0,0,0,0,0,3219\n",
      "1959,65,7,258,0,1479,139,6,437,204,20,12,5,0,16,8,124,94,392,12,12,0,10,0,0,29,2,3,230,0,0,214,8,0,0,3,0,0,0,0,0,0,0,0,0,0,0,4252\n",
      "1005,24,439,762,14,1262,302,78,23,8,48,7,26,0,20,162,846,6,146,2,0,91,132,1,0,20,1,4,122,0,0,65,4,0,0,0,142,0,0,1,1,0,360,0,0,0,4,3872\n",
      "316,11,777,128,0,733,125,274,154,0,28,245,19,0,1107,0,126,8,121,289,5,1,8,0,4,233,0,12,309,0,0,250,283,0,0,4,123,0,0,0,0,0,1,0,0,0,0,4306\n",
      "789,4,165,78,0,1833,45,0,843,119,197,16,3,51,52,3,37,374,165,1,2,42,34,0,45,0,23,16,245,0,0,11,59,0,172,41,376,0,0,0,0,11,0,163,0,0,0,3985\n",
      "2325,5,14,195,0,452,7,188,226,47,9,1268,1,333,6,1,0,174,782,59,367,52,1,0,0,197,0,0,65,0,0,0,1,0,0,0,47,0,0,0,7,0,0,0,0,6,4,3161\n",
      "1987,0,501,13,0,807,21,0,272,0,58,1,13,573,2,0,55,594,14,3,278,0,25,5,7,0,1,1,426,0,42,17,167,0,0,0,0,0,0,0,77,0,0,0,0,0,0,4040\n",
      "1832,627,5,826,0,2226,250,0,106,44,461,0,24,194,2,381,346,12,452,136,0,0,10,0,0,55,0,0,138,0,0,188,8,0,0,0,27,0,0,0,0,0,0,0,0,0,0,1650\n",
      "1011,3,73,1329,3,484,1851,2,49,0,189,1,8,30,51,3,28,19,22,0,0,19,21,3,0,0,15,3,166,1,2,11,0,0,0,3,747,0,0,0,0,0,0,0,0,0,0,3853\n",
      "617,0,0,38,141,1434,933,0,352,309,515,7,0,1,4,425,928,2,635,37,154,389,11,1,0,73,182,322,183,0,64,146,111,0,0,0,4,0,0,0,0,0,1,0,0,0,0,1981\n",
      "1823,0,713,364,113,218,2,0,24,4,46,12,1,104,20,3,193,1,50,43,21,0,11,0,1,7,1,0,125,0,0,0,91,0,0,0,234,0,0,21,0,0,0,0,0,0,0,5754\n",
      "1073,0,80,29,0,111,308,35,342,2,76,3,0,17,2,336,0,508,23,256,1,13,6,0,380,0,31,0,334,0,0,667,439,176,0,0,925,0,0,716,0,28,2,0,0,0,0,3081\n",
      "743,10,27,1566,0,1064,407,8,132,0,26,12,79,2,2,177,345,4,251,24,1,0,78,32,0,53,733,21,1,0,0,68,5,0,0,0,21,0,0,0,0,0,8,0,0,0,0,4100\n",
      "1499,49,14,727,0,1488,52,45,204,20,111,1,180,2,51,44,0,0,42,121,180,0,16,30,0,0,432,6,12,0,0,483,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4188\n",
      "253,0,236,1202,0,1012,543,170,618,0,1148,2,0,1,91,56,0,4,21,1,29,0,159,0,0,95,2,1,22,0,0,0,12,0,0,10,43,0,0,0,2,0,2,0,0,0,0,4265\n",
      "1544,2,130,99,0,1290,343,334,338,137,54,15,16,47,523,45,115,19,11,184,3,15,81,0,0,0,0,0,292,0,5,36,25,0,0,6,106,0,0,78,0,0,0,0,0,0,0,4107\n",
      "955,0,17,345,0,1636,32,5,615,6,19,1,1,5,55,0,1,73,272,38,0,136,343,29,0,119,36,1,373,0,110,37,0,0,0,0,6,0,0,8,141,0,0,0,0,0,0,4585\n",
      "641,0,7,1007,0,1771,235,0,491,57,927,30,5,16,384,0,33,100,125,169,0,0,64,23,0,595,0,0,230,0,0,56,18,0,2,0,7,0,0,0,0,0,0,0,0,0,0,3007\n",
      "947,730,245,910,0,574,679,0,35,0,235,59,8,5,163,583,159,118,138,475,0,72,73,0,0,52,0,0,895,0,0,490,36,46,0,3,336,0,0,39,0,0,0,0,0,0,0,1895\n",
      "284,128,36,468,0,674,1482,40,17,0,45,10,98,2,3,104,66,0,160,205,0,33,1355,22,0,1,40,0,0,0,0,4,1,7,0,3,70,0,67,76,0,0,0,0,0,0,0,4499\n",
      "583,23,980,1188,1,1518,19,93,703,0,145,1,0,0,30,30,8,3,15,117,0,0,53,2,7,0,0,0,37,0,3,119,411,0,0,0,170,0,0,0,0,0,0,0,0,0,0,3741\n",
      "1157,1,121,230,2,351,3,141,26,40,25,58,29,181,70,897,59,621,287,0,0,0,240,231,555,11,3,9,508,0,78,5,79,2,0,0,170,0,10,0,0,0,9,0,0,0,0,3791\n",
      "1056,0,150,340,187,1508,3,2,154,67,1,1,1,3,149,0,25,0,223,362,8,18,37,163,0,1,5,0,46,0,126,770,1,0,0,0,189,0,0,3,0,0,0,0,0,0,0,4401\n",
      "2274,0,851,181,184,1875,9,4,347,0,94,8,0,0,9,43,10,1,0,47,3,1,308,0,0,21,0,3,29,0,0,25,18,0,0,0,9,0,0,0,2,0,3,0,0,0,0,3641\n",
      "623,0,14,386,26,794,495,12,701,360,433,6,7,2,611,4,4,45,61,18,29,0,1459,0,0,1,19,0,73,9,1065,95,6,0,0,89,346,0,0,0,0,0,0,0,7,0,0,2200\n",
      "184,0,28,842,0,836,132,56,597,0,95,31,11,16,195,21,0,75,0,4,252,0,13,28,0,3,10,0,97,0,8,5,98,0,0,0,175,0,0,0,0,13,253,8,0,0,0,5914\n",
      "848,0,477,585,12,655,0,19,1366,3,228,324,345,0,8,11,89,138,6,26,0,11,61,616,217,73,0,0,348,0,0,187,0,0,0,0,10,0,277,0,0,0,0,0,0,0,0,3060\n",
      "965,232,38,50,39,1440,113,303,531,29,26,0,0,75,20,19,0,0,1,6,0,0,7,1,0,0,31,0,209,0,0,75,0,0,0,0,432,0,0,0,0,0,61,0,1,0,0,5296\n",
      "1401,0,406,87,0,300,556,392,6,29,201,10,52,0,265,0,246,9,437,49,26,242,310,0,29,0,1,18,13,0,93,1181,13,0,0,180,92,269,0,0,0,0,0,32,0,0,0,3055\n",
      "695,0,621,257,0,1288,11,0,163,0,945,306,39,41,397,25,34,161,0,11,20,24,0,153,0,1,0,94,0,51,26,0,0,0,0,0,816,0,0,3,0,0,0,0,0,0,0,3818\n",
      "1265,0,696,192,212,722,8,305,12,111,43,291,3,796,29,0,20,12,326,306,0,17,1,0,0,4,2,371,225,0,3,13,11,0,0,0,6,0,0,0,22,0,0,0,0,0,0,3976\n",
      "687,0,631,164,0,830,400,82,1,0,110,19,84,218,68,7,8,131,121,4,11,34,125,31,3,0,1,3,705,0,45,24,5,0,0,0,261,0,0,0,0,0,0,0,0,0,0,5187\n",
      "2983,0,660,140,0,1742,277,36,6,99,49,113,76,45,70,0,1,127,142,1,0,0,1,1,0,74,49,130,154,0,0,13,85,0,0,0,134,0,1,2,1,0,0,0,0,0,0,2788\n",
      "505,16,139,265,5,1501,238,232,124,391,662,0,140,574,14,35,22,999,13,3,126,13,830,0,0,1,12,1,5,0,86,1,108,0,0,0,4,0,0,0,0,0,0,0,0,1,0,2934\n",
      "1204,0,2,989,0,827,362,1,118,241,488,172,76,0,2,0,2,8,197,0,44,8,68,6,0,0,0,6,239,0,20,61,1431,0,0,0,317,0,0,0,0,0,0,0,0,0,0,3111\n",
      "806,16,1439,69,55,436,200,13,117,219,335,1204,52,38,376,0,0,68,15,112,63,0,257,0,0,1,6,0,171,0,1,36,177,0,0,0,108,0,0,133,351,0,0,0,0,0,0,3126\n",
      "419,679,140,383,0,725,21,35,35,14,59,0,93,0,57,0,47,1,10,77,204,7,243,184,101,451,0,84,151,0,0,340,287,0,0,0,10,0,0,0,0,0,0,0,0,0,0,5143\n",
      "596,5,1691,320,1,1011,238,21,247,69,71,178,273,3,1,0,338,200,2,0,110,48,50,1,0,0,0,8,2,0,37,35,0,0,0,0,0,0,0,292,6,0,0,0,0,0,0,4146\n",
      "1341,0,1107,1457,43,876,212,136,133,1,6,21,3,38,26,3,216,0,30,280,0,0,107,12,4,126,8,0,482,0,0,365,2,0,0,0,15,0,0,0,0,0,0,0,0,0,0,2950\n",
      "613,1,284,293,0,1402,295,114,1214,0,23,49,0,13,1689,13,94,0,7,10,0,2,107,4,0,17,61,49,110,0,0,100,65,0,0,0,69,0,3,11,0,0,0,0,0,2,0,3286\n",
      "1818,1,333,394,1,945,465,0,38,100,1,7,36,527,32,0,361,2,2,3,120,139,110,5,8,2,0,0,544,0,493,425,0,0,0,5,101,0,0,5,219,0,0,0,0,0,0,2758\n",
      "1057,0,0,322,217,650,1,969,214,41,1006,0,2,0,7,0,12,1,0,166,0,0,17,7,0,19,5,1,95,2,1,44,0,0,0,30,0,0,0,0,2,0,0,0,0,0,0,5112\n",
      "422,0,250,79,0,1381,225,0,72,0,784,2,1,0,916,0,227,91,307,91,0,10,60,0,0,80,0,0,95,0,0,123,16,0,0,73,1183,0,0,1,0,124,0,0,0,6,0,3381\n",
      "1401,4,30,526,0,923,25,0,127,0,483,11,70,1089,1,3,174,11,4,2,49,0,81,297,0,4,18,0,100,0,35,8,1,0,0,0,46,0,0,0,7,0,0,0,0,0,0,4470\n",
      "2655,6,106,74,0,952,76,13,158,125,736,43,19,6,49,0,2,21,971,138,95,0,548,0,0,5,105,0,223,0,1,4,5,0,0,0,36,0,0,2,0,0,0,0,0,0,0,2826\n",
      "335,0,71,259,67,718,1,4,4,167,6,0,174,12,6,0,2,56,1,104,8,0,124,0,0,0,0,4,861,0,0,0,1,0,0,0,236,0,0,246,0,0,6,0,0,0,0,6527\n",
      "649,69,966,1227,0,508,2,30,550,0,302,159,3,49,195,26,19,180,7,49,2,0,324,32,0,0,0,0,5,0,0,147,87,0,0,0,5,0,0,0,0,0,0,6,0,0,0,4402\n",
      "1258,0,0,1119,0,2348,25,0,137,176,2,12,148,92,35,0,0,10,26,0,336,164,18,0,0,23,0,4,1318,0,102,1,49,0,0,0,10,0,0,2,0,0,0,0,0,0,0,2585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(resource_filename('deepbiome', 'tests/data/onefile_x.csv')) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (regression)\n",
    "\n",
    "This is an example of the output file for regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.997270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.485126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.489590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1\n",
       "0  4.997270\n",
       "1  5.004092\n",
       "2  5.485126\n",
       "3  5.489590\n",
       "4  1.500001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/onefile_regression_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.609926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.488959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.498418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.486107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.319623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1\n",
       "995  2.609926\n",
       "996  5.488959\n",
       "997  3.498418\n",
       "998  5.486107\n",
       "999  5.319623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repetition, the deepbiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.997270\n",
       "1    5.004092\n",
       "2    5.485126\n",
       "3    5.489590\n",
       "4    1.500001\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    2.609926\n",
       "996    5.488959\n",
       "997    3.498418\n",
       "998    5.486107\n",
       "999    5.319623\n",
       "Name: x1, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the Y (classification)\n",
    "\n",
    "This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetition in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  0.0\n",
       "3  0.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(resource_filename('deepbiome', 'tests/data/onefile_classification_y.csv'))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1\n",
       "995  1.0\n",
       "996  0.0\n",
       "997  1.0\n",
       "998  0.0\n",
       "999  1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one repetition, DeepBiome will use the one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    1.0\n",
       "996    0.0\n",
       "997    1.0\n",
       "998    0.0\n",
       "999    1.0\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exmple of the training index file for `k` fold cross-validation\n",
    "\n",
    "For each fold, we have to set the training and test set. If the index file is given, DeepBiome sets the training set and test set based on the index file for 5 fold cross-validation. Below is the example of the index file. Each column has the training indices for each fold. DeepBiome will only use the samples in this index set for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  0  2  0  0\n",
       "1  1  1  3  1  1\n",
       "2  2  2  4  2  3\n",
       "3  5  3  6  3  4\n",
       "4  6  4  8  4  5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = pd.read_csv(resource_filename('deepbiome', 'tests/data/onefile_idx.csv'), dtype=np.int)\n",
    "idxs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>993</td>\n",
       "      <td>995</td>\n",
       "      <td>993</td>\n",
       "      <td>994</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>994</td>\n",
       "      <td>996</td>\n",
       "      <td>994</td>\n",
       "      <td>995</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>996</td>\n",
       "      <td>997</td>\n",
       "      <td>995</td>\n",
       "      <td>996</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>998</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4\n",
       "795  993  995  993  994  995\n",
       "796  994  996  994  995  996\n",
       "797  996  997  995  996  997\n",
       "798  998  998  997  997  998\n",
       "799  999  999  998  999  999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the index set for 1st fold. From 1000 samples above, it uses 800 samples for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    5\n",
       "4    6\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795    993\n",
       "796    994\n",
       "797    996\n",
       "798    998\n",
       "799    999\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.iloc[:,0].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the configuration\n",
    "\n",
    "For detailed configuration, we can build the configuration information for the network training by:\n",
    "1. the python dictionary format\n",
    "1. the configufation file (.cfg).\n",
    "\n",
    "In this notebook, we show the python dictionary format configuration.\n",
    "\n",
    "Please check the detailed information about each option in the [documantation](https://young-won.github.io/deepbiome/prerequisites.html#configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the network information (`network_info`)\n",
    "\n",
    "To give the information about the training process, we provide a dictionary of configurations to the `netowrk_info` field.\n",
    "Your configuration for the network training should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'taxa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'training_info': {\n",
    "        'batch_size': '50', \n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For preparing the configuration about the path information (`path_info`)\n",
    "\n",
    "To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, you have to provide a dictionary for configuration to the `path_info` feild.\n",
    "Your configuration for the path information should include the information about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_info = {\n",
    "    'data_info': {\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/onefile_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': 'onefile_x.csv',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'history': 'hist.json',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deepbiome Training\n",
    "\n",
    "Now we can train the DeepBiome network based on the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logging, we used the python logging library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.\n",
    "\n",
    "If we set `number_of_fold`, then DeepBiome performs cross-validation based on that value. If not, DeepBiome package performs cross-validation based on the index file. If both `number_of_fold` option and the index file are missing, then the library performs leave-one-out-cross-validation (LOOCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.6727 - binary_accuracy: 0.6484 - sensitivity: 0.9231 - specificity: 0.0667 - gmeasure: 0.0000e+00 - auc: 0.5214 - val_loss: 0.6434 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3761\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.6372 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4839 - val_loss: 0.6124 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5903 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6210\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6507 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6450\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6259 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6771 - val_loss: 0.6130 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6574\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6798 - val_loss: 0.6119 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6600\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6980 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6502\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7104 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6493\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 204us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6974 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6515\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7068 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6504\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6245 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7046 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6514\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.6247 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7178 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6482\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6240 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7270 - val_loss: 0.6104 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6468\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6229 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7281 - val_loss: 0.6088 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6479\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6209 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7288 - val_loss: 0.6050 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6518\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.6180 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7419 - val_loss: 0.6015 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6509\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.6137 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7433 - val_loss: 0.5975 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6548\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.6076 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7371 - val_loss: 0.5898 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6617\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 197us/step - loss: 0.5992 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7446 - val_loss: 0.5815 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6586\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.5889 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7461 - val_loss: 0.5727 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6579\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5800 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7569 - val_loss: 0.5648 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6695\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 199us/step - loss: 0.5644 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7420 - val_loss: 0.5583 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6650\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 233us/step - loss: 0.5541 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7459 - val_loss: 0.5508 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6563\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5432 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7588 - val_loss: 0.5465 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.5374 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7608 - val_loss: 0.5445 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6679\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.5303 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7594 - val_loss: 0.5408 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6724\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5267 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7564 - val_loss: 0.5372 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6774\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5228 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7680 - val_loss: 0.5353 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6802\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5194 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7587 - val_loss: 0.5324 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6827\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5162 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7788 - val_loss: 0.5274 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9855 - val_specificity: 0.1065 - val_gmeasure: 0.2771 - val_auc: 0.6881\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5125 - binary_accuracy: 0.7109 - sensitivity: 0.9847 - specificity: 0.1331 - gmeasure: 0.3311 - auc: 0.7796 - val_loss: 0.5246 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9931 - val_specificity: 0.0857 - val_gmeasure: 0.2050 - val_auc: 0.6929\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.5096 - binary_accuracy: 0.7344 - sensitivity: 0.9636 - specificity: 0.2443 - gmeasure: 0.4491 - auc: 0.7843 - val_loss: 0.5246 - val_binary_accuracy: 0.7063 - val_sensitivity: 1.0000 - val_specificity: 0.0500 - val_gmeasure: 0.1118 - val_auc: 0.6930\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.5094 - binary_accuracy: 0.7188 - sensitivity: 0.9700 - specificity: 0.2013 - gmeasure: 0.3955 - auc: 0.7883 - val_loss: 0.5192 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9931 - val_specificity: 0.1065 - val_gmeasure: 0.2771 - val_auc: 0.7054\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 227us/step - loss: 0.5042 - binary_accuracy: 0.7047 - sensitivity: 0.9874 - specificity: 0.0912 - gmeasure: 0.2571 - auc: 0.7905 - val_loss: 0.5163 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9931 - val_specificity: 0.1065 - val_gmeasure: 0.2771 - val_auc: 0.7208\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5018 - binary_accuracy: 0.7547 - sensitivity: 0.9574 - specificity: 0.3372 - gmeasure: 0.5496 - auc: 0.7936 - val_loss: 0.5144 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9931 - val_specificity: 0.1065 - val_gmeasure: 0.2771 - val_auc: 0.7150\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.5022 - binary_accuracy: 0.7297 - sensitivity: 0.8997 - specificity: 0.4051 - gmeasure: 0.5827 - auc: 0.7993 - val_loss: 0.5105 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9931 - val_specificity: 0.1213 - val_gmeasure: 0.3378 - val_auc: 0.7288\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5027 - binary_accuracy: 0.7031 - sensitivity: 0.9906 - specificity: 0.0868 - gmeasure: 0.2000 - auc: 0.8052 - val_loss: 0.5062 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.8265 - val_specificity: 0.2984 - val_gmeasure: 0.4707 - val_auc: 0.7212\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5008 - binary_accuracy: 0.7000 - sensitivity: 0.7774 - specificity: 0.5256 - gmeasure: 0.6245 - auc: 0.7912 - val_loss: 0.5056 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9931 - val_specificity: 0.1213 - val_gmeasure: 0.3378 - val_auc: 0.7246\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.4936 - binary_accuracy: 0.7297 - sensitivity: 0.9789 - specificity: 0.2035 - gmeasure: 0.4336 - auc: 0.8066 - val_loss: 0.5026 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9058 - val_specificity: 0.1538 - val_gmeasure: 0.3650 - val_auc: 0.7250\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.4895 - binary_accuracy: 0.7703 - sensitivity: 0.9266 - specificity: 0.4330 - gmeasure: 0.6249 - auc: 0.8085 - val_loss: 0.5010 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9058 - val_specificity: 0.1538 - val_gmeasure: 0.3650 - val_auc: 0.7251\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 232us/step - loss: 0.4891 - binary_accuracy: 0.7234 - sensitivity: 0.9846 - specificity: 0.1642 - gmeasure: 0.3550 - auc: 0.8092 - val_loss: 0.4972 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.8341 - val_specificity: 0.3402 - val_gmeasure: 0.5176 - val_auc: 0.7258\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.4862 - binary_accuracy: 0.7672 - sensitivity: 0.8970 - specificity: 0.4970 - gmeasure: 0.6486 - auc: 0.8147 - val_loss: 0.4977 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9634 - val_specificity: 0.1213 - val_gmeasure: 0.3336 - val_auc: 0.7276\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.4818 - binary_accuracy: 0.7750 - sensitivity: 0.9220 - specificity: 0.4633 - gmeasure: 0.6408 - auc: 0.8094 - val_loss: 0.4924 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.8492 - val_specificity: 0.2221 - val_gmeasure: 0.4153 - val_auc: 0.7290\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.4817 - binary_accuracy: 0.7563 - sensitivity: 0.9717 - specificity: 0.2819 - gmeasure: 0.5130 - auc: 0.8117 - val_loss: 0.4892 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.8265 - val_specificity: 0.3549 - val_gmeasure: 0.5268 - val_auc: 0.7300\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.4783 - binary_accuracy: 0.7781 - sensitivity: 0.9168 - specificity: 0.4932 - gmeasure: 0.6651 - auc: 0.8282 - val_loss: 0.4861 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.8050 - val_specificity: 0.3728 - val_gmeasure: 0.5306 - val_auc: 0.7328\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.4800 - binary_accuracy: 0.7578 - sensitivity: 0.9507 - specificity: 0.3531 - gmeasure: 0.5237 - auc: 0.8233 - val_loss: 0.4875 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9285 - val_specificity: 0.1570 - val_gmeasure: 0.3617 - val_auc: 0.7354\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.4757 - binary_accuracy: 0.7547 - sensitivity: 0.8410 - specificity: 0.5746 - gmeasure: 0.6845 - auc: 0.8244 - val_loss: 0.4839 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9285 - val_specificity: 0.1895 - val_gmeasure: 0.4018 - val_auc: 0.7389\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 202us/step - loss: 0.4753 - binary_accuracy: 0.7422 - sensitivity: 0.9838 - specificity: 0.2369 - gmeasure: 0.4164 - auc: 0.8315 - val_loss: 0.4790 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.7905 - val_specificity: 0.4438 - val_gmeasure: 0.5865 - val_auc: 0.7407\n",
      "Epoch 49/100\n",
      "640/640 [==============================] - 0s 228us/step - loss: 0.4742 - binary_accuracy: 0.7281 - sensitivity: 0.7896 - specificity: 0.5957 - gmeasure: 0.6696 - auc: 0.8288 - val_loss: 0.4913 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9931 - val_specificity: 0.1213 - val_gmeasure: 0.3378 - val_auc: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.4690 - binary_accuracy: 0.7641 - sensitivity: 0.9824 - specificity: 0.2929 - gmeasure: 0.5085 - auc: 0.8339 - val_loss: 0.4749 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.8126 - val_specificity: 0.3875 - val_gmeasure: 0.5438 - val_auc: 0.7445\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.4639 - binary_accuracy: 0.7937 - sensitivity: 0.9013 - specificity: 0.5644 - gmeasure: 0.7062 - auc: 0.8361 - val_loss: 0.4741 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9064 - val_specificity: 0.2902 - val_gmeasure: 0.5006 - val_auc: 0.7491\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.4628 - binary_accuracy: 0.7937 - sensitivity: 0.9247 - specificity: 0.5357 - gmeasure: 0.6924 - auc: 0.8521 - val_loss: 0.4705 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.7905 - val_specificity: 0.4230 - val_gmeasure: 0.5674 - val_auc: 0.7505\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.4589 - binary_accuracy: 0.8000 - sensitivity: 0.9435 - specificity: 0.4995 - gmeasure: 0.6761 - auc: 0.8492 - val_loss: 0.4695 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.9140 - val_specificity: 0.3049 - val_gmeasure: 0.5153 - val_auc: 0.7644\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.4543 - binary_accuracy: 0.8000 - sensitivity: 0.9089 - specificity: 0.5608 - gmeasure: 0.7084 - auc: 0.8472 - val_loss: 0.4710 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9285 - val_specificity: 0.2042 - val_gmeasure: 0.4208 - val_auc: 0.7659\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.4514 - binary_accuracy: 0.8031 - sensitivity: 0.9646 - specificity: 0.4576 - gmeasure: 0.6607 - auc: 0.8549 - val_loss: 0.4647 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.8268 - val_specificity: 0.3549 - val_gmeasure: 0.5255 - val_auc: 0.7594\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.4489 - binary_accuracy: 0.7984 - sensitivity: 0.9071 - specificity: 0.5690 - gmeasure: 0.7140 - auc: 0.8554 - val_loss: 0.4679 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9355 - val_specificity: 0.2042 - val_gmeasure: 0.4229 - val_auc: 0.7720\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.4457 - binary_accuracy: 0.7969 - sensitivity: 0.9436 - specificity: 0.4723 - gmeasure: 0.6576 - auc: 0.8491 - val_loss: 0.4599 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.8278 - val_specificity: 0.4230 - val_gmeasure: 0.5820 - val_auc: 0.7754\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.4443 - binary_accuracy: 0.8078 - sensitivity: 0.9497 - specificity: 0.5137 - gmeasure: 0.6923 - auc: 0.8652 - val_loss: 0.4570 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.8202 - val_specificity: 0.4730 - val_gmeasure: 0.6066 - val_auc: 0.7759\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.4412 - binary_accuracy: 0.7937 - sensitivity: 0.8979 - specificity: 0.5751 - gmeasure: 0.7121 - auc: 0.8665 - val_loss: 0.4636 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9355 - val_specificity: 0.1895 - val_gmeasure: 0.4039 - val_auc: 0.7640\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.4363 - binary_accuracy: 0.8125 - sensitivity: 0.9685 - specificity: 0.4925 - gmeasure: 0.6829 - auc: 0.8659 - val_loss: 0.4531 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.8060 - val_specificity: 0.4730 - val_gmeasure: 0.6021 - val_auc: 0.7664\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.4393 - binary_accuracy: 0.8031 - sensitivity: 0.9231 - specificity: 0.5584 - gmeasure: 0.7091 - auc: 0.8723 - val_loss: 0.4581 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9285 - val_specificity: 0.2189 - val_gmeasure: 0.4368 - val_auc: 0.7692\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.4324 - binary_accuracy: 0.8016 - sensitivity: 0.9079 - specificity: 0.5761 - gmeasure: 0.7164 - auc: 0.8712 - val_loss: 0.4567 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9355 - val_specificity: 0.2042 - val_gmeasure: 0.4229 - val_auc: 0.7930\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.4296 - binary_accuracy: 0.8172 - sensitivity: 0.9418 - specificity: 0.5536 - gmeasure: 0.7117 - auc: 0.8760 - val_loss: 0.4529 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9285 - val_specificity: 0.2189 - val_gmeasure: 0.4368 - val_auc: 0.7931\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.4238 - binary_accuracy: 0.8172 - sensitivity: 0.9665 - specificity: 0.4961 - gmeasure: 0.6820 - auc: 0.8750 - val_loss: 0.4442 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.7846 - val_specificity: 0.5681 - val_gmeasure: 0.6634 - val_auc: 0.7940\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 203us/step - loss: 0.4225 - binary_accuracy: 0.8031 - sensitivity: 0.9179 - specificity: 0.5617 - gmeasure: 0.7069 - auc: 0.8794 - val_loss: 0.4564 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9931 - val_specificity: 0.2042 - val_gmeasure: 0.4363 - val_auc: 0.7973\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.4188 - binary_accuracy: 0.8156 - sensitivity: 0.9178 - specificity: 0.5842 - gmeasure: 0.7109 - auc: 0.8814 - val_loss: 0.4401 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.7921 - val_specificity: 0.5681 - val_gmeasure: 0.6665 - val_auc: 0.7997\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.4149 - binary_accuracy: 0.8281 - sensitivity: 0.9462 - specificity: 0.5708 - gmeasure: 0.7258 - auc: 0.8898 - val_loss: 0.4400 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.9074 - val_specificity: 0.3610 - val_gmeasure: 0.5654 - val_auc: 0.8017\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.4147 - binary_accuracy: 0.8156 - sensitivity: 0.9390 - specificity: 0.5441 - gmeasure: 0.7021 - auc: 0.8905 - val_loss: 0.4507 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9931 - val_specificity: 0.2042 - val_gmeasure: 0.4363 - val_auc: 0.8027\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.4101 - binary_accuracy: 0.8172 - sensitivity: 0.9028 - specificity: 0.6399 - gmeasure: 0.7518 - auc: 0.8886 - val_loss: 0.4504 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9931 - val_specificity: 0.2042 - val_gmeasure: 0.4363 - val_auc: 0.8068\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 197us/step - loss: 0.4030 - binary_accuracy: 0.8219 - sensitivity: 0.9618 - specificity: 0.5216 - gmeasure: 0.7008 - auc: 0.8959 - val_loss: 0.4312 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.7921 - val_specificity: 0.5828 - val_gmeasure: 0.6752 - val_auc: 0.8107\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 205us/step - loss: 0.4003 - binary_accuracy: 0.8344 - sensitivity: 0.9192 - specificity: 0.6335 - gmeasure: 0.7544 - auc: 0.8986 - val_loss: 0.4432 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9861 - val_specificity: 0.2189 - val_gmeasure: 0.4504 - val_auc: 0.8112\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.3938 - binary_accuracy: 0.8438 - sensitivity: 0.9589 - specificity: 0.5986 - gmeasure: 0.7525 - auc: 0.8938 - val_loss: 0.4271 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.7991 - val_specificity: 0.5828 - val_gmeasure: 0.6783 - val_auc: 0.8265\n",
      "Epoch 73/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.3932 - binary_accuracy: 0.8281 - sensitivity: 0.9059 - specificity: 0.6481 - gmeasure: 0.7578 - auc: 0.8979 - val_loss: 0.4486 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.9931 - val_specificity: 0.2189 - val_gmeasure: 0.4526 - val_auc: 0.8243\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.3861 - binary_accuracy: 0.8469 - sensitivity: 0.9464 - specificity: 0.6268 - gmeasure: 0.7627 - auc: 0.9015 - val_loss: 0.4235 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.8067 - val_specificity: 0.5619 - val_gmeasure: 0.6665 - val_auc: 0.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.3883 - binary_accuracy: 0.8359 - sensitivity: 0.9402 - specificity: 0.6139 - gmeasure: 0.7564 - auc: 0.9031 - val_loss: 0.4205 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.7921 - val_specificity: 0.5975 - val_gmeasure: 0.6835 - val_auc: 0.8294\n",
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.3799 - binary_accuracy: 0.8453 - sensitivity: 0.9333 - specificity: 0.6365 - gmeasure: 0.7652 - auc: 0.9073 - val_loss: 0.4422 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.9931 - val_specificity: 0.2189 - val_gmeasure: 0.4526 - val_auc: 0.8310\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.3809 - binary_accuracy: 0.8422 - sensitivity: 0.9383 - specificity: 0.6308 - gmeasure: 0.7626 - auc: 0.9045 - val_loss: 0.4302 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.9720 - val_specificity: 0.3223 - val_gmeasure: 0.5514 - val_auc: 0.8324\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.3765 - binary_accuracy: 0.8484 - sensitivity: 0.9611 - specificity: 0.6167 - gmeasure: 0.7659 - auc: 0.9117 - val_loss: 0.4196 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9074 - val_specificity: 0.3966 - val_gmeasure: 0.5970 - val_auc: 0.8334\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.3696 - binary_accuracy: 0.8453 - sensitivity: 0.9285 - specificity: 0.6673 - gmeasure: 0.7824 - auc: 0.9097 - val_loss: 0.4248 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9720 - val_specificity: 0.3549 - val_gmeasure: 0.5769 - val_auc: 0.8338\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.3654 - binary_accuracy: 0.8578 - sensitivity: 0.9490 - specificity: 0.6533 - gmeasure: 0.7836 - auc: 0.9168 - val_loss: 0.4133 - val_binary_accuracy: 0.7875 - val_sensitivity: 0.9074 - val_specificity: 0.4291 - val_gmeasure: 0.6203 - val_auc: 0.8371\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 228us/step - loss: 0.3614 - binary_accuracy: 0.8547 - sensitivity: 0.9505 - specificity: 0.6500 - gmeasure: 0.7835 - auc: 0.9221 - val_loss: 0.4192 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9220 - val_specificity: 0.3549 - val_gmeasure: 0.5602 - val_auc: 0.8369\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 207us/step - loss: 0.3568 - binary_accuracy: 0.8516 - sensitivity: 0.9506 - specificity: 0.6348 - gmeasure: 0.7716 - auc: 0.9176 - val_loss: 0.4061 - val_binary_accuracy: 0.7875 - val_sensitivity: 0.7991 - val_specificity: 0.6153 - val_gmeasure: 0.6966 - val_auc: 0.8409\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.3517 - binary_accuracy: 0.8594 - sensitivity: 0.9268 - specificity: 0.7188 - gmeasure: 0.8136 - auc: 0.9200 - val_loss: 0.4342 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9865 - val_specificity: 0.3015 - val_gmeasure: 0.5263 - val_auc: 0.8405\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.3516 - binary_accuracy: 0.8484 - sensitivity: 0.9534 - specificity: 0.6060 - gmeasure: 0.7513 - auc: 0.9137 - val_loss: 0.4044 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.7770 - val_specificity: 0.6773 - val_gmeasure: 0.7178 - val_auc: 0.8455\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.3565 - binary_accuracy: 0.8469 - sensitivity: 0.9342 - specificity: 0.6671 - gmeasure: 0.7824 - auc: 0.9300 - val_loss: 0.4162 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9795 - val_specificity: 0.3370 - val_gmeasure: 0.5664 - val_auc: 0.8453\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.3443 - binary_accuracy: 0.8609 - sensitivity: 0.9150 - specificity: 0.7379 - gmeasure: 0.8185 - auc: 0.9237 - val_loss: 0.4083 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9720 - val_specificity: 0.4113 - val_gmeasure: 0.6303 - val_auc: 0.8457\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.3425 - binary_accuracy: 0.8547 - sensitivity: 0.9485 - specificity: 0.6540 - gmeasure: 0.7850 - auc: 0.9296 - val_loss: 0.3959 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8142 - val_specificity: 0.5359 - val_gmeasure: 0.6582 - val_auc: 0.8476\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.3394 - binary_accuracy: 0.8641 - sensitivity: 0.9449 - specificity: 0.6986 - gmeasure: 0.8089 - auc: 0.9318 - val_loss: 0.3992 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9220 - val_specificity: 0.4291 - val_gmeasure: 0.6255 - val_auc: 0.8499\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.3353 - binary_accuracy: 0.8609 - sensitivity: 0.9314 - specificity: 0.7115 - gmeasure: 0.8126 - auc: 0.9297 - val_loss: 0.4037 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9720 - val_specificity: 0.4113 - val_gmeasure: 0.6303 - val_auc: 0.8503\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.3384 - binary_accuracy: 0.8547 - sensitivity: 0.9316 - specificity: 0.7012 - gmeasure: 0.8050 - auc: 0.9342 - val_loss: 0.4098 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9795 - val_specificity: 0.3370 - val_gmeasure: 0.5664 - val_auc: 0.8510\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 227us/step - loss: 0.3270 - binary_accuracy: 0.8625 - sensitivity: 0.9325 - specificity: 0.7162 - gmeasure: 0.8147 - auc: 0.9367 - val_loss: 0.3857 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.8142 - val_specificity: 0.6479 - val_gmeasure: 0.7212 - val_auc: 0.8582\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.3306 - binary_accuracy: 0.8672 - sensitivity: 0.9563 - specificity: 0.6879 - gmeasure: 0.8060 - auc: 0.9406 - val_loss: 0.3828 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.8142 - val_specificity: 0.6479 - val_gmeasure: 0.7212 - val_auc: 0.8592\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.3226 - binary_accuracy: 0.8750 - sensitivity: 0.9362 - specificity: 0.7500 - gmeasure: 0.8344 - auc: 0.9417 - val_loss: 0.3966 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.9795 - val_specificity: 0.4113 - val_gmeasure: 0.6328 - val_auc: 0.8575\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.3278 - binary_accuracy: 0.8594 - sensitivity: 0.9235 - specificity: 0.7299 - gmeasure: 0.8169 - auc: 0.9421 - val_loss: 0.4360 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9865 - val_specificity: 0.3015 - val_gmeasure: 0.5263 - val_auc: 0.8525\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.3181 - binary_accuracy: 0.8703 - sensitivity: 0.9377 - specificity: 0.7008 - gmeasure: 0.7991 - auc: 0.9412 - val_loss: 0.3796 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.8650 - val_specificity: 0.5653 - val_gmeasure: 0.6972 - val_auc: 0.8608\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.3122 - binary_accuracy: 0.8766 - sensitivity: 0.9476 - specificity: 0.7244 - gmeasure: 0.8261 - auc: 0.9377 - val_loss: 0.3868 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.9720 - val_specificity: 0.4678 - val_gmeasure: 0.6701 - val_auc: 0.8589\n",
      "Epoch 97/100\n",
      "640/640 [==============================] - 0s 227us/step - loss: 0.3086 - binary_accuracy: 0.8813 - sensitivity: 0.9494 - specificity: 0.7429 - gmeasure: 0.8386 - auc: 0.9447 - val_loss: 0.3842 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.9720 - val_specificity: 0.4825 - val_gmeasure: 0.6810 - val_auc: 0.8600\n",
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.3069 - binary_accuracy: 0.8672 - sensitivity: 0.9449 - specificity: 0.6984 - gmeasure: 0.8068 - auc: 0.9450 - val_loss: 0.3757 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.7700 - val_specificity: 0.7481 - val_gmeasure: 0.7514 - val_auc: 0.8660\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.3101 - binary_accuracy: 0.8766 - sensitivity: 0.9379 - specificity: 0.7341 - gmeasure: 0.8249 - auc: 0.9445 - val_loss: 0.3839 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9795 - val_specificity: 0.4825 - val_gmeasure: 0.6836 - val_auc: 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.3018 - binary_accuracy: 0.8844 - sensitivity: 0.9434 - specificity: 0.7624 - gmeasure: 0.8459 - auc: 0.9471 - val_loss: 0.3857 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.9795 - val_specificity: 0.4617 - val_gmeasure: 0.6668 - val_auc: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 16.73941421508789!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.008795499801635742!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.31715595722198486, 0.8637499809265137, 0.9581056237220764, 0.6573705077171326, 0.7936185002326965, 0.9367557168006897]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.013047218322753906!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.3656657338142395, 0.8258706331253052, 0.9064748287200928, 0.6451612710952759, 0.7647368907928467, 0.9013692140579224]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 19.724050045013428\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 1s 846us/step - loss: 0.6622 - binary_accuracy: 0.6734 - sensitivity: 0.9231 - specificity: 0.0769 - gmeasure: 0.0000e+00 - auc: 0.5089 - val_loss: 0.6071 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4932\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6161 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5420 - val_loss: 0.5645 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4589\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6123 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5460 - val_loss: 0.5639 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4544\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5635 - val_loss: 0.5716 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4713\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6103 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5904 - val_loss: 0.5698 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4805\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5926 - val_loss: 0.5675 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4801\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5897 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4922\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6104 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6021 - val_loss: 0.5700 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4983\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.6105 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6057 - val_loss: 0.5655 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5014\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6101 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6032 - val_loss: 0.5668 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5061\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5954 - val_loss: 0.5714 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5090\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6110 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5978 - val_loss: 0.5674 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5081\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6058 - val_loss: 0.5697 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5073\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 204us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6100 - val_loss: 0.5686 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5046\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6103 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5947 - val_loss: 0.5688 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4985\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5962 - val_loss: 0.5665 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4979\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5968 - val_loss: 0.5669 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4967\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6110 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5921 - val_loss: 0.5695 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4962\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6006 - val_loss: 0.5674 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4958\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 197us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5968 - val_loss: 0.5676 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4886\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5941 - val_loss: 0.5671 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4676\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.6106 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5850 - val_loss: 0.5699 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4632\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5760 - val_loss: 0.5680 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4581\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5914 - val_loss: 0.5675 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5871 - val_loss: 0.5675 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4526\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6102 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5853 - val_loss: 0.5706 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4516\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5888 - val_loss: 0.5674 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4522\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.6106 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5738 - val_loss: 0.5666 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4526\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5736 - val_loss: 0.5704 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4538\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5913 - val_loss: 0.5676 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4515\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5852 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4516\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6092 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5856 - val_loss: 0.5696 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4505\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.6093 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5745 - val_loss: 0.5679 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4508\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6091 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5783 - val_loss: 0.5673 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4513\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6092 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5697 - val_loss: 0.5691 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4497\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.6087 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5773 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4511\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 204us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5840 - val_loss: 0.5662 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4499\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6089 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5728 - val_loss: 0.5694 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4498\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6087 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5757 - val_loss: 0.5699 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4475\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6082 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5770 - val_loss: 0.5675 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4475\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6079 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5767 - val_loss: 0.5685 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4481\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.6082 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5821 - val_loss: 0.5699 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4488\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6086 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5655 - val_loss: 0.5672 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4498\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6079 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5703 - val_loss: 0.5714 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4486\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6074 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5811 - val_loss: 0.5694 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4475\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.6072 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5547 - val_loss: 0.5686 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4459\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6067 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5855 - val_loss: 0.5739 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4372\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 182us/step - loss: 0.6065 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5850 - val_loss: 0.5710 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6052 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5873 - val_loss: 0.5733 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4494\n",
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6051 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.5787 - val_loss: 0.5719 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4517\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6043 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0048 - gmeasure: 0.0192 - auc: 0.5681 - val_loss: 0.5746 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4475\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6094 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.5820 - val_loss: 0.5713 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4535\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.6057 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.5903 - val_loss: 0.5802 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4463\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6030 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.5817 - val_loss: 0.5704 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4552\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.6036 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0043 - gmeasure: 0.0181 - auc: 0.5721 - val_loss: 0.5722 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4540\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6033 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0037 - gmeasure: 0.0168 - auc: 0.5830 - val_loss: 0.5748 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4541\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6044 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0055 - gmeasure: 0.0206 - auc: 0.5955 - val_loss: 0.5717 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4531\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6013 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0055 - gmeasure: 0.0206 - auc: 0.5930 - val_loss: 0.5781 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4577\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6031 - binary_accuracy: 0.7000 - sensitivity: 0.9960 - specificity: 0.0043 - gmeasure: 0.0181 - auc: 0.5790 - val_loss: 0.5781 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4581\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6033 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.5958 - val_loss: 0.5730 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4587\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6019 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0055 - gmeasure: 0.0206 - auc: 0.5795 - val_loss: 0.5766 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4590\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6011 - binary_accuracy: 0.7016 - sensitivity: 0.9978 - specificity: 0.0045 - gmeasure: 0.0187 - auc: 0.5962 - val_loss: 0.5776 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4585\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6018 - binary_accuracy: 0.7000 - sensitivity: 0.9957 - specificity: 0.0033 - gmeasure: 0.0160 - auc: 0.5975 - val_loss: 0.5778 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4555\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.6008 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0040 - gmeasure: 0.0176 - auc: 0.5933 - val_loss: 0.5714 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4479\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6041 - binary_accuracy: 0.7047 - sensitivity: 1.0000 - specificity: 0.0110 - gmeasure: 0.0291 - auc: 0.5953 - val_loss: 0.5793 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4577\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5996 - binary_accuracy: 0.7016 - sensitivity: 0.9977 - specificity: 0.0040 - gmeasure: 0.0176 - auc: 0.5912 - val_loss: 0.5732 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4462\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6008 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0043 - gmeasure: 0.0181 - auc: 0.6056 - val_loss: 0.5770 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4451\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6007 - binary_accuracy: 0.7016 - sensitivity: 0.9958 - specificity: 0.0107 - gmeasure: 0.0400 - auc: 0.5914 - val_loss: 0.5781 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4454\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.5993 - binary_accuracy: 0.7016 - sensitivity: 0.9959 - specificity: 0.0114 - gmeasure: 0.0416 - auc: 0.5916 - val_loss: 0.5750 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4418\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 197us/step - loss: 0.5994 - binary_accuracy: 0.7016 - sensitivity: 0.9980 - specificity: 0.0051 - gmeasure: 0.0199 - auc: 0.6026 - val_loss: 0.5764 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4447\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.5998 - binary_accuracy: 0.7016 - sensitivity: 0.9957 - specificity: 0.0162 - gmeasure: 0.0470 - auc: 0.5989 - val_loss: 0.5802 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4553\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6008 - binary_accuracy: 0.7000 - sensitivity: 0.9956 - specificity: 0.0070 - gmeasure: 0.0232 - auc: 0.5998 - val_loss: 0.5765 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4557\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 220us/step - loss: 0.5991 - binary_accuracy: 0.7000 - sensitivity: 0.9955 - specificity: 0.0051 - gmeasure: 0.0196 - auc: 0.5984 - val_loss: 0.5794 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4546\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.5996 - binary_accuracy: 0.7016 - sensitivity: 0.9933 - specificity: 0.0170 - gmeasure: 0.0496 - auc: 0.6067 - val_loss: 0.5803 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4544\n",
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.5977 - binary_accuracy: 0.7000 - sensitivity: 0.9930 - specificity: 0.0110 - gmeasure: 0.0409 - auc: 0.6036 - val_loss: 0.5748 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4533\n",
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 227us/step - loss: 0.6006 - binary_accuracy: 0.6984 - sensitivity: 0.9936 - specificity: 0.0051 - gmeasure: 0.0199 - auc: 0.5961 - val_loss: 0.5799 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4542\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6003 - binary_accuracy: 0.7000 - sensitivity: 0.9961 - specificity: 0.0037 - gmeasure: 0.0168 - auc: 0.6094 - val_loss: 0.5749 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4528\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5972 - binary_accuracy: 0.7000 - sensitivity: 0.9937 - specificity: 0.0107 - gmeasure: 0.0403 - auc: 0.6072 - val_loss: 0.5816 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4529\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5985 - binary_accuracy: 0.7016 - sensitivity: 0.9936 - specificity: 0.0170 - gmeasure: 0.0496 - auc: 0.6026 - val_loss: 0.5752 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4539\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.5998 - binary_accuracy: 0.7000 - sensitivity: 0.9914 - specificity: 0.0214 - gmeasure: 0.0570 - auc: 0.6199 - val_loss: 0.5799 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4661\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 231us/step - loss: 0.5975 - binary_accuracy: 0.7000 - sensitivity: 0.9960 - specificity: 0.0051 - gmeasure: 0.0199 - auc: 0.6106 - val_loss: 0.5750 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.5982 - binary_accuracy: 0.7000 - sensitivity: 0.9932 - specificity: 0.0075 - gmeasure: 0.0338 - auc: 0.5933 - val_loss: 0.5833 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 231us/step - loss: 0.5983 - binary_accuracy: 0.6984 - sensitivity: 0.9936 - specificity: 0.0055 - gmeasure: 0.0203 - auc: 0.6067 - val_loss: 0.5745 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4671\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.5960 - binary_accuracy: 0.7016 - sensitivity: 0.9956 - specificity: 0.0100 - gmeasure: 0.0389 - auc: 0.6082 - val_loss: 0.5816 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4665\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.5966 - binary_accuracy: 0.7000 - sensitivity: 0.9901 - specificity: 0.0159 - gmeasure: 0.0596 - auc: 0.6162 - val_loss: 0.5750 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4651\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.5958 - binary_accuracy: 0.7016 - sensitivity: 0.9952 - specificity: 0.0090 - gmeasure: 0.0370 - auc: 0.6171 - val_loss: 0.5778 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4781\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 224us/step - loss: 0.5956 - binary_accuracy: 0.7000 - sensitivity: 0.9936 - specificity: 0.0098 - gmeasure: 0.0387 - auc: 0.6099 - val_loss: 0.5767 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5993 - binary_accuracy: 0.6984 - sensitivity: 0.9894 - specificity: 0.0150 - gmeasure: 0.0576 - auc: 0.6129 - val_loss: 0.5819 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4786\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5957 - binary_accuracy: 0.7000 - sensitivity: 0.9933 - specificity: 0.0117 - gmeasure: 0.0420 - auc: 0.6222 - val_loss: 0.5752 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4748\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 198us/step - loss: 0.5955 - binary_accuracy: 0.6984 - sensitivity: 0.9931 - specificity: 0.0045 - gmeasure: 0.0187 - auc: 0.6122 - val_loss: 0.5811 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4774\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5947 - binary_accuracy: 0.7000 - sensitivity: 0.9910 - specificity: 0.0185 - gmeasure: 0.0647 - auc: 0.6049 - val_loss: 0.5784 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4783\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 205us/step - loss: 0.5939 - binary_accuracy: 0.6984 - sensitivity: 0.9912 - specificity: 0.0107 - gmeasure: 0.0400 - auc: 0.6085 - val_loss: 0.5796 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4783\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5938 - binary_accuracy: 0.7000 - sensitivity: 0.9907 - specificity: 0.0179 - gmeasure: 0.0635 - auc: 0.6068 - val_loss: 0.5805 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4753\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5933 - binary_accuracy: 0.7000 - sensitivity: 0.9919 - specificity: 0.0139 - gmeasure: 0.0563 - auc: 0.6185 - val_loss: 0.5799 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4741\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.5929 - binary_accuracy: 0.7000 - sensitivity: 0.9936 - specificity: 0.0103 - gmeasure: 0.0397 - auc: 0.6155 - val_loss: 0.5782 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4736\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.5927 - binary_accuracy: 0.7000 - sensitivity: 0.9933 - specificity: 0.0098 - gmeasure: 0.0387 - auc: 0.6140 - val_loss: 0.5817 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4627\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 223us/step - loss: 0.5937 - binary_accuracy: 0.7000 - sensitivity: 0.9939 - specificity: 0.0110 - gmeasure: 0.0287 - auc: 0.6219 - val_loss: 0.5805 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4606\n",
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.5948 - binary_accuracy: 0.7000 - sensitivity: 0.9916 - specificity: 0.0146 - gmeasure: 0.0572 - auc: 0.6234 - val_loss: 0.5844 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4623\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 227us/step - loss: 0.5959 - binary_accuracy: 0.7000 - sensitivity: 0.9953 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.6205 - val_loss: 0.5751 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4611\n",
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5926 - binary_accuracy: 0.7000 - sensitivity: 0.9915 - specificity: 0.0183 - gmeasure: 0.0509 - auc: 0.6255 - val_loss: 0.5839 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9643 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 15.866478681564331!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.00881338119506836!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5899850726127625, 0.7087500095367432, 0.9912126660346985, 0.012987012974917889, 0.11345876753330231, 0.5970602035522461]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.010343074798583984!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5914334058761597, 0.746268630027771, 0.9868420958518982, 0.0, 0.0, 0.507921576499939]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 17.177849054336548\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 1s 792us/step - loss: 0.6727 - binary_accuracy: 0.6562 - sensitivity: 0.9231 - specificity: 0.0714 - gmeasure: 0.0000e+00 - auc: 0.4645 - val_loss: 0.6484 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4659\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6287 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4560 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4626\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 225us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4811 - val_loss: 0.6232 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.6197 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5257 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4673\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5475 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4528\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5605 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4424\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 207us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5716 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4640\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5737 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4703\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5729 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4883\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 207us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5805 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4686\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6185 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5933 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4992\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6010 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4864\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6039 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4955\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 203us/step - loss: 0.6182 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6112 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4968\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6121 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5212\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6020 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5233\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6189 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5250\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6076 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5293\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6185 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5279\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6205 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5300\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 198us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6105 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5363\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6178 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5299\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6077 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5292\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 230us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6229 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.6182 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6150 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5325\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6123 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4805\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5755 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5123\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5658 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5068\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5661 - val_loss: 0.6216 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5096\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.6171 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5556 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5081\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5613 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5088\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6168 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5692 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5088\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6167 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5789 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5089\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5932 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5092\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 228us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5668 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5091\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6161 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5742 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5159\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6173 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5892 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5168\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6159 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5753 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5138\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6160 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5636 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5249\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6157 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5820 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5274\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6165 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5868 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5323\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6167 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5876 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5174\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6151 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5806 - val_loss: 0.6217 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5205\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6148 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5789 - val_loss: 0.6216 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5170\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.6141 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5844 - val_loss: 0.6217 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5040\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6140 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5901 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5049\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6149 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5886 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5076\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 216us/step - loss: 0.6133 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5943 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6127 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5957 - val_loss: 0.6221 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071\n",
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6131 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5956 - val_loss: 0.6223 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5068\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6127 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5941 - val_loss: 0.6226 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5070\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6123 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6035 - val_loss: 0.6226 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.6112 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6042 - val_loss: 0.6238 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5088\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6094 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6048 - val_loss: 0.6240 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5078\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.6091 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6165 - val_loss: 0.6237 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5065\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.6086 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6117 - val_loss: 0.6239 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.6076 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6102 - val_loss: 0.6249 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5031\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6093 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6173 - val_loss: 0.6256 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5072\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6062 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6175 - val_loss: 0.6253 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5022\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 206us/step - loss: 0.6058 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6230 - val_loss: 0.6266 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5021\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 209us/step - loss: 0.6050 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6140 - val_loss: 0.6280 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5026\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.6039 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6196 - val_loss: 0.6275 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5024\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 222us/step - loss: 0.6043 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6202 - val_loss: 0.6283 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5022\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.6032 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6240 - val_loss: 0.6279 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5004\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.6016 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6226 - val_loss: 0.6297 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4981\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 218us/step - loss: 0.6006 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6319 - val_loss: 0.6288 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4956\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - 0s 212us/step - loss: 0.6000 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6290 - val_loss: 0.6310 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4951\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.6000 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6241 - val_loss: 0.6306 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5066\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.5981 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6277 - val_loss: 0.6316 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5082\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 226us/step - loss: 0.5979 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6349 - val_loss: 0.6319 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5074\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5962 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6314 - val_loss: 0.6334 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5165\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5953 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6497 - val_loss: 0.6346 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.5964 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6455 - val_loss: 0.6333 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5122\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5946 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6455 - val_loss: 0.6359 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 202us/step - loss: 0.5924 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6430 - val_loss: 0.6350 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5122\n",
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.5915 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6453 - val_loss: 0.6370 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5121\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.5914 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6527 - val_loss: 0.6376 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5131\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.5917 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6580 - val_loss: 0.6385 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5126\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 223us/step - loss: 0.5912 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6516 - val_loss: 0.6375 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5098\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5914 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6546 - val_loss: 0.6398 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5095\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5884 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6607 - val_loss: 0.6404 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4957\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.5866 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6586 - val_loss: 0.6415 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5088\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.5874 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6583 - val_loss: 0.6413 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4949\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.5844 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6584 - val_loss: 0.6434 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4824\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5837 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6743 - val_loss: 0.6460 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4806\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 215us/step - loss: 0.5830 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6549 - val_loss: 0.6421 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4814\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 220us/step - loss: 0.5852 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6634 - val_loss: 0.6497 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4810\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 217us/step - loss: 0.5861 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6701 - val_loss: 0.6470 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4771\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5804 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6583 - val_loss: 0.6492 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4802\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 207us/step - loss: 0.5812 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6658 - val_loss: 0.6443 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4814\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 213us/step - loss: 0.5816 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6745 - val_loss: 0.6495 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4796\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5783 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6684 - val_loss: 0.6500 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4774\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5784 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6685 - val_loss: 0.6523 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4776\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 219us/step - loss: 0.5769 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6650 - val_loss: 0.6506 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4771\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 221us/step - loss: 0.5761 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6720 - val_loss: 0.6514 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4798\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 210us/step - loss: 0.5762 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6782 - val_loss: 0.6516 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5748 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6771 - val_loss: 0.6554 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4765\n",
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 228us/step - loss: 0.5745 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6685 - val_loss: 0.6544 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4799\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 208us/step - loss: 0.5754 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6759 - val_loss: 0.6537 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4830\n",
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 214us/step - loss: 0.5763 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6771 - val_loss: 0.6592 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 15.829649448394775!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012595176696777344!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5890567302703857, 0.6912500262260437, 1.0, 0.0, 0.0, 0.645869791507721]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "200/200 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.010534048080444336!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.6973899602890015, 0.6800000071525574, 1.0, 0.0, 0.0, 0.4499080777168274]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 17.17546772956848\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.49873259 0.75458334 0.9831061  0.22345251 0.30235909 0.7265619 ]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.12839463 0.07752238 0.01803833 0.30687217 0.35044741 0.14995927]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.55149637 0.75071309 0.96443897 0.21505376 0.2549123  0.61973296]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.13833887 0.0596343  0.04133735 0.30413194 0.36050043 0.20055029]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, network_info, path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `deepbiome_train` saves the trained model weights, evaluation results and history based on the path information from the configuration.\n",
    "\n",
    "From the example above, we can check that `hist_*.json`, `weight_*.h5`, `test_eval.npy`, `train_eval.npy` files were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hist_0.json',\n",
       " 'weight_2.h5',\n",
       " 'test_eval.npy',\n",
       " 'weight_0.h5',\n",
       " 'train_eval.npy',\n",
       " 'hist_2.json',\n",
       " 'weight_1.h5',\n",
       " 'hist_1.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_info['model_info']['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the history files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6a8590630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36566573, 0.82587063, 0.90647483, 0.64516127, 0.76473689,\n",
       "        0.90136921],\n",
       "       [0.59143341, 0.74626863, 0.9868421 , 0.        , 0.        ,\n",
       "        0.50792158],\n",
       "       [0.69738996, 0.68000001, 1.        , 0.        , 0.        ,\n",
       "        0.44990808]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31715596, 0.86374998, 0.95810562, 0.65737051, 0.7936185 ,\n",
       "        0.93675572],\n",
       "       [0.58998507, 0.70875001, 0.99121267, 0.01298701, 0.11345877,\n",
       "        0.5970602 ],\n",
       "       [0.58905673, 0.69125003, 1.        , 0.        , 0.        ,\n",
       "        0.64586979]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the pre-trained network for training\n",
    "\n",
    "If you have a pre-trianed model, you warm_start next training using the pre-trained weights by setting the `warm_start` option in `training_info` to `True`. The file path of the pre-trained weights passed in the `warm_start_model` option. Below is the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warm_start_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'training_info': {\n",
    "        'warm_start':'True',\n",
    "        'warm_start_model':'./example_result/weight.h5',\n",
    "        'batch_size': '200',\n",
    "        'epochs': '100'\n",
    "    },\n",
    "    'validation_info': {\n",
    "        'batch_size': 'None', \n",
    "        'validation_size': '0.2'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 1 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 0s 657us/step - loss: 0.3072 - binary_accuracy: 0.8797 - sensitivity: 0.9379 - specificity: 0.7269 - gmeasure: 0.8189 - auc: 0.9370 - val_loss: 0.3777 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9643 - val_specificity: 0.5208 - val_gmeasure: 0.7087 - val_auc: 0.8953\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.2973 - binary_accuracy: 0.8844 - sensitivity: 0.9597 - specificity: 0.7013 - gmeasure: 0.8171 - auc: 0.9383 - val_loss: 0.3685 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9554 - val_specificity: 0.5833 - val_gmeasure: 0.7465 - val_auc: 0.8977\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2969 - binary_accuracy: 0.8891 - sensitivity: 0.9544 - specificity: 0.7345 - gmeasure: 0.8345 - auc: 0.9440 - val_loss: 0.3708 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.8973\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 68us/step - loss: 0.2936 - binary_accuracy: 0.8891 - sensitivity: 0.9460 - specificity: 0.7120 - gmeasure: 0.8185 - auc: 0.9507 - val_loss: 0.3693 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9554 - val_specificity: 0.5625 - val_gmeasure: 0.7331 - val_auc: 0.8981\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2952 - binary_accuracy: 0.8922 - sensitivity: 0.9259 - specificity: 0.7647 - gmeasure: 0.8409 - auc: 0.9299 - val_loss: 0.3720 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.8979\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 78us/step - loss: 0.2900 - binary_accuracy: 0.8859 - sensitivity: 0.9616 - specificity: 0.7578 - gmeasure: 0.8533 - auc: 0.9541 - val_loss: 0.3701 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.8984\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2893 - binary_accuracy: 0.8859 - sensitivity: 0.9376 - specificity: 0.7684 - gmeasure: 0.8487 - auc: 0.9552 - val_loss: 0.3675 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9464 - val_specificity: 0.5833 - val_gmeasure: 0.7430 - val_auc: 0.8992\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2909 - binary_accuracy: 0.8813 - sensitivity: 0.9445 - specificity: 0.6772 - gmeasure: 0.7958 - auc: 0.9382 - val_loss: 0.3679 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9554 - val_specificity: 0.5625 - val_gmeasure: 0.7331 - val_auc: 0.8992\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2914 - binary_accuracy: 0.8750 - sensitivity: 0.9091 - specificity: 0.7915 - gmeasure: 0.8472 - auc: 0.9509 - val_loss: 0.3611 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8304 - val_specificity: 0.7292 - val_gmeasure: 0.7781 - val_auc: 0.9020\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2887 - binary_accuracy: 0.8859 - sensitivity: 0.9394 - specificity: 0.7974 - gmeasure: 0.8643 - auc: 0.9529 - val_loss: 0.3811 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9732 - val_specificity: 0.5208 - val_gmeasure: 0.7120 - val_auc: 0.8997\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2882 - binary_accuracy: 0.8750 - sensitivity: 0.9666 - specificity: 0.7026 - gmeasure: 0.8238 - auc: 0.9520 - val_loss: 0.3686 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9643 - val_specificity: 0.5208 - val_gmeasure: 0.7087 - val_auc: 0.9012\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2812 - binary_accuracy: 0.8859 - sensitivity: 0.9152 - specificity: 0.8007 - gmeasure: 0.8531 - auc: 0.9516 - val_loss: 0.3566 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9375 - val_specificity: 0.6667 - val_gmeasure: 0.7906 - val_auc: 0.9038\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2790 - binary_accuracy: 0.8922 - sensitivity: 0.9414 - specificity: 0.7715 - gmeasure: 0.8520 - auc: 0.9510 - val_loss: 0.3809 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9732 - val_specificity: 0.5000 - val_gmeasure: 0.6976 - val_auc: 0.9003\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.2842 - binary_accuracy: 0.8781 - sensitivity: 0.9724 - specificity: 0.6639 - gmeasure: 0.8021 - auc: 0.9570 - val_loss: 0.3626 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9554 - val_specificity: 0.5833 - val_gmeasure: 0.7465 - val_auc: 0.9027\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2914 - binary_accuracy: 0.8781 - sensitivity: 0.8887 - specificity: 0.8227 - gmeasure: 0.8523 - auc: 0.9509 - val_loss: 0.3525 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8750 - val_specificity: 0.7083 - val_gmeasure: 0.7873 - val_auc: 0.9068\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2779 - binary_accuracy: 0.8938 - sensitivity: 0.9418 - specificity: 0.7805 - gmeasure: 0.8572 - auc: 0.9530 - val_loss: 0.4066 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9821 - val_specificity: 0.3750 - val_gmeasure: 0.6069 - val_auc: 0.9003\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2987 - binary_accuracy: 0.8656 - sensitivity: 0.9533 - specificity: 0.5939 - gmeasure: 0.7515 - auc: 0.9410 - val_loss: 0.3756 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9643 - val_specificity: 0.5208 - val_gmeasure: 0.7087 - val_auc: 0.9022\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2777 - binary_accuracy: 0.8906 - sensitivity: 0.9339 - specificity: 0.8045 - gmeasure: 0.8655 - auc: 0.9617 - val_loss: 0.3539 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8482 - val_specificity: 0.7917 - val_gmeasure: 0.8195 - val_auc: 0.9070\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.2827 - binary_accuracy: 0.8828 - sensitivity: 0.9122 - specificity: 0.8787 - gmeasure: 0.8950 - auc: 0.9635 - val_loss: 0.3630 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9038\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2729 - binary_accuracy: 0.8859 - sensitivity: 0.9597 - specificity: 0.7502 - gmeasure: 0.8480 - auc: 0.9611 - val_loss: 0.3914 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.9643 - val_specificity: 0.4583 - val_gmeasure: 0.6648 - val_auc: 0.9022\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2776 - binary_accuracy: 0.8781 - sensitivity: 0.9617 - specificity: 0.7093 - gmeasure: 0.8256 - auc: 0.9540 - val_loss: 0.3545 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.9042\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2777 - binary_accuracy: 0.8906 - sensitivity: 0.9205 - specificity: 0.8451 - gmeasure: 0.8813 - auc: 0.9623 - val_loss: 0.3514 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8661 - val_specificity: 0.7083 - val_gmeasure: 0.7832 - val_auc: 0.9057\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2742 - binary_accuracy: 0.8906 - sensitivity: 0.9514 - specificity: 0.7242 - gmeasure: 0.8217 - auc: 0.9492 - val_loss: 0.3734 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9643 - val_specificity: 0.5417 - val_gmeasure: 0.7227 - val_auc: 0.9016\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2679 - binary_accuracy: 0.8922 - sensitivity: 0.9460 - specificity: 0.7539 - gmeasure: 0.8438 - auc: 0.9445 - val_loss: 0.3535 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9375 - val_specificity: 0.6458 - val_gmeasure: 0.7781 - val_auc: 0.9051\n",
      "Epoch 25/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2671 - binary_accuracy: 0.8969 - sensitivity: 0.9356 - specificity: 0.8154 - gmeasure: 0.8732 - auc: 0.9549 - val_loss: 0.3558 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9643 - val_specificity: 0.5833 - val_gmeasure: 0.7500 - val_auc: 0.9055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2656 - binary_accuracy: 0.8891 - sensitivity: 0.9581 - specificity: 0.7541 - gmeasure: 0.8496 - auc: 0.9579 - val_loss: 0.3627 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9051\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2631 - binary_accuracy: 0.8922 - sensitivity: 0.9403 - specificity: 0.7636 - gmeasure: 0.8465 - auc: 0.9545 - val_loss: 0.3462 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9107 - val_specificity: 0.6875 - val_gmeasure: 0.7913 - val_auc: 0.9100\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2675 - binary_accuracy: 0.8969 - sensitivity: 0.9145 - specificity: 0.8439 - gmeasure: 0.8776 - auc: 0.9574 - val_loss: 0.3468 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.9107\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.2669 - binary_accuracy: 0.8859 - sensitivity: 0.9443 - specificity: 0.7146 - gmeasure: 0.8193 - auc: 0.9452 - val_loss: 0.3714 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9643 - val_specificity: 0.5417 - val_gmeasure: 0.7227 - val_auc: 0.9098\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 66us/step - loss: 0.2617 - binary_accuracy: 0.8906 - sensitivity: 0.9692 - specificity: 0.7134 - gmeasure: 0.8304 - auc: 0.9596 - val_loss: 0.3400 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9286 - val_specificity: 0.7083 - val_gmeasure: 0.8110 - val_auc: 0.9133\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.2661 - binary_accuracy: 0.8938 - sensitivity: 0.9239 - specificity: 0.8296 - gmeasure: 0.8754 - auc: 0.9543 - val_loss: 0.3383 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9144\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2651 - binary_accuracy: 0.8906 - sensitivity: 0.9520 - specificity: 0.7515 - gmeasure: 0.8441 - auc: 0.9600 - val_loss: 0.3630 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9732 - val_specificity: 0.5208 - val_gmeasure: 0.7120 - val_auc: 0.9141\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 68us/step - loss: 0.2624 - binary_accuracy: 0.8859 - sensitivity: 0.9589 - specificity: 0.7593 - gmeasure: 0.8524 - auc: 0.9639 - val_loss: 0.3403 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9643 - val_specificity: 0.6250 - val_gmeasure: 0.7763 - val_auc: 0.9152\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2564 - binary_accuracy: 0.8953 - sensitivity: 0.9541 - specificity: 0.7712 - gmeasure: 0.8564 - auc: 0.9694 - val_loss: 0.3427 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9643 - val_specificity: 0.6042 - val_gmeasure: 0.7633 - val_auc: 0.9154\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2570 - binary_accuracy: 0.8969 - sensitivity: 0.9415 - specificity: 0.7806 - gmeasure: 0.8563 - auc: 0.9576 - val_loss: 0.3424 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9643 - val_specificity: 0.6458 - val_gmeasure: 0.7892 - val_auc: 0.9156\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2564 - binary_accuracy: 0.8984 - sensitivity: 0.9641 - specificity: 0.7971 - gmeasure: 0.8761 - auc: 0.9686 - val_loss: 0.3485 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9144\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2558 - binary_accuracy: 0.8969 - sensitivity: 0.9431 - specificity: 0.8032 - gmeasure: 0.8694 - auc: 0.9639 - val_loss: 0.3372 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9375 - val_specificity: 0.6875 - val_gmeasure: 0.8028 - val_auc: 0.9163\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2533 - binary_accuracy: 0.9000 - sensitivity: 0.9384 - specificity: 0.8331 - gmeasure: 0.8838 - auc: 0.9658 - val_loss: 0.3492 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9141\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2556 - binary_accuracy: 0.8891 - sensitivity: 0.9675 - specificity: 0.7370 - gmeasure: 0.8441 - auc: 0.9653 - val_loss: 0.3509 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9131\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2546 - binary_accuracy: 0.9016 - sensitivity: 0.9345 - specificity: 0.8312 - gmeasure: 0.8808 - auc: 0.9632 - val_loss: 0.3368 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.8661 - val_specificity: 0.7708 - val_gmeasure: 0.8171 - val_auc: 0.9178\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2584 - binary_accuracy: 0.8969 - sensitivity: 0.9309 - specificity: 0.8524 - gmeasure: 0.8902 - auc: 0.9674 - val_loss: 0.3396 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9643 - val_specificity: 0.6458 - val_gmeasure: 0.7892 - val_auc: 0.9159\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2483 - binary_accuracy: 0.9000 - sensitivity: 0.9532 - specificity: 0.8386 - gmeasure: 0.8929 - auc: 0.9692 - val_loss: 0.3532 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9167\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2539 - binary_accuracy: 0.8891 - sensitivity: 0.9529 - specificity: 0.7511 - gmeasure: 0.8459 - auc: 0.9658 - val_loss: 0.3543 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9643 - val_specificity: 0.5625 - val_gmeasure: 0.7365 - val_auc: 0.9176\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.2496 - binary_accuracy: 0.8938 - sensitivity: 0.9573 - specificity: 0.7892 - gmeasure: 0.8683 - auc: 0.9680 - val_loss: 0.3371 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9643 - val_specificity: 0.6458 - val_gmeasure: 0.7892 - val_auc: 0.9182\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2455 - binary_accuracy: 0.9000 - sensitivity: 0.9394 - specificity: 0.8291 - gmeasure: 0.8812 - auc: 0.9650 - val_loss: 0.3331 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9187\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2463 - binary_accuracy: 0.9016 - sensitivity: 0.9269 - specificity: 0.8154 - gmeasure: 0.8692 - auc: 0.9640 - val_loss: 0.3350 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9180\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2445 - binary_accuracy: 0.9000 - sensitivity: 0.9524 - specificity: 0.8197 - gmeasure: 0.8836 - auc: 0.9690 - val_loss: 0.3411 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9643 - val_specificity: 0.6458 - val_gmeasure: 0.7892 - val_auc: 0.9180\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2456 - binary_accuracy: 0.9000 - sensitivity: 0.9617 - specificity: 0.7855 - gmeasure: 0.8686 - auc: 0.9624 - val_loss: 0.3421 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9643 - val_specificity: 0.6250 - val_gmeasure: 0.7763 - val_auc: 0.9182\n",
      "Epoch 49/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2419 - binary_accuracy: 0.8984 - sensitivity: 0.9470 - specificity: 0.7747 - gmeasure: 0.8556 - auc: 0.9676 - val_loss: 0.3273 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9018 - val_specificity: 0.7708 - val_gmeasure: 0.8337 - val_auc: 0.9196\n",
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.2498 - binary_accuracy: 0.9125 - sensitivity: 0.9299 - specificity: 0.8871 - gmeasure: 0.9081 - auc: 0.9663 - val_loss: 0.3246 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9196 - val_specificity: 0.7292 - val_gmeasure: 0.8189 - val_auc: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2412 - binary_accuracy: 0.9062 - sensitivity: 0.9472 - specificity: 0.7792 - gmeasure: 0.8583 - auc: 0.9613 - val_loss: 0.3415 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9643 - val_specificity: 0.5833 - val_gmeasure: 0.7500 - val_auc: 0.9196\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.2444 - binary_accuracy: 0.8891 - sensitivity: 0.9654 - specificity: 0.7593 - gmeasure: 0.8556 - auc: 0.9626 - val_loss: 0.3274 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.9219\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 66us/step - loss: 0.2389 - binary_accuracy: 0.9000 - sensitivity: 0.9393 - specificity: 0.8466 - gmeasure: 0.8897 - auc: 0.9670 - val_loss: 0.3176 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9375 - val_specificity: 0.7083 - val_gmeasure: 0.8149 - val_auc: 0.9241\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2395 - binary_accuracy: 0.9031 - sensitivity: 0.9488 - specificity: 0.7917 - gmeasure: 0.8652 - auc: 0.9666 - val_loss: 0.3258 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9232\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2374 - binary_accuracy: 0.9016 - sensitivity: 0.9449 - specificity: 0.8232 - gmeasure: 0.8812 - auc: 0.9630 - val_loss: 0.3214 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9232\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2359 - binary_accuracy: 0.9031 - sensitivity: 0.9496 - specificity: 0.7991 - gmeasure: 0.8709 - auc: 0.9713 - val_loss: 0.3223 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9234\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2350 - binary_accuracy: 0.9031 - sensitivity: 0.9503 - specificity: 0.8148 - gmeasure: 0.8796 - auc: 0.9692 - val_loss: 0.3249 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9237\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2343 - binary_accuracy: 0.9031 - sensitivity: 0.9508 - specificity: 0.8112 - gmeasure: 0.8778 - auc: 0.9672 - val_loss: 0.3199 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9249\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2364 - binary_accuracy: 0.9078 - sensitivity: 0.9396 - specificity: 0.8704 - gmeasure: 0.9030 - auc: 0.9729 - val_loss: 0.3238 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9256\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.2453 - binary_accuracy: 0.8891 - sensitivity: 0.9624 - specificity: 0.6865 - gmeasure: 0.8095 - auc: 0.9544 - val_loss: 0.3377 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9732 - val_specificity: 0.5625 - val_gmeasure: 0.7399 - val_auc: 0.9265\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2333 - binary_accuracy: 0.8938 - sensitivity: 0.9596 - specificity: 0.7855 - gmeasure: 0.8682 - auc: 0.9737 - val_loss: 0.3088 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9107 - val_specificity: 0.7708 - val_gmeasure: 0.8379 - val_auc: 0.9278\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2378 - binary_accuracy: 0.9219 - sensitivity: 0.9489 - specificity: 0.8891 - gmeasure: 0.9183 - auc: 0.9746 - val_loss: 0.3112 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9280\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2303 - binary_accuracy: 0.9000 - sensitivity: 0.9559 - specificity: 0.7500 - gmeasure: 0.8454 - auc: 0.9719 - val_loss: 0.3193 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.9276\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2306 - binary_accuracy: 0.9078 - sensitivity: 0.9603 - specificity: 0.7843 - gmeasure: 0.8671 - auc: 0.9707 - val_loss: 0.3063 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9297\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2287 - binary_accuracy: 0.9094 - sensitivity: 0.9604 - specificity: 0.8140 - gmeasure: 0.8836 - auc: 0.9714 - val_loss: 0.3095 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9291\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2280 - binary_accuracy: 0.9109 - sensitivity: 0.9567 - specificity: 0.8558 - gmeasure: 0.9045 - auc: 0.9763 - val_loss: 0.3095 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9295\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2249 - binary_accuracy: 0.9109 - sensitivity: 0.9467 - specificity: 0.8613 - gmeasure: 0.9015 - auc: 0.9732 - val_loss: 0.3257 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9643 - val_specificity: 0.5833 - val_gmeasure: 0.7500 - val_auc: 0.9289\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2294 - binary_accuracy: 0.8922 - sensitivity: 0.9623 - specificity: 0.7560 - gmeasure: 0.8528 - auc: 0.9746 - val_loss: 0.3340 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9732 - val_specificity: 0.5833 - val_gmeasure: 0.7535 - val_auc: 0.9280\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2292 - binary_accuracy: 0.8938 - sensitivity: 0.9534 - specificity: 0.7829 - gmeasure: 0.8630 - auc: 0.9755 - val_loss: 0.3133 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9289\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2224 - binary_accuracy: 0.9094 - sensitivity: 0.9474 - specificity: 0.8541 - gmeasure: 0.8982 - auc: 0.9742 - val_loss: 0.3166 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9288\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2220 - binary_accuracy: 0.9094 - sensitivity: 0.9542 - specificity: 0.8389 - gmeasure: 0.8938 - auc: 0.9728 - val_loss: 0.3183 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9284\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2224 - binary_accuracy: 0.9062 - sensitivity: 0.9525 - specificity: 0.7592 - gmeasure: 0.8491 - auc: 0.9666 - val_loss: 0.3139 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9291\n",
      "Epoch 73/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2259 - binary_accuracy: 0.9172 - sensitivity: 0.9318 - specificity: 0.8846 - gmeasure: 0.9057 - auc: 0.9695 - val_loss: 0.3055 - val_binary_accuracy: 0.8813 - val_sensitivity: 0.9375 - val_specificity: 0.7500 - val_gmeasure: 0.8385 - val_auc: 0.9297\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2196 - binary_accuracy: 0.9141 - sensitivity: 0.9547 - specificity: 0.8465 - gmeasure: 0.8987 - auc: 0.9718 - val_loss: 0.3273 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9643 - val_specificity: 0.5833 - val_gmeasure: 0.7500 - val_auc: 0.9284\n",
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2243 - binary_accuracy: 0.8984 - sensitivity: 0.9615 - specificity: 0.7533 - gmeasure: 0.8503 - auc: 0.9659 - val_loss: 0.3125 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 79us/step - loss: 0.2181 - binary_accuracy: 0.9141 - sensitivity: 0.9572 - specificity: 0.8430 - gmeasure: 0.8979 - auc: 0.9753 - val_loss: 0.3103 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9302\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.2155 - binary_accuracy: 0.9125 - sensitivity: 0.9394 - specificity: 0.8305 - gmeasure: 0.8829 - auc: 0.9690 - val_loss: 0.3250 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9643 - val_specificity: 0.6458 - val_gmeasure: 0.7892 - val_auc: 0.9288\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2198 - binary_accuracy: 0.9016 - sensitivity: 0.9619 - specificity: 0.7662 - gmeasure: 0.8579 - auc: 0.9743 - val_loss: 0.3116 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9301\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2164 - binary_accuracy: 0.9219 - sensitivity: 0.9495 - specificity: 0.8819 - gmeasure: 0.9145 - auc: 0.9765 - val_loss: 0.3028 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9196 - val_specificity: 0.7708 - val_gmeasure: 0.8420 - val_auc: 0.9323\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2192 - binary_accuracy: 0.9297 - sensitivity: 0.9464 - specificity: 0.8957 - gmeasure: 0.9204 - auc: 0.9753 - val_loss: 0.3088 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9317\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 63us/step - loss: 0.2153 - binary_accuracy: 0.9078 - sensitivity: 0.9657 - specificity: 0.7984 - gmeasure: 0.8769 - auc: 0.9739 - val_loss: 0.3057 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9321\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2145 - binary_accuracy: 0.9266 - sensitivity: 0.9460 - specificity: 0.8985 - gmeasure: 0.9218 - auc: 0.9741 - val_loss: 0.3030 - val_binary_accuracy: 0.8875 - val_sensitivity: 0.9196 - val_specificity: 0.8125 - val_gmeasure: 0.8644 - val_auc: 0.9327\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2176 - binary_accuracy: 0.9203 - sensitivity: 0.9516 - specificity: 0.8837 - gmeasure: 0.9163 - auc: 0.9797 - val_loss: 0.3118 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9315\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2109 - binary_accuracy: 0.9109 - sensitivity: 0.9630 - specificity: 0.8219 - gmeasure: 0.8896 - auc: 0.9773 - val_loss: 0.3036 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9286 - val_specificity: 0.7500 - val_gmeasure: 0.8345 - val_auc: 0.9321\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2113 - binary_accuracy: 0.9312 - sensitivity: 0.9584 - specificity: 0.8685 - gmeasure: 0.9103 - auc: 0.9750 - val_loss: 0.3018 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9196 - val_specificity: 0.7500 - val_gmeasure: 0.8305 - val_auc: 0.9323\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.2122 - binary_accuracy: 0.9312 - sensitivity: 0.9402 - specificity: 0.8820 - gmeasure: 0.9104 - auc: 0.9730 - val_loss: 0.3054 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9317\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2083 - binary_accuracy: 0.9156 - sensitivity: 0.9611 - specificity: 0.8723 - gmeasure: 0.9152 - auc: 0.9781 - val_loss: 0.3163 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9306\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2096 - binary_accuracy: 0.9109 - sensitivity: 0.9602 - specificity: 0.7734 - gmeasure: 0.8600 - auc: 0.9755 - val_loss: 0.3074 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9464 - val_specificity: 0.7083 - val_gmeasure: 0.8188 - val_auc: 0.9319\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 78us/step - loss: 0.2074 - binary_accuracy: 0.9219 - sensitivity: 0.9357 - specificity: 0.8623 - gmeasure: 0.8981 - auc: 0.9594 - val_loss: 0.2983 - val_binary_accuracy: 0.8875 - val_sensitivity: 0.9464 - val_specificity: 0.7500 - val_gmeasure: 0.8425 - val_auc: 0.9340\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.2078 - binary_accuracy: 0.9266 - sensitivity: 0.9600 - specificity: 0.8765 - gmeasure: 0.9169 - auc: 0.9758 - val_loss: 0.3005 - val_binary_accuracy: 0.8813 - val_sensitivity: 0.9554 - val_specificity: 0.7083 - val_gmeasure: 0.8226 - val_auc: 0.9347\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2063 - binary_accuracy: 0.9234 - sensitivity: 0.9331 - specificity: 0.8734 - gmeasure: 0.9018 - auc: 0.9714 - val_loss: 0.2978 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9353\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2055 - binary_accuracy: 0.9141 - sensitivity: 0.9587 - specificity: 0.8049 - gmeasure: 0.8783 - auc: 0.9750 - val_loss: 0.3007 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9356\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.2034 - binary_accuracy: 0.9234 - sensitivity: 0.9554 - specificity: 0.8467 - gmeasure: 0.8992 - auc: 0.9767 - val_loss: 0.2941 - val_binary_accuracy: 0.8875 - val_sensitivity: 0.9196 - val_specificity: 0.8125 - val_gmeasure: 0.8644 - val_auc: 0.9358\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2117 - binary_accuracy: 0.9359 - sensitivity: 0.9429 - specificity: 0.9303 - gmeasure: 0.9364 - auc: 0.9747 - val_loss: 0.2958 - val_binary_accuracy: 0.8813 - val_sensitivity: 0.9554 - val_specificity: 0.7083 - val_gmeasure: 0.8226 - val_auc: 0.9368\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.2037 - binary_accuracy: 0.9141 - sensitivity: 0.9604 - specificity: 0.8304 - gmeasure: 0.8929 - auc: 0.9703 - val_loss: 0.3169 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9643 - val_specificity: 0.6250 - val_gmeasure: 0.7763 - val_auc: 0.9364\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 79us/step - loss: 0.2076 - binary_accuracy: 0.9078 - sensitivity: 0.9456 - specificity: 0.8380 - gmeasure: 0.8872 - auc: 0.9753 - val_loss: 0.2936 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9381\n",
      "Epoch 97/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.2007 - binary_accuracy: 0.9281 - sensitivity: 0.9510 - specificity: 0.8789 - gmeasure: 0.9137 - auc: 0.9761 - val_loss: 0.3065 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9356\n",
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 80us/step - loss: 0.2040 - binary_accuracy: 0.9094 - sensitivity: 0.9634 - specificity: 0.7893 - gmeasure: 0.8719 - auc: 0.9759 - val_loss: 0.3161 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9643 - val_specificity: 0.6667 - val_gmeasure: 0.8018 - val_auc: 0.9336\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.2035 - binary_accuracy: 0.9203 - sensitivity: 0.9451 - specificity: 0.8635 - gmeasure: 0.9028 - auc: 0.9689 - val_loss: 0.3099 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9286 - val_specificity: 0.7500 - val_gmeasure: 0.8345 - val_auc: 0.9314\n",
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.2017 - binary_accuracy: 0.9219 - sensitivity: 0.9447 - specificity: 0.8538 - gmeasure: 0.8980 - auc: 0.9753 - val_loss: 0.3235 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9643 - val_specificity: 0.6667 - val_gmeasure: 0.8018 - val_auc: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 6.693759918212891!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.009623050689697266!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.22576484084129333, 0.90625, 0.9635701179504395, 0.7808765172958374, 0.8674268126487732, 0.9678009152412415]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 24us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012128114700317383!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.284936785697937, 0.8905472755432129, 0.935251772403717, 0.7903226017951965, 0.8597387075424194, 0.9432002902030945]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.164530992507935\n",
      "[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 2 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 1s 803us/step - loss: 0.5933 - binary_accuracy: 0.7016 - sensitivity: 0.9964 - specificity: 0.0087 - gmeasure: 0.0658 - auc: 0.6093 - val_loss: 0.5767 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4781\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5920 - binary_accuracy: 0.7000 - sensitivity: 0.9930 - specificity: 0.0228 - gmeasure: 0.1249 - auc: 0.6177 - val_loss: 0.5953 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4804\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5981 - binary_accuracy: 0.7063 - sensitivity: 0.9894 - specificity: 0.0504 - gmeasure: 0.2206 - auc: 0.6014 - val_loss: 0.5985 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4804\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5960 - binary_accuracy: 0.7016 - sensitivity: 0.9930 - specificity: 0.0167 - gmeasure: 0.1103 - auc: 0.6452 - val_loss: 0.5840 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4785\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5904 - binary_accuracy: 0.7000 - sensitivity: 0.9931 - specificity: 0.0126 - gmeasure: 0.0965 - auc: 0.6298 - val_loss: 0.5772 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4767\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5910 - binary_accuracy: 0.7016 - sensitivity: 0.9964 - specificity: 0.0089 - gmeasure: 0.0471 - auc: 0.6399 - val_loss: 0.5755 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4756\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5923 - binary_accuracy: 0.7000 - sensitivity: 0.9964 - specificity: 0.0043 - gmeasure: 0.0328 - auc: 0.6281 - val_loss: 0.5773 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4762\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5891 - binary_accuracy: 0.7000 - sensitivity: 0.9923 - specificity: 0.0112 - gmeasure: 0.0741 - auc: 0.6422 - val_loss: 0.5856 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4775\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5924 - binary_accuracy: 0.7016 - sensitivity: 0.9929 - specificity: 0.0173 - gmeasure: 0.1106 - auc: 0.6427 - val_loss: 0.5885 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4775\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5900 - binary_accuracy: 0.7000 - sensitivity: 0.9925 - specificity: 0.0107 - gmeasure: 0.0512 - auc: 0.6248 - val_loss: 0.5795 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 59us/step - loss: 0.5901 - binary_accuracy: 0.7000 - sensitivity: 0.9946 - specificity: 0.0089 - gmeasure: 0.0472 - auc: 0.6605 - val_loss: 0.5759 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 58us/step - loss: 0.5933 - binary_accuracy: 0.7000 - sensitivity: 0.9965 - specificity: 0.0038 - gmeasure: 0.0310 - auc: 0.6218 - val_loss: 0.5762 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4742\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5910 - binary_accuracy: 0.7016 - sensitivity: 0.9963 - specificity: 0.0083 - gmeasure: 0.0641 - auc: 0.6366 - val_loss: 0.5796 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4744\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5894 - binary_accuracy: 0.6984 - sensitivity: 0.9927 - specificity: 0.0398 - gmeasure: 0.1265 - auc: 0.6661 - val_loss: 0.5847 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4767\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 80us/step - loss: 0.5894 - binary_accuracy: 0.7000 - sensitivity: 0.9930 - specificity: 0.0129 - gmeasure: 0.0792 - auc: 0.6343 - val_loss: 0.5808 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4760\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.5883 - binary_accuracy: 0.7000 - sensitivity: 0.9928 - specificity: 0.0132 - gmeasure: 0.0798 - auc: 0.6624 - val_loss: 0.5843 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4769\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 60us/step - loss: 0.5884 - binary_accuracy: 0.7016 - sensitivity: 0.9927 - specificity: 0.0175 - gmeasure: 0.0884 - auc: 0.6340 - val_loss: 0.5860 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4771\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5885 - binary_accuracy: 0.7031 - sensitivity: 0.9843 - specificity: 0.0314 - gmeasure: 0.1464 - auc: 0.6298 - val_loss: 0.5861 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4773\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5881 - binary_accuracy: 0.7047 - sensitivity: 0.9928 - specificity: 0.0260 - gmeasure: 0.1344 - auc: 0.6364 - val_loss: 0.5845 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4762\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5872 - binary_accuracy: 0.7016 - sensitivity: 0.9928 - specificity: 0.0165 - gmeasure: 0.1088 - auc: 0.6059 - val_loss: 0.5799 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5896 - binary_accuracy: 0.7016 - sensitivity: 0.9966 - specificity: 0.0089 - gmeasure: 0.0472 - auc: 0.6491 - val_loss: 0.5788 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4733\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5872 - binary_accuracy: 0.6984 - sensitivity: 0.9840 - specificity: 0.0093 - gmeasure: 0.0680 - auc: 0.6157 - val_loss: 0.5881 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5880 - binary_accuracy: 0.7109 - sensitivity: 0.9929 - specificity: 0.0589 - gmeasure: 0.2385 - auc: 0.6341 - val_loss: 0.5971 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4758\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 81us/step - loss: 0.5901 - binary_accuracy: 0.7094 - sensitivity: 0.9895 - specificity: 0.0609 - gmeasure: 0.2125 - auc: 0.6469 - val_loss: 0.5877 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4750\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 68us/step - loss: 0.5875 - binary_accuracy: 0.7047 - sensitivity: 0.9927 - specificity: 0.0247 - gmeasure: 0.1333 - auc: 0.6818 - val_loss: 0.5813 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4744\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5866 - binary_accuracy: 0.7000 - sensitivity: 0.9946 - specificity: 0.0083 - gmeasure: 0.0453 - auc: 0.6368 - val_loss: 0.5820 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4758\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5869 - binary_accuracy: 0.7000 - sensitivity: 0.9948 - specificity: 0.0291 - gmeasure: 0.1110 - auc: 0.6309 - val_loss: 0.5806 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4746\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5871 - binary_accuracy: 0.7016 - sensitivity: 0.9943 - specificity: 0.0139 - gmeasure: 0.0589 - auc: 0.6547 - val_loss: 0.5821 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4765\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5864 - binary_accuracy: 0.7016 - sensitivity: 0.9949 - specificity: 0.0135 - gmeasure: 0.0798 - auc: 0.6195 - val_loss: 0.5829 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4773\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5855 - binary_accuracy: 0.7078 - sensitivity: 0.9851 - specificity: 0.0329 - gmeasure: 0.1433 - auc: 0.5980 - val_loss: 0.5926 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4765\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5872 - binary_accuracy: 0.7078 - sensitivity: 0.9876 - specificity: 0.0635 - gmeasure: 0.2470 - auc: 0.6230 - val_loss: 0.5927 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4773\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5856 - binary_accuracy: 0.7094 - sensitivity: 0.9910 - specificity: 0.0683 - gmeasure: 0.2466 - auc: 0.6191 - val_loss: 0.5826 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4756\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5871 - binary_accuracy: 0.7031 - sensitivity: 0.9948 - specificity: 0.0172 - gmeasure: 0.0924 - auc: 0.6326 - val_loss: 0.5788 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4756\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5846 - binary_accuracy: 0.7016 - sensitivity: 0.9873 - specificity: 0.0129 - gmeasure: 0.0979 - auc: 0.6405 - val_loss: 0.5852 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4748\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5851 - binary_accuracy: 0.7109 - sensitivity: 0.9803 - specificity: 0.0406 - gmeasure: 0.1720 - auc: 0.6412 - val_loss: 0.5939 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5853 - binary_accuracy: 0.7078 - sensitivity: 0.9874 - specificity: 0.0447 - gmeasure: 0.1805 - auc: 0.6325 - val_loss: 0.5826 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5870 - binary_accuracy: 0.7078 - sensitivity: 0.9962 - specificity: 0.0271 - gmeasure: 0.1320 - auc: 0.6498 - val_loss: 0.5779 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4773\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5873 - binary_accuracy: 0.7000 - sensitivity: 0.9964 - specificity: 0.0045 - gmeasure: 0.0337 - auc: 0.6289 - val_loss: 0.5796 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5837 - binary_accuracy: 0.7063 - sensitivity: 0.9949 - specificity: 0.0486 - gmeasure: 0.1809 - auc: 0.6565 - val_loss: 0.5876 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4771\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5850 - binary_accuracy: 0.7094 - sensitivity: 0.9911 - specificity: 0.0804 - gmeasure: 0.2606 - auc: 0.6392 - val_loss: 0.5954 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4765\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 64us/step - loss: 0.5865 - binary_accuracy: 0.7078 - sensitivity: 0.9801 - specificity: 0.0495 - gmeasure: 0.1561 - auc: 0.6444 - val_loss: 0.5889 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4773\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.5832 - binary_accuracy: 0.7094 - sensitivity: 0.9910 - specificity: 0.0607 - gmeasure: 0.2412 - auc: 0.6297 - val_loss: 0.5819 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4779\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5836 - binary_accuracy: 0.7063 - sensitivity: 0.9948 - specificity: 0.0378 - gmeasure: 0.1616 - auc: 0.6622 - val_loss: 0.5798 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4796\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5833 - binary_accuracy: 0.7094 - sensitivity: 0.9947 - specificity: 0.0328 - gmeasure: 0.1554 - auc: 0.6087 - val_loss: 0.5878 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4798\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5828 - binary_accuracy: 0.7094 - sensitivity: 0.9894 - specificity: 0.0596 - gmeasure: 0.2407 - auc: 0.6503 - val_loss: 0.5896 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4821\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5832 - binary_accuracy: 0.7094 - sensitivity: 0.9814 - specificity: 0.0589 - gmeasure: 0.2393 - auc: 0.6524 - val_loss: 0.5873 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4825\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5819 - binary_accuracy: 0.7078 - sensitivity: 0.9829 - specificity: 0.0410 - gmeasure: 0.1725 - auc: 0.6320 - val_loss: 0.5833 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4837\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5813 - binary_accuracy: 0.7109 - sensitivity: 0.9928 - specificity: 0.0417 - gmeasure: 0.1733 - auc: 0.6361 - val_loss: 0.5790 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4844\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 74us/step - loss: 0.5832 - binary_accuracy: 0.7063 - sensitivity: 0.9944 - specificity: 0.0254 - gmeasure: 0.1339 - auc: 0.6452 - val_loss: 0.5798 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4840\n",
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5820 - binary_accuracy: 0.7109 - sensitivity: 0.9947 - specificity: 0.0565 - gmeasure: 0.2329 - auc: 0.6449 - val_loss: 0.5830 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4842\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5808 - binary_accuracy: 0.7109 - sensitivity: 0.9929 - specificity: 0.0599 - gmeasure: 0.2404 - auc: 0.6499 - val_loss: 0.5843 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4846\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 68us/step - loss: 0.5806 - binary_accuracy: 0.7094 - sensitivity: 0.9836 - specificity: 0.0569 - gmeasure: 0.2340 - auc: 0.6557 - val_loss: 0.5826 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4863\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5805 - binary_accuracy: 0.7109 - sensitivity: 0.9928 - specificity: 0.1328 - gmeasure: 0.3082 - auc: 0.7116 - val_loss: 0.5817 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4860\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5795 - binary_accuracy: 0.7109 - sensitivity: 0.9945 - specificity: 0.0510 - gmeasure: 0.2231 - auc: 0.6761 - val_loss: 0.5791 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4867\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5812 - binary_accuracy: 0.7109 - sensitivity: 0.9947 - specificity: 0.0345 - gmeasure: 0.1198 - auc: 0.6613 - val_loss: 0.5825 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4869\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5805 - binary_accuracy: 0.7109 - sensitivity: 0.9847 - specificity: 0.0953 - gmeasure: 0.2780 - auc: 0.6570 - val_loss: 0.5870 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4875\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5785 - binary_accuracy: 0.7141 - sensitivity: 0.9908 - specificity: 0.0548 - gmeasure: 0.1992 - auc: 0.6774 - val_loss: 0.5807 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4875\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5803 - binary_accuracy: 0.7094 - sensitivity: 0.9946 - specificity: 0.0645 - gmeasure: 0.2139 - auc: 0.6590 - val_loss: 0.5789 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4885\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5841 - binary_accuracy: 0.7078 - sensitivity: 0.9963 - specificity: 0.0473 - gmeasure: 0.1827 - auc: 0.6680 - val_loss: 0.5793 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4871\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5798 - binary_accuracy: 0.7109 - sensitivity: 0.9964 - specificity: 0.0474 - gmeasure: 0.2148 - auc: 0.6394 - val_loss: 0.5849 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4873\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5781 - binary_accuracy: 0.7172 - sensitivity: 0.9816 - specificity: 0.1083 - gmeasure: 0.3106 - auc: 0.6792 - val_loss: 0.5967 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.4879\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5816 - binary_accuracy: 0.7156 - sensitivity: 0.9683 - specificity: 0.1183 - gmeasure: 0.3335 - auc: 0.6357 - val_loss: 0.5901 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4871\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5770 - binary_accuracy: 0.7156 - sensitivity: 0.9822 - specificity: 0.0804 - gmeasure: 0.2794 - auc: 0.6518 - val_loss: 0.5805 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4877\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5810 - binary_accuracy: 0.7109 - sensitivity: 0.9947 - specificity: 0.0368 - gmeasure: 0.1621 - auc: 0.6579 - val_loss: 0.5808 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5784 - binary_accuracy: 0.7141 - sensitivity: 0.9946 - specificity: 0.0603 - gmeasure: 0.2441 - auc: 0.6737 - val_loss: 0.5878 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4854\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 61us/step - loss: 0.5784 - binary_accuracy: 0.7141 - sensitivity: 0.9600 - specificity: 0.1344 - gmeasure: 0.3440 - auc: 0.6460 - val_loss: 0.5940 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.4856\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - ETA: 0s - loss: 0.6016 - binary_accuracy: 0.6850 - sensitivity: 0.9697 - specificity: 0.1324 - gmeasure: 0.3582 - auc: 0.66 - 0s 74us/step - loss: 0.5778 - binary_accuracy: 0.7156 - sensitivity: 0.9856 - specificity: 0.0908 - gmeasure: 0.2935 - auc: 0.6563 - val_loss: 0.5862 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4871\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5762 - binary_accuracy: 0.7141 - sensitivity: 0.9893 - specificity: 0.0590 - gmeasure: 0.2079 - auc: 0.6683 - val_loss: 0.5871 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4896\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5760 - binary_accuracy: 0.7125 - sensitivity: 0.9806 - specificity: 0.0772 - gmeasure: 0.2724 - auc: 0.6266 - val_loss: 0.5870 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4900\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5756 - binary_accuracy: 0.7141 - sensitivity: 0.9895 - specificity: 0.0876 - gmeasure: 0.2837 - auc: 0.6706 - val_loss: 0.5841 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4902\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5755 - binary_accuracy: 0.7156 - sensitivity: 0.9687 - specificity: 0.0742 - gmeasure: 0.2675 - auc: 0.6675 - val_loss: 0.5846 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4913\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5754 - binary_accuracy: 0.7141 - sensitivity: 0.9896 - specificity: 0.0590 - gmeasure: 0.2068 - auc: 0.6151 - val_loss: 0.5860 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4919\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 74us/step - loss: 0.5748 - binary_accuracy: 0.7156 - sensitivity: 0.9856 - specificity: 0.1119 - gmeasure: 0.3234 - auc: 0.6656 - val_loss: 0.5888 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4919\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5748 - binary_accuracy: 0.7156 - sensitivity: 0.9768 - specificity: 0.0907 - gmeasure: 0.2963 - auc: 0.6382 - val_loss: 0.5876 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4900\n",
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5743 - binary_accuracy: 0.7156 - sensitivity: 0.9641 - specificity: 0.1155 - gmeasure: 0.3254 - auc: 0.6465 - val_loss: 0.5855 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4892\n",
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5751 - binary_accuracy: 0.7125 - sensitivity: 0.9895 - specificity: 0.0706 - gmeasure: 0.2602 - auc: 0.6560 - val_loss: 0.5832 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4898\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5743 - binary_accuracy: 0.7141 - sensitivity: 0.9896 - specificity: 0.0813 - gmeasure: 0.2779 - auc: 0.6436 - val_loss: 0.5896 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9833 - val_specificity: 0.0250 - val_gmeasure: 0.1568 - val_auc: 0.4908\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5740 - binary_accuracy: 0.7156 - sensitivity: 0.9692 - specificity: 0.1398 - gmeasure: 0.3586 - auc: 0.6626 - val_loss: 0.5960 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9750 - val_specificity: 0.0500 - val_gmeasure: 0.2208 - val_auc: 0.4904\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5759 - binary_accuracy: 0.7219 - sensitivity: 0.9668 - specificity: 0.1184 - gmeasure: 0.2906 - auc: 0.6447 - val_loss: 0.5878 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4913\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5739 - binary_accuracy: 0.7156 - sensitivity: 0.9693 - specificity: 0.1006 - gmeasure: 0.3063 - auc: 0.6723 - val_loss: 0.5863 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4933\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5753 - binary_accuracy: 0.7141 - sensitivity: 0.9896 - specificity: 0.0607 - gmeasure: 0.2091 - auc: 0.6414 - val_loss: 0.5824 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4919\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5736 - binary_accuracy: 0.7156 - sensitivity: 0.9876 - specificity: 0.1286 - gmeasure: 0.3260 - auc: 0.6577 - val_loss: 0.5883 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9833 - val_specificity: 0.0250 - val_gmeasure: 0.1568 - val_auc: 0.4921\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 64us/step - loss: 0.5743 - binary_accuracy: 0.7141 - sensitivity: 0.9728 - specificity: 0.0815 - gmeasure: 0.2426 - auc: 0.6200 - val_loss: 0.5894 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.4925\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5745 - binary_accuracy: 0.7172 - sensitivity: 0.9876 - specificity: 0.0901 - gmeasure: 0.2887 - auc: 0.6584 - val_loss: 0.5818 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4925\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5771 - binary_accuracy: 0.7172 - sensitivity: 0.9983 - specificity: 0.0460 - gmeasure: 0.1833 - auc: 0.6485 - val_loss: 0.5849 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4923\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5714 - binary_accuracy: 0.7188 - sensitivity: 0.9839 - specificity: 0.0787 - gmeasure: 0.2366 - auc: 0.6483 - val_loss: 0.6023 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9500 - val_specificity: 0.0500 - val_gmeasure: 0.2179 - val_auc: 0.4946\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.5772 - binary_accuracy: 0.7156 - sensitivity: 0.9485 - specificity: 0.1965 - gmeasure: 0.4290 - auc: 0.6830 - val_loss: 0.5902 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.4950\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.5736 - binary_accuracy: 0.7172 - sensitivity: 0.9858 - specificity: 0.0866 - gmeasure: 0.2860 - auc: 0.6514 - val_loss: 0.5812 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4971\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5724 - binary_accuracy: 0.7141 - sensitivity: 0.9787 - specificity: 0.1163 - gmeasure: 0.3207 - auc: 0.6696 - val_loss: 0.5873 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9833 - val_specificity: 0.0250 - val_gmeasure: 0.1568 - val_auc: 0.4979\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5711 - binary_accuracy: 0.7219 - sensitivity: 0.9804 - specificity: 0.1000 - gmeasure: 0.2677 - auc: 0.6782 - val_loss: 0.5900 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.4977\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5717 - binary_accuracy: 0.7234 - sensitivity: 0.9769 - specificity: 0.1065 - gmeasure: 0.2629 - auc: 0.6594 - val_loss: 0.5864 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9833 - val_specificity: 0.0250 - val_gmeasure: 0.1568 - val_auc: 0.4977\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5716 - binary_accuracy: 0.7156 - sensitivity: 0.9859 - specificity: 0.0859 - gmeasure: 0.2873 - auc: 0.6664 - val_loss: 0.5821 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4977\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5706 - binary_accuracy: 0.7172 - sensitivity: 0.9876 - specificity: 0.0952 - gmeasure: 0.3051 - auc: 0.6533 - val_loss: 0.5899 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.4971\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5757 - binary_accuracy: 0.7234 - sensitivity: 0.9419 - specificity: 0.1744 - gmeasure: 0.4021 - auc: 0.6483 - val_loss: 0.5958 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9667 - val_specificity: 0.0500 - val_gmeasure: 0.2198 - val_auc: 0.4975\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5696 - binary_accuracy: 0.7203 - sensitivity: 0.9701 - specificity: 0.1022 - gmeasure: 0.2690 - auc: 0.6669 - val_loss: 0.5814 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5002\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.5738 - binary_accuracy: 0.7188 - sensitivity: 0.9965 - specificity: 0.0543 - gmeasure: 0.2005 - auc: 0.6821 - val_loss: 0.5813 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5004\n",
      "Epoch 97/100\n",
      "640/640 [==============================] - 0s 66us/step - loss: 0.5709 - binary_accuracy: 0.7172 - sensitivity: 0.9737 - specificity: 0.0812 - gmeasure: 0.2807 - auc: 0.6326 - val_loss: 0.5883 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 61us/step - loss: 0.5715 - binary_accuracy: 0.7188 - sensitivity: 0.9616 - specificity: 0.1301 - gmeasure: 0.3483 - auc: 0.6480 - val_loss: 0.5999 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9417 - val_specificity: 0.0500 - val_gmeasure: 0.2170 - val_auc: 0.5017\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5737 - binary_accuracy: 0.7219 - sensitivity: 0.9426 - specificity: 0.1677 - gmeasure: 0.3875 - auc: 0.6668 - val_loss: 0.5883 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5023\n",
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.5692 - binary_accuracy: 0.7156 - sensitivity: 0.9721 - specificity: 0.0884 - gmeasure: 0.2488 - auc: 0.6498 - val_loss: 0.5809 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 6.830451726913452!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 6us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012296915054321289!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5730411410331726, 0.7250000238418579, 0.9912126660346985, 0.06926406919956207, 0.2620218098163605, 0.6369875073432922]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.012672901153564453!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5885742902755737, 0.746268630027771, 0.9802631735801697, 0.020408162847161293, 0.14144033193588257, 0.5285983085632324]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.461602687835693\n",
      "[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:148] Build network for 3 simulation\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:133] Training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "640/640 [==============================] - 0s 666us/step - loss: 0.5796 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6810 - val_loss: 0.6538 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5151\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5829 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6697 - val_loss: 0.6543 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5147\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5747 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6962 - val_loss: 0.6655 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5009\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5737 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6444 - val_loss: 0.6631 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4995\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5744 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6680 - val_loss: 0.6569 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5102\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5733 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6462 - val_loss: 0.6590 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5713 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6942 - val_loss: 0.6659 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5022\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5721 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7014 - val_loss: 0.6603 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5087\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5716 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6932 - val_loss: 0.6582 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5115\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5713 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6633 - val_loss: 0.6648 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5698 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7079 - val_loss: 0.6645 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5051\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5689 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6736 - val_loss: 0.6678 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5024\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5701 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6736 - val_loss: 0.6657 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5056\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5702 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7103 - val_loss: 0.6617 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5089\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 0s 68us/step - loss: 0.5701 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6739 - val_loss: 0.6658 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5682 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7178 - val_loss: 0.6674 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5679 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6737 - val_loss: 0.6666 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5696 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6540 - val_loss: 0.6647 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5683 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7098 - val_loss: 0.6690 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5055\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5715 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6888 - val_loss: 0.6731 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5022\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5665 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6856 - val_loss: 0.6660 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5075\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5718 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6823 - val_loss: 0.6656 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5688 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6728 - val_loss: 0.6739 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5013\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 0s 68us/step - loss: 0.5677 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6673 - val_loss: 0.6722 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5659 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6947 - val_loss: 0.6684 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5080\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5664 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6805 - val_loss: 0.6675 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5080\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5677 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7193 - val_loss: 0.6682 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5075\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 0s 67us/step - loss: 0.5670 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6917 - val_loss: 0.6771 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5029\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5659 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6920 - val_loss: 0.6707 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5080\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5670 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6760 - val_loss: 0.6704 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5060\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5657 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6677 - val_loss: 0.6751 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5031\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5647 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6959 - val_loss: 0.6702 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5655 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7039 - val_loss: 0.6694 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5051\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5657 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6814 - val_loss: 0.6731 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5049\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5649 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7016 - val_loss: 0.6722 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5056\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5654 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7030 - val_loss: 0.6735 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5668 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6745 - val_loss: 0.6819 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4989\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5650 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6981 - val_loss: 0.6731 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5049\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5655 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7269 - val_loss: 0.6729 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5035\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5673 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7192 - val_loss: 0.6780 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5020\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5649 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7046 - val_loss: 0.6815 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5016\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5633 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6990 - val_loss: 0.6758 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5060\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5649 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6899 - val_loss: 0.6765 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5635 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6972 - val_loss: 0.6820 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5027\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 0s 80us/step - loss: 0.5654 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6892 - val_loss: 0.6834 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5024\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5620 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7052 - val_loss: 0.6780 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.9364 - val_specificity: 0.0800 - val_gmeasure: 0.2737 - val_auc: 0.5047\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 0s 79us/step - loss: 0.5652 - binary_accuracy: 0.6922 - sensitivity: 0.9515 - specificity: 0.1115 - gmeasure: 0.2737 - auc: 0.7314 - val_loss: 0.6800 - val_binary_accuracy: 0.6938 - val_sensitivity: 1.0000 - val_specificity: 0.0200 - val_gmeasure: 0.1414 - val_auc: 0.5047\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5613 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0042 - gmeasure: 0.0323 - auc: 0.6997 - val_loss: 0.6913 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5671 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6774 - val_loss: 0.6897 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5007\n",
      "Epoch 50/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5623 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6953 - val_loss: 0.6803 - val_binary_accuracy: 0.6938 - val_sensitivity: 1.0000 - val_specificity: 0.0200 - val_gmeasure: 0.1414 - val_auc: 0.5002\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 0s 79us/step - loss: 0.5661 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0046 - gmeasure: 0.0340 - auc: 0.6935 - val_loss: 0.6825 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5038\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5626 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7034 - val_loss: 0.6915 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5025\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5629 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6750 - val_loss: 0.6875 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5078\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5597 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6811 - val_loss: 0.6820 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5022\n",
      "Epoch 55/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5642 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6811 - val_loss: 0.6837 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5038\n",
      "Epoch 56/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5636 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6894 - val_loss: 0.6970 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5024\n",
      "Epoch 57/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5641 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7227 - val_loss: 0.6879 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067\n",
      "Epoch 58/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5597 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7191 - val_loss: 0.6828 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5040\n",
      "Epoch 59/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5631 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6917 - val_loss: 0.6809 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4975\n",
      "Epoch 60/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5638 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7080 - val_loss: 0.6868 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5040\n",
      "Epoch 61/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5595 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7293 - val_loss: 0.6951 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5038\n",
      "Epoch 62/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5610 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7017 - val_loss: 0.6905 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5051\n",
      "Epoch 63/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5607 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6802 - val_loss: 0.6869 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5024\n",
      "Epoch 64/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5609 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6994 - val_loss: 0.6925 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 65/100\n",
      "640/640 [==============================] - 0s 66us/step - loss: 0.5615 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6983 - val_loss: 0.7028 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5027\n",
      "Epoch 66/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5598 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7061 - val_loss: 0.6885 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5029\n",
      "Epoch 67/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5637 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0227 - gmeasure: 0.0754 - auc: 0.6842 - val_loss: 0.6848 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4995\n",
      "Epoch 68/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5631 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6872 - val_loss: 0.6970 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 69/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5599 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7119 - val_loss: 0.7012 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5029\n",
      "Epoch 70/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5626 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6960 - val_loss: 0.6904 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5038\n",
      "Epoch 71/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5597 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6956 - val_loss: 0.6909 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5040\n",
      "Epoch 72/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5611 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7066 - val_loss: 0.6944 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5607 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6882 - val_loss: 0.6943 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5055\n",
      "Epoch 74/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5597 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6694 - val_loss: 0.6962 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071\n",
      "Epoch 75/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5603 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7176 - val_loss: 0.6854 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4989\n",
      "Epoch 76/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5596 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7126 - val_loss: 0.6943 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 77/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5608 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6957 - val_loss: 0.6996 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5093\n",
      "Epoch 78/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5595 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7182 - val_loss: 0.6889 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5040\n",
      "Epoch 79/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5600 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7038 - val_loss: 0.6902 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5047\n",
      "Epoch 80/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5579 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7171 - val_loss: 0.6964 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 81/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5589 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6973 - val_loss: 0.6958 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5065\n",
      "Epoch 82/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5568 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7001 - val_loss: 0.6901 - val_binary_accuracy: 0.6938 - val_sensitivity: 1.0000 - val_specificity: 0.0200 - val_gmeasure: 0.1414 - val_auc: 0.5029\n",
      "Epoch 83/100\n",
      "640/640 [==============================] - 0s 65us/step - loss: 0.5612 - binary_accuracy: 0.6953 - sensitivity: 1.0000 - specificity: 0.0085 - gmeasure: 0.0650 - auc: 0.7508 - val_loss: 0.6976 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 84/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5605 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6713 - val_loss: 0.7253 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 85/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5728 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7021 - val_loss: 0.7004 - val_binary_accuracy: 0.6938 - val_sensitivity: 1.0000 - val_specificity: 0.0200 - val_gmeasure: 0.1414 - val_auc: 0.5080\n",
      "Epoch 86/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5615 - binary_accuracy: 0.6734 - sensitivity: 0.8550 - specificity: 0.2339 - gmeasure: 0.3448 - auc: 0.6887 - val_loss: 0.6885 - val_binary_accuracy: 0.5625 - val_sensitivity: 0.6636 - val_specificity: 0.3400 - val_gmeasure: 0.4750 - val_auc: 0.5007\n",
      "Epoch 87/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5762 - binary_accuracy: 0.6859 - sensitivity: 0.7828 - specificity: 0.4302 - gmeasure: 0.5717 - auc: 0.6887 - val_loss: 0.6901 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.9182 - val_specificity: 0.1200 - val_gmeasure: 0.3319 - val_auc: 0.5013\n",
      "Epoch 88/100\n",
      "640/640 [==============================] - 0s 78us/step - loss: 0.5580 - binary_accuracy: 0.6922 - sensitivity: 0.9874 - specificity: 0.0285 - gmeasure: 0.1143 - auc: 0.7247 - val_loss: 0.7003 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5087\n",
      "Epoch 89/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5606 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7266 - val_loss: 0.7023 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5089\n",
      "Epoch 90/100\n",
      "640/640 [==============================] - 0s 74us/step - loss: 0.5579 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6964 - val_loss: 0.6925 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5065\n",
      "Epoch 91/100\n",
      "640/640 [==============================] - 0s 69us/step - loss: 0.5587 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7086 - val_loss: 0.6916 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5045\n",
      "Epoch 92/100\n",
      "640/640 [==============================] - 0s 70us/step - loss: 0.5562 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6917 - val_loss: 0.7050 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5064\n",
      "Epoch 93/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5612 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7299 - val_loss: 0.7042 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067\n",
      "Epoch 94/100\n",
      "640/640 [==============================] - 0s 72us/step - loss: 0.5601 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6944 - val_loss: 0.6931 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5062\n",
      "Epoch 95/100\n",
      "640/640 [==============================] - 0s 77us/step - loss: 0.5578 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7487 - val_loss: 0.6944 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 96/100\n",
      "640/640 [==============================] - 0s 73us/step - loss: 0.5571 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6996 - val_loss: 0.7076 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5590 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7195 - val_loss: 0.6989 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5065\n",
      "Epoch 98/100\n",
      "640/640 [==============================] - 0s 71us/step - loss: 0.5551 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6990 - val_loss: 0.6967 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071\n",
      "Epoch 99/100\n",
      "640/640 [==============================] - 0s 76us/step - loss: 0.5546 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7526 - val_loss: 0.7004 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067\n",
      "Epoch 100/100\n",
      "640/640 [==============================] - 0s 75us/step - loss: 0.5544 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7266 - val_loss: 0.7043 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:143] Training end with time 6.6846489906311035!\n",
      "[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5 \n",
      "[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5\n",
      "[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "800/800 [==============================] - 0s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.008782625198364258!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5850404500961304, 0.6912500262260437, 1.0, 0.0, 0.0, 0.6665226817131042]\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "200/200 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.009485960006713867!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.7680084109306335, 0.6800000071525574, 1.0, 0.0, 0.0, 0.4273897111415863]\n",
      "[root    |INFO|deepbiome.py:179] Compute time : 8.338343620300293\n",
      "[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:185] Train Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:188]       mean : [0.46128214 0.77416668 0.98492759 0.2833802  0.37648287 0.7571037 ]\n",
      "[root    |INFO|deepbiome.py:189]        std : [0.16660791 0.09440787 0.01552226 0.35291767 0.36325686 0.14947256]\n",
      "[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:192] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:195]       mean : [0.54717316 0.77227197 0.97183832 0.27024359 0.33372635 0.63306277]\n",
      "[root    |INFO|deepbiome.py:196]        std : [0.19937417 0.0879002  0.02709633 0.36784576 0.37640235 0.22315877]\n",
      "[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:206] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_evaluation, train_evaluation, network = deepbiome.deepbiome_train(log, warm_start_network_info, path_info, \n",
    "                                                                       number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the history plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx0nE4CkqKOsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6dc26e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./%s/hist_0.json' % path_info['model_info']['model_dir'], 'r') as f:\n",
    "    history = json.load(f)\n",
    "    \n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load the pre-trained network for testing\n",
    "\n",
    "To test the trained model, we can use the `deepbiome_test` function. If you use the index file, this function provides the evaluation using test index (index set not included in the index file) for each fold. If not, this function provides the evaluation using the whole samples. If `number_of_fold` is set to `k`, the function will test the model only with first `k` folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lr': '0.01',\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path_info = {\n",
    "    'data_info': {\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'idx_path': resource_filename('deepbiome', 'tests/data/onefile_idx.csv'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': 'onefile_x.csv',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'evaluation': 'eval.npy',\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:294] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 347us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.20604419708251953!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.284936785697937, 0.8905472755432129, 0.935251772403717, 0.7903226017951965, 0.8597387075424194, 0.9432002902030945]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.4026703834533691\n",
      "[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "201/201 [==============================] - 0s 392us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.22733139991760254!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.5885742902755737, 0.746268630027771, 0.9802631735801697, 0.020408162847161293, 0.14144033193588257, 0.5285983085632324]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.4291009902954102\n",
      "[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:307] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------\n",
      "[root    |INFO|build_network.py:169] Evaluation start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "200/200 [==============================] - 0s 454us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:174] Evaluation end with time 0.22405052185058594!\n",
      "[root    |INFO|build_network.py:175] Evaluation: [0.7680084109306335, 0.6800000071525574, 1.0, 0.0, 0.0, 0.4273897111415863]\n",
      "[root    |INFO|deepbiome.py:320] \n",
      "[root    |INFO|deepbiome.py:322] Compute time : 1.4915955066680908\n",
      "[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:328] Test Evaluation : ['loss' 'binary_accuracy' 'sensitivity' 'specificity' 'gmeasure' 'auc']\n",
      "[root    |INFO|deepbiome.py:331]       mean : [0.54717316 0.77227197 0.97183832 0.27024359 0.33372635 0.63306277]\n",
      "[root    |INFO|deepbiome.py:332]        std : [0.19937417 0.0879002  0.02709633 0.36784576 0.37640235 0.22315877]\n",
      "[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:336] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluation = deepbiome.deepbiome_test(log, test_network_info, test_path_info, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function provide the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc\n",
      "Mean:           0.5472          0.7723          0.9718          0.2702          0.3337          0.6331\n",
      "Std :           0.1994          0.0879          0.0271          0.3678          0.3764          0.2232\n"
     ]
    }
   ],
   "source": [
    "print('      %s' % ''.join(['%16s'%'loss']+ ['%16s'%s.strip() for s in network_info['model_info']['metrics'].split(',')]))\n",
    "print('Mean: %s' % ''.join(['%16.4f'%v for v in np.mean(evaluation, axis=0)]))\n",
    "print('Std : %s' % ''.join(['%16.4f'%v for v in np.std(evaluation, axis=0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load the pre-trained network for prediction\n",
    "\n",
    "If you want to predict using the pre-trained model, you can use the `deepbiome_prediction` function. If `number_of_fold` is setted as `k`, the function will predict only with first `k` folds sample's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_network_info = {\n",
    "    'architecture_info': {\n",
    "        'batch_normalization': 'False',\n",
    "        'drop_out': '0',\n",
    "        'weight_initial': 'glorot_uniform',\n",
    "        'weight_l1_penalty':'0.01',\n",
    "        'weight_decay': 'phylogenetic_tree',\n",
    "    },\n",
    "    'model_info': {\n",
    "        'decay': '0.001',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'lr': '0.01',\n",
    "        'metrics': 'binary_accuracy, sensitivity, specificity, gmeasure, auc',\n",
    "        'network_class': 'DeepBiomeNetwork',\n",
    "        'normalizer': 'normalize_minmax',\n",
    "        'optimizer': 'adam',\n",
    "        'reader_class': 'MicroBiomeClassificationReader',\n",
    "        'texa_selection_metrics': 'accuracy, sensitivity, specificity, gmeasure'\n",
    "    },\n",
    "    'test_info': {\n",
    "        'batch_size': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_path_info = {\n",
    "    'data_info': {\n",
    "        'data_path': resource_filename('deepbiome', 'tests/data'),\n",
    "        'tree_info_path': resource_filename('deepbiome', 'tests/data/genus48_dic.csv'),\n",
    "        'x_path': 'onefile_x.csv',\n",
    "        'y_path': 'classification_y.csv'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'model_dir': './example_result/',\n",
    "        'weight': 'weight_0.h5'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 1 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.048128604888916016!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 0.9910094738006592\n",
      "[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 2 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.03895401954650879!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 0.9998486042022705\n",
      "[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------\n",
      "[root    |INFO|readers.py:58] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:59] Construct Dataset\n",
      "[root    |INFO|readers.py:60] -----------------------------------------------------------------------\n",
      "[root    |INFO|readers.py:61] Load data\n",
      "[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------\n",
      "[root    |INFO|deepbiome.py:430] Build network for 3 fold testing\n",
      "[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv\n",
      "[root    |INFO|build_network.py:510] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:518]      Genus: 48\n",
      "[root    |INFO|build_network.py:518]     Family: 40\n",
      "[root    |INFO|build_network.py:518]      Order: 23\n",
      "[root    |INFO|build_network.py:518]      Class: 17\n",
      "[root    |INFO|build_network.py:518]     Phylum: 9\n",
      "[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: ['Class', 'Number', 'Phylum', 'Order', 'Genus', 'Family']\n",
      "[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = binary_crossentropy\n",
      "[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc\n",
      "[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:189] Prediction start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1000 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:194] Prediction end with time 0.04842853546142578!\n",
      "[root    |INFO|deepbiome.py:444] Compute time : 1.0276074409484863\n",
      "[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------\n",
      "[root    |INFO|deepbiome.py:449] Total Computing Ended\n",
      "[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prediction = deepbiome.deepbiome_prediction(log, prediction_network_info, prediction_path_info,\n",
    "                                            num_classes = 1, number_of_fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82867134],\n",
       "       [0.9641832 ],\n",
       "       [0.10825878],\n",
       "       [0.08233523],\n",
       "       [0.9999995 ],\n",
       "       [0.9699232 ],\n",
       "       [0.24979487],\n",
       "       [0.08233523],\n",
       "       [0.92984045],\n",
       "       [0.9995712 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0,:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
