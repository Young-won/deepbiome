

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Example : k fold cross-validation with an input file &mdash; deepbiome 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Release History" href="release-history.html" />
    <link rel="prev" title="Example : k times repetition with the list of k input files" href="example_with_the_list_of_inputs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deepbiome
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_with_the_list_of_inputs.html">Example : k times repetition with the list of k input files</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example : k fold cross-validation with an input file</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#1.-Load-library">1. Load library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Prepare-the-dataset">2. Prepare the dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-tree-information">Example of the tree information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-input-file">Example of the input file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(regression)">Example of the Y (regression)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(classification)">Example of the Y (classification)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exmple-of-the-training-index-file-for-k-fold-cross-validation">Exmple of the training index file for <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#3.-Prepare-the-configuration">3. Prepare the configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-network-information-(network_info)">For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-path-information-(path_info)">For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#4.-Deepbiome-Training">4. Deepbiome Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5.-Load-the-pre-trained-network-for-training">5. Load the pre-trained network for training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#6.-Load-the-pre-trained-network-for-testing">6. Load the pre-trained network for testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#7.-Load-the-pre-trained-network-for-prediction">7. Load the pre-trained network for prediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="release-history.html">Release History</a></li>
<li class="toctree-l1"><a class="reference internal" href="min_versions.html">Minimum Version of Python and NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepbiome</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Example : k fold cross-validation with an input file</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/example_with_one_input_file.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Example-:-k-fold-cross-validation-with-an-input-file">
<h1>Example : k fold cross-validation with an input file<a class="headerlink" href="#Example-:-k-fold-cross-validation-with-an-input-file" title="Permalink to this headline">¶</a></h1>
<p>DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.</p>
<p>To use DeepBiome, you can experiment (1) <strong>k times repetition</strong> or (2) <strong>k fold cross-validation</strong>. For each experiment, we asuume that the dataset is given by - <strong>A list of k input files for k times repetition.</strong> - <strong>One input file for k fold cross-validation.</strong></p>
<p>This notebook contains an example of (2) <strong>k fold cross-validation</strong> for the deep neural netowrk using deepbiome.</p>
<div class="section" id="1.-Load-library">
<h2>1. Load library<a class="headerlink" href="#1.-Load-library" title="Permalink to this headline">¶</a></h2>
<p>First, we load the DeepBiome package. The DeepBiome package is built on the tensorflow and keras library</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">resource_filename</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">deepbiome</span> <span class="kn">import</span> <span class="n">deepbiome</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
</pre></div></div>
</div>
</div>
<div class="section" id="2.-Prepare-the-dataset">
<h2>2. Prepare the dataset<a class="headerlink" href="#2.-Prepare-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this example, we assume that we have <strong>one input file for k times repetition.</strong></p>
<p>DeepBiome needs 3 data files as follows: 1. <strong>the tree information</strong> 1. <strong>the input file</strong> 1. <strong>y</strong></p>
<p>For <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation, we can use an input file. In addition, we can set <strong>the training index for each fold</strong>. If we set the index file, DeepBiome build the training set for each fold based on each fold index in the index file. If not, DeepBiome will generate the index file locally.</p>
<p>Eath data should have the csv format as follow:</p>
<div class="section" id="Example-of-the-tree-information">
<h3>Example of the tree information<a class="headerlink" href="#Example-of-the-tree-information" title="Permalink to this headline">¶</a></h3>
<p>First we need a file about the phylogenetic tree information. This tree information file should have the format below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tree_information</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">))</span>
<span class="n">tree_information</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genus</th>
      <th>Family</th>
      <th>Order</th>
      <th>Class</th>
      <th>Phylum</th>
      <th>Domain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Streptococcus</td>
      <td>Streptococcaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tropheryma</td>
      <td>Cellulomonadaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Veillonella</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Actinomyces</td>
      <td>Actinomycetaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Flavobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Prevotella</td>
      <td>Prevotellaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Porphyromonas</td>
      <td>Porphyromonadaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Parvimonas</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Fusobacterium</td>
      <td>Fusobacteriaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Propionibacterium</td>
      <td>Propionibacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Gemella</td>
      <td>Bacillales_Incertae_Sedis_XI</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Rothia</td>
      <td>Micrococcaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Granulicatella</td>
      <td>Carnobacteriaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Neisseria</td>
      <td>Neisseriaceae</td>
      <td>Neisseriales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Lactobacillus</td>
      <td>Lactobacillaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Megasphaera</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Catonella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Atopobium</td>
      <td>Coriobacteriaceae</td>
      <td>Coriobacteriales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Campylobacter</td>
      <td>Campylobacteraceae</td>
      <td>Campylobacterales</td>
      <td>Epsilonproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Capnocytophaga</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Solobacterium</td>
      <td>Erysipelotrichaceae</td>
      <td>Erysipelotrichales</td>
      <td>Erysipelotrichia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Moryella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>22</th>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Staphylococcus</td>
      <td>Staphylococcaceae</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Filifactor</td>
      <td>Peptostreptococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Oribacterium</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Burkholderia</td>
      <td>Burkholderiaceae</td>
      <td>Burkholderiales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Sneathia</td>
      <td>Leptotrichiaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Treponema</td>
      <td>Spirochaetaceae</td>
      <td>Spirochaetales</td>
      <td>Spirochaetes</td>
      <td>Spirochaetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Moraxella</td>
      <td>Moraxellaceae</td>
      <td>Pseudomonadales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Haemophilus</td>
      <td>Pasteurellaceae</td>
      <td>Pasteurellales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Selenomonas</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Corynebacterium</td>
      <td>Corynebacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Rhizobium</td>
      <td>Rhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Bradyrhizobium</td>
      <td>Bradyrhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Methylobacterium</td>
      <td>Methylobacteriaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>36</th>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Finegoldia</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Microbacterium</td>
      <td>Microbacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Sphingomonas</td>
      <td>Sphingomonadaceae</td>
      <td>Sphingomonadales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Chryseobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Bacteroides</td>
      <td>Bacteroidaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Bdellovibrio</td>
      <td>Bdellovibrionaceae</td>
      <td>Bdellovibrionales</td>
      <td>Deltaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Streptophyta</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Cyanobacteria_Chloroplast</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Lachnospiracea_incertae_sedis</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Paracoccus</td>
      <td>Rhodobacteraceae</td>
      <td>Rhodobacterales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Fastidiosipila</td>
      <td>Ruminococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Pseudonocardia</td>
      <td>Pseudonocardiaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-input-file">
<h3>Example of the input file<a class="headerlink" href="#Example-of-the-input-file" title="Permalink to this headline">¶</a></h3>
<p>Below is an example of the input file. This example has 1000 samples’ microbiome abandunce.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_x.csv&#39;</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>841</td>
      <td>0</td>
      <td>813</td>
      <td>505</td>
      <td>5</td>
      <td>3224</td>
      <td>0</td>
      <td>362</td>
      <td>11</td>
      <td>65</td>
      <td>...</td>
      <td>0</td>
      <td>87</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2133</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1445</td>
      <td>0</td>
      <td>1</td>
      <td>573</td>
      <td>0</td>
      <td>1278</td>
      <td>82</td>
      <td>85</td>
      <td>69</td>
      <td>154</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3638</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1259</td>
      <td>0</td>
      <td>805</td>
      <td>650</td>
      <td>0</td>
      <td>1088</td>
      <td>0</td>
      <td>0</td>
      <td>74</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3445</td>
    </tr>
    <tr>
      <th>3</th>
      <td>982</td>
      <td>0</td>
      <td>327</td>
      <td>594</td>
      <td>0</td>
      <td>960</td>
      <td>81</td>
      <td>19</td>
      <td>9</td>
      <td>0</td>
      <td>...</td>
      <td>157</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3507</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1162</td>
      <td>0</td>
      <td>130</td>
      <td>969</td>
      <td>163</td>
      <td>1515</td>
      <td>167</td>
      <td>4</td>
      <td>162</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>3945</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1401</td>
      <td>4</td>
      <td>30</td>
      <td>526</td>
      <td>0</td>
      <td>923</td>
      <td>25</td>
      <td>0</td>
      <td>127</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4470</td>
    </tr>
    <tr>
      <th>996</th>
      <td>2655</td>
      <td>6</td>
      <td>106</td>
      <td>74</td>
      <td>0</td>
      <td>952</td>
      <td>76</td>
      <td>13</td>
      <td>158</td>
      <td>125</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2826</td>
    </tr>
    <tr>
      <th>997</th>
      <td>335</td>
      <td>0</td>
      <td>71</td>
      <td>259</td>
      <td>67</td>
      <td>718</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>167</td>
      <td>...</td>
      <td>0</td>
      <td>246</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6527</td>
    </tr>
    <tr>
      <th>998</th>
      <td>649</td>
      <td>69</td>
      <td>966</td>
      <td>1227</td>
      <td>0</td>
      <td>508</td>
      <td>2</td>
      <td>30</td>
      <td>550</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4402</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1258</td>
      <td>0</td>
      <td>0</td>
      <td>1119</td>
      <td>0</td>
      <td>2348</td>
      <td>25</td>
      <td>0</td>
      <td>137</td>
      <td>176</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2585</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(regression)">
<h3>Example of the Y (regression)<a class="headerlink" href="#Example-of-the-Y-(regression)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for regression problem.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_regression_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.997270</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.004092</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.485126</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.489590</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.500001</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>2.609926</td>
    </tr>
    <tr>
      <th>996</th>
      <td>5.488959</td>
    </tr>
    <tr>
      <th>997</th>
      <td>3.498418</td>
    </tr>
    <tr>
      <th>998</th>
      <td>5.486107</td>
    </tr>
    <tr>
      <th>999</th>
      <td>5.319623</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>For one repetition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    4.997270
1    5.004092
2    5.485126
3    5.489590
4    1.500001
Name: x1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    2.609926
996    5.488959
997    3.498418
998    5.486107
999    5.319623
Name: x1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(classification)">
<h3>Example of the Y (classification)<a class="headerlink" href="#Example-of-the-Y-(classification)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetition in columns.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_classification_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>997</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>For one repetition, DeepBiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    1.0
1    1.0
2    0.0
3    0.0
4    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    1.0
996    0.0
997    1.0
998    0.0
999    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Exmple-of-the-training-index-file-for-k-fold-cross-validation">
<h3>Exmple of the training index file for <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation<a class="headerlink" href="#Exmple-of-the-training-index-file-for-k-fold-cross-validation" title="Permalink to this headline">¶</a></h3>
<p>For each fold, we have to set the training and test set. If the index file is given, DeepBiome sets the training set and test set based on the index file for 5 fold cross-validation. Below is the example of the index file. Each column has the training indices for each fold. DeepBiome will only use the samples in this index set for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">idxs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>3</td>
      <td>6</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>4</td>
      <td>8</td>
      <td>4</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>795</th>
      <td>993</td>
      <td>995</td>
      <td>993</td>
      <td>994</td>
      <td>995</td>
    </tr>
    <tr>
      <th>796</th>
      <td>994</td>
      <td>996</td>
      <td>994</td>
      <td>995</td>
      <td>996</td>
    </tr>
    <tr>
      <th>797</th>
      <td>996</td>
      <td>997</td>
      <td>995</td>
      <td>996</td>
      <td>997</td>
    </tr>
    <tr>
      <th>798</th>
      <td>998</td>
      <td>998</td>
      <td>997</td>
      <td>997</td>
      <td>998</td>
    </tr>
    <tr>
      <th>799</th>
      <td>999</td>
      <td>999</td>
      <td>998</td>
      <td>999</td>
      <td>999</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Below is the index set for 1st fold. From 1000 samples above, it uses 800 samples for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    0
1    1
2    2
3    5
4    6
Name: 0, dtype: int64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>795    993
796    994
797    996
798    998
799    999
Name: 0, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="3.-Prepare-the-configuration">
<h2>3. Prepare the configuration<a class="headerlink" href="#3.-Prepare-the-configuration" title="Permalink to this headline">¶</a></h2>
<p>For detailed configuration, we can build the configuration information for the network training by: 1. the python dictionary format 1. the configufation file (.cfg).</p>
<p>In this notebook, we show the python dictionary format configuration.</p>
<p>Please check the detailed information about each option in the <a class="reference external" href="https://young-won.github.io/deepbiome/prerequisites.html#configuration">documantation</a></p>
<div class="section" id="For-preparing-the-configuration-about-the-network-information-(network_info)">
<h3>For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-network-information-(network_info)" title="Permalink to this headline">¶</a></h3>
<p>To give the information about the training process, we provide a dictionary of configurations to the <code class="docutils literal notranslate"><span class="pre">netowrk_info</span></code> field. Your configuration for the network training should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;taxa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;50&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="For-preparing-the-configuration-about-the-path-information-(path_info)">
<h3>For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-path-information-(path_info)" title="Permalink to this headline">¶</a></h3>
<p>To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, you have to provide a dictionary for configuration to the <code class="docutils literal notranslate"><span class="pre">path_info</span></code> feild. Your configuration for the path information should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;hist.json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="4.-Deepbiome-Training">
<h2>4. Deepbiome Training<a class="headerlink" href="#4.-Deepbiome-Training" title="Permalink to this headline">¶</a></h2>
<p>Now we can train the DeepBiome network based on the configurations.</p>
<p>For logging, we used the python logging library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;[</span><span class="si">%(name)-8s</span><span class="s1">|</span><span class="si">%(levelname)s</span><span class="s1">|</span><span class="si">%(filename)s</span><span class="s1">:</span><span class="si">%(lineno)s</span><span class="s1">] </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.</p>
<p>If we set <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code>, then DeepBiome performs cross-validation based on that value. If not, DeepBiome package performs cross-validation based on the index file. If both <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> option and the index file are missing, then the library performs leave-one-out-cross-validation (LOOCV).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 1ms/step - loss: 0.6749 - binary_accuracy: 0.6609 - sensitivity: 0.9231 - specificity: 0.0769 - gmeasure: 0.0000e+00 - auc: 0.5002 - val_loss: 0.6493 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5616
Epoch 2/100
640/640 [==============================] - 0s 214us/step - loss: 0.6394 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5082 - val_loss: 0.6155 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5117
Epoch 3/100
640/640 [==============================] - 0s 216us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5127 - val_loss: 0.6109 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5159
Epoch 4/100
640/640 [==============================] - 0s 225us/step - loss: 0.6260 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5028 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5161
Epoch 5/100
640/640 [==============================] - 0s 216us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5054 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5143
Epoch 6/100
640/640 [==============================] - 0s 215us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5020 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5159
Epoch 7/100
640/640 [==============================] - 0s 211us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5053 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5096
Epoch 8/100
640/640 [==============================] - 0s 221us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5160 - val_loss: 0.6127 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5388
Epoch 9/100
640/640 [==============================] - 0s 218us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5113 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5365
Epoch 10/100
640/640 [==============================] - 0s 218us/step - loss: 0.6257 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5051 - val_loss: 0.6120 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5175
Epoch 11/100
640/640 [==============================] - 0s 217us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5058 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5164
Epoch 12/100
640/640 [==============================] - 0s 206us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5175 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5201
Epoch 13/100
640/640 [==============================] - 0s 206us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5294 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5463
Epoch 14/100
640/640 [==============================] - 0s 224us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5145 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5470
Epoch 15/100
640/640 [==============================] - 0s 223us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5196 - val_loss: 0.6121 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5198
Epoch 16/100
640/640 [==============================] - 0s 217us/step - loss: 0.6255 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5146 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5260
Epoch 17/100
640/640 [==============================] - 0s 215us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5177 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5629
Epoch 18/100
640/640 [==============================] - 0s 220us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5173 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5615
Epoch 19/100
640/640 [==============================] - 0s 209us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5267 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5613
Epoch 20/100
640/640 [==============================] - 0s 208us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5259 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5586
Epoch 21/100
640/640 [==============================] - 0s 222us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5395 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5427
Epoch 22/100
640/640 [==============================] - 0s 221us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5245 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5159
Epoch 23/100
640/640 [==============================] - 0s 207us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5217 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5460
Epoch 24/100
640/640 [==============================] - 0s 211us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5381 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5246
Epoch 25/100
640/640 [==============================] - 0s 222us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5258 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5235
Epoch 26/100
640/640 [==============================] - 0s 210us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5178 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5441
Epoch 27/100
640/640 [==============================] - 0s 200us/step - loss: 0.6247 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5305 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5492
Epoch 28/100
640/640 [==============================] - 0s 219us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5216 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5164
Epoch 29/100
640/640 [==============================] - 0s 223us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5245 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5238
Epoch 30/100
640/640 [==============================] - 0s 211us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5323 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5492
Epoch 31/100
640/640 [==============================] - 0s 210us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5442 - val_loss: 0.6120 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5303
Epoch 32/100
640/640 [==============================] - 0s 212us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5410 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5452
Epoch 33/100
640/640 [==============================] - 0s 219us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5408 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5566
Epoch 34/100
640/640 [==============================] - 0s 196us/step - loss: 0.6257 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5352 - val_loss: 0.6125 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5200
Epoch 35/100
640/640 [==============================] - ETA: 0s - loss: 0.6083 - binary_accuracy: 0.7050 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.55 - 0s 202us/step - loss: 0.6256 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5241 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5224
Epoch 36/100
640/640 [==============================] - 0s 228us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5310 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5539
Epoch 37/100
640/640 [==============================] - 0s 218us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5407 - val_loss: 0.6119 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5541
Epoch 38/100
640/640 [==============================] - 0s 221us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5422 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5348
Epoch 39/100
640/640 [==============================] - 0s 219us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5461 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5304
Epoch 40/100
640/640 [==============================] - 0s 227us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5489 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5242
Epoch 41/100
640/640 [==============================] - 0s 218us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5454 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5525
Epoch 42/100
640/640 [==============================] - 0s 216us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5605 - val_loss: 0.6120 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5574
Epoch 43/100
640/640 [==============================] - 0s 218us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5564 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5315
Epoch 44/100
640/640 [==============================] - 0s 216us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5490 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5351
Epoch 45/100
640/640 [==============================] - 0s 222us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5586 - val_loss: 0.6123 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5379
Epoch 46/100
640/640 [==============================] - 0s 228us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5521 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5316
Epoch 47/100
640/640 [==============================] - 0s 216us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5514 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5805
Epoch 48/100
640/640 [==============================] - 0s 211us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5629 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5550
Epoch 49/100
640/640 [==============================] - 0s 213us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5541 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5509
Epoch 50/100
640/640 [==============================] - 0s 214us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5569 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5468
Epoch 51/100
640/640 [==============================] - 0s 213us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5627 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5493
Epoch 52/100
640/640 [==============================] - 0s 218us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5675 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5830
Epoch 53/100
640/640 [==============================] - 0s 220us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5549 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5695
Epoch 54/100
640/640 [==============================] - 0s 219us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5620 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5455
Epoch 55/100
640/640 [==============================] - 0s 189us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5626 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5505
Epoch 56/100
640/640 [==============================] - 0s 211us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5597 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5461
Epoch 57/100
640/640 [==============================] - 0s 193us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5753 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6036
Epoch 58/100
640/640 [==============================] - 0s 213us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5731 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5983
Epoch 59/100
640/640 [==============================] - 0s 208us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5776 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5547
Epoch 60/100
640/640 [==============================] - 0s 223us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5696 - val_loss: 0.6118 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5693
Epoch 61/100
640/640 [==============================] - 0s 214us/step - loss: 0.6255 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5750 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5649
Epoch 62/100
640/640 [==============================] - 0s 214us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5798 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5876
Epoch 63/100
640/640 [==============================] - 0s 199us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5894 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5995
Epoch 64/100
640/640 [==============================] - 0s 222us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5883 - val_loss: 0.6120 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5784
Epoch 65/100
640/640 [==============================] - 0s 206us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5848 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5777
Epoch 66/100
640/640 [==============================] - 0s 188us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5924 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6182
Epoch 67/100
640/640 [==============================] - 0s 214us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6019 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6356
Epoch 68/100
640/640 [==============================] - 0s 224us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5943 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6048
Epoch 69/100
640/640 [==============================] - 0s 227us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5970 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5790
Epoch 70/100
640/640 [==============================] - 0s 214us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6021 - val_loss: 0.6119 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5944
Epoch 71/100
640/640 [==============================] - 0s 226us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5925 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5956
Epoch 72/100
640/640 [==============================] - 0s 215us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5988 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6014
Epoch 73/100
640/640 [==============================] - 0s 225us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6014 - val_loss: 0.6120 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5959
Epoch 74/100
640/640 [==============================] - 0s 218us/step - loss: 0.6250 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6122 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5953
Epoch 75/100
640/640 [==============================] - 0s 214us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5963 - val_loss: 0.6111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5984
Epoch 76/100
640/640 [==============================] - 0s 215us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6058 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6551
Epoch 77/100
640/640 [==============================] - 0s 210us/step - loss: 0.6251 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6202 - val_loss: 0.6122 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6526
Epoch 78/100
640/640 [==============================] - 0s 216us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6318 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6470
Epoch 79/100
640/640 [==============================] - 0s 222us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6233 - val_loss: 0.6113 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6218
Epoch 80/100
640/640 [==============================] - 0s 223us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6117 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6299
Epoch 81/100
640/640 [==============================] - 0s 211us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6261 - val_loss: 0.6115 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6328
Epoch 82/100
640/640 [==============================] - 0s 216us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6347 - val_loss: 0.6117 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6251
Epoch 83/100
640/640 [==============================] - 0s 221us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6994 - val_loss: 0.6116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6846
Epoch 84/100
640/640 [==============================] - 0s 207us/step - loss: 0.6247 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7142 - val_loss: 0.6114 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6451
Epoch 85/100
640/640 [==============================] - 0s 201us/step - loss: 0.6234 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7146 - val_loss: 0.6095 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6668
Epoch 86/100
640/640 [==============================] - 0s 220us/step - loss: 0.6205 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7230 - val_loss: 0.6076 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6594
Epoch 87/100
640/640 [==============================] - 0s 205us/step - loss: 0.6181 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7439 - val_loss: 0.6053 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6629
Epoch 88/100
640/640 [==============================] - 0s 208us/step - loss: 0.6154 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7506 - val_loss: 0.6019 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6613
Epoch 89/100
640/640 [==============================] - 0s 210us/step - loss: 0.6116 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7418 - val_loss: 0.5977 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6798
Epoch 90/100
640/640 [==============================] - 0s 216us/step - loss: 0.6061 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7528 - val_loss: 0.5924 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6850
Epoch 91/100
640/640 [==============================] - 0s 220us/step - loss: 0.5990 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7501 - val_loss: 0.5839 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6919
Epoch 92/100
640/640 [==============================] - 0s 207us/step - loss: 0.5897 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7521 - val_loss: 0.5839 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6953
Epoch 93/100
640/640 [==============================] - 0s 214us/step - loss: 0.5825 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7588 - val_loss: 0.5691 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7089
Epoch 94/100
640/640 [==============================] - 0s 213us/step - loss: 0.5746 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7743 - val_loss: 0.5637 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7003
Epoch 95/100
640/640 [==============================] - 0s 225us/step - loss: 0.5607 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7605 - val_loss: 0.5439 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7098
Epoch 96/100
640/640 [==============================] - 0s 224us/step - loss: 0.5515 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7700 - val_loss: 0.5397 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7101
Epoch 97/100
640/640 [==============================] - 0s 204us/step - loss: 0.5422 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7652 - val_loss: 0.5275 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7131
Epoch 98/100
640/640 [==============================] - 0s 223us/step - loss: 0.5368 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7796 - val_loss: 0.5220 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7218
Epoch 99/100
640/640 [==============================] - 0s 222us/step - loss: 0.5265 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7768 - val_loss: 0.5111 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7129
Epoch 100/100
640/640 [==============================] - 0s 235us/step - loss: 0.5215 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7840 - val_loss: 0.5048 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7294
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 16.51238703727722!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.015098810195922852!
[root    |INFO|build_network.py:175] Evaluation: [0.5201159119606018, 0.6862499713897705, 1.0, 0.0, 0.0, 0.7842437028884888]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 26us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.01297307014465332!
[root    |INFO|build_network.py:175] Evaluation: [0.5442847013473511, 0.6915422677993774, 1.0, 0.0, 0.0, 0.7287073731422424]
[root    |INFO|deepbiome.py:179] Compute time : 19.35059142112732
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 752us/step - loss: 0.6658 - binary_accuracy: 0.6516 - sensitivity: 0.9231 - specificity: 0.0769 - gmeasure: 0.0000e+00 - auc: 0.4946 - val_loss: 0.6060 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5807
Epoch 2/100
640/640 [==============================] - 0s 216us/step - loss: 0.6139 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5009 - val_loss: 0.5655 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5581
Epoch 3/100
640/640 [==============================] - 0s 225us/step - loss: 0.6118 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5838 - val_loss: 0.5638 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5243
Epoch 4/100
640/640 [==============================] - 0s 222us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5912 - val_loss: 0.5701 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4863
Epoch 5/100
640/640 [==============================] - 0s 214us/step - loss: 0.6103 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5893 - val_loss: 0.5725 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4536
Epoch 6/100
640/640 [==============================] - 0s 223us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5894 - val_loss: 0.5689 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4475
Epoch 7/100
640/640 [==============================] - 0s 214us/step - loss: 0.6116 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6069 - val_loss: 0.5655 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4570
Epoch 8/100
640/640 [==============================] - 0s 217us/step - loss: 0.6110 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5956 - val_loss: 0.5705 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4611
Epoch 9/100
640/640 [==============================] - 0s 209us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5928 - val_loss: 0.5692 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4487
Epoch 10/100
640/640 [==============================] - 0s 218us/step - loss: 0.6101 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5929 - val_loss: 0.5675 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4586
Epoch 11/100
640/640 [==============================] - 0s 207us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5953 - val_loss: 0.5667 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4428
Epoch 12/100
640/640 [==============================] - 0s 205us/step - loss: 0.6105 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5967 - val_loss: 0.5705 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4450
Epoch 13/100
640/640 [==============================] - 0s 226us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5901 - val_loss: 0.5688 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4506
Epoch 14/100
640/640 [==============================] - 0s 215us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5994 - val_loss: 0.5671 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4523
Epoch 15/100
640/640 [==============================] - 0s 220us/step - loss: 0.6103 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5973 - val_loss: 0.5662 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4478
Epoch 16/100
640/640 [==============================] - 0s 218us/step - loss: 0.6124 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5759 - val_loss: 0.5727 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4454
Epoch 17/100
640/640 [==============================] - 0s 214us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5736 - val_loss: 0.5677 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4424
Epoch 18/100
640/640 [==============================] - 0s 215us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5761 - val_loss: 0.5682 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4425
Epoch 19/100
640/640 [==============================] - 0s 213us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5686 - val_loss: 0.5667 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4407
Epoch 20/100
640/640 [==============================] - 0s 221us/step - loss: 0.6094 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5843 - val_loss: 0.5684 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4489
Epoch 21/100
640/640 [==============================] - 0s 207us/step - loss: 0.6094 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5762 - val_loss: 0.5699 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4478
Epoch 22/100
640/640 [==============================] - 0s 202us/step - loss: 0.6117 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6027 - val_loss: 0.5667 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4443
Epoch 23/100
640/640 [==============================] - 0s 218us/step - loss: 0.6092 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5798 - val_loss: 0.5710 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4523
Epoch 24/100
640/640 [==============================] - 0s 207us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5799 - val_loss: 0.5707 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4489
Epoch 25/100
640/640 [==============================] - 0s 215us/step - loss: 0.6117 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5646 - val_loss: 0.5652 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4493
Epoch 26/100
640/640 [==============================] - 0s 209us/step - loss: 0.6089 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5724 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4474
Epoch 27/100
640/640 [==============================] - 0s 223us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5689 - val_loss: 0.5702 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4440
Epoch 28/100
640/640 [==============================] - 0s 215us/step - loss: 0.6091 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5731 - val_loss: 0.5698 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4434
Epoch 29/100
640/640 [==============================] - 0s 220us/step - loss: 0.6089 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5861 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4433
Epoch 30/100
640/640 [==============================] - 0s 213us/step - loss: 0.6088 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5727 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4448
Epoch 31/100
640/640 [==============================] - 0s 185us/step - loss: 0.6083 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5781 - val_loss: 0.5685 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4465
Epoch 32/100
640/640 [==============================] - 0s 205us/step - loss: 0.6082 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5660 - val_loss: 0.5683 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4432
Epoch 33/100
640/640 [==============================] - 0s 203us/step - loss: 0.6084 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5707 - val_loss: 0.5709 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4449
Epoch 34/100
640/640 [==============================] - 0s 209us/step - loss: 0.6075 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5793 - val_loss: 0.5688 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4456
Epoch 35/100
640/640 [==============================] - 0s 200us/step - loss: 0.6085 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5745 - val_loss: 0.5684 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4461
Epoch 36/100
640/640 [==============================] - 0s 215us/step - loss: 0.6069 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5754 - val_loss: 0.5720 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4445
Epoch 37/100
640/640 [==============================] - 0s 212us/step - loss: 0.6070 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5741 - val_loss: 0.5718 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4440
Epoch 38/100
640/640 [==============================] - 0s 218us/step - loss: 0.6087 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5640 - val_loss: 0.5695 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4429
Epoch 39/100
640/640 [==============================] - 0s 212us/step - loss: 0.6082 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5729 - val_loss: 0.5796 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4402
Epoch 40/100
640/640 [==============================] - 0s 211us/step - loss: 0.6064 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5619 - val_loss: 0.5716 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4455
Epoch 41/100
640/640 [==============================] - 0s 211us/step - loss: 0.6061 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5671 - val_loss: 0.5721 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4435
Epoch 42/100
640/640 [==============================] - 0s 211us/step - loss: 0.6058 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5645 - val_loss: 0.5737 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4450
Epoch 43/100
640/640 [==============================] - 0s 197us/step - loss: 0.6050 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5673 - val_loss: 0.5715 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4440
Epoch 44/100
640/640 [==============================] - 0s 204us/step - loss: 0.6061 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5717 - val_loss: 0.5752 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4445
Epoch 45/100
640/640 [==============================] - 0s 194us/step - loss: 0.6052 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5711 - val_loss: 0.5725 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4453
Epoch 46/100
640/640 [==============================] - 0s 198us/step - loss: 0.6056 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5667 - val_loss: 0.5767 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4443
Epoch 47/100
640/640 [==============================] - 0s 197us/step - loss: 0.6050 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5828 - val_loss: 0.5728 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4431
Epoch 48/100
640/640 [==============================] - 0s 201us/step - loss: 0.6052 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5679 - val_loss: 0.5744 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4562
Epoch 49/100
640/640 [==============================] - 0s 210us/step - loss: 0.6053 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5740 - val_loss: 0.5782 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4572
Epoch 50/100
640/640 [==============================] - 0s 210us/step - loss: 0.6050 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5623 - val_loss: 0.5728 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4566
Epoch 51/100
640/640 [==============================] - 0s 221us/step - loss: 0.6040 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5800 - val_loss: 0.5760 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4588
Epoch 52/100
640/640 [==============================] - 0s 214us/step - loss: 0.6040 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5747 - val_loss: 0.5759 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4578
Epoch 53/100
640/640 [==============================] - 0s 213us/step - loss: 0.6036 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5840 - val_loss: 0.5754 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4586
Epoch 54/100
640/640 [==============================] - 0s 221us/step - loss: 0.6044 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5879 - val_loss: 0.5772 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4589
Epoch 55/100
640/640 [==============================] - 0s 220us/step - loss: 0.6047 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5841 - val_loss: 0.5739 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4572
Epoch 56/100
640/640 [==============================] - 0s 214us/step - loss: 0.6036 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5754 - val_loss: 0.5748 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4603
Epoch 57/100
640/640 [==============================] - 0s 208us/step - loss: 0.6033 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5796 - val_loss: 0.5760 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4471
Epoch 58/100
640/640 [==============================] - 0s 216us/step - loss: 0.6037 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5836 - val_loss: 0.5792 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4488
Epoch 59/100
640/640 [==============================] - 0s 216us/step - loss: 0.6033 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5729 - val_loss: 0.5745 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4482
Epoch 60/100
640/640 [==============================] - 0s 210us/step - loss: 0.6035 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5878 - val_loss: 0.5770 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4492
Epoch 61/100
640/640 [==============================] - 0s 214us/step - loss: 0.6024 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5904 - val_loss: 0.5747 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4492
Epoch 62/100
640/640 [==============================] - 0s 211us/step - loss: 0.6025 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5912 - val_loss: 0.5761 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4514
Epoch 63/100
640/640 [==============================] - 0s 208us/step - loss: 0.6021 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5923 - val_loss: 0.5749 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4530
Epoch 64/100
640/640 [==============================] - 0s 194us/step - loss: 0.6020 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5830 - val_loss: 0.5768 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4513
Epoch 65/100
640/640 [==============================] - 0s 220us/step - loss: 0.6016 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5838 - val_loss: 0.5750 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4517
Epoch 66/100
640/640 [==============================] - 0s 205us/step - loss: 0.6015 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5893 - val_loss: 0.5758 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4533
Epoch 67/100
640/640 [==============================] - 0s 220us/step - loss: 0.6027 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5845 - val_loss: 0.5735 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4429
Epoch 68/100
640/640 [==============================] - 0s 213us/step - loss: 0.6014 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5913 - val_loss: 0.5784 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4532
Epoch 69/100
640/640 [==============================] - 0s 221us/step - loss: 0.6016 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5953 - val_loss: 0.5747 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4537
Epoch 70/100
640/640 [==============================] - 0s 221us/step - loss: 0.6006 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5928 - val_loss: 0.5759 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4520
Epoch 71/100
640/640 [==============================] - 0s 212us/step - loss: 0.6003 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5950 - val_loss: 0.5755 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4550
Epoch 72/100
640/640 [==============================] - 0s 214us/step - loss: 0.6021 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6046 - val_loss: 0.5760 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4540
Epoch 73/100
640/640 [==============================] - 0s 214us/step - loss: 0.5994 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6149 - val_loss: 0.5746 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4569
Epoch 74/100
640/640 [==============================] - 0s 214us/step - loss: 0.5997 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6064 - val_loss: 0.5741 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4575
Epoch 75/100
640/640 [==============================] - 0s 214us/step - loss: 0.5998 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6130 - val_loss: 0.5760 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4565
Epoch 76/100
640/640 [==============================] - 0s 206us/step - loss: 0.5993 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6107 - val_loss: 0.5771 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4559
Epoch 77/100
640/640 [==============================] - 0s 200us/step - loss: 0.6019 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6115 - val_loss: 0.5750 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4567
Epoch 78/100
640/640 [==============================] - 0s 216us/step - loss: 0.6001 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6029 - val_loss: 0.5788 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4566
Epoch 79/100
640/640 [==============================] - 0s 217us/step - loss: 0.5978 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6168 - val_loss: 0.5745 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4546
Epoch 80/100
640/640 [==============================] - 0s 212us/step - loss: 0.5979 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6088 - val_loss: 0.5760 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4529
Epoch 81/100
640/640 [==============================] - 0s 215us/step - loss: 0.5985 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6176 - val_loss: 0.5793 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4582
Epoch 82/100
640/640 [==============================] - 0s 202us/step - loss: 0.5988 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6144 - val_loss: 0.5761 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4594
Epoch 83/100
640/640 [==============================] - 0s 219us/step - loss: 0.5966 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6175 - val_loss: 0.5777 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4693
Epoch 84/100
640/640 [==============================] - 0s 214us/step - loss: 0.5959 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6132 - val_loss: 0.5768 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4603
Epoch 85/100
640/640 [==============================] - 0s 206us/step - loss: 0.5956 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6175 - val_loss: 0.5770 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4629
Epoch 86/100
640/640 [==============================] - 0s 200us/step - loss: 0.5958 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6312 - val_loss: 0.5766 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4621
Epoch 87/100
640/640 [==============================] - 0s 170us/step - loss: 0.5944 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0070 - gmeasure: 0.0232 - auc: 0.6302 - val_loss: 0.5796 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4854
Epoch 88/100
640/640 [==============================] - 0s 196us/step - loss: 0.5944 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.6243 - val_loss: 0.5778 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4872
Epoch 89/100
640/640 [==============================] - 0s 205us/step - loss: 0.5944 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0051 - gmeasure: 0.0199 - auc: 0.6337 - val_loss: 0.5763 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4885
Epoch 90/100
640/640 [==============================] - 0s 225us/step - loss: 0.5935 - binary_accuracy: 0.7016 - sensitivity: 0.9979 - specificity: 0.0048 - gmeasure: 0.0192 - auc: 0.6234 - val_loss: 0.5802 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4914
Epoch 91/100
640/640 [==============================] - 0s 215us/step - loss: 0.5935 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0059 - gmeasure: 0.0213 - auc: 0.6347 - val_loss: 0.5761 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4922
Epoch 92/100
640/640 [==============================] - 0s 206us/step - loss: 0.5936 - binary_accuracy: 0.7016 - sensitivity: 0.9978 - specificity: 0.0045 - gmeasure: 0.0187 - auc: 0.6285 - val_loss: 0.5796 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4720
Epoch 93/100
640/640 [==============================] - 0s 216us/step - loss: 0.5918 - binary_accuracy: 0.7016 - sensitivity: 0.9980 - specificity: 0.0040 - gmeasure: 0.0176 - auc: 0.6311 - val_loss: 0.5792 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4706
Epoch 94/100
640/640 [==============================] - 0s 217us/step - loss: 0.5916 - binary_accuracy: 0.7016 - sensitivity: 0.9977 - specificity: 0.0055 - gmeasure: 0.0206 - auc: 0.6263 - val_loss: 0.5805 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4830
Epoch 95/100
640/640 [==============================] - 0s 212us/step - loss: 0.5906 - binary_accuracy: 0.7016 - sensitivity: 0.9976 - specificity: 0.0055 - gmeasure: 0.0206 - auc: 0.6385 - val_loss: 0.5768 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4877
Epoch 96/100
640/640 [==============================] - 0s 214us/step - loss: 0.5932 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0048 - gmeasure: 0.0192 - auc: 0.6417 - val_loss: 0.5768 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4852
Epoch 97/100
640/640 [==============================] - 0s 192us/step - loss: 0.5941 - binary_accuracy: 0.7016 - sensitivity: 0.9976 - specificity: 0.0051 - gmeasure: 0.0199 - auc: 0.6412 - val_loss: 0.5885 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4813
Epoch 98/100
640/640 [==============================] - 0s 192us/step - loss: 0.5914 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0045 - gmeasure: 0.0187 - auc: 0.6512 - val_loss: 0.5741 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4848
Epoch 99/100
640/640 [==============================] - 0s 214us/step - loss: 0.5888 - binary_accuracy: 0.7016 - sensitivity: 0.9980 - specificity: 0.0043 - gmeasure: 0.0181 - auc: 0.6400 - val_loss: 0.5830 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4863
Epoch 100/100
640/640 [==============================] - 0s 221us/step - loss: 0.5900 - binary_accuracy: 0.7016 - sensitivity: 0.9977 - specificity: 0.0043 - gmeasure: 0.0181 - auc: 0.6441 - val_loss: 0.5792 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9937 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5032
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 15.50827431678772!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 5us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.01117086410522461!
[root    |INFO|build_network.py:175] Evaluation: [0.5856000185012817, 0.7099999785423279, 0.9964850544929504, 0.0043290043249726295, 0.06567943096160889, 0.6182411909103394]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 19us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010822296142578125!
[root    |INFO|build_network.py:175] Evaluation: [0.5753821730613708, 0.7562189102172852, 1.0, 0.0, 0.0, 0.5248388648033142]
[root    |INFO|deepbiome.py:179] Compute time : 16.846028566360474
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 785us/step - loss: 0.6634 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5278 - val_loss: 0.6307 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5970
Epoch 2/100
640/640 [==============================] - 0s 193us/step - loss: 0.6192 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5265 - val_loss: 0.6261 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5969
Epoch 3/100
640/640 [==============================] - 0s 213us/step - loss: 0.6209 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5314 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6038
Epoch 4/100
640/640 [==============================] - 0s 222us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5297 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6044
Epoch 5/100
640/640 [==============================] - 0s 202us/step - loss: 0.6192 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5291 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6039
Epoch 6/100
640/640 [==============================] - 0s 212us/step - loss: 0.6170 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5328 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6042
Epoch 7/100
640/640 [==============================] - 0s 209us/step - loss: 0.6182 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5392 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6147
Epoch 8/100
640/640 [==============================] - 0s 219us/step - loss: 0.6188 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5334 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6257
Epoch 9/100
640/640 [==============================] - 0s 203us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5365 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6255
Epoch 10/100
640/640 [==============================] - 0s 213us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5401 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6259
Epoch 11/100
640/640 [==============================] - 0s 218us/step - loss: 0.6182 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5428 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6498
Epoch 12/100
640/640 [==============================] - 0s 210us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5471 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6507
Epoch 13/100
640/640 [==============================] - 0s 212us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5643 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6485
Epoch 14/100
640/640 [==============================] - 0s 213us/step - loss: 0.6173 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5609 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6450
Epoch 15/100
640/640 [==============================] - 0s 219us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5542 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6424
Epoch 16/100
640/640 [==============================] - 0s 219us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6433
Epoch 17/100
640/640 [==============================] - 0s 215us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5631 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6467
Epoch 18/100
640/640 [==============================] - 0s 199us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5685 - val_loss: 0.6207 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6487
Epoch 19/100
640/640 [==============================] - 0s 212us/step - loss: 0.6173 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5742 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6459
Epoch 20/100
640/640 [==============================] - 0s 194us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5777 - val_loss: 0.6206 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6470
Epoch 21/100
640/640 [==============================] - 0s 211us/step - loss: 0.6173 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5816 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6414
Epoch 22/100
640/640 [==============================] - 0s 206us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5836 - val_loss: 0.6205 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6434
Epoch 23/100
640/640 [==============================] - 0s 219us/step - loss: 0.6171 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5796 - val_loss: 0.6205 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6428
Epoch 24/100
640/640 [==============================] - 0s 218us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5781 - val_loss: 0.6204 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6361
Epoch 25/100
640/640 [==============================] - 0s 220us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5952 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6414
Epoch 26/100
640/640 [==============================] - 0s 211us/step - loss: 0.6168 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5889 - val_loss: 0.6203 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6434
Epoch 27/100
640/640 [==============================] - 0s 223us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5859 - val_loss: 0.6203 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6369
Epoch 28/100
640/640 [==============================] - 0s 216us/step - loss: 0.6189 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5957 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6327
Epoch 29/100
640/640 [==============================] - 0s 221us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5899 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6328
Epoch 30/100
640/640 [==============================] - 0s 206us/step - loss: 0.6169 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5988 - val_loss: 0.6200 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6332
Epoch 31/100
640/640 [==============================] - 0s 211us/step - loss: 0.6167 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5949 - val_loss: 0.6202 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6249
Epoch 32/100
640/640 [==============================] - 0s 212us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6079 - val_loss: 0.6203 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6157
Epoch 33/100
640/640 [==============================] - 0s 219us/step - loss: 0.6171 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6086 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6020
Epoch 34/100
640/640 [==============================] - 0s 218us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6035 - val_loss: 0.6200 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6187
Epoch 35/100
640/640 [==============================] - 0s 212us/step - loss: 0.6154 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5993 - val_loss: 0.6199 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6116
Epoch 36/100
640/640 [==============================] - 0s 213us/step - loss: 0.6146 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6012 - val_loss: 0.6205 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5897
Epoch 37/100
640/640 [==============================] - 0s 212us/step - loss: 0.6143 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6007 - val_loss: 0.6201 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5867
Epoch 38/100
640/640 [==============================] - 0s 213us/step - loss: 0.6157 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6081 - val_loss: 0.6201 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5855
Epoch 39/100
640/640 [==============================] - 0s 222us/step - loss: 0.6135 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5988 - val_loss: 0.6203 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5789
Epoch 40/100
640/640 [==============================] - 0s 216us/step - loss: 0.6128 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5974 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5751
Epoch 41/100
640/640 [==============================] - 0s 221us/step - loss: 0.6115 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5932 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5746
Epoch 42/100
640/640 [==============================] - 0s 219us/step - loss: 0.6115 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5864 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5712
Epoch 43/100
640/640 [==============================] - 0s 215us/step - loss: 0.6116 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5919 - val_loss: 0.6229 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5787
Epoch 44/100
640/640 [==============================] - 0s 209us/step - loss: 0.6114 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6044 - val_loss: 0.6229 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5834
Epoch 45/100
640/640 [==============================] - 0s 212us/step - loss: 0.6088 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6005 - val_loss: 0.6241 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5824
Epoch 46/100
640/640 [==============================] - 0s 210us/step - loss: 0.6079 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5983 - val_loss: 0.6250 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5816
Epoch 47/100
640/640 [==============================] - 0s 215us/step - loss: 0.6066 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6042 - val_loss: 0.6248 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5831
Epoch 48/100
640/640 [==============================] - 0s 219us/step - loss: 0.6073 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6034 - val_loss: 0.6251 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5726
Epoch 49/100
640/640 [==============================] - 0s 217us/step - loss: 0.6053 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6176 - val_loss: 0.6240 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5758
Epoch 50/100
640/640 [==============================] - 0s 211us/step - loss: 0.6062 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6218 - val_loss: 0.6240 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5800
Epoch 51/100
640/640 [==============================] - 0s 219us/step - loss: 0.6071 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6193 - val_loss: 0.6252 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5684
Epoch 52/100
640/640 [==============================] - 0s 215us/step - loss: 0.6045 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6379 - val_loss: 0.6227 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5815
Epoch 53/100
640/640 [==============================] - 0s 225us/step - loss: 0.6043 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6353 - val_loss: 0.6236 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5689
Epoch 54/100
640/640 [==============================] - 0s 217us/step - loss: 0.6002 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6267 - val_loss: 0.6263 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5694
Epoch 55/100
640/640 [==============================] - 0s 193us/step - loss: 0.5978 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6534 - val_loss: 0.6249 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5799
Epoch 56/100
640/640 [==============================] - 0s 202us/step - loss: 0.5986 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6461 - val_loss: 0.6252 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5797
Epoch 57/100
640/640 [==============================] - 0s 211us/step - loss: 0.5995 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6419 - val_loss: 0.6286 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5801
Epoch 58/100
640/640 [==============================] - 0s 215us/step - loss: 0.5952 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6548 - val_loss: 0.6268 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5830
Epoch 59/100
640/640 [==============================] - 0s 207us/step - loss: 0.5979 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6516 - val_loss: 0.6303 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5796
Epoch 60/100
640/640 [==============================] - 0s 207us/step - loss: 0.5942 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6579 - val_loss: 0.6277 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5797
Epoch 61/100
640/640 [==============================] - 0s 220us/step - loss: 0.5911 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6582 - val_loss: 0.6340 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5792
Epoch 62/100
640/640 [==============================] - 0s 213us/step - loss: 0.5897 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6603 - val_loss: 0.6322 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5811
Epoch 63/100
640/640 [==============================] - 0s 215us/step - loss: 0.5919 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6760 - val_loss: 0.6321 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5773
Epoch 64/100
640/640 [==============================] - 0s 214us/step - loss: 0.5869 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6674 - val_loss: 0.6316 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5784
Epoch 65/100
640/640 [==============================] - 0s 206us/step - loss: 0.5861 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6716 - val_loss: 0.6354 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5777
Epoch 66/100
640/640 [==============================] - 0s 218us/step - loss: 0.5887 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6677 - val_loss: 0.6348 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 67/100
640/640 [==============================] - 0s 198us/step - loss: 0.5847 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6702 - val_loss: 0.6378 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5804
Epoch 68/100
640/640 [==============================] - 0s 188us/step - loss: 0.5865 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6725 - val_loss: 0.6373 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5793
Epoch 69/100
640/640 [==============================] - 0s 214us/step - loss: 0.5815 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6756 - val_loss: 0.6429 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5761
Epoch 70/100
640/640 [==============================] - 0s 210us/step - loss: 0.5810 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6717 - val_loss: 0.6382 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5915
Epoch 71/100
640/640 [==============================] - 0s 212us/step - loss: 0.5867 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6805 - val_loss: 0.6490 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5890
Epoch 72/100
640/640 [==============================] - 0s 216us/step - loss: 0.5796 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6867 - val_loss: 0.6404 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5900
Epoch 73/100
640/640 [==============================] - 0s 218us/step - loss: 0.5834 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6815 - val_loss: 0.6396 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5916
Epoch 74/100
640/640 [==============================] - 0s 220us/step - loss: 0.5794 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6800 - val_loss: 0.6396 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5911
Epoch 75/100
640/640 [==============================] - 0s 217us/step - loss: 0.5844 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6839 - val_loss: 0.6393 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5944
Epoch 76/100
640/640 [==============================] - 0s 211us/step - loss: 0.5822 - binary_accuracy: 0.6906 - sensitivity: 0.9965 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6810 - val_loss: 0.6383 - val_binary_accuracy: 0.6938 - val_sensitivity: 1.0000 - val_specificity: 0.0208 - val_gmeasure: 0.0722 - val_auc: 0.5953
Epoch 77/100
640/640 [==============================] - 0s 210us/step - loss: 0.5777 - binary_accuracy: 0.7016 - sensitivity: 0.9936 - specificity: 0.0462 - gmeasure: 0.1543 - auc: 0.6858 - val_loss: 0.6431 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5913
Epoch 78/100
640/640 [==============================] - 0s 210us/step - loss: 0.5772 - binary_accuracy: 0.6922 - sensitivity: 0.9977 - specificity: 0.0064 - gmeasure: 0.0222 - auc: 0.6801 - val_loss: 0.6405 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0514 - val_gmeasure: 0.1938 - val_auc: 0.6055
Epoch 79/100
640/640 [==============================] - 0s 202us/step - loss: 0.5761 - binary_accuracy: 0.7063 - sensitivity: 0.9912 - specificity: 0.0639 - gmeasure: 0.1918 - auc: 0.6824 - val_loss: 0.6437 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0322 - val_gmeasure: 0.1255 - val_auc: 0.5944
Epoch 80/100
640/640 [==============================] - 0s 222us/step - loss: 0.5748 - binary_accuracy: 0.6953 - sensitivity: 0.9957 - specificity: 0.0194 - gmeasure: 0.0769 - auc: 0.6773 - val_loss: 0.6417 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0514 - val_gmeasure: 0.1938 - val_auc: 0.6085
Epoch 81/100
640/640 [==============================] - 0s 218us/step - loss: 0.5733 - binary_accuracy: 0.7000 - sensitivity: 0.9911 - specificity: 0.0491 - gmeasure: 0.1692 - auc: 0.6867 - val_loss: 0.6456 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0514 - val_gmeasure: 0.1938 - val_auc: 0.6049
Epoch 82/100
640/640 [==============================] - 0s 206us/step - loss: 0.5744 - binary_accuracy: 0.7047 - sensitivity: 0.9938 - specificity: 0.0612 - gmeasure: 0.2011 - auc: 0.6923 - val_loss: 0.6530 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6096
Epoch 83/100
640/640 [==============================] - 0s 211us/step - loss: 0.5721 - binary_accuracy: 0.6969 - sensitivity: 0.9935 - specificity: 0.0300 - gmeasure: 0.1065 - auc: 0.6889 - val_loss: 0.6457 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9418 - val_specificity: 0.1461 - val_gmeasure: 0.3473 - val_auc: 0.5896
Epoch 84/100
640/640 [==============================] - 0s 224us/step - loss: 0.5736 - binary_accuracy: 0.7063 - sensitivity: 0.9912 - specificity: 0.0681 - gmeasure: 0.2090 - auc: 0.6829 - val_loss: 0.6489 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0514 - val_gmeasure: 0.1938 - val_auc: 0.5956
Epoch 85/100
640/640 [==============================] - 0s 215us/step - loss: 0.5712 - binary_accuracy: 0.7094 - sensitivity: 0.9868 - specificity: 0.0852 - gmeasure: 0.2465 - auc: 0.6912 - val_loss: 0.6547 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9911 - val_specificity: 0.0322 - val_gmeasure: 0.1245 - val_auc: 0.6016
Epoch 86/100
640/640 [==============================] - 0s 219us/step - loss: 0.5720 - binary_accuracy: 0.7063 - sensitivity: 0.9899 - specificity: 0.0723 - gmeasure: 0.2153 - auc: 0.6860 - val_loss: 0.6536 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0514 - val_gmeasure: 0.1938 - val_auc: 0.5934
Epoch 87/100
640/640 [==============================] - 0s 224us/step - loss: 0.5696 - binary_accuracy: 0.7109 - sensitivity: 0.9909 - specificity: 0.0834 - gmeasure: 0.2496 - auc: 0.6895 - val_loss: 0.6505 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9418 - val_specificity: 0.1348 - val_gmeasure: 0.3256 - val_auc: 0.5962
Epoch 88/100
640/640 [==============================] - 0s 208us/step - loss: 0.5688 - binary_accuracy: 0.7125 - sensitivity: 0.9912 - specificity: 0.0890 - gmeasure: 0.2687 - auc: 0.6935 - val_loss: 0.6523 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9418 - val_specificity: 0.1348 - val_gmeasure: 0.3256 - val_auc: 0.5719
Epoch 89/100
640/640 [==============================] - 0s 208us/step - loss: 0.5679 - binary_accuracy: 0.7156 - sensitivity: 0.9915 - specificity: 0.0965 - gmeasure: 0.2769 - auc: 0.6970 - val_loss: 0.6568 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9911 - val_specificity: 0.0322 - val_gmeasure: 0.1245 - val_auc: 0.5963
Epoch 90/100
640/640 [==============================] - 0s 202us/step - loss: 0.5679 - binary_accuracy: 0.7156 - sensitivity: 0.9928 - specificity: 0.0959 - gmeasure: 0.2741 - auc: 0.6902 - val_loss: 0.6567 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9418 - val_specificity: 0.0514 - val_gmeasure: 0.1919 - val_auc: 0.5905
Epoch 91/100
640/640 [==============================] - 0s 208us/step - loss: 0.5687 - binary_accuracy: 0.7031 - sensitivity: 0.9859 - specificity: 0.0597 - gmeasure: 0.1856 - auc: 0.7003 - val_loss: 0.6567 - val_binary_accuracy: 0.6625 - val_sensitivity: 0.8552 - val_specificity: 0.2679 - val_gmeasure: 0.4271 - val_auc: 0.5807
Epoch 92/100
640/640 [==============================] - 0s 191us/step - loss: 0.5735 - binary_accuracy: 0.7031 - sensitivity: 0.9466 - specificity: 0.1636 - gmeasure: 0.3811 - auc: 0.6962 - val_loss: 0.6627 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9911 - val_specificity: 0.0322 - val_gmeasure: 0.1245 - val_auc: 0.6052
Epoch 93/100
640/640 [==============================] - 0s 217us/step - loss: 0.5683 - binary_accuracy: 0.7141 - sensitivity: 0.9915 - specificity: 0.0893 - gmeasure: 0.2808 - auc: 0.7004 - val_loss: 0.6572 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9843 - val_specificity: 0.0514 - val_gmeasure: 0.1929 - val_auc: 0.5818
Epoch 94/100
640/640 [==============================] - 0s 219us/step - loss: 0.5663 - binary_accuracy: 0.7141 - sensitivity: 0.9841 - specificity: 0.1039 - gmeasure: 0.2758 - auc: 0.7053 - val_loss: 0.6594 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9777 - val_specificity: 0.1348 - val_gmeasure: 0.3363 - val_auc: 0.5774
Epoch 95/100
640/640 [==============================] - 0s 218us/step - loss: 0.5651 - binary_accuracy: 0.7172 - sensitivity: 0.9910 - specificity: 0.0973 - gmeasure: 0.2181 - auc: 0.7007 - val_loss: 0.6585 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9353 - val_specificity: 0.1461 - val_gmeasure: 0.3463 - val_auc: 0.5785
Epoch 96/100
640/640 [==============================] - 0s 213us/step - loss: 0.5655 - binary_accuracy: 0.7172 - sensitivity: 0.9782 - specificity: 0.1289 - gmeasure: 0.3476 - auc: 0.6960 - val_loss: 0.6631 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9710 - val_specificity: 0.0514 - val_gmeasure: 0.1910 - val_auc: 0.5769
Epoch 97/100
640/640 [==============================] - 0s 216us/step - loss: 0.5640 - binary_accuracy: 0.7109 - sensitivity: 0.9914 - specificity: 0.0766 - gmeasure: 0.2241 - auc: 0.7021 - val_loss: 0.6586 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.9064 - val_specificity: 0.2295 - val_gmeasure: 0.3973 - val_auc: 0.5802
Epoch 98/100
640/640 [==============================] - 0s 202us/step - loss: 0.5684 - binary_accuracy: 0.7063 - sensitivity: 0.9781 - specificity: 0.0990 - gmeasure: 0.2657 - auc: 0.6997 - val_loss: 0.6592 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9353 - val_specificity: 0.1461 - val_gmeasure: 0.3463 - val_auc: 0.5785
Epoch 99/100
640/640 [==============================] - 0s 195us/step - loss: 0.5668 - binary_accuracy: 0.7172 - sensitivity: 0.9718 - specificity: 0.1426 - gmeasure: 0.3298 - auc: 0.7069 - val_loss: 0.6665 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9710 - val_specificity: 0.1348 - val_gmeasure: 0.3353 - val_auc: 0.5880
Epoch 100/100
640/640 [==============================] - 0s 211us/step - loss: 0.5652 - binary_accuracy: 0.7156 - sensitivity: 0.9774 - specificity: 0.1299 - gmeasure: 0.3353 - auc: 0.7003 - val_loss: 0.6640 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9353 - val_specificity: 0.1348 - val_gmeasure: 0.3246 - val_auc: 0.5761
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 15.530826568603516!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.013373851776123047!
[root    |INFO|build_network.py:175] Evaluation: [0.5819013714790344, 0.7099999785423279, 0.9819168448448181, 0.10121457278728485, 0.31525275111198425, 0.6671669483184814]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 18us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010436296463012695!
[root    |INFO|build_network.py:175] Evaluation: [0.7333670854568481, 0.6399999856948853, 0.9338235259056091, 0.015625, 0.1207931786775589, 0.43669578433036804]
[root    |INFO|deepbiome.py:179] Compute time : 16.87532639503479
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.5625391  0.70208331 0.99280063 0.03518119 0.12697739 0.68988395]
[root    |INFO|deepbiome.py:189]        std : [0.0300357  0.01119586 0.00782864 0.04672609 0.13580416 0.06964795]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.61767799 0.69592039 0.97794118 0.00520833 0.04026439 0.56341401]
[root    |INFO|deepbiome.py:196]        std : [0.08278381 0.04754707 0.03119589 0.0073657  0.05694245 0.12229397]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">deepbiome_train</span></code> saves the trained model weights, evaluation results and history based on the path information from the configuration.</p>
<p>From the example above, we can check that <code class="docutils literal notranslate"><span class="pre">hist_*.json</span></code>, <code class="docutils literal notranslate"><span class="pre">weight_*.h5</span></code>, <code class="docutils literal notranslate"><span class="pre">test_eval.npy</span></code>, <code class="docutils literal notranslate"><span class="pre">train_eval.npy</span></code> files were saved.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[&#39;hist_0.json&#39;,
 &#39;weight_2.h5&#39;,
 &#39;test_eval.npy&#39;,
 &#39;weight_0.h5&#39;,
 &#39;train_eval.npy&#39;,
 &#39;hist_2.json&#39;,
 &#39;weight_1.h5&#39;,
 &#39;hist_1.json&#39;]
</pre></div>
</div>
</div>
<p>Lets check the history files.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_one_input_file_40_0.png" src="_images/example_with_one_input_file_40_0.png" />
</div>
</div>
<p>Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.5442847 , 0.69154227, 1.        , 0.        , 0.        ,
        0.72870737],
       [0.57538217, 0.75621891, 1.        , 0.        , 0.        ,
        0.52483886],
       [0.73336709, 0.63999999, 0.93382353, 0.015625  , 0.12079318,
        0.43669578]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.52011591, 0.68624997, 1.        , 0.        , 0.        ,
        0.7842437 ],
       [0.58560002, 0.70999998, 0.99648505, 0.004329  , 0.06567943,
        0.61824119],
       [0.58190137, 0.70999998, 0.98191684, 0.10121457, 0.31525275,
        0.66716695]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="5.-Load-the-pre-trained-network-for-training">
<h2>5. Load the pre-trained network for training<a class="headerlink" href="#5.-Load-the-pre-trained-network-for-training" title="Permalink to this headline">¶</a></h2>
<p>If you have a pre-trianed model, you warm_start next training using the pre-trained weights by setting the <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> option in <code class="docutils literal notranslate"><span class="pre">training_info</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>. The file path of the pre-trained weights passed in the <code class="docutils literal notranslate"><span class="pre">warm_start_model</span></code> option. Below is the example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">warm_start_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span><span class="s1">&#39;True&#39;</span><span class="p">,</span>
        <span class="s1">&#39;warm_start_model&#39;</span><span class="p">:</span><span class="s1">&#39;./example_result/weight.h5&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;200&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">warm_start_network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span>
                                                                       <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 674us/step - loss: 0.5209 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7779 - val_loss: 0.5028 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7387
Epoch 2/100
640/640 [==============================] - 0s 66us/step - loss: 0.5136 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7949 - val_loss: 0.4982 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7396
Epoch 3/100
640/640 [==============================] - 0s 79us/step - loss: 0.5125 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7776 - val_loss: 0.4973 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7351
Epoch 4/100
640/640 [==============================] - 0s 80us/step - loss: 0.5098 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8021 - val_loss: 0.4965 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7333
Epoch 5/100
640/640 [==============================] - 0s 75us/step - loss: 0.5078 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7889 - val_loss: 0.5013 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7312
Epoch 6/100
640/640 [==============================] - 0s 78us/step - loss: 0.5068 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7791 - val_loss: 0.5008 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7323
Epoch 7/100
640/640 [==============================] - 0s 77us/step - loss: 0.5045 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7593 - val_loss: 0.4941 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7338
Epoch 8/100
640/640 [==============================] - 0s 72us/step - loss: 0.5031 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8055 - val_loss: 0.4882 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7357
Epoch 9/100
640/640 [==============================] - 0s 72us/step - loss: 0.5030 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7902 - val_loss: 0.4871 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7346
Epoch 10/100
640/640 [==============================] - 0s 74us/step - loss: 0.5007 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7743 - val_loss: 0.4913 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7347
Epoch 11/100
640/640 [==============================] - 0s 72us/step - loss: 0.4988 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7913 - val_loss: 0.4960 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7325
Epoch 12/100
640/640 [==============================] - 0s 73us/step - loss: 0.4984 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7945 - val_loss: 0.4988 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7303
Epoch 13/100
640/640 [==============================] - 0s 72us/step - loss: 0.4976 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7808 - val_loss: 0.4896 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7294
Epoch 14/100
640/640 [==============================] - 0s 70us/step - loss: 0.4947 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7783 - val_loss: 0.4808 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7314
Epoch 15/100
640/640 [==============================] - 0s 74us/step - loss: 0.4988 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7964 - val_loss: 0.4801 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7308
Epoch 16/100
640/640 [==============================] - 0s 75us/step - loss: 0.4944 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7751 - val_loss: 0.4846 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7266
Epoch 17/100
640/640 [==============================] - 0s 70us/step - loss: 0.4943 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7989 - val_loss: 0.4904 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7269
Epoch 18/100
640/640 [==============================] - 0s 73us/step - loss: 0.4917 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7735 - val_loss: 0.4797 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7284
Epoch 19/100
640/640 [==============================] - 0s 75us/step - loss: 0.4901 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7681 - val_loss: 0.4779 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7331
Epoch 20/100
640/640 [==============================] - 0s 73us/step - loss: 0.4921 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8057 - val_loss: 0.4773 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7353
Epoch 21/100
640/640 [==============================] - 0s 69us/step - loss: 0.4893 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8071 - val_loss: 0.4803 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7379
Epoch 22/100
640/640 [==============================] - 0s 74us/step - loss: 0.4879 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7872 - val_loss: 0.4828 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7387
Epoch 23/100
640/640 [==============================] - 0s 72us/step - loss: 0.4878 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8230 - val_loss: 0.4800 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7411
Epoch 24/100
640/640 [==============================] - 0s 66us/step - loss: 0.4865 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7856 - val_loss: 0.4770 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7400
Epoch 25/100
640/640 [==============================] - 0s 71us/step - loss: 0.4863 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7667 - val_loss: 0.4769 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 26/100
640/640 [==============================] - 0s 72us/step - loss: 0.4855 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8206 - val_loss: 0.4781 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7400
Epoch 27/100
640/640 [==============================] - ETA: 0s - loss: 0.5126 - binary_accuracy: 0.6550 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.78 - 0s 70us/step - loss: 0.4832 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7918 - val_loss: 0.4860 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7388
Epoch 28/100
640/640 [==============================] - 0s 72us/step - loss: 0.4869 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8075 - val_loss: 0.4964 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7385
Epoch 29/100
640/640 [==============================] - 0s 75us/step - loss: 0.4878 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8018 - val_loss: 0.4853 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7398
Epoch 30/100
640/640 [==============================] - 0s 73us/step - loss: 0.4827 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7936 - val_loss: 0.4773 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 31/100
640/640 [==============================] - 0s 72us/step - loss: 0.4831 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8105 - val_loss: 0.4777 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 32/100
640/640 [==============================] - 0s 71us/step - loss: 0.4821 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8034 - val_loss: 0.4843 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7400
Epoch 33/100
640/640 [==============================] - 0s 71us/step - loss: 0.4809 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8209 - val_loss: 0.4819 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7388
Epoch 34/100
640/640 [==============================] - 0s 78us/step - loss: 0.4794 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8052 - val_loss: 0.4870 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7370
Epoch 35/100
640/640 [==============================] - 0s 62us/step - loss: 0.4801 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8108 - val_loss: 0.4896 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7366
Epoch 36/100
640/640 [==============================] - 0s 69us/step - loss: 0.4807 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7890 - val_loss: 0.4898 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7370
Epoch 37/100
640/640 [==============================] - 0s 74us/step - loss: 0.4795 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7804 - val_loss: 0.4843 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7394
Epoch 38/100
640/640 [==============================] - 0s 73us/step - loss: 0.4777 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7829 - val_loss: 0.4821 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 39/100
640/640 [==============================] - 0s 74us/step - loss: 0.4776 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8071 - val_loss: 0.4828 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7401
Epoch 40/100
640/640 [==============================] - 0s 76us/step - loss: 0.4769 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7750 - val_loss: 0.4843 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7394
Epoch 41/100
640/640 [==============================] - 0s 72us/step - loss: 0.4765 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7889 - val_loss: 0.4855 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7394
Epoch 42/100
640/640 [==============================] - 0s 81us/step - loss: 0.4757 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8077 - val_loss: 0.4840 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7394
Epoch 43/100
640/640 [==============================] - 0s 74us/step - loss: 0.4753 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8064 - val_loss: 0.4882 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7379
Epoch 44/100
640/640 [==============================] - 0s 76us/step - loss: 0.4755 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7793 - val_loss: 0.4914 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7377
Epoch 45/100
640/640 [==============================] - 0s 73us/step - loss: 0.4744 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8103 - val_loss: 0.4865 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7379
Epoch 46/100
640/640 [==============================] - 0s 68us/step - loss: 0.4744 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7799 - val_loss: 0.4882 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7379
Epoch 47/100
640/640 [==============================] - 0s 68us/step - loss: 0.4754 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8059 - val_loss: 0.4943 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7364
Epoch 48/100
640/640 [==============================] - 0s 71us/step - loss: 0.4742 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8113 - val_loss: 0.4914 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7372
Epoch 49/100
640/640 [==============================] - 0s 77us/step - loss: 0.4729 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8270 - val_loss: 0.5000 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7347
Epoch 50/100
640/640 [==============================] - 0s 75us/step - loss: 0.4744 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7766 - val_loss: 0.5018 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7353
Epoch 51/100
640/640 [==============================] - 0s 75us/step - loss: 0.4721 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7979 - val_loss: 0.4920 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7383
Epoch 52/100
640/640 [==============================] - 0s 79us/step - loss: 0.4737 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7961 - val_loss: 0.4903 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7396
Epoch 53/100
640/640 [==============================] - 0s 71us/step - loss: 0.4724 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8057 - val_loss: 0.4952 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7372
Epoch 54/100
640/640 [==============================] - 0s 75us/step - loss: 0.4697 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7940 - val_loss: 0.5012 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7368
Epoch 55/100
640/640 [==============================] - 0s 72us/step - loss: 0.4708 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7983 - val_loss: 0.4971 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7394
Epoch 56/100
640/640 [==============================] - 0s 64us/step - loss: 0.4704 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8176 - val_loss: 0.4905 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7446
Epoch 57/100
640/640 [==============================] - 0s 69us/step - loss: 0.4733 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7928 - val_loss: 0.4929 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7446
Epoch 58/100
640/640 [==============================] - 0s 72us/step - loss: 0.4696 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8242 - val_loss: 0.5083 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7427
Epoch 59/100
640/640 [==============================] - 0s 73us/step - loss: 0.4724 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7870 - val_loss: 0.5073 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7429
Epoch 60/100
640/640 [==============================] - 0s 72us/step - loss: 0.4683 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8037 - val_loss: 0.4983 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7441
Epoch 61/100
640/640 [==============================] - 0s 74us/step - loss: 0.4692 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8281 - val_loss: 0.4967 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7452
Epoch 62/100
640/640 [==============================] - 0s 76us/step - loss: 0.4669 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8256 - val_loss: 0.5095 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7413
Epoch 63/100
640/640 [==============================] - 0s 69us/step - loss: 0.4676 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7953 - val_loss: 0.5137 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7405
Epoch 64/100
640/640 [==============================] - 0s 67us/step - loss: 0.4670 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7849 - val_loss: 0.5055 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7416
Epoch 65/100
640/640 [==============================] - 0s 72us/step - loss: 0.4654 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8087 - val_loss: 0.5034 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7423
Epoch 66/100
640/640 [==============================] - 0s 73us/step - loss: 0.4654 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7891 - val_loss: 0.5051 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7426
Epoch 67/100
640/640 [==============================] - 0s 75us/step - loss: 0.4657 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8092 - val_loss: 0.5116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7420
Epoch 68/100
640/640 [==============================] - 0s 65us/step - loss: 0.4640 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8035 - val_loss: 0.5131 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7416
Epoch 69/100
640/640 [==============================] - 0s 72us/step - loss: 0.4636 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8259 - val_loss: 0.5116 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7437
Epoch 70/100
640/640 [==============================] - 0s 72us/step - loss: 0.4631 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8113 - val_loss: 0.5155 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7442
Epoch 71/100
640/640 [==============================] - 0s 71us/step - loss: 0.4632 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7575 - val_loss: 0.5119 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7450
Epoch 72/100
640/640 [==============================] - 0s 71us/step - loss: 0.4621 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8143 - val_loss: 0.5125 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7435
Epoch 73/100
640/640 [==============================] - 0s 64us/step - loss: 0.4618 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8235 - val_loss: 0.5155 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7418
Epoch 74/100
640/640 [==============================] - 0s 67us/step - loss: 0.4628 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8044 - val_loss: 0.5218 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7411
Epoch 75/100
640/640 [==============================] - 0s 72us/step - loss: 0.4638 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8304 - val_loss: 0.5164 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7413
Epoch 76/100
640/640 [==============================] - 0s 72us/step - loss: 0.4612 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8318 - val_loss: 0.5150 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7424
Epoch 77/100
640/640 [==============================] - 0s 76us/step - loss: 0.4599 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8157 - val_loss: 0.5211 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7427
Epoch 78/100
640/640 [==============================] - 0s 75us/step - loss: 0.4602 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8178 - val_loss: 0.5180 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7433
Epoch 79/100
640/640 [==============================] - 0s 68us/step - loss: 0.4595 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8134 - val_loss: 0.5172 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7435
Epoch 80/100
640/640 [==============================] - 0s 66us/step - loss: 0.4586 - binary_accuracy: 0.6984 - sensitivity: 0.9737 - specificity: 0.0927 - gmeasure: 0.2542 - auc: 0.8105 - val_loss: 0.5152 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9464 - val_specificity: 0.1042 - val_gmeasure: 0.3140 - val_auc: 0.7440
Epoch 81/100
640/640 [==============================] - 0s 71us/step - loss: 0.4588 - binary_accuracy: 0.7281 - sensitivity: 0.9605 - specificity: 0.2346 - gmeasure: 0.4700 - auc: 0.8281 - val_loss: 0.5171 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9107 - val_specificity: 0.2292 - val_gmeasure: 0.4568 - val_auc: 0.7444
Epoch 82/100
640/640 [==============================] - 0s 64us/step - loss: 0.4581 - binary_accuracy: 0.7516 - sensitivity: 0.9221 - specificity: 0.3913 - gmeasure: 0.5974 - auc: 0.8047 - val_loss: 0.5148 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.8839 - val_specificity: 0.2500 - val_gmeasure: 0.4701 - val_auc: 0.7455
Epoch 83/100
640/640 [==============================] - 0s 66us/step - loss: 0.4595 - binary_accuracy: 0.7547 - sensitivity: 0.8812 - specificity: 0.4685 - gmeasure: 0.6342 - auc: 0.8388 - val_loss: 0.5170 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9107 - val_specificity: 0.1667 - val_gmeasure: 0.3896 - val_auc: 0.7448
Epoch 84/100
640/640 [==============================] - 0s 69us/step - loss: 0.4588 - binary_accuracy: 0.7203 - sensitivity: 0.9712 - specificity: 0.1723 - gmeasure: 0.3946 - auc: 0.8059 - val_loss: 0.5319 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9821 - val_specificity: 0.0417 - val_gmeasure: 0.2023 - val_auc: 0.7455
Epoch 85/100
640/640 [==============================] - 0s 74us/step - loss: 0.4595 - binary_accuracy: 0.7109 - sensitivity: 0.9745 - specificity: 0.1608 - gmeasure: 0.3895 - auc: 0.8372 - val_loss: 0.5180 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9107 - val_specificity: 0.2292 - val_gmeasure: 0.4568 - val_auc: 0.7487
Epoch 86/100
640/640 [==============================] - 0s 72us/step - loss: 0.4567 - binary_accuracy: 0.7547 - sensitivity: 0.8885 - specificity: 0.5114 - gmeasure: 0.6697 - auc: 0.8195 - val_loss: 0.5149 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9107 - val_specificity: 0.1667 - val_gmeasure: 0.3896 - val_auc: 0.7500
Epoch 87/100
640/640 [==============================] - 0s 76us/step - loss: 0.4589 - binary_accuracy: 0.7031 - sensitivity: 0.9800 - specificity: 0.1136 - gmeasure: 0.2526 - auc: 0.8237 - val_loss: 0.5275 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7509
Epoch 88/100
640/640 [==============================] - 0s 74us/step - loss: 0.4587 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8133 - val_loss: 0.5237 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7519
Epoch 89/100
640/640 [==============================] - 0s 71us/step - loss: 0.4563 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8218 - val_loss: 0.5149 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7537
Epoch 90/100
640/640 [==============================] - 0s 71us/step - loss: 0.4562 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8225 - val_loss: 0.5166 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7545
Epoch 91/100
640/640 [==============================] - 0s 72us/step - loss: 0.4550 - binary_accuracy: 0.6844 - sensitivity: 1.0000 - specificity: 0.0357 - gmeasure: 0.0945 - auc: 0.7881 - val_loss: 0.5242 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7543
Epoch 92/100
640/640 [==============================] - 0s 73us/step - loss: 0.4542 - binary_accuracy: 0.6875 - sensitivity: 1.0000 - specificity: 0.0393 - gmeasure: 0.1519 - auc: 0.8322 - val_loss: 0.5285 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7545
Epoch 93/100
640/640 [==============================] - 0s 74us/step - loss: 0.4551 - binary_accuracy: 0.6844 - sensitivity: 1.0000 - specificity: 0.0041 - gmeasure: 0.0320 - auc: 0.8349 - val_loss: 0.5217 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7554
Epoch 94/100
640/640 [==============================] - 0s 73us/step - loss: 0.4530 - binary_accuracy: 0.6875 - sensitivity: 1.0000 - specificity: 0.0114 - gmeasure: 0.0741 - auc: 0.8268 - val_loss: 0.5211 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7545
Epoch 95/100
640/640 [==============================] - 0s 70us/step - loss: 0.4522 - binary_accuracy: 0.6891 - sensitivity: 0.9982 - specificity: 0.0194 - gmeasure: 0.1160 - auc: 0.8377 - val_loss: 0.5256 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0208 - val_gmeasure: 0.1437 - val_auc: 0.7533
Epoch 96/100
640/640 [==============================] - 0s 77us/step - loss: 0.4521 - binary_accuracy: 0.7125 - sensitivity: 0.9777 - specificity: 0.1337 - gmeasure: 0.3382 - auc: 0.8257 - val_loss: 0.5194 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9107 - val_specificity: 0.2708 - val_gmeasure: 0.4966 - val_auc: 0.7539
Epoch 97/100
640/640 [==============================] - 0s 71us/step - loss: 0.4514 - binary_accuracy: 0.7453 - sensitivity: 0.7774 - specificity: 0.6043 - gmeasure: 0.6771 - auc: 0.8082 - val_loss: 0.5154 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.6339 - val_specificity: 0.7708 - val_gmeasure: 0.6990 - val_auc: 0.7567
Epoch 98/100
640/640 [==============================] - 0s 72us/step - loss: 0.4531 - binary_accuracy: 0.6812 - sensitivity: 0.5464 - specificity: 0.8844 - gmeasure: 0.6935 - auc: 0.8090 - val_loss: 0.5233 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.6964 - val_specificity: 0.7083 - val_gmeasure: 0.7024 - val_auc: 0.7561
Epoch 99/100
640/640 [==============================] - 0s 71us/step - loss: 0.4522 - binary_accuracy: 0.7406 - sensitivity: 0.8400 - specificity: 0.4966 - gmeasure: 0.6048 - auc: 0.7880 - val_loss: 0.5265 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9643 - val_specificity: 0.0417 - val_gmeasure: 0.2004 - val_auc: 0.7582
Epoch 100/100
640/640 [==============================] - 0s 76us/step - loss: 0.4505 - binary_accuracy: 0.7141 - sensitivity: 0.9874 - specificity: 0.1396 - gmeasure: 0.3701 - auc: 0.8495 - val_loss: 0.5115 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9911 - val_specificity: 0.0208 - val_gmeasure: 0.1437 - val_auc: 0.7600
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 6.599108457565308!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 6us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.011509180068969727!
[root    |INFO|build_network.py:175] Evaluation: [0.46618956327438354, 0.6974999904632568, 0.994535505771637, 0.04780876636505127, 0.2180539220571518, 0.8145197033882141]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 24us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.012199163436889648!
[root    |INFO|build_network.py:175] Evaluation: [0.5137165784835815, 0.6865671873092651, 0.9928057789802551, 0.0, 0.0, 0.7464609146118164]
[root    |INFO|deepbiome.py:179] Compute time : 8.093743562698364
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 663us/step - loss: 0.5891 - binary_accuracy: 0.7016 - sensitivity: 0.9982 - specificity: 0.0050 - gmeasure: 0.0354 - auc: 0.6714 - val_loss: 0.5786 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4944
Epoch 2/100
640/640 [==============================] - 0s 70us/step - loss: 0.5871 - binary_accuracy: 0.7016 - sensitivity: 0.9983 - specificity: 0.0043 - gmeasure: 0.0328 - auc: 0.6247 - val_loss: 0.5779 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4956
Epoch 3/100
640/640 [==============================] - 0s 73us/step - loss: 0.5864 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0042 - gmeasure: 0.0323 - auc: 0.6933 - val_loss: 0.5778 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4940
Epoch 4/100
640/640 [==============================] - 0s 76us/step - loss: 0.5864 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0037 - gmeasure: 0.0305 - auc: 0.6136 - val_loss: 0.5773 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4938
Epoch 5/100
640/640 [==============================] - 0s 73us/step - loss: 0.5853 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0039 - gmeasure: 0.0312 - auc: 0.6414 - val_loss: 0.5810 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4929
Epoch 6/100
640/640 [==============================] - 0s 73us/step - loss: 0.5852 - binary_accuracy: 0.7016 - sensitivity: 0.9922 - specificity: 0.0045 - gmeasure: 0.0337 - auc: 0.6862 - val_loss: 0.5790 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4948
Epoch 7/100
640/640 [==============================] - 0s 77us/step - loss: 0.5851 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0040 - gmeasure: 0.0315 - auc: 0.6445 - val_loss: 0.5770 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4965
Epoch 8/100
640/640 [==============================] - 0s 70us/step - loss: 0.5841 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0037 - gmeasure: 0.0303 - auc: 0.6713 - val_loss: 0.5793 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4992
Epoch 9/100
640/640 [==============================] - 0s 74us/step - loss: 0.5846 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0036 - gmeasure: 0.0299 - auc: 0.6058 - val_loss: 0.5791 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4998
Epoch 10/100
640/640 [==============================] - 0s 75us/step - loss: 0.5844 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0046 - gmeasure: 0.0340 - auc: 0.6313 - val_loss: 0.5761 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5029
Epoch 11/100
640/640 [==============================] - 0s 74us/step - loss: 0.5849 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0035 - gmeasure: 0.0297 - auc: 0.6540 - val_loss: 0.5754 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5060
Epoch 12/100
640/640 [==============================] - 0s 75us/step - loss: 0.5839 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0047 - gmeasure: 0.0343 - auc: 0.6165 - val_loss: 0.5780 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5065
Epoch 13/100
640/640 [==============================] - 0s 73us/step - loss: 0.5831 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0041 - gmeasure: 0.0320 - auc: 0.6646 - val_loss: 0.5823 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5060
Epoch 14/100
640/640 [==============================] - 0s 72us/step - loss: 0.5846 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0046 - gmeasure: 0.0340 - auc: 0.6487 - val_loss: 0.5849 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5071
Epoch 15/100
640/640 [==============================] - 0s 69us/step - loss: 0.5854 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0044 - gmeasure: 0.0331 - auc: 0.6466 - val_loss: 0.5795 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5079
Epoch 16/100
640/640 [==============================] - 0s 68us/step - loss: 0.5828 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0051 - gmeasure: 0.0357 - auc: 0.6708 - val_loss: 0.5771 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5092
Epoch 17/100
640/640 [==============================] - 0s 71us/step - loss: 0.5824 - binary_accuracy: 0.7063 - sensitivity: 1.0000 - specificity: 0.0132 - gmeasure: 0.0788 - auc: 0.6323 - val_loss: 0.5763 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5102
Epoch 18/100
640/640 [==============================] - 0s 76us/step - loss: 0.5819 - binary_accuracy: 0.7063 - sensitivity: 1.0000 - specificity: 0.0109 - gmeasure: 0.0730 - auc: 0.6422 - val_loss: 0.5764 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5106
Epoch 19/100
640/640 [==============================] - 0s 72us/step - loss: 0.5823 - binary_accuracy: 0.7063 - sensitivity: 1.0000 - specificity: 0.0121 - gmeasure: 0.0767 - auc: 0.6783 - val_loss: 0.5766 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5113
Epoch 20/100
640/640 [==============================] - 0s 75us/step - loss: 0.5824 - binary_accuracy: 0.7063 - sensitivity: 1.0000 - specificity: 0.0128 - gmeasure: 0.0979 - auc: 0.6350 - val_loss: 0.5805 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5113
Epoch 21/100
640/640 [==============================] - 0s 75us/step - loss: 0.5810 - binary_accuracy: 0.7094 - sensitivity: 0.9983 - specificity: 0.0231 - gmeasure: 0.1057 - auc: 0.6199 - val_loss: 0.5817 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5131
Epoch 22/100
640/640 [==============================] - 0s 70us/step - loss: 0.5808 - binary_accuracy: 0.7094 - sensitivity: 0.9981 - specificity: 0.0264 - gmeasure: 0.1362 - auc: 0.6720 - val_loss: 0.5789 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5142
Epoch 23/100
640/640 [==============================] - 0s 69us/step - loss: 0.5808 - binary_accuracy: 0.7078 - sensitivity: 0.9984 - specificity: 0.0178 - gmeasure: 0.0939 - auc: 0.6672 - val_loss: 0.5778 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5148
Epoch 24/100
640/640 [==============================] - 0s 72us/step - loss: 0.5815 - binary_accuracy: 0.7063 - sensitivity: 1.0000 - specificity: 0.0127 - gmeasure: 0.0976 - auc: 0.6675 - val_loss: 0.5772 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5165
Epoch 25/100
640/640 [==============================] - 0s 75us/step - loss: 0.5807 - binary_accuracy: 0.7063 - sensitivity: 0.9983 - specificity: 0.0166 - gmeasure: 0.0886 - auc: 0.6842 - val_loss: 0.5820 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5125
Epoch 26/100
640/640 [==============================] - 0s 74us/step - loss: 0.5821 - binary_accuracy: 0.7109 - sensitivity: 0.9882 - specificity: 0.0622 - gmeasure: 0.2113 - auc: 0.6536 - val_loss: 0.5853 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5108
Epoch 27/100
640/640 [==============================] - 0s 76us/step - loss: 0.5795 - binary_accuracy: 0.7125 - sensitivity: 0.9948 - specificity: 0.0723 - gmeasure: 0.2583 - auc: 0.6691 - val_loss: 0.5801 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5096
Epoch 28/100
640/640 [==============================] - 0s 72us/step - loss: 0.5828 - binary_accuracy: 0.7047 - sensitivity: 0.9982 - specificity: 0.0130 - gmeasure: 0.0795 - auc: 0.6616 - val_loss: 0.5797 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5096
Epoch 29/100
640/640 [==============================] - 0s 73us/step - loss: 0.5792 - binary_accuracy: 0.7078 - sensitivity: 1.0000 - specificity: 0.0170 - gmeasure: 0.1116 - auc: 0.6492 - val_loss: 0.5840 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5067
Epoch 30/100
640/640 [==============================] - 0s 74us/step - loss: 0.5827 - binary_accuracy: 0.7078 - sensitivity: 0.9889 - specificity: 0.0398 - gmeasure: 0.1699 - auc: 0.6723 - val_loss: 0.5924 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9583 - val_specificity: 0.0250 - val_gmeasure: 0.1548 - val_auc: 0.5060
Epoch 31/100
640/640 [==============================] - 0s 74us/step - loss: 0.5824 - binary_accuracy: 0.7094 - sensitivity: 0.9858 - specificity: 0.0669 - gmeasure: 0.2544 - auc: 0.6576 - val_loss: 0.5821 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5098
Epoch 32/100
640/640 [==============================] - 0s 76us/step - loss: 0.5783 - binary_accuracy: 0.7109 - sensitivity: 0.9964 - specificity: 0.0339 - gmeasure: 0.1505 - auc: 0.6922 - val_loss: 0.5775 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5127
Epoch 33/100
640/640 [==============================] - 0s 74us/step - loss: 0.5800 - binary_accuracy: 0.7094 - sensitivity: 1.0000 - specificity: 0.0401 - gmeasure: 0.1685 - auc: 0.6779 - val_loss: 0.5771 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5121
Epoch 34/100
640/640 [==============================] - 0s 68us/step - loss: 0.5794 - binary_accuracy: 0.7094 - sensitivity: 1.0000 - specificity: 0.0202 - gmeasure: 0.0955 - auc: 0.6459 - val_loss: 0.5780 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5142
Epoch 35/100
640/640 [==============================] - 0s 73us/step - loss: 0.5779 - binary_accuracy: 0.7125 - sensitivity: 0.9981 - specificity: 0.0556 - gmeasure: 0.2255 - auc: 0.6456 - val_loss: 0.5799 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5152
Epoch 36/100
640/640 [==============================] - 0s 73us/step - loss: 0.5793 - binary_accuracy: 0.7078 - sensitivity: 0.9891 - specificity: 0.0404 - gmeasure: 0.1698 - auc: 0.6256 - val_loss: 0.5838 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5133
Epoch 37/100
640/640 [==============================] - 0s 74us/step - loss: 0.5781 - binary_accuracy: 0.7094 - sensitivity: 0.9910 - specificity: 0.0431 - gmeasure: 0.1457 - auc: 0.6773 - val_loss: 0.5786 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5156
Epoch 38/100
640/640 [==============================] - 0s 72us/step - loss: 0.5799 - binary_accuracy: 0.7109 - sensitivity: 0.9983 - specificity: 0.0310 - gmeasure: 0.1456 - auc: 0.6806 - val_loss: 0.5784 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5171
Epoch 39/100
640/640 [==============================] - 0s 77us/step - loss: 0.5796 - binary_accuracy: 0.7109 - sensitivity: 0.9864 - specificity: 0.0393 - gmeasure: 0.1676 - auc: 0.6538 - val_loss: 0.5830 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5181
Epoch 40/100
640/640 [==============================] - 0s 75us/step - loss: 0.5775 - binary_accuracy: 0.7109 - sensitivity: 0.9830 - specificity: 0.0492 - gmeasure: 0.1902 - auc: 0.6541 - val_loss: 0.5820 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5171
Epoch 41/100
640/640 [==============================] - 0s 74us/step - loss: 0.5780 - binary_accuracy: 0.7109 - sensitivity: 0.9932 - specificity: 0.0562 - gmeasure: 0.2340 - auc: 0.6577 - val_loss: 0.5785 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5185
Epoch 42/100
640/640 [==============================] - 0s 72us/step - loss: 0.5767 - binary_accuracy: 0.7125 - sensitivity: 0.9965 - specificity: 0.0579 - gmeasure: 0.2341 - auc: 0.6713 - val_loss: 0.5795 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5183
Epoch 43/100
640/640 [==============================] - 0s 77us/step - loss: 0.5762 - binary_accuracy: 0.7125 - sensitivity: 0.9947 - specificity: 0.0547 - gmeasure: 0.2316 - auc: 0.6578 - val_loss: 0.5797 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5192
Epoch 44/100
640/640 [==============================] - 0s 73us/step - loss: 0.5758 - binary_accuracy: 0.7078 - sensitivity: 0.9818 - specificity: 0.0424 - gmeasure: 0.1766 - auc: 0.6365 - val_loss: 0.5817 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5208
Epoch 45/100
640/640 [==============================] - 0s 74us/step - loss: 0.5764 - binary_accuracy: 0.7109 - sensitivity: 0.9892 - specificity: 0.0648 - gmeasure: 0.2515 - auc: 0.6499 - val_loss: 0.5800 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5231
Epoch 46/100
640/640 [==============================] - 0s 74us/step - loss: 0.5759 - binary_accuracy: 0.7109 - sensitivity: 0.9910 - specificity: 0.0637 - gmeasure: 0.2426 - auc: 0.6761 - val_loss: 0.5793 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5225
Epoch 47/100
640/640 [==============================] - 0s 72us/step - loss: 0.5755 - binary_accuracy: 0.7109 - sensitivity: 0.9912 - specificity: 0.0453 - gmeasure: 0.1830 - auc: 0.6750 - val_loss: 0.5776 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5221
Epoch 48/100
640/640 [==============================] - 0s 76us/step - loss: 0.5761 - binary_accuracy: 0.7109 - sensitivity: 0.9947 - specificity: 0.0702 - gmeasure: 0.2125 - auc: 0.6779 - val_loss: 0.5771 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5233
Epoch 49/100
640/640 [==============================] - 0s 74us/step - loss: 0.5771 - binary_accuracy: 0.7141 - sensitivity: 0.9965 - specificity: 0.0629 - gmeasure: 0.2349 - auc: 0.6547 - val_loss: 0.5784 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5223
Epoch 50/100
640/640 [==============================] - 0s 65us/step - loss: 0.5761 - binary_accuracy: 0.7109 - sensitivity: 0.9827 - specificity: 0.0856 - gmeasure: 0.2733 - auc: 0.7132 - val_loss: 0.5806 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5204
Epoch 51/100
640/640 [==============================] - 0s 64us/step - loss: 0.5743 - binary_accuracy: 0.7125 - sensitivity: 0.9824 - specificity: 0.0749 - gmeasure: 0.2661 - auc: 0.6541 - val_loss: 0.5793 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5179
Epoch 52/100
640/640 [==============================] - 0s 69us/step - loss: 0.5749 - binary_accuracy: 0.7125 - sensitivity: 0.9912 - specificity: 0.0491 - gmeasure: 0.1814 - auc: 0.6276 - val_loss: 0.5793 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5177
Epoch 53/100
640/640 [==============================] - 0s 78us/step - loss: 0.5742 - binary_accuracy: 0.7125 - sensitivity: 0.9829 - specificity: 0.0995 - gmeasure: 0.2538 - auc: 0.6941 - val_loss: 0.5809 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5163
Epoch 54/100
640/640 [==============================] - 0s 72us/step - loss: 0.5748 - binary_accuracy: 0.7109 - sensitivity: 0.9860 - specificity: 0.0732 - gmeasure: 0.2666 - auc: 0.6642 - val_loss: 0.5845 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5160
Epoch 55/100
640/640 [==============================] - 0s 77us/step - loss: 0.5745 - binary_accuracy: 0.7094 - sensitivity: 0.9822 - specificity: 0.0872 - gmeasure: 0.2866 - auc: 0.6750 - val_loss: 0.5831 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5160
Epoch 56/100
640/640 [==============================] - 0s 72us/step - loss: 0.5736 - binary_accuracy: 0.7109 - sensitivity: 0.9817 - specificity: 0.0893 - gmeasure: 0.2952 - auc: 0.6854 - val_loss: 0.5817 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5154
Epoch 57/100
640/640 [==============================] - 0s 71us/step - loss: 0.5743 - binary_accuracy: 0.7109 - sensitivity: 0.9893 - specificity: 0.0519 - gmeasure: 0.1909 - auc: 0.6594 - val_loss: 0.5801 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5163
Epoch 58/100
640/640 [==============================] - 0s 74us/step - loss: 0.5733 - binary_accuracy: 0.7156 - sensitivity: 0.9912 - specificity: 0.0587 - gmeasure: 0.2078 - auc: 0.6553 - val_loss: 0.5833 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5160
Epoch 59/100
640/640 [==============================] - 0s 74us/step - loss: 0.5731 - binary_accuracy: 0.7156 - sensitivity: 0.9840 - specificity: 0.0880 - gmeasure: 0.2926 - auc: 0.6649 - val_loss: 0.5850 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9667 - val_specificity: 0.0500 - val_gmeasure: 0.2198 - val_auc: 0.5165
Epoch 60/100
640/640 [==============================] - 0s 72us/step - loss: 0.5738 - binary_accuracy: 0.7203 - sensitivity: 0.9802 - specificity: 0.1404 - gmeasure: 0.3626 - auc: 0.6903 - val_loss: 0.5861 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9667 - val_specificity: 0.0500 - val_gmeasure: 0.2198 - val_auc: 0.5160
Epoch 61/100
640/640 [==============================] - 0s 78us/step - loss: 0.5721 - binary_accuracy: 0.7203 - sensitivity: 0.9875 - specificity: 0.0793 - gmeasure: 0.2403 - auc: 0.6611 - val_loss: 0.5795 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5217
Epoch 62/100
640/640 [==============================] - 0s 73us/step - loss: 0.5744 - binary_accuracy: 0.7141 - sensitivity: 0.9929 - specificity: 0.0647 - gmeasure: 0.2510 - auc: 0.6780 - val_loss: 0.5785 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5221
Epoch 63/100
640/640 [==============================] - 0s 73us/step - loss: 0.5743 - binary_accuracy: 0.7141 - sensitivity: 0.9893 - specificity: 0.1061 - gmeasure: 0.3025 - auc: 0.6755 - val_loss: 0.5817 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9750 - val_specificity: 0.0500 - val_gmeasure: 0.2208 - val_auc: 0.5229
Epoch 64/100
640/640 [==============================] - 0s 73us/step - loss: 0.5728 - binary_accuracy: 0.7172 - sensitivity: 0.9741 - specificity: 0.1223 - gmeasure: 0.3386 - auc: 0.6605 - val_loss: 0.5837 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9750 - val_specificity: 0.0750 - val_gmeasure: 0.2704 - val_auc: 0.5238
Epoch 65/100
640/640 [==============================] - 0s 75us/step - loss: 0.5732 - binary_accuracy: 0.7188 - sensitivity: 0.9769 - specificity: 0.0989 - gmeasure: 0.2680 - auc: 0.6664 - val_loss: 0.5812 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5225
Epoch 66/100
640/640 [==============================] - 0s 72us/step - loss: 0.5726 - binary_accuracy: 0.7125 - sensitivity: 0.9755 - specificity: 0.0680 - gmeasure: 0.2234 - auc: 0.6547 - val_loss: 0.5789 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5227
Epoch 67/100
640/640 [==============================] - 0s 76us/step - loss: 0.5746 - binary_accuracy: 0.7125 - sensitivity: 0.9709 - specificity: 0.1095 - gmeasure: 0.3165 - auc: 0.6602 - val_loss: 0.5827 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9750 - val_specificity: 0.0500 - val_gmeasure: 0.2208 - val_auc: 0.5215
Epoch 68/100
640/640 [==============================] - 0s 74us/step - loss: 0.5713 - binary_accuracy: 0.7172 - sensitivity: 0.9737 - specificity: 0.1057 - gmeasure: 0.3159 - auc: 0.6254 - val_loss: 0.5809 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5219
Epoch 69/100
640/640 [==============================] - 0s 73us/step - loss: 0.5712 - binary_accuracy: 0.7156 - sensitivity: 0.9857 - specificity: 0.0688 - gmeasure: 0.2230 - auc: 0.6737 - val_loss: 0.5795 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5210
Epoch 70/100
640/640 [==============================] - 0s 77us/step - loss: 0.5732 - binary_accuracy: 0.7172 - sensitivity: 0.9912 - specificity: 0.0766 - gmeasure: 0.2750 - auc: 0.6661 - val_loss: 0.5801 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5200
Epoch 71/100
640/640 [==============================] - 0s 72us/step - loss: 0.5722 - binary_accuracy: 0.7203 - sensitivity: 0.9841 - specificity: 0.0885 - gmeasure: 0.2489 - auc: 0.6509 - val_loss: 0.5883 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9583 - val_specificity: 0.1000 - val_gmeasure: 0.3096 - val_auc: 0.5185
Epoch 72/100
640/640 [==============================] - 0s 71us/step - loss: 0.5730 - binary_accuracy: 0.7188 - sensitivity: 0.9754 - specificity: 0.1420 - gmeasure: 0.3705 - auc: 0.6670 - val_loss: 0.5860 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9583 - val_specificity: 0.0500 - val_gmeasure: 0.2189 - val_auc: 0.5171
Epoch 73/100
640/640 [==============================] - 0s 74us/step - loss: 0.5709 - binary_accuracy: 0.7203 - sensitivity: 0.9718 - specificity: 0.1375 - gmeasure: 0.3629 - auc: 0.6714 - val_loss: 0.5820 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5196
Epoch 74/100
640/640 [==============================] - 0s 77us/step - loss: 0.5709 - binary_accuracy: 0.7156 - sensitivity: 0.9783 - specificity: 0.1172 - gmeasure: 0.3268 - auc: 0.6665 - val_loss: 0.5790 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5246
Epoch 75/100
640/640 [==============================] - 0s 70us/step - loss: 0.5709 - binary_accuracy: 0.7156 - sensitivity: 0.9803 - specificity: 0.0821 - gmeasure: 0.2711 - auc: 0.6550 - val_loss: 0.5802 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5252
Epoch 76/100
640/640 [==============================] - 0s 75us/step - loss: 0.5709 - binary_accuracy: 0.7203 - sensitivity: 0.9820 - specificity: 0.1108 - gmeasure: 0.3264 - auc: 0.6436 - val_loss: 0.5841 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9583 - val_specificity: 0.0750 - val_gmeasure: 0.2681 - val_auc: 0.5242
Epoch 77/100
640/640 [==============================] - 0s 74us/step - loss: 0.5705 - binary_accuracy: 0.7234 - sensitivity: 0.9732 - specificity: 0.1554 - gmeasure: 0.3805 - auc: 0.6751 - val_loss: 0.5817 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9583 - val_specificity: 0.0500 - val_gmeasure: 0.2189 - val_auc: 0.5258
Epoch 78/100
640/640 [==============================] - 0s 71us/step - loss: 0.5698 - binary_accuracy: 0.7188 - sensitivity: 0.9841 - specificity: 0.0983 - gmeasure: 0.3089 - auc: 0.6721 - val_loss: 0.5785 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5281
Epoch 79/100
640/640 [==============================] - 0s 75us/step - loss: 0.5702 - binary_accuracy: 0.7188 - sensitivity: 0.9802 - specificity: 0.1222 - gmeasure: 0.3398 - auc: 0.7222 - val_loss: 0.5783 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5294
Epoch 80/100
640/640 [==============================] - 0s 73us/step - loss: 0.5714 - binary_accuracy: 0.7203 - sensitivity: 0.9895 - specificity: 0.0885 - gmeasure: 0.2944 - auc: 0.6497 - val_loss: 0.5764 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5300
Epoch 81/100
640/640 [==============================] - 0s 72us/step - loss: 0.5699 - binary_accuracy: 0.7203 - sensitivity: 0.9805 - specificity: 0.1121 - gmeasure: 0.3278 - auc: 0.6775 - val_loss: 0.5818 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9667 - val_specificity: 0.1000 - val_gmeasure: 0.3109 - val_auc: 0.5269
Epoch 82/100
640/640 [==============================] - 0s 74us/step - loss: 0.5698 - binary_accuracy: 0.7188 - sensitivity: 0.9753 - specificity: 0.1372 - gmeasure: 0.3636 - auc: 0.6593 - val_loss: 0.5818 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9667 - val_specificity: 0.1000 - val_gmeasure: 0.3109 - val_auc: 0.5260
Epoch 83/100
640/640 [==============================] - 0s 74us/step - loss: 0.5691 - binary_accuracy: 0.7203 - sensitivity: 0.9768 - specificity: 0.1247 - gmeasure: 0.3477 - auc: 0.6969 - val_loss: 0.5799 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5254
Epoch 84/100
640/640 [==============================] - 0s 72us/step - loss: 0.5685 - binary_accuracy: 0.7156 - sensitivity: 0.9818 - specificity: 0.0926 - gmeasure: 0.2986 - auc: 0.6440 - val_loss: 0.5790 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5242
Epoch 85/100
640/640 [==============================] - 0s 70us/step - loss: 0.5690 - binary_accuracy: 0.7156 - sensitivity: 0.9757 - specificity: 0.0800 - gmeasure: 0.2386 - auc: 0.6534 - val_loss: 0.5806 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5229
Epoch 86/100
640/640 [==============================] - 0s 75us/step - loss: 0.5692 - binary_accuracy: 0.7203 - sensitivity: 0.9673 - specificity: 0.1760 - gmeasure: 0.3914 - auc: 0.7245 - val_loss: 0.5806 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5229
Epoch 87/100
640/640 [==============================] - 0s 73us/step - loss: 0.5700 - binary_accuracy: 0.7188 - sensitivity: 0.9786 - specificity: 0.0991 - gmeasure: 0.3071 - auc: 0.6753 - val_loss: 0.5801 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5231
Epoch 88/100
640/640 [==============================] - 0s 72us/step - loss: 0.5682 - binary_accuracy: 0.7156 - sensitivity: 0.9841 - specificity: 0.1102 - gmeasure: 0.3240 - auc: 0.6702 - val_loss: 0.5835 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9667 - val_specificity: 0.1000 - val_gmeasure: 0.3109 - val_auc: 0.5271
Epoch 89/100
640/640 [==============================] - 0s 74us/step - loss: 0.5688 - binary_accuracy: 0.7250 - sensitivity: 0.9567 - specificity: 0.1514 - gmeasure: 0.3774 - auc: 0.6993 - val_loss: 0.5869 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9583 - val_specificity: 0.1000 - val_gmeasure: 0.3096 - val_auc: 0.5296
Epoch 90/100
640/640 [==============================] - 0s 74us/step - loss: 0.5690 - binary_accuracy: 0.7266 - sensitivity: 0.9579 - specificity: 0.1519 - gmeasure: 0.3227 - auc: 0.6187 - val_loss: 0.5800 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5308
Epoch 91/100
640/640 [==============================] - 0s 75us/step - loss: 0.5725 - binary_accuracy: 0.7172 - sensitivity: 0.9857 - specificity: 0.0723 - gmeasure: 0.2298 - auc: 0.6582 - val_loss: 0.5821 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5310
Epoch 92/100
640/640 [==============================] - 0s 73us/step - loss: 0.5763 - binary_accuracy: 0.7188 - sensitivity: 0.9910 - specificity: 0.1007 - gmeasure: 0.3108 - auc: 0.6982 - val_loss: 0.5802 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5304
Epoch 93/100
640/640 [==============================] - 0s 78us/step - loss: 0.5683 - binary_accuracy: 0.7203 - sensitivity: 0.9598 - specificity: 0.1119 - gmeasure: 0.3066 - auc: 0.6243 - val_loss: 0.5892 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9583 - val_specificity: 0.1250 - val_gmeasure: 0.3461 - val_auc: 0.5277
Epoch 94/100
640/640 [==============================] - 0s 74us/step - loss: 0.5705 - binary_accuracy: 0.7281 - sensitivity: 0.9605 - specificity: 0.1608 - gmeasure: 0.3378 - auc: 0.6554 - val_loss: 0.5877 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9583 - val_specificity: 0.1250 - val_gmeasure: 0.3461 - val_auc: 0.5277
Epoch 95/100
640/640 [==============================] - 0s 76us/step - loss: 0.5673 - binary_accuracy: 0.7250 - sensitivity: 0.9694 - specificity: 0.1543 - gmeasure: 0.3827 - auc: 0.6849 - val_loss: 0.5808 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5290
Epoch 96/100
640/640 [==============================] - 0s 73us/step - loss: 0.5685 - binary_accuracy: 0.7203 - sensitivity: 0.9857 - specificity: 0.1034 - gmeasure: 0.3189 - auc: 0.6911 - val_loss: 0.5812 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5290
Epoch 97/100
640/640 [==============================] - 0s 73us/step - loss: 0.5709 - binary_accuracy: 0.7203 - sensitivity: 0.9819 - specificity: 0.1059 - gmeasure: 0.3107 - auc: 0.6507 - val_loss: 0.5813 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9667 - val_specificity: 0.0250 - val_gmeasure: 0.1555 - val_auc: 0.5283
Epoch 98/100
640/640 [==============================] - 0s 74us/step - loss: 0.5668 - binary_accuracy: 0.7219 - sensitivity: 0.9631 - specificity: 0.1304 - gmeasure: 0.3478 - auc: 0.6677 - val_loss: 0.5884 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.9583 - val_specificity: 0.1250 - val_gmeasure: 0.3461 - val_auc: 0.5283
Epoch 99/100
640/640 [==============================] - 0s 78us/step - loss: 0.5705 - binary_accuracy: 0.7297 - sensitivity: 0.9499 - specificity: 0.1702 - gmeasure: 0.3427 - auc: 0.6616 - val_loss: 0.5862 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9667 - val_specificity: 0.1250 - val_gmeasure: 0.3476 - val_auc: 0.5283
Epoch 100/100
640/640 [==============================] - 0s 72us/step - loss: 0.5662 - binary_accuracy: 0.7219 - sensitivity: 0.9588 - specificity: 0.1656 - gmeasure: 0.3946 - auc: 0.6885 - val_loss: 0.5808 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9750 - val_specificity: 0.0250 - val_gmeasure: 0.1561 - val_auc: 0.5273
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 6.688857316970825!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.012678146362304688!
[root    |INFO|build_network.py:175] Evaluation: [0.570883572101593, 0.7212499976158142, 0.9789103865623474, 0.08658009022474289, 0.29112565517425537, 0.647463858127594]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 16us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.007781267166137695!
[root    |INFO|build_network.py:175] Evaluation: [0.5779709815979004, 0.7363184094429016, 0.9736841917037964, 0.0, 0.0, 0.5371912121772766]
[root    |INFO|deepbiome.py:179] Compute time : 8.250972747802734
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 660us/step - loss: 0.5650 - binary_accuracy: 0.7266 - sensitivity: 0.9654 - specificity: 0.2113 - gmeasure: 0.4428 - auc: 0.7229 - val_loss: 0.6797 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9909 - val_specificity: 0.0400 - val_gmeasure: 0.1991 - val_auc: 0.5236
Epoch 2/100
640/640 [==============================] - 0s 73us/step - loss: 0.5737 - binary_accuracy: 0.6984 - sensitivity: 0.9881 - specificity: 0.0226 - gmeasure: 0.0990 - auc: 0.7058 - val_loss: 0.6658 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9636 - val_specificity: 0.0800 - val_gmeasure: 0.2777 - val_auc: 0.5215
Epoch 3/100
640/640 [==============================] - 0s 70us/step - loss: 0.5645 - binary_accuracy: 0.7188 - sensitivity: 0.9565 - specificity: 0.1833 - gmeasure: 0.4017 - auc: 0.6556 - val_loss: 0.6630 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8364 - val_specificity: 0.2400 - val_gmeasure: 0.4480 - val_auc: 0.5229
Epoch 4/100
640/640 [==============================] - 0s 70us/step - loss: 0.5706 - binary_accuracy: 0.7063 - sensitivity: 0.9208 - specificity: 0.2421 - gmeasure: 0.4708 - auc: 0.7274 - val_loss: 0.6624 - val_binary_accuracy: 0.6625 - val_sensitivity: 0.9273 - val_specificity: 0.0800 - val_gmeasure: 0.2724 - val_auc: 0.5197
Epoch 5/100
640/640 [==============================] - 0s 68us/step - loss: 0.5616 - binary_accuracy: 0.7203 - sensitivity: 0.9895 - specificity: 0.0995 - gmeasure: 0.2705 - auc: 0.6914 - val_loss: 0.6751 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9818 - val_specificity: 0.0400 - val_gmeasure: 0.1982 - val_auc: 0.5193
Epoch 6/100
640/640 [==============================] - 0s 78us/step - loss: 0.5633 - binary_accuracy: 0.7094 - sensitivity: 0.9929 - specificity: 0.0729 - gmeasure: 0.2685 - auc: 0.6810 - val_loss: 0.6628 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9455 - val_specificity: 0.1000 - val_gmeasure: 0.3075 - val_auc: 0.5188
Epoch 7/100
640/640 [==============================] - 0s 74us/step - loss: 0.5629 - binary_accuracy: 0.7188 - sensitivity: 0.9660 - specificity: 0.1862 - gmeasure: 0.4237 - auc: 0.7107 - val_loss: 0.6618 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8545 - val_specificity: 0.2200 - val_gmeasure: 0.4336 - val_auc: 0.5195
Epoch 8/100
640/640 [==============================] - 0s 74us/step - loss: 0.5703 - binary_accuracy: 0.7188 - sensitivity: 0.9110 - specificity: 0.2713 - gmeasure: 0.4959 - auc: 0.7169 - val_loss: 0.6593 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9000 - val_specificity: 0.2000 - val_gmeasure: 0.4243 - val_auc: 0.5221
Epoch 9/100
640/640 [==============================] - 0s 74us/step - loss: 0.5622 - binary_accuracy: 0.7156 - sensitivity: 0.9603 - specificity: 0.1505 - gmeasure: 0.3700 - auc: 0.7101 - val_loss: 0.6649 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9545 - val_specificity: 0.0800 - val_gmeasure: 0.2763 - val_auc: 0.5211
Epoch 10/100
640/640 [==============================] - 0s 74us/step - loss: 0.5630 - binary_accuracy: 0.7141 - sensitivity: 0.9929 - specificity: 0.0937 - gmeasure: 0.3048 - auc: 0.6864 - val_loss: 0.6672 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9636 - val_specificity: 0.0800 - val_gmeasure: 0.2777 - val_auc: 0.5215
Epoch 11/100
640/640 [==============================] - 0s 77us/step - loss: 0.5585 - binary_accuracy: 0.7172 - sensitivity: 0.9911 - specificity: 0.1136 - gmeasure: 0.3338 - auc: 0.7186 - val_loss: 0.6617 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9091 - val_specificity: 0.2000 - val_gmeasure: 0.4264 - val_auc: 0.5217
Epoch 12/100
640/640 [==============================] - 0s 73us/step - loss: 0.5653 - binary_accuracy: 0.7141 - sensitivity: 0.9281 - specificity: 0.2263 - gmeasure: 0.4543 - auc: 0.7099 - val_loss: 0.6644 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8364 - val_specificity: 0.2400 - val_gmeasure: 0.4480 - val_auc: 0.5202
Epoch 13/100
640/640 [==============================] - 0s 74us/step - loss: 0.5672 - binary_accuracy: 0.7188 - sensitivity: 0.9139 - specificity: 0.2388 - gmeasure: 0.4632 - auc: 0.6914 - val_loss: 0.6625 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9455 - val_specificity: 0.1200 - val_gmeasure: 0.3368 - val_auc: 0.5205
Epoch 14/100
640/640 [==============================] - 0s 74us/step - loss: 0.5580 - binary_accuracy: 0.7188 - sensitivity: 0.9838 - specificity: 0.1187 - gmeasure: 0.3340 - auc: 0.6845 - val_loss: 0.6715 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9636 - val_specificity: 0.0600 - val_gmeasure: 0.2405 - val_auc: 0.5216
Epoch 15/100
640/640 [==============================] - 0s 74us/step - loss: 0.5635 - binary_accuracy: 0.7109 - sensitivity: 0.9946 - specificity: 0.0745 - gmeasure: 0.2717 - auc: 0.7096 - val_loss: 0.6691 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9636 - val_specificity: 0.0800 - val_gmeasure: 0.2777 - val_auc: 0.5222
Epoch 16/100
640/640 [==============================] - 0s 73us/step - loss: 0.5609 - binary_accuracy: 0.7188 - sensitivity: 0.9776 - specificity: 0.1307 - gmeasure: 0.3564 - auc: 0.7260 - val_loss: 0.6606 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9273 - val_specificity: 0.1200 - val_gmeasure: 0.3336 - val_auc: 0.5238
Epoch 17/100
640/640 [==============================] - 0s 79us/step - loss: 0.5593 - binary_accuracy: 0.7219 - sensitivity: 0.9706 - specificity: 0.1959 - gmeasure: 0.4248 - auc: 0.7231 - val_loss: 0.6641 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9455 - val_specificity: 0.0800 - val_gmeasure: 0.2750 - val_auc: 0.5211
Epoch 18/100
640/640 [==============================] - 0s 70us/step - loss: 0.5587 - binary_accuracy: 0.7234 - sensitivity: 0.9892 - specificity: 0.1049 - gmeasure: 0.2767 - auc: 0.7444 - val_loss: 0.6690 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9545 - val_specificity: 0.0800 - val_gmeasure: 0.2763 - val_auc: 0.5205
Epoch 19/100
640/640 [==============================] - 0s 69us/step - loss: 0.5586 - binary_accuracy: 0.7203 - sensitivity: 0.9890 - specificity: 0.1285 - gmeasure: 0.3475 - auc: 0.6926 - val_loss: 0.6693 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9455 - val_specificity: 0.0800 - val_gmeasure: 0.2750 - val_auc: 0.5207
Epoch 20/100
640/640 [==============================] - 0s 74us/step - loss: 0.5575 - binary_accuracy: 0.7219 - sensitivity: 0.9836 - specificity: 0.1463 - gmeasure: 0.3777 - auc: 0.7369 - val_loss: 0.6691 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9364 - val_specificity: 0.1200 - val_gmeasure: 0.3352 - val_auc: 0.5198
Epoch 21/100
640/640 [==============================] - 0s 74us/step - loss: 0.5571 - binary_accuracy: 0.7250 - sensitivity: 0.9655 - specificity: 0.1597 - gmeasure: 0.3916 - auc: 0.6936 - val_loss: 0.6691 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5199
Epoch 22/100
640/640 [==============================] - 0s 72us/step - loss: 0.5572 - binary_accuracy: 0.7250 - sensitivity: 0.9709 - specificity: 0.1482 - gmeasure: 0.3221 - auc: 0.6830 - val_loss: 0.6701 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9273 - val_specificity: 0.1400 - val_gmeasure: 0.3603 - val_auc: 0.5191
Epoch 23/100
640/640 [==============================] - 0s 78us/step - loss: 0.5570 - binary_accuracy: 0.7219 - sensitivity: 0.9684 - specificity: 0.1592 - gmeasure: 0.3910 - auc: 0.6952 - val_loss: 0.6718 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9364 - val_specificity: 0.1000 - val_gmeasure: 0.3060 - val_auc: 0.5189
Epoch 24/100
640/640 [==============================] - 0s 76us/step - loss: 0.5564 - binary_accuracy: 0.7250 - sensitivity: 0.9598 - specificity: 0.1866 - gmeasure: 0.4165 - auc: 0.6964 - val_loss: 0.6701 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5198
Epoch 25/100
640/640 [==============================] - 0s 72us/step - loss: 0.5570 - binary_accuracy: 0.7266 - sensitivity: 0.9816 - specificity: 0.1440 - gmeasure: 0.3692 - auc: 0.6952 - val_loss: 0.6699 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9364 - val_specificity: 0.1200 - val_gmeasure: 0.3352 - val_auc: 0.5208
Epoch 26/100
640/640 [==============================] - 0s 73us/step - loss: 0.5563 - binary_accuracy: 0.7250 - sensitivity: 0.9803 - specificity: 0.1501 - gmeasure: 0.3787 - auc: 0.6826 - val_loss: 0.6673 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9182 - val_specificity: 0.1600 - val_gmeasure: 0.3833 - val_auc: 0.5235
Epoch 27/100
640/640 [==============================] - 0s 75us/step - loss: 0.5582 - binary_accuracy: 0.7234 - sensitivity: 0.9565 - specificity: 0.1905 - gmeasure: 0.4226 - auc: 0.7148 - val_loss: 0.6666 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.8818 - val_specificity: 0.2200 - val_gmeasure: 0.4405 - val_auc: 0.5244
Epoch 28/100
640/640 [==============================] - 0s 75us/step - loss: 0.5604 - binary_accuracy: 0.7219 - sensitivity: 0.9451 - specificity: 0.3207 - gmeasure: 0.5388 - auc: 0.7325 - val_loss: 0.6686 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9273 - val_specificity: 0.1400 - val_gmeasure: 0.3603 - val_auc: 0.5241
Epoch 29/100
640/640 [==============================] - 0s 71us/step - loss: 0.5604 - binary_accuracy: 0.7172 - sensitivity: 0.9823 - specificity: 0.1014 - gmeasure: 0.2709 - auc: 0.7086 - val_loss: 0.6900 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9636 - val_specificity: 0.0400 - val_gmeasure: 0.1963 - val_auc: 0.5209
Epoch 30/100
640/640 [==============================] - 0s 73us/step - loss: 0.5656 - binary_accuracy: 0.7078 - sensitivity: 0.9945 - specificity: 0.0526 - gmeasure: 0.1933 - auc: 0.7295 - val_loss: 0.6757 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9455 - val_specificity: 0.0800 - val_gmeasure: 0.2750 - val_auc: 0.5207
Epoch 31/100
640/640 [==============================] - 0s 78us/step - loss: 0.5546 - binary_accuracy: 0.7281 - sensitivity: 0.9819 - specificity: 0.1721 - gmeasure: 0.4094 - auc: 0.7275 - val_loss: 0.6699 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8545 - val_specificity: 0.2200 - val_gmeasure: 0.4336 - val_auc: 0.5242
Epoch 32/100
640/640 [==============================] - 0s 58us/step - loss: 0.5620 - binary_accuracy: 0.7125 - sensitivity: 0.9045 - specificity: 0.2691 - gmeasure: 0.4923 - auc: 0.6955 - val_loss: 0.6716 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8545 - val_specificity: 0.2200 - val_gmeasure: 0.4336 - val_auc: 0.5235
Epoch 33/100
640/640 [==============================] - 0s 69us/step - loss: 0.5558 - binary_accuracy: 0.7266 - sensitivity: 0.9641 - specificity: 0.2142 - gmeasure: 0.4508 - auc: 0.7282 - val_loss: 0.6825 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9545 - val_specificity: 0.0800 - val_gmeasure: 0.2763 - val_auc: 0.5182
Epoch 34/100
640/640 [==============================] - 0s 72us/step - loss: 0.5580 - binary_accuracy: 0.7188 - sensitivity: 0.9725 - specificity: 0.1285 - gmeasure: 0.3455 - auc: 0.6845 - val_loss: 0.6829 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.9364 - val_specificity: 0.0800 - val_gmeasure: 0.2737 - val_auc: 0.5176
Epoch 35/100
640/640 [==============================] - 0s 75us/step - loss: 0.5540 - binary_accuracy: 0.7203 - sensitivity: 0.9549 - specificity: 0.1311 - gmeasure: 0.3446 - auc: 0.7119 - val_loss: 0.6751 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9091 - val_specificity: 0.2200 - val_gmeasure: 0.4472 - val_auc: 0.5191
Epoch 36/100
640/640 [==============================] - 0s 74us/step - loss: 0.5583 - binary_accuracy: 0.7141 - sensitivity: 0.9083 - specificity: 0.2425 - gmeasure: 0.4677 - auc: 0.7121 - val_loss: 0.6762 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.8909 - val_specificity: 0.2200 - val_gmeasure: 0.4427 - val_auc: 0.5185
Epoch 37/100
640/640 [==============================] - 0s 73us/step - loss: 0.5559 - binary_accuracy: 0.7234 - sensitivity: 0.9712 - specificity: 0.1607 - gmeasure: 0.3874 - auc: 0.7082 - val_loss: 0.6896 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9545 - val_specificity: 0.0800 - val_gmeasure: 0.2763 - val_auc: 0.5169
Epoch 38/100
640/640 [==============================] - 0s 71us/step - loss: 0.5583 - binary_accuracy: 0.7219 - sensitivity: 0.9810 - specificity: 0.1287 - gmeasure: 0.3524 - auc: 0.7207 - val_loss: 0.6820 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5166
Epoch 39/100
640/640 [==============================] - 0s 77us/step - loss: 0.5536 - binary_accuracy: 0.7203 - sensitivity: 0.9495 - specificity: 0.2095 - gmeasure: 0.4436 - auc: 0.7103 - val_loss: 0.6778 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8364 - val_specificity: 0.2400 - val_gmeasure: 0.4480 - val_auc: 0.5180
Epoch 40/100
640/640 [==============================] - 0s 75us/step - loss: 0.5630 - binary_accuracy: 0.7172 - sensitivity: 0.9009 - specificity: 0.3183 - gmeasure: 0.5355 - auc: 0.7060 - val_loss: 0.6754 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8545 - val_specificity: 0.2200 - val_gmeasure: 0.4336 - val_auc: 0.5211
Epoch 41/100
640/640 [==============================] - 0s 73us/step - loss: 0.5552 - binary_accuracy: 0.7172 - sensitivity: 0.9452 - specificity: 0.1890 - gmeasure: 0.4126 - auc: 0.7148 - val_loss: 0.6821 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9455 - val_specificity: 0.1200 - val_gmeasure: 0.3368 - val_auc: 0.5211
Epoch 42/100
640/640 [==============================] - 0s 76us/step - loss: 0.5556 - binary_accuracy: 0.7234 - sensitivity: 0.9791 - specificity: 0.1834 - gmeasure: 0.4131 - auc: 0.7406 - val_loss: 0.6841 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9455 - val_specificity: 0.1200 - val_gmeasure: 0.3368 - val_auc: 0.5209
Epoch 43/100
640/640 [==============================] - 0s 77us/step - loss: 0.5558 - binary_accuracy: 0.7219 - sensitivity: 0.9770 - specificity: 0.1181 - gmeasure: 0.3335 - auc: 0.7113 - val_loss: 0.6764 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9182 - val_specificity: 0.1800 - val_gmeasure: 0.4065 - val_auc: 0.5225
Epoch 44/100
640/640 [==============================] - 0s 73us/step - loss: 0.5574 - binary_accuracy: 0.7219 - sensitivity: 0.9228 - specificity: 0.2858 - gmeasure: 0.5118 - auc: 0.7077 - val_loss: 0.6772 - val_binary_accuracy: 0.6250 - val_sensitivity: 0.7909 - val_specificity: 0.2600 - val_gmeasure: 0.4535 - val_auc: 0.5218
Epoch 45/100
640/640 [==============================] - 0s 75us/step - loss: 0.5655 - binary_accuracy: 0.7203 - sensitivity: 0.8895 - specificity: 0.3561 - gmeasure: 0.5583 - auc: 0.7525 - val_loss: 0.6755 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9091 - val_specificity: 0.1800 - val_gmeasure: 0.4045 - val_auc: 0.5215
Epoch 46/100
640/640 [==============================] - 0s 76us/step - loss: 0.5524 - binary_accuracy: 0.7219 - sensitivity: 0.9661 - specificity: 0.1500 - gmeasure: 0.3785 - auc: 0.7127 - val_loss: 0.6992 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9727 - val_specificity: 0.0400 - val_gmeasure: 0.1973 - val_auc: 0.5189
Epoch 47/100
640/640 [==============================] - 0s 72us/step - loss: 0.5664 - binary_accuracy: 0.7094 - sensitivity: 0.9791 - specificity: 0.0788 - gmeasure: 0.2621 - auc: 0.7256 - val_loss: 0.6876 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9455 - val_specificity: 0.1000 - val_gmeasure: 0.3075 - val_auc: 0.5184
Epoch 48/100
640/640 [==============================] - 0s 67us/step - loss: 0.5537 - binary_accuracy: 0.7328 - sensitivity: 0.9802 - specificity: 0.2182 - gmeasure: 0.4524 - auc: 0.7211 - val_loss: 0.6769 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8455 - val_specificity: 0.2200 - val_gmeasure: 0.4313 - val_auc: 0.5193
Epoch 49/100
640/640 [==============================] - 0s 67us/step - loss: 0.5602 - binary_accuracy: 0.7156 - sensitivity: 0.9038 - specificity: 0.3112 - gmeasure: 0.5290 - auc: 0.7140 - val_loss: 0.6764 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8636 - val_specificity: 0.1800 - val_gmeasure: 0.3943 - val_auc: 0.5198
Epoch 50/100
640/640 [==============================] - ETA: 0s - loss: 0.5367 - binary_accuracy: 0.7300 - sensitivity: 0.9437 - specificity: 0.2069 - gmeasure: 0.4419 - auc: 0.71 - 0s 73us/step - loss: 0.5538 - binary_accuracy: 0.7203 - sensitivity: 0.9624 - specificity: 0.1605 - gmeasure: 0.3347 - auc: 0.6748 - val_loss: 0.6869 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9455 - val_specificity: 0.1000 - val_gmeasure: 0.3075 - val_auc: 0.5176
Epoch 51/100
640/640 [==============================] - 0s 70us/step - loss: 0.5551 - binary_accuracy: 0.7219 - sensitivity: 0.9874 - specificity: 0.1362 - gmeasure: 0.3638 - auc: 0.7302 - val_loss: 0.6849 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9455 - val_specificity: 0.1400 - val_gmeasure: 0.3638 - val_auc: 0.5180
Epoch 52/100
640/640 [==============================] - 0s 73us/step - loss: 0.5536 - binary_accuracy: 0.7188 - sensitivity: 0.9394 - specificity: 0.2274 - gmeasure: 0.4483 - auc: 0.7008 - val_loss: 0.6787 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8636 - val_specificity: 0.1800 - val_gmeasure: 0.3943 - val_auc: 0.5195
Epoch 53/100
640/640 [==============================] - 0s 75us/step - loss: 0.5529 - binary_accuracy: 0.7125 - sensitivity: 0.9291 - specificity: 0.2071 - gmeasure: 0.4343 - auc: 0.7182 - val_loss: 0.6814 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9182 - val_specificity: 0.1800 - val_gmeasure: 0.4065 - val_auc: 0.5185
Epoch 54/100
640/640 [==============================] - 0s 76us/step - loss: 0.5508 - binary_accuracy: 0.7172 - sensitivity: 0.9439 - specificity: 0.1735 - gmeasure: 0.4035 - auc: 0.7006 - val_loss: 0.6870 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5171
Epoch 55/100
640/640 [==============================] - 0s 71us/step - loss: 0.5549 - binary_accuracy: 0.7219 - sensitivity: 0.9841 - specificity: 0.1145 - gmeasure: 0.2875 - auc: 0.7058 - val_loss: 0.6850 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9182 - val_specificity: 0.1600 - val_gmeasure: 0.3833 - val_auc: 0.5180
Epoch 56/100
640/640 [==============================] - 0s 68us/step - loss: 0.5606 - binary_accuracy: 0.7047 - sensitivity: 0.9057 - specificity: 0.2163 - gmeasure: 0.4283 - auc: 0.7061 - val_loss: 0.6823 - val_binary_accuracy: 0.6375 - val_sensitivity: 0.8091 - val_specificity: 0.2600 - val_gmeasure: 0.4587 - val_auc: 0.5189
Epoch 57/100
640/640 [==============================] - 0s 73us/step - loss: 0.5574 - binary_accuracy: 0.7156 - sensitivity: 0.9023 - specificity: 0.2781 - gmeasure: 0.4934 - auc: 0.7536 - val_loss: 0.6840 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9364 - val_specificity: 0.1800 - val_gmeasure: 0.4105 - val_auc: 0.5191
Epoch 58/100
640/640 [==============================] - 0s 72us/step - loss: 0.5517 - binary_accuracy: 0.7219 - sensitivity: 0.9832 - specificity: 0.1494 - gmeasure: 0.3796 - auc: 0.7347 - val_loss: 0.7051 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9636 - val_specificity: 0.0400 - val_gmeasure: 0.1963 - val_auc: 0.5176
Epoch 59/100
640/640 [==============================] - 0s 80us/step - loss: 0.5625 - binary_accuracy: 0.7125 - sensitivity: 0.9841 - specificity: 0.1093 - gmeasure: 0.3169 - auc: 0.7375 - val_loss: 0.6865 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9455 - val_specificity: 0.1600 - val_gmeasure: 0.3889 - val_auc: 0.5182
Epoch 60/100
640/640 [==============================] - 0s 72us/step - loss: 0.5536 - binary_accuracy: 0.7266 - sensitivity: 0.9524 - specificity: 0.2082 - gmeasure: 0.4311 - auc: 0.7217 - val_loss: 0.6795 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8455 - val_specificity: 0.2200 - val_gmeasure: 0.4313 - val_auc: 0.5218
Epoch 61/100
640/640 [==============================] - 0s 68us/step - loss: 0.5555 - binary_accuracy: 0.7250 - sensitivity: 0.9296 - specificity: 0.2773 - gmeasure: 0.5006 - auc: 0.7196 - val_loss: 0.6792 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8636 - val_specificity: 0.1800 - val_gmeasure: 0.3943 - val_auc: 0.5215
Epoch 62/100
640/640 [==============================] - 0s 72us/step - loss: 0.5513 - binary_accuracy: 0.7203 - sensitivity: 0.9434 - specificity: 0.1976 - gmeasure: 0.4292 - auc: 0.7150 - val_loss: 0.6881 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9455 - val_specificity: 0.1200 - val_gmeasure: 0.3368 - val_auc: 0.5184
Epoch 63/100
640/640 [==============================] - 0s 71us/step - loss: 0.5516 - binary_accuracy: 0.7266 - sensitivity: 0.9819 - specificity: 0.1473 - gmeasure: 0.3740 - auc: 0.7174 - val_loss: 0.6876 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9364 - val_specificity: 0.1600 - val_gmeasure: 0.3871 - val_auc: 0.5191
Epoch 64/100
640/640 [==============================] - 0s 67us/step - loss: 0.5508 - binary_accuracy: 0.7219 - sensitivity: 0.9640 - specificity: 0.1585 - gmeasure: 0.3344 - auc: 0.7494 - val_loss: 0.6860 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9182 - val_specificity: 0.1800 - val_gmeasure: 0.4065 - val_auc: 0.5178
Epoch 65/100
640/640 [==============================] - 0s 76us/step - loss: 0.5500 - binary_accuracy: 0.7172 - sensitivity: 0.9572 - specificity: 0.1799 - gmeasure: 0.4146 - auc: 0.7027 - val_loss: 0.6934 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9364 - val_specificity: 0.1600 - val_gmeasure: 0.3871 - val_auc: 0.5160
Epoch 66/100
640/640 [==============================] - 0s 78us/step - loss: 0.5501 - binary_accuracy: 0.7250 - sensitivity: 0.9663 - specificity: 0.2026 - gmeasure: 0.4372 - auc: 0.7131 - val_loss: 0.6898 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9091 - val_specificity: 0.1800 - val_gmeasure: 0.4045 - val_auc: 0.5151
Epoch 67/100
640/640 [==============================] - 0s 75us/step - loss: 0.5487 - binary_accuracy: 0.7203 - sensitivity: 0.9302 - specificity: 0.2229 - gmeasure: 0.4520 - auc: 0.7076 - val_loss: 0.6875 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8636 - val_specificity: 0.2000 - val_gmeasure: 0.4156 - val_auc: 0.5145
Epoch 68/100
640/640 [==============================] - 0s 71us/step - loss: 0.5511 - binary_accuracy: 0.7219 - sensitivity: 0.9008 - specificity: 0.3083 - gmeasure: 0.5235 - auc: 0.7217 - val_loss: 0.6892 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9000 - val_specificity: 0.1800 - val_gmeasure: 0.4025 - val_auc: 0.5162
Epoch 69/100
640/640 [==============================] - 0s 72us/step - loss: 0.5521 - binary_accuracy: 0.7234 - sensitivity: 0.9715 - specificity: 0.1772 - gmeasure: 0.4139 - auc: 0.7361 - val_loss: 0.6994 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9455 - val_specificity: 0.1000 - val_gmeasure: 0.3075 - val_auc: 0.5191
Epoch 70/100
640/640 [==============================] - 0s 72us/step - loss: 0.5513 - binary_accuracy: 0.7250 - sensitivity: 0.9676 - specificity: 0.1648 - gmeasure: 0.3928 - auc: 0.7214 - val_loss: 0.6855 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8636 - val_specificity: 0.2000 - val_gmeasure: 0.4156 - val_auc: 0.5191
Epoch 71/100
640/640 [==============================] - 0s 74us/step - loss: 0.5550 - binary_accuracy: 0.7344 - sensitivity: 0.9054 - specificity: 0.3348 - gmeasure: 0.5437 - auc: 0.7085 - val_loss: 0.6865 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8364 - val_specificity: 0.2600 - val_gmeasure: 0.4663 - val_auc: 0.5191
Epoch 72/100
640/640 [==============================] - 0s 74us/step - loss: 0.5521 - binary_accuracy: 0.7219 - sensitivity: 0.9318 - specificity: 0.2449 - gmeasure: 0.4703 - auc: 0.7190 - val_loss: 0.6951 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9455 - val_specificity: 0.1600 - val_gmeasure: 0.3889 - val_auc: 0.5178
Epoch 73/100
640/640 [==============================] - 0s 71us/step - loss: 0.5511 - binary_accuracy: 0.7266 - sensitivity: 0.9719 - specificity: 0.1342 - gmeasure: 0.3124 - auc: 0.6781 - val_loss: 0.6935 - val_binary_accuracy: 0.7000 - val_sensitivity: 0.9364 - val_specificity: 0.1800 - val_gmeasure: 0.4105 - val_auc: 0.5171
Epoch 74/100
640/640 [==============================] - 0s 72us/step - loss: 0.5495 - binary_accuracy: 0.7297 - sensitivity: 0.9424 - specificity: 0.2204 - gmeasure: 0.4401 - auc: 0.7002 - val_loss: 0.6879 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8364 - val_specificity: 0.2600 - val_gmeasure: 0.4663 - val_auc: 0.5182
Epoch 75/100
640/640 [==============================] - 0s 73us/step - loss: 0.5560 - binary_accuracy: 0.7219 - sensitivity: 0.8763 - specificity: 0.3680 - gmeasure: 0.5650 - auc: 0.7405 - val_loss: 0.6879 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8455 - val_specificity: 0.2200 - val_gmeasure: 0.4313 - val_auc: 0.5165
Epoch 76/100
640/640 [==============================] - 0s 69us/step - loss: 0.5485 - binary_accuracy: 0.7312 - sensitivity: 0.9330 - specificity: 0.3051 - gmeasure: 0.5312 - auc: 0.7422 - val_loss: 0.6970 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5158
Epoch 77/100
640/640 [==============================] - 0s 70us/step - loss: 0.5551 - binary_accuracy: 0.7234 - sensitivity: 0.9791 - specificity: 0.1341 - gmeasure: 0.3589 - auc: 0.6884 - val_loss: 0.7067 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9455 - val_specificity: 0.1000 - val_gmeasure: 0.3075 - val_auc: 0.5149
Epoch 78/100
640/640 [==============================] - 0s 71us/step - loss: 0.5506 - binary_accuracy: 0.7266 - sensitivity: 0.9752 - specificity: 0.1484 - gmeasure: 0.3777 - auc: 0.7156 - val_loss: 0.6912 - val_binary_accuracy: 0.6625 - val_sensitivity: 0.8818 - val_specificity: 0.1800 - val_gmeasure: 0.3984 - val_auc: 0.5159
Epoch 79/100
640/640 [==============================] - 0s 73us/step - loss: 0.5497 - binary_accuracy: 0.7172 - sensitivity: 0.9047 - specificity: 0.2447 - gmeasure: 0.4687 - auc: 0.7032 - val_loss: 0.6896 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8636 - val_specificity: 0.2000 - val_gmeasure: 0.4156 - val_auc: 0.5164
Epoch 80/100
640/640 [==============================] - 0s 71us/step - loss: 0.5490 - binary_accuracy: 0.7250 - sensitivity: 0.9500 - specificity: 0.2221 - gmeasure: 0.4556 - auc: 0.7193 - val_loss: 0.6968 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5153
Epoch 81/100
640/640 [==============================] - 0s 75us/step - loss: 0.5496 - binary_accuracy: 0.7250 - sensitivity: 0.9720 - specificity: 0.1329 - gmeasure: 0.3058 - auc: 0.7079 - val_loss: 0.6960 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5147
Epoch 82/100
640/640 [==============================] - 0s 74us/step - loss: 0.5472 - binary_accuracy: 0.7219 - sensitivity: 0.9665 - specificity: 0.1757 - gmeasure: 0.4090 - auc: 0.7707 - val_loss: 0.6922 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9000 - val_specificity: 0.1800 - val_gmeasure: 0.4025 - val_auc: 0.5151
Epoch 83/100
640/640 [==============================] - 0s 74us/step - loss: 0.5471 - binary_accuracy: 0.7250 - sensitivity: 0.9431 - specificity: 0.2075 - gmeasure: 0.4405 - auc: 0.7304 - val_loss: 0.6931 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8727 - val_specificity: 0.1800 - val_gmeasure: 0.3963 - val_auc: 0.5140
Epoch 84/100
640/640 [==============================] - 0s 72us/step - loss: 0.5465 - binary_accuracy: 0.7328 - sensitivity: 0.9574 - specificity: 0.2020 - gmeasure: 0.3753 - auc: 0.7074 - val_loss: 0.6932 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8545 - val_specificity: 0.2200 - val_gmeasure: 0.4336 - val_auc: 0.5144
Epoch 85/100
640/640 [==============================] - 0s 77us/step - loss: 0.5498 - binary_accuracy: 0.7234 - sensitivity: 0.8984 - specificity: 0.3020 - gmeasure: 0.5202 - auc: 0.7200 - val_loss: 0.6950 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8636 - val_specificity: 0.2000 - val_gmeasure: 0.4156 - val_auc: 0.5124
Epoch 86/100
640/640 [==============================] - 0s 74us/step - loss: 0.5463 - binary_accuracy: 0.7312 - sensitivity: 0.9621 - specificity: 0.2525 - gmeasure: 0.4892 - auc: 0.7295 - val_loss: 0.7068 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5111
Epoch 87/100
640/640 [==============================] - 0s 76us/step - loss: 0.5500 - binary_accuracy: 0.7297 - sensitivity: 0.9763 - specificity: 0.1800 - gmeasure: 0.4178 - auc: 0.7333 - val_loss: 0.7033 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9364 - val_specificity: 0.1600 - val_gmeasure: 0.3871 - val_auc: 0.5109
Epoch 88/100
640/640 [==============================] - 0s 76us/step - loss: 0.5464 - binary_accuracy: 0.7266 - sensitivity: 0.9543 - specificity: 0.2193 - gmeasure: 0.4531 - auc: 0.7194 - val_loss: 0.6955 - val_binary_accuracy: 0.6625 - val_sensitivity: 0.8727 - val_specificity: 0.2000 - val_gmeasure: 0.4178 - val_auc: 0.5125
Epoch 89/100
640/640 [==============================] - 0s 68us/step - loss: 0.5469 - binary_accuracy: 0.7281 - sensitivity: 0.9405 - specificity: 0.2284 - gmeasure: 0.4454 - auc: 0.7143 - val_loss: 0.6960 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.8818 - val_specificity: 0.2000 - val_gmeasure: 0.4200 - val_auc: 0.5111
Epoch 90/100
640/640 [==============================] - 0s 70us/step - loss: 0.5462 - binary_accuracy: 0.7234 - sensitivity: 0.9339 - specificity: 0.2498 - gmeasure: 0.4776 - auc: 0.7265 - val_loss: 0.6993 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9000 - val_specificity: 0.1800 - val_gmeasure: 0.4025 - val_auc: 0.5113
Epoch 91/100
640/640 [==============================] - 0s 71us/step - loss: 0.5455 - binary_accuracy: 0.7281 - sensitivity: 0.9595 - specificity: 0.1984 - gmeasure: 0.4339 - auc: 0.7381 - val_loss: 0.7004 - val_binary_accuracy: 0.6750 - val_sensitivity: 0.9000 - val_specificity: 0.1800 - val_gmeasure: 0.4025 - val_auc: 0.5122
Epoch 92/100
640/640 [==============================] - 0s 74us/step - loss: 0.5453 - binary_accuracy: 0.7250 - sensitivity: 0.9555 - specificity: 0.2385 - gmeasure: 0.4746 - auc: 0.7426 - val_loss: 0.7043 - val_binary_accuracy: 0.6938 - val_sensitivity: 0.9273 - val_specificity: 0.1800 - val_gmeasure: 0.4085 - val_auc: 0.5107
Epoch 93/100
640/640 [==============================] - 0s 75us/step - loss: 0.5471 - binary_accuracy: 0.7250 - sensitivity: 0.9524 - specificity: 0.1731 - gmeasure: 0.3992 - auc: 0.6891 - val_loss: 0.7039 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9091 - val_specificity: 0.1800 - val_gmeasure: 0.4045 - val_auc: 0.5109
Epoch 94/100
640/640 [==============================] - 0s 73us/step - loss: 0.5437 - binary_accuracy: 0.7281 - sensitivity: 0.9467 - specificity: 0.2216 - gmeasure: 0.4574 - auc: 0.7232 - val_loss: 0.6991 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8545 - val_specificity: 0.2000 - val_gmeasure: 0.4134 - val_auc: 0.5105
Epoch 95/100
640/640 [==============================] - 0s 72us/step - loss: 0.5488 - binary_accuracy: 0.7094 - sensitivity: 0.9042 - specificity: 0.3061 - gmeasure: 0.5244 - auc: 0.7356 - val_loss: 0.6991 - val_binary_accuracy: 0.6562 - val_sensitivity: 0.8636 - val_specificity: 0.2000 - val_gmeasure: 0.4156 - val_auc: 0.5118
Epoch 96/100
640/640 [==============================] - 0s 68us/step - loss: 0.5465 - binary_accuracy: 0.7250 - sensitivity: 0.9486 - specificity: 0.2027 - gmeasure: 0.4346 - auc: 0.7476 - val_loss: 0.7115 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5098
Epoch 97/100
640/640 [==============================] - 0s 72us/step - loss: 0.5507 - binary_accuracy: 0.7281 - sensitivity: 0.9780 - specificity: 0.1560 - gmeasure: 0.3896 - auc: 0.7148 - val_loss: 0.7080 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5102
Epoch 98/100
640/640 [==============================] - 0s 76us/step - loss: 0.5447 - binary_accuracy: 0.7359 - sensitivity: 0.9519 - specificity: 0.2701 - gmeasure: 0.4992 - auc: 0.7413 - val_loss: 0.6980 - val_binary_accuracy: 0.6625 - val_sensitivity: 0.8545 - val_specificity: 0.2400 - val_gmeasure: 0.4529 - val_auc: 0.5107
Epoch 99/100
640/640 [==============================] - 0s 77us/step - loss: 0.5476 - binary_accuracy: 0.7172 - sensitivity: 0.9224 - specificity: 0.2872 - gmeasure: 0.5088 - auc: 0.7223 - val_loss: 0.7003 - val_binary_accuracy: 0.6500 - val_sensitivity: 0.8636 - val_specificity: 0.1800 - val_gmeasure: 0.3943 - val_auc: 0.5098
Epoch 100/100
640/640 [==============================] - 0s 79us/step - loss: 0.5429 - binary_accuracy: 0.7297 - sensitivity: 0.9426 - specificity: 0.1900 - gmeasure: 0.3649 - auc: 0.6942 - val_loss: 0.7107 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9364 - val_specificity: 0.1400 - val_gmeasure: 0.3621 - val_auc: 0.5093
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:143] Training end with time 6.652949571609497!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.012808561325073242!
[root    |INFO|build_network.py:175] Evaluation: [0.5787315368652344, 0.7174999713897705, 0.9602169990539551, 0.17408907413482666, 0.408856064081192, 0.6828048825263977]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 17us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.010796785354614258!
[root    |INFO|build_network.py:175] Evaluation: [0.7851572632789612, 0.6050000190734863, 0.8823529481887817, 0.015625, 0.11741705238819122, 0.42463234066963196]
[root    |INFO|deepbiome.py:179] Compute time : 8.323055028915405
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.53860156 0.71208332 0.97788763 0.10282598 0.30601188 0.71492948]
[root    |INFO|deepbiome.py:189]        std : [0.05130315 0.010425   0.01402912 0.05281809 0.07860265 0.07188373]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.62561494 0.67596187 0.94961431 0.00520833 0.03913902 0.56942816]
[root    |INFO|deepbiome.py:196]        std : [0.11582306 0.05413246 0.04819735 0.0073657  0.05535093 0.13334872]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>Let’s check the history plot again.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_one_input_file_48_0.png" src="_images/example_with_one_input_file_48_0.png" />
</div>
</div>
</div>
<div class="section" id="6.-Load-the-pre-trained-network-for-testing">
<h2>6. Load the pre-trained network for testing<a class="headerlink" href="#6.-Load-the-pre-trained-network-for-testing" title="Permalink to this headline">¶</a></h2>
<p>To test the trained model, we can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_test</span></code> function. If you use the index file, this function provides the evaluation using test index (index set not included in the index file) for each fold. If not, this function provides the evaluation using the whole samples. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is set to <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will test the model only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_test</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">test_network_info</span><span class="p">,</span> <span class="n">test_path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:294] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 1 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 452us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.20798230171203613!
[root    |INFO|build_network.py:175] Evaluation: [0.5137165784835815, 0.6865671873092651, 0.9928057789802551, 0.0, 0.0, 0.7464609146118164]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.42946457862854
[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 2 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 336us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.1733410358428955!
[root    |INFO|build_network.py:175] Evaluation: [0.5779709815979004, 0.7363184094429016, 0.9736841917037964, 0.0, 0.0, 0.5371912121772766]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.478259563446045
[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 3 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 346us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.18228578567504883!
[root    |INFO|build_network.py:175] Evaluation: [0.7851572632789612, 0.6050000190734863, 0.8823529481887817, 0.015625, 0.11741705238819122, 0.42463234066963196]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.442732572555542
[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:328] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:331]       mean : [0.62561494 0.67596187 0.94961431 0.00520833 0.03913902 0.56942816]
[root    |INFO|deepbiome.py:332]        std : [0.11582306 0.05413246 0.04819735 0.0073657  0.05535093 0.13334872]
[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:336] Total Computing Ended
[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>This function provide the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">+</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">s</span>.strip() for s in network_info[&#39;model_info&#39;][&#39;metrics&#39;].split(&#39;,&#39;)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.mean(evaluation, axis=0)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Std : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.std(evaluation, axis=0)]))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc
Mean:           0.6256          0.6760          0.9496          0.0052          0.0391          0.5694
Std :           0.1158          0.0541          0.0482          0.0074          0.0554          0.1333
</pre></div></div>
</div>
</div>
<div class="section" id="7.-Load-the-pre-trained-network-for-prediction">
<h2>7. Load the pre-trained network for prediction<a class="headerlink" href="#7.-Load-the-pre-trained-network-for-prediction" title="Permalink to this headline">¶</a></h2>
<p>If you want to predict using the pre-trained model, you can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_prediction</span></code> function. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is setted as <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will predict only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds sample’s outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight_0.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_prediction</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">prediction_network_info</span><span class="p">,</span> <span class="n">prediction_path_info</span><span class="p">,</span>
                                            <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 1 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 31us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.03324389457702637!
[root    |INFO|deepbiome.py:444] Compute time : 1.058173418045044
[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 2 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 42us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.04417729377746582!
[root    |INFO|deepbiome.py:444] Compute time : 1.021308422088623
[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 3 fold testing
[root    |INFO|build_network.py:505] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:506] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:510] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:511] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:518]      Genus: 48
[root    |INFO|build_network.py:518]     Family: 40
[root    |INFO|build_network.py:518]      Order: 23
[root    |INFO|build_network.py:518]      Class: 17
[root    |INFO|build_network.py:518]     Phylum: 9
[root    |INFO|build_network.py:521] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:522] Phylogenetic_tree_dict info: [&#39;Phylum&#39;, &#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:523] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:533] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:533] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:533] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:533] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:546] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:562] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:563] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:564] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:640] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:189] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 45us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:194] Prediction end with time 0.048058509826660156!
[root    |INFO|deepbiome.py:444] Compute time : 1.0855350494384766
[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:449] Total Computing Ended
[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(3, 1000, 1)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.51283437],
       [0.5276185 ],
       [0.52633697],
       [0.50822663],
       [0.9946495 ],
       [0.9972797 ],
       [0.52487856],
       [0.51862556],
       [0.519346  ],
       [0.71094966]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="release-history.html" class="btn btn-neutral float-right" title="Release History" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="example_with_the_list_of_inputs.html" class="btn btn-neutral float-left" title="Example : k times repetition with the list of k input files" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Youngwon Choi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>