

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Example : k fold cross-validation with an input file &mdash; deepbiome 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Release History" href="release-history.html" />
    <link rel="prev" title="Example : k times repetition with the list of k input files" href="example_with_the_list_of_inputs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deepbiome
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_with_the_list_of_inputs.html">Example : k times repetition with the list of k input files</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Example : k fold cross-validation with an input file</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#1.-Load-library">1. Load library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Prepare-the-dataset">2. Prepare the dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-tree-information">Example of the tree information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-input-file">Example of the input file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(regression)">Example of the Y (regression)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example-of-the-Y-(classification)">Example of the Y (classification)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exmple-of-the-training-index-file-for-k-fold-cross-validation">Exmple of the training index file for <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#3.-Prepare-the-configuration">3. Prepare the configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-network-information-(network_info)">For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#For-preparing-the-configuration-about-the-path-information-(path_info)">For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#4.-Deepbiome-Training">4. Deepbiome Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5.-Load-the-pre-trained-network-for-training">5. Load the pre-trained network for training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#6.-Load-the-pre-trained-network-for-testing">6. Load the pre-trained network for testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#7.-Load-the-pre-trained-network-for-prediction">7. Load the pre-trained network for prediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="release-history.html">Release History</a></li>
<li class="toctree-l1"><a class="reference internal" href="min_versions.html">Minimum Version of Python and NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepbiome</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Example : k fold cross-validation with an input file</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/example_with_one_input_file.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Example-:-k-fold-cross-validation-with-an-input-file">
<h1>Example : k fold cross-validation with an input file<a class="headerlink" href="#Example-:-k-fold-cross-validation-with-an-input-file" title="Permalink to this headline">¶</a></h1>
<p>DeepBiome package takes microbiome abundance data as input and uses the phylogenetic taxonomy to guide the decision of the optimal number of layers and neurons in the deep learning architecture.</p>
<p>To use DeepBiome, you can experiment (1) <strong>k times repetition</strong> or (2) <strong>k fold cross-validation</strong>. For each experiment, we asuume that the dataset is given by - <strong>A list of k input files for k times repetition.</strong> - <strong>One input file for k fold cross-validation.</strong></p>
<p>This notebook contains an example of (2) <strong>k fold cross-validation</strong> for the deep neural netowrk using deepbiome.</p>
<div class="section" id="1.-Load-library">
<h2>1. Load library<a class="headerlink" href="#1.-Load-library" title="Permalink to this headline">¶</a></h2>
<p>First, we load the DeepBiome package. The DeepBiome package is built on the tensorflow and keras library</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">resource_filename</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">deepbiome</span> <span class="kn">import</span> <span class="n">deepbiome</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
</pre></div></div>
</div>
</div>
<div class="section" id="2.-Prepare-the-dataset">
<h2>2. Prepare the dataset<a class="headerlink" href="#2.-Prepare-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this example, we assume that we have <strong>one input file for k times repetition.</strong></p>
<p>DeepBiome needs 3 data files as follows: 1. <strong>the tree information</strong> 1. <strong>the input file</strong> 1. <strong>y</strong></p>
<p>For <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation, we can use an input file. In addition, we can set <strong>the training index for each fold</strong>. If we set the index file, DeepBiome build the training set for each fold based on each fold index in the index file. If not, DeepBiome will generate the index file locally.</p>
<p>Eath data should have the csv format as follow:</p>
<div class="section" id="Example-of-the-tree-information">
<h3>Example of the tree information<a class="headerlink" href="#Example-of-the-tree-information" title="Permalink to this headline">¶</a></h3>
<p>First we need a file about the phylogenetic tree information. This tree information file should have the format below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tree_information</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">))</span>
<span class="n">tree_information</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genus</th>
      <th>Family</th>
      <th>Order</th>
      <th>Class</th>
      <th>Phylum</th>
      <th>Domain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Streptococcus</td>
      <td>Streptococcaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Tropheryma</td>
      <td>Cellulomonadaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Veillonella</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Actinomyces</td>
      <td>Actinomycetaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Flavobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Prevotella</td>
      <td>Prevotellaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Porphyromonas</td>
      <td>Porphyromonadaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Parvimonas</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Fusobacterium</td>
      <td>Fusobacteriaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Propionibacterium</td>
      <td>Propionibacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Gemella</td>
      <td>Bacillales_Incertae_Sedis_XI</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Rothia</td>
      <td>Micrococcaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Granulicatella</td>
      <td>Carnobacteriaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Neisseria</td>
      <td>Neisseriaceae</td>
      <td>Neisseriales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Lactobacillus</td>
      <td>Lactobacillaceae</td>
      <td>Lactobacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Megasphaera</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Catonella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Atopobium</td>
      <td>Coriobacteriaceae</td>
      <td>Coriobacteriales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Campylobacter</td>
      <td>Campylobacteraceae</td>
      <td>Campylobacterales</td>
      <td>Epsilonproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Capnocytophaga</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Solobacterium</td>
      <td>Erysipelotrichaceae</td>
      <td>Erysipelotrichales</td>
      <td>Erysipelotrichia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Moryella</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>22</th>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7_genera_incertae_sedis</td>
      <td>TM7</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Staphylococcus</td>
      <td>Staphylococcaceae</td>
      <td>Bacillales</td>
      <td>Bacilli</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Filifactor</td>
      <td>Peptostreptococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Oribacterium</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Burkholderia</td>
      <td>Burkholderiaceae</td>
      <td>Burkholderiales</td>
      <td>Betaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Sneathia</td>
      <td>Leptotrichiaceae</td>
      <td>Fusobacteriales</td>
      <td>Fusobacteria</td>
      <td>Fusobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Treponema</td>
      <td>Spirochaetaceae</td>
      <td>Spirochaetales</td>
      <td>Spirochaetes</td>
      <td>Spirochaetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Moraxella</td>
      <td>Moraxellaceae</td>
      <td>Pseudomonadales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Haemophilus</td>
      <td>Pasteurellaceae</td>
      <td>Pasteurellales</td>
      <td>Gammaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Selenomonas</td>
      <td>Veillonellaceae</td>
      <td>Selenomonadales</td>
      <td>Negativicutes</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Corynebacterium</td>
      <td>Corynebacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Rhizobium</td>
      <td>Rhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Bradyrhizobium</td>
      <td>Bradyrhizobiaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Methylobacterium</td>
      <td>Methylobacteriaceae</td>
      <td>Rhizobiales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>36</th>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1_genera_incertae_sedis</td>
      <td>OD1</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Finegoldia</td>
      <td>Clostridiales_Incertae_Sedis_XI</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Microbacterium</td>
      <td>Microbacteriaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Sphingomonas</td>
      <td>Sphingomonadaceae</td>
      <td>Sphingomonadales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Chryseobacterium</td>
      <td>Flavobacteriaceae</td>
      <td>Flavobacteriales</td>
      <td>Flavobacteria</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Bacteroides</td>
      <td>Bacteroidaceae</td>
      <td>Bacteroidales</td>
      <td>Bacteroidia</td>
      <td>Bacteroidetes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Bdellovibrio</td>
      <td>Bdellovibrionaceae</td>
      <td>Bdellovibrionales</td>
      <td>Deltaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Streptophyta</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Chloroplast</td>
      <td>Cyanobacteria_Chloroplast</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Lachnospiracea_incertae_sedis</td>
      <td>Lachnospiraceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Paracoccus</td>
      <td>Rhodobacteraceae</td>
      <td>Rhodobacterales</td>
      <td>Alphaproteobacteria</td>
      <td>Proteobacteria</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Fastidiosipila</td>
      <td>Ruminococcaceae</td>
      <td>Clostridiales</td>
      <td>Clostridia</td>
      <td>Firmicutes</td>
      <td>Bacteria</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Pseudonocardia</td>
      <td>Pseudonocardiaceae</td>
      <td>Actinomycetales</td>
      <td>Actinobacteria</td>
      <td>Actinobacteria</td>
      <td>Bacteria</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-input-file">
<h3>Example of the input file<a class="headerlink" href="#Example-of-the-input-file" title="Permalink to this headline">¶</a></h3>
<p>Below is an example of the input file. This example has 1000 samples’ microbiome abandunce.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_x.csv&#39;</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>841</td>
      <td>0</td>
      <td>813</td>
      <td>505</td>
      <td>5</td>
      <td>3224</td>
      <td>0</td>
      <td>362</td>
      <td>11</td>
      <td>65</td>
      <td>...</td>
      <td>0</td>
      <td>87</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2133</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1445</td>
      <td>0</td>
      <td>1</td>
      <td>573</td>
      <td>0</td>
      <td>1278</td>
      <td>82</td>
      <td>85</td>
      <td>69</td>
      <td>154</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3638</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1259</td>
      <td>0</td>
      <td>805</td>
      <td>650</td>
      <td>0</td>
      <td>1088</td>
      <td>0</td>
      <td>0</td>
      <td>74</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3445</td>
    </tr>
    <tr>
      <th>3</th>
      <td>982</td>
      <td>0</td>
      <td>327</td>
      <td>594</td>
      <td>0</td>
      <td>960</td>
      <td>81</td>
      <td>19</td>
      <td>9</td>
      <td>0</td>
      <td>...</td>
      <td>157</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3507</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1162</td>
      <td>0</td>
      <td>130</td>
      <td>969</td>
      <td>163</td>
      <td>1515</td>
      <td>167</td>
      <td>4</td>
      <td>162</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>60</td>
      <td>0</td>
      <td>0</td>
      <td>3945</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Streptococcus</th>
      <th>Tropheryma</th>
      <th>Veillonella</th>
      <th>Actinomyces</th>
      <th>Flavobacterium</th>
      <th>Prevotella</th>
      <th>Porphyromonas</th>
      <th>Parvimonas</th>
      <th>Fusobacterium</th>
      <th>Propionibacterium</th>
      <th>...</th>
      <th>Microbacterium</th>
      <th>Sphingomonas</th>
      <th>Chryseobacterium</th>
      <th>Bacteroides</th>
      <th>Bdellovibrio</th>
      <th>Streptophyta</th>
      <th>Lachnospiracea_incertae_sedis</th>
      <th>Paracoccus</th>
      <th>Fastidiosipila</th>
      <th>Pseudonocardia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1401</td>
      <td>4</td>
      <td>30</td>
      <td>526</td>
      <td>0</td>
      <td>923</td>
      <td>25</td>
      <td>0</td>
      <td>127</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4470</td>
    </tr>
    <tr>
      <th>996</th>
      <td>2655</td>
      <td>6</td>
      <td>106</td>
      <td>74</td>
      <td>0</td>
      <td>952</td>
      <td>76</td>
      <td>13</td>
      <td>158</td>
      <td>125</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2826</td>
    </tr>
    <tr>
      <th>997</th>
      <td>335</td>
      <td>0</td>
      <td>71</td>
      <td>259</td>
      <td>67</td>
      <td>718</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>167</td>
      <td>...</td>
      <td>0</td>
      <td>246</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6527</td>
    </tr>
    <tr>
      <th>998</th>
      <td>649</td>
      <td>69</td>
      <td>966</td>
      <td>1227</td>
      <td>0</td>
      <td>508</td>
      <td>2</td>
      <td>30</td>
      <td>550</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4402</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1258</td>
      <td>0</td>
      <td>0</td>
      <td>1119</td>
      <td>0</td>
      <td>2348</td>
      <td>25</td>
      <td>0</td>
      <td>137</td>
      <td>176</td>
      <td>...</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2585</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 48 columns</p>
</div></div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(regression)">
<h3>Example of the Y (regression)<a class="headerlink" href="#Example-of-the-Y-(regression)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for regression problem.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_regression_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.997270</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.004092</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.485126</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.489590</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.500001</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>2.609926</td>
    </tr>
    <tr>
      <th>996</th>
      <td>5.488959</td>
    </tr>
    <tr>
      <th>997</th>
      <td>3.498418</td>
    </tr>
    <tr>
      <th>998</th>
      <td>5.486107</td>
    </tr>
    <tr>
      <th>999</th>
      <td>5.319623</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>For one repetition, the deepbiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    4.997270
1    5.004092
2    5.485126
3    5.489590
4    1.500001
Name: x1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    2.609926
996    5.488959
997    3.498418
998    5.486107
999    5.319623
Name: x1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Example-of-the-Y-(classification)">
<h3>Example of the Y (classification)<a class="headerlink" href="#Example-of-the-Y-(classification)" title="Permalink to this headline">¶</a></h3>
<p>This is an example of the output file for classification problem. Below example file has 1000 samples in rows, 1000 repetition in columns.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_classification_y.csv&#39;</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>997</th>
      <td>1.0</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.0</td>
    </tr>
    <tr>
      <th>999</th>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>For one repetition, DeepBiome will use the one column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    1.0
1    1.0
2    0.0
3    0.0
4    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>995    1.0
996    0.0
997    1.0
998    0.0
999    1.0
Name: V1, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="Exmple-of-the-training-index-file-for-k-fold-cross-validation">
<h3>Exmple of the training index file for <code class="docutils literal notranslate"><span class="pre">k</span></code> fold cross-validation<a class="headerlink" href="#Exmple-of-the-training-index-file-for-k-fold-cross-validation" title="Permalink to this headline">¶</a></h3>
<p>For each fold, we have to set the training and test set. If the index file is given, DeepBiome sets the training set and test set based on the index file for 5 fold cross-validation. Below is the example of the index file. Each column has the training indices for each fold. DeepBiome will only use the samples in this index set for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">idxs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>3</td>
      <td>6</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>4</td>
      <td>8</td>
      <td>4</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>795</th>
      <td>993</td>
      <td>995</td>
      <td>993</td>
      <td>994</td>
      <td>995</td>
    </tr>
    <tr>
      <th>796</th>
      <td>994</td>
      <td>996</td>
      <td>994</td>
      <td>995</td>
      <td>996</td>
    </tr>
    <tr>
      <th>797</th>
      <td>996</td>
      <td>997</td>
      <td>995</td>
      <td>996</td>
      <td>997</td>
    </tr>
    <tr>
      <th>798</th>
      <td>998</td>
      <td>998</td>
      <td>997</td>
      <td>997</td>
      <td>998</td>
    </tr>
    <tr>
      <th>799</th>
      <td>999</td>
      <td>999</td>
      <td>998</td>
      <td>999</td>
      <td>999</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Below is the index set for 1st fold. From 1000 samples above, it uses 800 samples for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0    0
1    1
2    2
3    5
4    6
Name: 0, dtype: int64
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idxs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>795    993
796    994
797    996
798    998
799    999
Name: 0, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="3.-Prepare-the-configuration">
<h2>3. Prepare the configuration<a class="headerlink" href="#3.-Prepare-the-configuration" title="Permalink to this headline">¶</a></h2>
<p>For detailed configuration, we can build the configuration information for the network training by: 1. the python dictionary format 1. the configufation file (.cfg).</p>
<p>In this notebook, we show the python dictionary format configuration.</p>
<p>Please check the detailed information about each option in the <a class="reference external" href="https://young-won.github.io/deepbiome/prerequisites.html#configuration">documantation</a></p>
<div class="section" id="For-preparing-the-configuration-about-the-network-information-(network_info)">
<h3>For preparing the configuration about the network information (<code class="docutils literal notranslate"><span class="pre">network_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-network-information-(network_info)" title="Permalink to this headline">¶</a></h3>
<p>To give the information about the training process, we provide a dictionary of configurations to the <code class="docutils literal notranslate"><span class="pre">netowrk_info</span></code> field. Your configuration for the network training should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;50&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="For-preparing-the-configuration-about-the-path-information-(path_info)">
<h3>For preparing the configuration about the path information (<code class="docutils literal notranslate"><span class="pre">path_info</span></code>)<a class="headerlink" href="#For-preparing-the-configuration-about-the-path-information-(path_info)" title="Permalink to this headline">¶</a></h3>
<p>To give the information about the path of dataset, paths for saving the trained weights and the evaluation results, you have to provide a dictionary for configuration to the <code class="docutils literal notranslate"><span class="pre">path_info</span></code> feild. Your configuration for the path information should include the information about:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;hist.json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="4.-Deepbiome-Training">
<h2>4. Deepbiome Training<a class="headerlink" href="#4.-Deepbiome-Training" title="Permalink to this headline">¶</a></h2>
<p>Now we can train the DeepBiome network based on the configurations.</p>
<p>For logging, we used the python logging library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;[</span><span class="si">%(name)-8s</span><span class="s1">|</span><span class="si">%(levelname)s</span><span class="s1">|</span><span class="si">%(filename)s</span><span class="s1">:</span><span class="si">%(lineno)s</span><span class="s1">] </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The deeobiome_train function provide the test evaluation, train evaluation and the deepbiome network instance.</p>
<p>If we set <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code>, then DeepBiome performs cross-validation based on that value. If not, DeepBiome package performs cross-validation based on the index file. If both <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> option and the index file are missing, then the library performs leave-one-out-cross-validation (LOOCV).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 1ms/step - loss: 0.6514 - binary_accuracy: 0.6500 - sensitivity: 0.9295 - specificity: 0.0659 - gmeasure: 0.0206 - auc: 0.4973 - val_loss: 0.6110 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4696
Epoch 2/100
640/640 [==============================] - 0s 241us/step - loss: 0.6326 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5566 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5507
Epoch 3/100
640/640 [==============================] - 0s 202us/step - loss: 0.6249 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6458 - val_loss: 0.6127 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5947
Epoch 4/100
640/640 [==============================] - 0s 208us/step - loss: 0.6263 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6683 - val_loss: 0.6143 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6251
Epoch 5/100
640/640 [==============================] - 0s 222us/step - loss: 0.6253 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7046 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6216
Epoch 6/100
640/640 [==============================] - 0s 232us/step - loss: 0.6248 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7147 - val_loss: 0.6112 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6169
Epoch 7/100
640/640 [==============================] - 0s 222us/step - loss: 0.6254 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7202 - val_loss: 0.6121 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6134
Epoch 8/100
640/640 [==============================] - 0s 216us/step - loss: 0.6238 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7316 - val_loss: 0.6100 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5999
Epoch 9/100
640/640 [==============================] - 0s 218us/step - loss: 0.6252 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7316 - val_loss: 0.6095 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5955
Epoch 10/100
640/640 [==============================] - 0s 232us/step - loss: 0.6215 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7324 - val_loss: 0.6052 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5943
Epoch 11/100
640/640 [==============================] - 0s 220us/step - loss: 0.6150 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7446 - val_loss: 0.5979 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6042
Epoch 12/100
640/640 [==============================] - 0s 213us/step - loss: 0.6020 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7295 - val_loss: 0.5843 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6185
Epoch 13/100
640/640 [==============================] - 0s 234us/step - loss: 0.5830 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7310 - val_loss: 0.5742 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5963
Epoch 14/100
640/640 [==============================] - 0s 227us/step - loss: 0.5594 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7434 - val_loss: 0.5720 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6028
Epoch 15/100
640/640 [==============================] - 0s 229us/step - loss: 0.5479 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7572 - val_loss: 0.5721 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6422
Epoch 16/100
640/640 [==============================] - 0s 222us/step - loss: 0.5378 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7665 - val_loss: 0.5614 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6976
Epoch 17/100
640/640 [==============================] - 0s 235us/step - loss: 0.5343 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.8129 - val_loss: 0.5447 - val_binary_accuracy: 0.7000 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.7136
Epoch 18/100
640/640 [==============================] - 0s 237us/step - loss: 0.5160 - binary_accuracy: 0.6828 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.7930 - val_loss: 0.5333 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9858 - val_specificity: 0.1267 - val_gmeasure: 0.2980 - val_auc: 0.7166
Epoch 19/100
640/640 [==============================] - 0s 233us/step - loss: 0.5029 - binary_accuracy: 0.7094 - sensitivity: 0.9934 - specificity: 0.0960 - gmeasure: 0.2634 - auc: 0.8179 - val_loss: 0.5223 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9858 - val_specificity: 0.1267 - val_gmeasure: 0.2980 - val_auc: 0.7305
Epoch 20/100
640/640 [==============================] - 0s 233us/step - loss: 0.4878 - binary_accuracy: 0.7172 - sensitivity: 0.9824 - specificity: 0.1507 - gmeasure: 0.3761 - auc: 0.8316 - val_loss: 0.5158 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9358 - val_specificity: 0.1801 - val_gmeasure: 0.3992 - val_auc: 0.7579
Epoch 21/100
640/640 [==============================] - 0s 242us/step - loss: 0.4805 - binary_accuracy: 0.7281 - sensitivity: 0.9845 - specificity: 0.1822 - gmeasure: 0.4031 - auc: 0.8336 - val_loss: 0.5197 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.8943 - val_specificity: 0.3131 - val_gmeasure: 0.5092 - val_auc: 0.7545
Epoch 22/100
640/640 [==============================] - 0s 239us/step - loss: 0.4803 - binary_accuracy: 0.7484 - sensitivity: 0.9624 - specificity: 0.2987 - gmeasure: 0.5055 - auc: 0.8363 - val_loss: 0.5122 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9358 - val_specificity: 0.1832 - val_gmeasure: 0.4064 - val_auc: 0.7800
Epoch 23/100
640/640 [==============================] - 0s 241us/step - loss: 0.4683 - binary_accuracy: 0.7703 - sensitivity: 0.9351 - specificity: 0.4282 - gmeasure: 0.6112 - auc: 0.8415 - val_loss: 0.5276 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9009 - val_specificity: 0.2775 - val_gmeasure: 0.4284 - val_auc: 0.7517
Epoch 24/100
640/640 [==============================] - 0s 244us/step - loss: 0.4630 - binary_accuracy: 0.7328 - sensitivity: 0.9619 - specificity: 0.2336 - gmeasure: 0.4591 - auc: 0.8320 - val_loss: 0.5054 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9009 - val_specificity: 0.3839 - val_gmeasure: 0.5711 - val_auc: 0.7879
Epoch 25/100
640/640 [==============================] - 0s 228us/step - loss: 0.4573 - binary_accuracy: 0.7516 - sensitivity: 0.9451 - specificity: 0.3370 - gmeasure: 0.5547 - auc: 0.8507 - val_loss: 0.5066 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.9009 - val_specificity: 0.3839 - val_gmeasure: 0.5711 - val_auc: 0.7771
Epoch 26/100
640/640 [==============================] - 0s 214us/step - loss: 0.4517 - binary_accuracy: 0.7531 - sensitivity: 0.9504 - specificity: 0.3337 - gmeasure: 0.5563 - auc: 0.8561 - val_loss: 0.5053 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.8867 - val_specificity: 0.4047 - val_gmeasure: 0.5892 - val_auc: 0.7894
Epoch 27/100
640/640 [==============================] - 0s 223us/step - loss: 0.4497 - binary_accuracy: 0.7688 - sensitivity: 0.9071 - specificity: 0.4917 - gmeasure: 0.6588 - auc: 0.8509 - val_loss: 0.5082 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.9217 - val_specificity: 0.3131 - val_gmeasure: 0.5166 - val_auc: 0.7948
Epoch 28/100
640/640 [==============================] - 0s 235us/step - loss: 0.4447 - binary_accuracy: 0.7531 - sensitivity: 0.9520 - specificity: 0.3175 - gmeasure: 0.5381 - auc: 0.8538 - val_loss: 0.5046 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.8445 - val_specificity: 0.5766 - val_gmeasure: 0.6948 - val_auc: 0.7879
Epoch 29/100
640/640 [==============================] - 0s 220us/step - loss: 0.4515 - binary_accuracy: 0.7563 - sensitivity: 0.8802 - specificity: 0.5025 - gmeasure: 0.6365 - auc: 0.8643 - val_loss: 0.5104 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9358 - val_specificity: 0.3309 - val_gmeasure: 0.5343 - val_auc: 0.7974
Epoch 30/100
640/640 [==============================] - 0s 224us/step - loss: 0.4443 - binary_accuracy: 0.7672 - sensitivity: 0.9199 - specificity: 0.4487 - gmeasure: 0.6356 - auc: 0.8609 - val_loss: 0.4964 - val_binary_accuracy: 0.7563 - val_sensitivity: 0.8867 - val_specificity: 0.4226 - val_gmeasure: 0.6028 - val_auc: 0.7922
Epoch 31/100
640/640 [==============================] - 0s 233us/step - loss: 0.4380 - binary_accuracy: 0.7734 - sensitivity: 0.9277 - specificity: 0.4441 - gmeasure: 0.6346 - auc: 0.8526 - val_loss: 0.5011 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.8445 - val_specificity: 0.5588 - val_gmeasure: 0.6842 - val_auc: 0.8014
Epoch 32/100
640/640 [==============================] - 0s 234us/step - loss: 0.4385 - binary_accuracy: 0.7766 - sensitivity: 0.9159 - specificity: 0.4755 - gmeasure: 0.6460 - auc: 0.8650 - val_loss: 0.4980 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.9141 - val_specificity: 0.3518 - val_gmeasure: 0.5574 - val_auc: 0.7976
Epoch 33/100
640/640 [==============================] - 0s 233us/step - loss: 0.4287 - binary_accuracy: 0.7734 - sensitivity: 0.9405 - specificity: 0.4063 - gmeasure: 0.6058 - auc: 0.8647 - val_loss: 0.5054 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.8511 - val_specificity: 0.5409 - val_gmeasure: 0.6751 - val_auc: 0.7954
Epoch 34/100
640/640 [==============================] - 0s 242us/step - loss: 0.4305 - binary_accuracy: 0.7812 - sensitivity: 0.8614 - specificity: 0.5960 - gmeasure: 0.7041 - auc: 0.8614 - val_loss: 0.5096 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9217 - val_specificity: 0.3518 - val_gmeasure: 0.5599 - val_auc: 0.8066
Epoch 35/100
640/640 [==============================] - 0s 238us/step - loss: 0.4256 - binary_accuracy: 0.7844 - sensitivity: 0.9283 - specificity: 0.4875 - gmeasure: 0.6635 - auc: 0.8761 - val_loss: 0.5047 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.8369 - val_specificity: 0.5588 - val_gmeasure: 0.6809 - val_auc: 0.8061
Epoch 36/100
640/640 [==============================] - 0s 220us/step - loss: 0.4233 - binary_accuracy: 0.8062 - sensitivity: 0.8970 - specificity: 0.6019 - gmeasure: 0.7240 - auc: 0.8682 - val_loss: 0.5126 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.9217 - val_specificity: 0.3518 - val_gmeasure: 0.5599 - val_auc: 0.8005
Epoch 37/100
640/640 [==============================] - 0s 212us/step - loss: 0.4229 - binary_accuracy: 0.7828 - sensitivity: 0.9103 - specificity: 0.5097 - gmeasure: 0.6752 - auc: 0.8689 - val_loss: 0.5031 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.8369 - val_specificity: 0.5588 - val_gmeasure: 0.6809 - val_auc: 0.7975
Epoch 38/100
640/640 [==============================] - 0s 238us/step - loss: 0.4141 - binary_accuracy: 0.8016 - sensitivity: 0.9247 - specificity: 0.5261 - gmeasure: 0.6934 - auc: 0.8777 - val_loss: 0.5053 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.8716 - val_specificity: 0.4404 - val_gmeasure: 0.6102 - val_auc: 0.7972
Epoch 39/100
640/640 [==============================] - 0s 220us/step - loss: 0.4171 - binary_accuracy: 0.7953 - sensitivity: 0.8910 - specificity: 0.5991 - gmeasure: 0.7234 - auc: 0.8762 - val_loss: 0.5048 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.8369 - val_specificity: 0.5735 - val_gmeasure: 0.6889 - val_auc: 0.8078
Epoch 40/100
640/640 [==============================] - 0s 228us/step - loss: 0.4177 - binary_accuracy: 0.7812 - sensitivity: 0.9415 - specificity: 0.4394 - gmeasure: 0.6248 - auc: 0.8841 - val_loss: 0.5086 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8294 - val_specificity: 0.6269 - val_gmeasure: 0.7180 - val_auc: 0.7991
Epoch 41/100
640/640 [==============================] - 0s 226us/step - loss: 0.4142 - binary_accuracy: 0.7969 - sensitivity: 0.8060 - specificity: 0.7865 - gmeasure: 0.7892 - auc: 0.8881 - val_loss: 0.5341 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9283 - val_specificity: 0.3518 - val_gmeasure: 0.5613 - val_auc: 0.8102
Epoch 42/100
640/640 [==============================] - 0s 226us/step - loss: 0.4358 - binary_accuracy: 0.7484 - sensitivity: 0.8804 - specificity: 0.4836 - gmeasure: 0.6149 - auc: 0.8800 - val_loss: 0.5225 - val_binary_accuracy: 0.6687 - val_sensitivity: 0.5680 - val_specificity: 0.7896 - val_gmeasure: 0.6660 - val_auc: 0.7821
Epoch 43/100
640/640 [==============================] - 0s 219us/step - loss: 0.4194 - binary_accuracy: 0.7875 - sensitivity: 0.8406 - specificity: 0.6650 - gmeasure: 0.7240 - auc: 0.8855 - val_loss: 0.5258 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9283 - val_specificity: 0.3518 - val_gmeasure: 0.5613 - val_auc: 0.8080
Epoch 44/100
640/640 [==============================] - 0s 236us/step - loss: 0.4042 - binary_accuracy: 0.7891 - sensitivity: 0.9226 - specificity: 0.4883 - gmeasure: 0.6520 - auc: 0.8840 - val_loss: 0.5047 - val_binary_accuracy: 0.7500 - val_sensitivity: 0.7311 - val_specificity: 0.7124 - val_gmeasure: 0.7168 - val_auc: 0.7970
Epoch 45/100
640/640 [==============================] - 0s 239us/step - loss: 0.4149 - binary_accuracy: 0.8047 - sensitivity: 0.8793 - specificity: 0.6355 - gmeasure: 0.7267 - auc: 0.8962 - val_loss: 0.5213 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.9207 - val_specificity: 0.3726 - val_gmeasure: 0.5814 - val_auc: 0.8164
Epoch 46/100
640/640 [==============================] - 0s 238us/step - loss: 0.4044 - binary_accuracy: 0.8109 - sensitivity: 0.8868 - specificity: 0.6313 - gmeasure: 0.7346 - auc: 0.8858 - val_loss: 0.5087 - val_binary_accuracy: 0.7750 - val_sensitivity: 0.8085 - val_specificity: 0.6916 - val_gmeasure: 0.7429 - val_auc: 0.8117
Epoch 47/100
640/640 [==============================] - 0s 236us/step - loss: 0.4004 - binary_accuracy: 0.8234 - sensitivity: 0.9134 - specificity: 0.6220 - gmeasure: 0.7444 - auc: 0.8851 - val_loss: 0.5018 - val_binary_accuracy: 0.7875 - val_sensitivity: 0.8716 - val_specificity: 0.5409 - val_gmeasure: 0.6826 - val_auc: 0.8050
Epoch 48/100
640/640 [==============================] - 0s 241us/step - loss: 0.3951 - binary_accuracy: 0.8188 - sensitivity: 0.9210 - specificity: 0.6046 - gmeasure: 0.7438 - auc: 0.8953 - val_loss: 0.5062 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8439 - val_specificity: 0.5882 - val_gmeasure: 0.6995 - val_auc: 0.8113
Epoch 49/100
640/640 [==============================] - 0s 225us/step - loss: 0.3909 - binary_accuracy: 0.8188 - sensitivity: 0.9059 - specificity: 0.6124 - gmeasure: 0.7377 - auc: 0.8907 - val_loss: 0.5110 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8716 - val_specificity: 0.5735 - val_gmeasure: 0.7025 - val_auc: 0.8051
Epoch 50/100
640/640 [==============================] - 0s 231us/step - loss: 0.3895 - binary_accuracy: 0.8203 - sensitivity: 0.9182 - specificity: 0.6083 - gmeasure: 0.7436 - auc: 0.8934 - val_loss: 0.5101 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8300 - val_specificity: 0.6269 - val_gmeasure: 0.7187 - val_auc: 0.8132
Epoch 51/100
640/640 [==============================] - 0s 235us/step - loss: 0.3882 - binary_accuracy: 0.8250 - sensitivity: 0.8910 - specificity: 0.6684 - gmeasure: 0.7625 - auc: 0.8935 - val_loss: 0.5308 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9062 - val_specificity: 0.4907 - val_gmeasure: 0.6605 - val_auc: 0.8053
Epoch 52/100
640/640 [==============================] - 0s 230us/step - loss: 0.3901 - binary_accuracy: 0.8078 - sensitivity: 0.8744 - specificity: 0.6957 - gmeasure: 0.7744 - auc: 0.8994 - val_loss: 0.5126 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.8570 - val_specificity: 0.5882 - val_gmeasure: 0.7040 - val_auc: 0.8071
Epoch 53/100
640/640 [==============================] - 0s 225us/step - loss: 0.3916 - binary_accuracy: 0.8094 - sensitivity: 0.9139 - specificity: 0.6145 - gmeasure: 0.7385 - auc: 0.8997 - val_loss: 0.5096 - val_binary_accuracy: 0.7688 - val_sensitivity: 0.8155 - val_specificity: 0.6269 - val_gmeasure: 0.7119 - val_auc: 0.8126
Epoch 54/100
640/640 [==============================] - 0s 237us/step - loss: 0.3820 - binary_accuracy: 0.8219 - sensitivity: 0.9020 - specificity: 0.6470 - gmeasure: 0.7590 - auc: 0.8968 - val_loss: 0.5086 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.8570 - val_specificity: 0.5882 - val_gmeasure: 0.7040 - val_auc: 0.8168
Epoch 55/100
640/640 [==============================] - 0s 222us/step - loss: 0.3768 - binary_accuracy: 0.8375 - sensitivity: 0.9164 - specificity: 0.6763 - gmeasure: 0.7839 - auc: 0.9012 - val_loss: 0.5057 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8369 - val_specificity: 0.6061 - val_gmeasure: 0.7073 - val_auc: 0.8157
Epoch 56/100
640/640 [==============================] - 0s 227us/step - loss: 0.3756 - binary_accuracy: 0.8328 - sensitivity: 0.9019 - specificity: 0.6851 - gmeasure: 0.7798 - auc: 0.9094 - val_loss: 0.5269 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8986 - val_specificity: 0.5201 - val_gmeasure: 0.6752 - val_auc: 0.8100
Epoch 57/100
640/640 [==============================] - 0s 219us/step - loss: 0.3756 - binary_accuracy: 0.8344 - sensitivity: 0.9195 - specificity: 0.6578 - gmeasure: 0.7747 - auc: 0.9084 - val_loss: 0.5130 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8917 - val_specificity: 0.5380 - val_gmeasure: 0.6845 - val_auc: 0.8106
Epoch 58/100
640/640 [==============================] - 0s 203us/step - loss: 0.3674 - binary_accuracy: 0.8313 - sensitivity: 0.9140 - specificity: 0.6554 - gmeasure: 0.7656 - auc: 0.9136 - val_loss: 0.5051 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8570 - val_specificity: 0.6061 - val_gmeasure: 0.7148 - val_auc: 0.7962
Epoch 59/100
640/640 [==============================] - 0s 216us/step - loss: 0.3644 - binary_accuracy: 0.8328 - sensitivity: 0.9135 - specificity: 0.6513 - gmeasure: 0.7684 - auc: 0.9080 - val_loss: 0.5104 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8570 - val_specificity: 0.6061 - val_gmeasure: 0.7148 - val_auc: 0.7996
Epoch 60/100
640/640 [==============================] - 0s 218us/step - loss: 0.3605 - binary_accuracy: 0.8453 - sensitivity: 0.9161 - specificity: 0.6840 - gmeasure: 0.7878 - auc: 0.9085 - val_loss: 0.5120 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8771 - val_specificity: 0.5527 - val_gmeasure: 0.6866 - val_auc: 0.8099
Epoch 61/100
640/640 [==============================] - 0s 239us/step - loss: 0.3613 - binary_accuracy: 0.8422 - sensitivity: 0.8988 - specificity: 0.7275 - gmeasure: 0.8047 - auc: 0.9125 - val_loss: 0.5289 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.8986 - val_specificity: 0.5380 - val_gmeasure: 0.6872 - val_auc: 0.8154
Epoch 62/100
640/640 [==============================] - 0s 222us/step - loss: 0.3528 - binary_accuracy: 0.8438 - sensitivity: 0.9351 - specificity: 0.6457 - gmeasure: 0.7728 - auc: 0.9139 - val_loss: 0.4996 - val_binary_accuracy: 0.7625 - val_sensitivity: 0.7516 - val_specificity: 0.6686 - val_gmeasure: 0.7079 - val_auc: 0.7992
Epoch 63/100
640/640 [==============================] - 0s 214us/step - loss: 0.3667 - binary_accuracy: 0.8391 - sensitivity: 0.9052 - specificity: 0.7087 - gmeasure: 0.7965 - auc: 0.9160 - val_loss: 0.5001 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8636 - val_specificity: 0.6061 - val_gmeasure: 0.7170 - val_auc: 0.8220
Epoch 64/100
640/640 [==============================] - 0s 232us/step - loss: 0.3559 - binary_accuracy: 0.8422 - sensitivity: 0.8898 - specificity: 0.7276 - gmeasure: 0.7962 - auc: 0.9158 - val_loss: 0.5403 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.9207 - val_specificity: 0.4167 - val_gmeasure: 0.6112 - val_auc: 0.8133
Epoch 65/100
640/640 [==============================] - 0s 241us/step - loss: 0.3518 - binary_accuracy: 0.8391 - sensitivity: 0.9116 - specificity: 0.6760 - gmeasure: 0.7810 - auc: 0.9136 - val_loss: 0.5077 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.8155 - val_specificity: 0.6686 - val_gmeasure: 0.7374 - val_auc: 0.8103
Epoch 66/100
640/640 [==============================] - 0s 224us/step - loss: 0.3483 - binary_accuracy: 0.8422 - sensitivity: 0.9101 - specificity: 0.6962 - gmeasure: 0.7940 - auc: 0.9150 - val_loss: 0.5012 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8771 - val_specificity: 0.5705 - val_gmeasure: 0.6975 - val_auc: 0.8112
Epoch 67/100
640/640 [==============================] - 0s 206us/step - loss: 0.3421 - binary_accuracy: 0.8578 - sensitivity: 0.9127 - specificity: 0.7378 - gmeasure: 0.8195 - auc: 0.9211 - val_loss: 0.5002 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8771 - val_specificity: 0.5705 - val_gmeasure: 0.6975 - val_auc: 0.8162
Epoch 68/100
640/640 [==============================] - 0s 213us/step - loss: 0.3455 - binary_accuracy: 0.8359 - sensitivity: 0.9044 - specificity: 0.6984 - gmeasure: 0.7855 - auc: 0.9257 - val_loss: 0.5056 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8431 - val_specificity: 0.6686 - val_gmeasure: 0.7498 - val_auc: 0.8169
Epoch 69/100
640/640 [==============================] - 0s 201us/step - loss: 0.3472 - binary_accuracy: 0.8391 - sensitivity: 0.9189 - specificity: 0.6494 - gmeasure: 0.7604 - auc: 0.9205 - val_loss: 0.4866 - val_binary_accuracy: 0.7812 - val_sensitivity: 0.7657 - val_specificity: 0.6894 - val_gmeasure: 0.7261 - val_auc: 0.8083
Epoch 70/100
640/640 [==============================] - 0s 220us/step - loss: 0.3373 - binary_accuracy: 0.8609 - sensitivity: 0.9173 - specificity: 0.7434 - gmeasure: 0.8229 - auc: 0.9267 - val_loss: 0.5179 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8771 - val_specificity: 0.5705 - val_gmeasure: 0.6975 - val_auc: 0.8170
Epoch 71/100
640/640 [==============================] - 0s 226us/step - loss: 0.3368 - binary_accuracy: 0.8594 - sensitivity: 0.9145 - specificity: 0.7401 - gmeasure: 0.8176 - auc: 0.9233 - val_loss: 0.4765 - val_binary_accuracy: 0.7875 - val_sensitivity: 0.8497 - val_specificity: 0.5914 - val_gmeasure: 0.7032 - val_auc: 0.8326
Epoch 72/100
640/640 [==============================] - 0s 223us/step - loss: 0.3311 - binary_accuracy: 0.8500 - sensitivity: 0.9280 - specificity: 0.6729 - gmeasure: 0.7854 - auc: 0.9262 - val_loss: 0.4914 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.7862 - val_specificity: 0.6686 - val_gmeasure: 0.7236 - val_auc: 0.8308
Epoch 73/100
640/640 [==============================] - 0s 227us/step - loss: 0.3218 - binary_accuracy: 0.8672 - sensitivity: 0.9104 - specificity: 0.7724 - gmeasure: 0.8362 - auc: 0.9307 - val_loss: 0.5140 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.9131 - val_specificity: 0.5411 - val_gmeasure: 0.6958 - val_auc: 0.8228
Epoch 74/100
640/640 [==============================] - 0s 225us/step - loss: 0.3256 - binary_accuracy: 0.8578 - sensitivity: 0.9092 - specificity: 0.7348 - gmeasure: 0.8114 - auc: 0.9312 - val_loss: 0.4880 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8771 - val_specificity: 0.5705 - val_gmeasure: 0.6975 - val_auc: 0.8329
Epoch 75/100
640/640 [==============================] - 0s 254us/step - loss: 0.3243 - binary_accuracy: 0.8594 - sensitivity: 0.9229 - specificity: 0.7147 - gmeasure: 0.8083 - auc: 0.9292 - val_loss: 0.4832 - val_binary_accuracy: 0.8000 - val_sensitivity: 0.8431 - val_specificity: 0.6477 - val_gmeasure: 0.7372 - val_auc: 0.8322
Epoch 76/100
640/640 [==============================] - 0s 229us/step - loss: 0.3130 - binary_accuracy: 0.8562 - sensitivity: 0.9149 - specificity: 0.7360 - gmeasure: 0.8188 - auc: 0.9348 - val_loss: 0.5090 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8986 - val_specificity: 0.5705 - val_gmeasure: 0.7067 - val_auc: 0.8208
Epoch 77/100
640/640 [==============================] - 0s 211us/step - loss: 0.3217 - binary_accuracy: 0.8578 - sensitivity: 0.9154 - specificity: 0.7228 - gmeasure: 0.8045 - auc: 0.9349 - val_loss: 0.4718 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8917 - val_specificity: 0.5705 - val_gmeasure: 0.7039 - val_auc: 0.8172
Epoch 78/100
640/640 [==============================] - 0s 224us/step - loss: 0.3094 - binary_accuracy: 0.8609 - sensitivity: 0.9288 - specificity: 0.7124 - gmeasure: 0.8107 - auc: 0.9363 - val_loss: 0.4896 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8702 - val_specificity: 0.5914 - val_gmeasure: 0.7114 - val_auc: 0.8442
Epoch 79/100
640/640 [==============================] - 0s 228us/step - loss: 0.3074 - binary_accuracy: 0.8656 - sensitivity: 0.9170 - specificity: 0.7477 - gmeasure: 0.8235 - auc: 0.9345 - val_loss: 0.4692 - val_binary_accuracy: 0.8062 - val_sensitivity: 0.8632 - val_specificity: 0.6122 - val_gmeasure: 0.7236 - val_auc: 0.8333
Epoch 80/100
640/640 [==============================] - 0s 209us/step - loss: 0.3111 - binary_accuracy: 0.8641 - sensitivity: 0.9124 - specificity: 0.7725 - gmeasure: 0.8356 - auc: 0.9388 - val_loss: 0.4648 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8841 - val_specificity: 0.5914 - val_gmeasure: 0.7172 - val_auc: 0.8305
Epoch 81/100
640/640 [==============================] - 0s 196us/step - loss: 0.3068 - binary_accuracy: 0.8625 - sensitivity: 0.9362 - specificity: 0.7079 - gmeasure: 0.8087 - auc: 0.9418 - val_loss: 0.4747 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.7862 - val_specificity: 0.6686 - val_gmeasure: 0.7236 - val_auc: 0.8228
Epoch 82/100
640/640 [==============================] - 0s 244us/step - loss: 0.3005 - binary_accuracy: 0.8672 - sensitivity: 0.9228 - specificity: 0.7454 - gmeasure: 0.8275 - auc: 0.9397 - val_loss: 0.4749 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8910 - val_specificity: 0.5914 - val_gmeasure: 0.7201 - val_auc: 0.8256
Epoch 83/100
640/640 [==============================] - 0s 233us/step - loss: 0.2965 - binary_accuracy: 0.8734 - sensitivity: 0.9226 - specificity: 0.7683 - gmeasure: 0.8397 - auc: 0.9398 - val_loss: 0.4684 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.8702 - val_specificity: 0.6122 - val_gmeasure: 0.7266 - val_auc: 0.8250
Epoch 84/100
640/640 [==============================] - 0s 229us/step - loss: 0.2973 - binary_accuracy: 0.8703 - sensitivity: 0.9182 - specificity: 0.7623 - gmeasure: 0.8339 - auc: 0.9406 - val_loss: 0.4571 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8841 - val_specificity: 0.5914 - val_gmeasure: 0.7172 - val_auc: 0.8521
Epoch 85/100
640/640 [==============================] - 0s 239us/step - loss: 0.2919 - binary_accuracy: 0.8813 - sensitivity: 0.9223 - specificity: 0.7929 - gmeasure: 0.8520 - auc: 0.9452 - val_loss: 0.4773 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8910 - val_specificity: 0.5914 - val_gmeasure: 0.7201 - val_auc: 0.8491
Epoch 86/100
640/640 [==============================] - 0s 234us/step - loss: 0.2913 - binary_accuracy: 0.8703 - sensitivity: 0.9064 - specificity: 0.7852 - gmeasure: 0.8385 - auc: 0.9432 - val_loss: 0.4964 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9207 - val_specificity: 0.5558 - val_gmeasure: 0.7078 - val_auc: 0.8535
Epoch 87/100
640/640 [==============================] - 0s 223us/step - loss: 0.2988 - binary_accuracy: 0.8656 - sensitivity: 0.9102 - specificity: 0.7824 - gmeasure: 0.8385 - auc: 0.9474 - val_loss: 0.4548 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8910 - val_specificity: 0.5914 - val_gmeasure: 0.7201 - val_auc: 0.8520
Epoch 88/100
640/640 [==============================] - 0s 197us/step - loss: 0.2877 - binary_accuracy: 0.8781 - sensitivity: 0.9346 - specificity: 0.7526 - gmeasure: 0.8347 - auc: 0.9442 - val_loss: 0.4553 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8841 - val_specificity: 0.6122 - val_gmeasure: 0.7324 - val_auc: 0.8550
Epoch 89/100
640/640 [==============================] - 0s 229us/step - loss: 0.2790 - binary_accuracy: 0.8797 - sensitivity: 0.9350 - specificity: 0.7677 - gmeasure: 0.8451 - auc: 0.9479 - val_loss: 0.4482 - val_binary_accuracy: 0.7937 - val_sensitivity: 0.7928 - val_specificity: 0.6477 - val_gmeasure: 0.7135 - val_auc: 0.8321
Epoch 90/100
640/640 [==============================] - 0s 221us/step - loss: 0.2891 - binary_accuracy: 0.8687 - sensitivity: 0.9216 - specificity: 0.7529 - gmeasure: 0.8274 - auc: 0.9457 - val_loss: 0.4548 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9062 - val_specificity: 0.5914 - val_gmeasure: 0.7270 - val_auc: 0.8581
Epoch 91/100
640/640 [==============================] - 0s 227us/step - loss: 0.2825 - binary_accuracy: 0.8781 - sensitivity: 0.9112 - specificity: 0.8156 - gmeasure: 0.8572 - auc: 0.9539 - val_loss: 0.4672 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9062 - val_specificity: 0.5705 - val_gmeasure: 0.7102 - val_auc: 0.8543
Epoch 92/100
640/640 [==============================] - 0s 239us/step - loss: 0.2805 - binary_accuracy: 0.8719 - sensitivity: 0.9031 - specificity: 0.7992 - gmeasure: 0.8468 - auc: 0.9431 - val_loss: 0.4746 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9131 - val_specificity: 0.5705 - val_gmeasure: 0.7130 - val_auc: 0.8543
Epoch 93/100
640/640 [==============================] - 0s 236us/step - loss: 0.2791 - binary_accuracy: 0.8813 - sensitivity: 0.9295 - specificity: 0.7751 - gmeasure: 0.8440 - auc: 0.9529 - val_loss: 0.4285 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8706 - val_specificity: 0.6269 - val_gmeasure: 0.7349 - val_auc: 0.8599
Epoch 94/100
640/640 [==============================] - 0s 222us/step - loss: 0.2713 - binary_accuracy: 0.8859 - sensitivity: 0.9320 - specificity: 0.7847 - gmeasure: 0.8514 - auc: 0.9491 - val_loss: 0.4496 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8775 - val_specificity: 0.6269 - val_gmeasure: 0.7378 - val_auc: 0.8519
Epoch 95/100
640/640 [==============================] - 0s 238us/step - loss: 0.2792 - binary_accuracy: 0.8781 - sensitivity: 0.9302 - specificity: 0.7723 - gmeasure: 0.8429 - auc: 0.9531 - val_loss: 0.4257 - val_binary_accuracy: 0.8125 - val_sensitivity: 0.7858 - val_specificity: 0.7511 - val_gmeasure: 0.7634 - val_auc: 0.8390
Epoch 96/100
640/640 [==============================] - 0s 233us/step - loss: 0.2714 - binary_accuracy: 0.8875 - sensitivity: 0.9306 - specificity: 0.7959 - gmeasure: 0.8587 - auc: 0.9541 - val_loss: 0.4375 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8841 - val_specificity: 0.6269 - val_gmeasure: 0.7402 - val_auc: 0.8590
Epoch 97/100
640/640 [==============================] - 0s 224us/step - loss: 0.2633 - binary_accuracy: 0.8984 - sensitivity: 0.9340 - specificity: 0.8168 - gmeasure: 0.8725 - auc: 0.9516 - val_loss: 0.4209 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8706 - val_specificity: 0.6269 - val_gmeasure: 0.7349 - val_auc: 0.8604
Epoch 98/100
640/640 [==============================] - 0s 200us/step - loss: 0.2626 - binary_accuracy: 0.8953 - sensitivity: 0.9361 - specificity: 0.8078 - gmeasure: 0.8680 - auc: 0.9551 - val_loss: 0.4397 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8775 - val_specificity: 0.6269 - val_gmeasure: 0.7378 - val_auc: 0.8684
Epoch 99/100
640/640 [==============================] - 0s 233us/step - loss: 0.2620 - binary_accuracy: 0.8813 - sensitivity: 0.9254 - specificity: 0.7839 - gmeasure: 0.8496 - auc: 0.9553 - val_loss: 0.4338 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9131 - val_specificity: 0.6269 - val_gmeasure: 0.7530 - val_auc: 0.8712
Epoch 100/100
640/640 [==============================] - 0s 224us/step - loss: 0.2581 - binary_accuracy: 0.9016 - sensitivity: 0.9440 - specificity: 0.8127 - gmeasure: 0.8740 - auc: 0.9590 - val_loss: 0.4237 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8706 - val_specificity: 0.6595 - val_gmeasure: 0.7528 - val_auc: 0.8746
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 17.63860583305359!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 11us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.017470836639404297!
[root    |INFO|build_network.py:183] Evaluation: [0.29080748558044434, 0.8774999976158142, 0.9016393423080444, 0.824701189994812, 0.8623126149177551, 0.944165050983429]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 28us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.013396501541137695!
[root    |INFO|build_network.py:183] Evaluation: [0.4595063328742981, 0.7860696315765381, 0.8057553768157959, 0.7419354915618896, 0.7731872200965881, 0.8563472032546997]
[root    |INFO|deepbiome.py:179] Compute time : 20.946328163146973
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 873us/step - loss: 0.6680 - binary_accuracy: 0.6828 - sensitivity: 0.9615 - specificity: 0.0330 - gmeasure: 0.0356 - auc: 0.4846 - val_loss: 0.6180 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5978
Epoch 2/100
640/640 [==============================] - 0s 237us/step - loss: 0.6229 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4893 - val_loss: 0.5677 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5776
Epoch 3/100
640/640 [==============================] - 0s 232us/step - loss: 0.6107 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4903 - val_loss: 0.5650 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5910
Epoch 4/100
640/640 [==============================] - 0s 236us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4966 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5999
Epoch 5/100
640/640 [==============================] - 0s 244us/step - loss: 0.6114 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5062 - val_loss: 0.5738 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6121
Epoch 6/100
640/640 [==============================] - 0s 233us/step - loss: 0.6110 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5196 - val_loss: 0.5664 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6080
Epoch 7/100
640/640 [==============================] - 0s 220us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5145 - val_loss: 0.5681 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.6104
Epoch 8/100
640/640 [==============================] - 0s 229us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5204 - val_loss: 0.5680 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5821
Epoch 9/100
640/640 [==============================] - 0s 215us/step - loss: 0.6102 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5174 - val_loss: 0.5667 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5734
Epoch 10/100
640/640 [==============================] - 0s 246us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5288 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5772
Epoch 11/100
640/640 [==============================] - 0s 231us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5400 - val_loss: 0.5691 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5785
Epoch 12/100
640/640 [==============================] - 0s 232us/step - loss: 0.6102 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5366 - val_loss: 0.5685 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5712
Epoch 13/100
640/640 [==============================] - 0s 230us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5499 - val_loss: 0.5681 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5571
Epoch 14/100
640/640 [==============================] - 0s 236us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5621 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5649
Epoch 15/100
640/640 [==============================] - 0s 225us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5767 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5379
Epoch 16/100
640/640 [==============================] - 0s 227us/step - loss: 0.6102 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5739 - val_loss: 0.5710 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5411
Epoch 17/100
640/640 [==============================] - 0s 230us/step - loss: 0.6098 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5729 - val_loss: 0.5682 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5339
Epoch 18/100
640/640 [==============================] - 0s 244us/step - loss: 0.6112 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5808 - val_loss: 0.5656 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5285
Epoch 19/100
640/640 [==============================] - 0s 249us/step - loss: 0.6096 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5873 - val_loss: 0.5691 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5229
Epoch 20/100
640/640 [==============================] - 0s 239us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5898 - val_loss: 0.5706 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5196
Epoch 21/100
640/640 [==============================] - 0s 226us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5974 - val_loss: 0.5665 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5150
Epoch 22/100
640/640 [==============================] - 0s 231us/step - loss: 0.6106 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5938 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5188
Epoch 23/100
640/640 [==============================] - 0s 237us/step - loss: 0.6105 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6054 - val_loss: 0.5666 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5086
Epoch 24/100
640/640 [==============================] - 0s 228us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5967 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5069
Epoch 25/100
640/640 [==============================] - 0s 237us/step - loss: 0.6104 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5997 - val_loss: 0.5667 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5017
Epoch 26/100
640/640 [==============================] - 0s 220us/step - loss: 0.6094 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6006 - val_loss: 0.5694 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4864
Epoch 27/100
640/640 [==============================] - 0s 214us/step - loss: 0.6099 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5986 - val_loss: 0.5677 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4905
Epoch 28/100
640/640 [==============================] - 0s 213us/step - loss: 0.6093 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5941 - val_loss: 0.5694 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4818
Epoch 29/100
640/640 [==============================] - 0s 253us/step - loss: 0.6092 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5940 - val_loss: 0.5686 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4826
Epoch 30/100
640/640 [==============================] - 0s 227us/step - loss: 0.6094 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6007 - val_loss: 0.5666 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4656
Epoch 31/100
640/640 [==============================] - 0s 233us/step - loss: 0.6095 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5916 - val_loss: 0.5686 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4704
Epoch 32/100
640/640 [==============================] - 0s 218us/step - loss: 0.6091 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5985 - val_loss: 0.5688 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4703
Epoch 33/100
640/640 [==============================] - 0s 230us/step - loss: 0.6089 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5977 - val_loss: 0.5679 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4670
Epoch 34/100
640/640 [==============================] - 0s 227us/step - loss: 0.6100 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5957 - val_loss: 0.5669 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4666
Epoch 35/100
640/640 [==============================] - 0s 241us/step - loss: 0.6097 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6051 - val_loss: 0.5715 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4731
Epoch 36/100
640/640 [==============================] - 0s 241us/step - loss: 0.6087 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5922 - val_loss: 0.5672 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4702
Epoch 37/100
640/640 [==============================] - 0s 217us/step - loss: 0.6121 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5989 - val_loss: 0.5639 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4642
Epoch 38/100
640/640 [==============================] - 0s 242us/step - loss: 0.6088 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5899 - val_loss: 0.5720 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4751
Epoch 39/100
640/640 [==============================] - 0s 216us/step - loss: 0.6089 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5908 - val_loss: 0.5703 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4704
Epoch 40/100
640/640 [==============================] - 0s 235us/step - loss: 0.6081 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5874 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4689
Epoch 41/100
640/640 [==============================] - 0s 236us/step - loss: 0.6078 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6017 - val_loss: 0.5668 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4699
Epoch 42/100
640/640 [==============================] - 0s 254us/step - loss: 0.6078 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6010 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4718
Epoch 43/100
640/640 [==============================] - 0s 259us/step - loss: 0.6078 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6044 - val_loss: 0.5677 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4717
Epoch 44/100
640/640 [==============================] - 0s 239us/step - loss: 0.6079 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5941 - val_loss: 0.5679 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4735
Epoch 45/100
640/640 [==============================] - 0s 232us/step - loss: 0.6076 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5874 - val_loss: 0.5698 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4752
Epoch 46/100
640/640 [==============================] - 0s 232us/step - loss: 0.6078 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5978 - val_loss: 0.5671 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4741
Epoch 47/100
640/640 [==============================] - 0s 223us/step - loss: 0.6067 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5990 - val_loss: 0.5683 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4739
Epoch 48/100
640/640 [==============================] - 0s 226us/step - loss: 0.6062 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5901 - val_loss: 0.5690 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4723
Epoch 49/100
640/640 [==============================] - 0s 197us/step - loss: 0.6062 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5911 - val_loss: 0.5682 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4734
Epoch 50/100
640/640 [==============================] - 0s 256us/step - loss: 0.6061 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5876 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4754
Epoch 51/100
640/640 [==============================] - 0s 229us/step - loss: 0.6069 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6035 - val_loss: 0.5661 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4713
Epoch 52/100
640/640 [==============================] - 0s 247us/step - loss: 0.6052 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6023 - val_loss: 0.5689 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4742
Epoch 53/100
640/640 [==============================] - 0s 234us/step - loss: 0.6059 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6024 - val_loss: 0.5705 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4764
Epoch 54/100
640/640 [==============================] - 0s 208us/step - loss: 0.6064 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6062 - val_loss: 0.5656 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4741
Epoch 55/100
640/640 [==============================] - 0s 226us/step - loss: 0.6044 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5942 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4736
Epoch 56/100
640/640 [==============================] - 0s 226us/step - loss: 0.6043 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5908 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4740
Epoch 57/100
640/640 [==============================] - 0s 232us/step - loss: 0.6046 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6027 - val_loss: 0.5688 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4746
Epoch 58/100
640/640 [==============================] - 0s 239us/step - loss: 0.6035 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6041 - val_loss: 0.5674 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4740
Epoch 59/100
640/640 [==============================] - 0s 225us/step - loss: 0.6035 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5948 - val_loss: 0.5673 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4766
Epoch 60/100
640/640 [==============================] - 0s 225us/step - loss: 0.6048 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5983 - val_loss: 0.5703 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4800
Epoch 61/100
640/640 [==============================] - 0s 235us/step - loss: 0.6030 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6007 - val_loss: 0.5665 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4766
Epoch 62/100
640/640 [==============================] - 0s 228us/step - loss: 0.6032 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6064 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4799
Epoch 63/100
640/640 [==============================] - 0s 232us/step - loss: 0.6021 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6098 - val_loss: 0.5710 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4817
Epoch 64/100
640/640 [==============================] - 0s 225us/step - loss: 0.6029 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6041 - val_loss: 0.5721 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4824
Epoch 65/100
640/640 [==============================] - 0s 240us/step - loss: 0.6027 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6004 - val_loss: 0.5664 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4815
Epoch 66/100
640/640 [==============================] - 0s 235us/step - loss: 0.6036 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6120 - val_loss: 0.5726 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4822
Epoch 67/100
640/640 [==============================] - 0s 230us/step - loss: 0.6009 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5998 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4814
Epoch 68/100
640/640 [==============================] - 0s 238us/step - loss: 0.6006 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6092 - val_loss: 0.5687 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4815
Epoch 69/100
640/640 [==============================] - 0s 237us/step - loss: 0.6014 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6064 - val_loss: 0.5719 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4837
Epoch 70/100
640/640 [==============================] - 0s 224us/step - loss: 0.6039 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6137 - val_loss: 0.5678 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4825
Epoch 71/100
640/640 [==============================] - 0s 233us/step - loss: 0.6013 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6039 - val_loss: 0.5748 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4861
Epoch 72/100
640/640 [==============================] - 0s 227us/step - loss: 0.5996 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6112 - val_loss: 0.5683 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4825
Epoch 73/100
640/640 [==============================] - 0s 226us/step - loss: 0.6004 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6081 - val_loss: 0.5702 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4826
Epoch 74/100
640/640 [==============================] - 0s 240us/step - loss: 0.5981 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6021 - val_loss: 0.5742 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4841
Epoch 75/100
640/640 [==============================] - 0s 221us/step - loss: 0.5985 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6149 - val_loss: 0.5702 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4857
Epoch 76/100
640/640 [==============================] - 0s 214us/step - loss: 0.5993 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6006 - val_loss: 0.5719 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4883
Epoch 77/100
640/640 [==============================] - 0s 230us/step - loss: 0.5979 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6136 - val_loss: 0.5706 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4886
Epoch 78/100
640/640 [==============================] - 0s 242us/step - loss: 0.5982 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6239 - val_loss: 0.5702 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4893
Epoch 79/100
640/640 [==============================] - 0s 238us/step - loss: 0.5967 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6143 - val_loss: 0.5762 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4883
Epoch 80/100
640/640 [==============================] - 0s 239us/step - loss: 0.5958 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6149 - val_loss: 0.5717 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4941
Epoch 81/100
640/640 [==============================] - 0s 226us/step - loss: 0.5959 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6196 - val_loss: 0.5713 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4944
Epoch 82/100
640/640 [==============================] - 0s 225us/step - loss: 0.5950 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6062 - val_loss: 0.5739 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4937
Epoch 83/100
640/640 [==============================] - 0s 230us/step - loss: 0.5981 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6220 - val_loss: 0.5788 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4929
Epoch 84/100
640/640 [==============================] - 0s 237us/step - loss: 0.5954 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6245 - val_loss: 0.5713 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4929
Epoch 85/100
640/640 [==============================] - 0s 235us/step - loss: 0.5944 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6193 - val_loss: 0.5752 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4956
Epoch 86/100
640/640 [==============================] - 0s 227us/step - loss: 0.5934 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6229 - val_loss: 0.5744 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4958
Epoch 87/100
640/640 [==============================] - 0s 235us/step - loss: 0.5932 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6278 - val_loss: 0.5745 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4966
Epoch 88/100
640/640 [==============================] - 0s 237us/step - loss: 0.5930 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6135 - val_loss: 0.5748 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4948
Epoch 89/100
640/640 [==============================] - 0s 225us/step - loss: 0.5929 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6148 - val_loss: 0.5759 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4962
Epoch 90/100
640/640 [==============================] - 0s 254us/step - loss: 0.5929 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6206 - val_loss: 0.5791 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4960
Epoch 91/100
640/640 [==============================] - 0s 248us/step - loss: 0.5918 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6221 - val_loss: 0.5761 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4973
Epoch 92/100
640/640 [==============================] - 0s 241us/step - loss: 0.5933 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6139 - val_loss: 0.5758 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4969
Epoch 93/100
640/640 [==============================] - 0s 235us/step - loss: 0.5920 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6288 - val_loss: 0.5814 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4970
Epoch 94/100
640/640 [==============================] - 0s 236us/step - loss: 0.5902 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6232 - val_loss: 0.5768 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4848
Epoch 95/100
640/640 [==============================] - 0s 245us/step - loss: 0.5905 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6266 - val_loss: 0.5790 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4857
Epoch 96/100
640/640 [==============================] - 0s 231us/step - loss: 0.5903 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6226 - val_loss: 0.5794 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4864
Epoch 97/100
640/640 [==============================] - 0s 232us/step - loss: 0.5902 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6315 - val_loss: 0.5806 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4854
Epoch 98/100
640/640 [==============================] - 0s 240us/step - loss: 0.5898 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6265 - val_loss: 0.5780 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4861
Epoch 99/100
640/640 [==============================] - 0s 235us/step - loss: 0.5893 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6309 - val_loss: 0.5827 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4850
Epoch 100/100
640/640 [==============================] - 0s 238us/step - loss: 0.5886 - binary_accuracy: 0.7016 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6214 - val_loss: 0.5819 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4845
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 17.24140453338623!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.015735149383544922!
[root    |INFO|build_network.py:183] Evaluation: [0.5864784121513367, 0.7112500071525574, 1.0, 0.0, 0.0, 0.6002137660980225]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 26us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.01349329948425293!
[root    |INFO|build_network.py:183] Evaluation: [0.5759527683258057, 0.7562189102172852, 1.0, 0.0, 0.0, 0.49046725034713745]
[root    |INFO|deepbiome.py:179] Compute time : 18.8231201171875
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 975us/step - loss: 0.6694 - binary_accuracy: 0.6453 - sensitivity: 0.9304 - specificity: 0.0769 - gmeasure: 0.0237 - auc: 0.4645 - val_loss: 0.6437 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3888
Epoch 2/100
640/640 [==============================] - 0s 260us/step - loss: 0.6278 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4657 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3909
Epoch 3/100
640/640 [==============================] - 0s 255us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4737 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3866
Epoch 4/100
640/640 [==============================] - 0s 241us/step - loss: 0.6184 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4657 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4061
Epoch 5/100
640/640 [==============================] - 0s 247us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4756 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4015
Epoch 6/100
640/640 [==============================] - 0s 231us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4828 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3973
Epoch 7/100
640/640 [==============================] - 0s 241us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4889 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4038
Epoch 8/100
640/640 [==============================] - 0s 262us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5004 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3805
Epoch 9/100
640/640 [==============================] - 0s 216us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.4902 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3900
Epoch 10/100
640/640 [==============================] - 0s 237us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5030 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3912
Epoch 11/100
640/640 [==============================] - 0s 241us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5069 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.3888
Epoch 12/100
640/640 [==============================] - 0s 233us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5171 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4165
Epoch 13/100
640/640 [==============================] - 0s 241us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5148 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4315
Epoch 14/100
640/640 [==============================] - 0s 218us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5164 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4669
Epoch 15/100
640/640 [==============================] - 0s 213us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5383 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5412
Epoch 16/100
640/640 [==============================] - 0s 242us/step - loss: 0.6183 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5437 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5466
Epoch 17/100
640/640 [==============================] - 0s 210us/step - loss: 0.6177 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5569 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5415
Epoch 18/100
640/640 [==============================] - 0s 214us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5601 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5376
Epoch 19/100
640/640 [==============================] - 0s 232us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5500 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5431
Epoch 20/100
640/640 [==============================] - 0s 240us/step - loss: 0.6185 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5568 - val_loss: 0.6217 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5402
Epoch 21/100
640/640 [==============================] - 0s 242us/step - loss: 0.6184 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5431 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5401
Epoch 22/100
640/640 [==============================] - 0s 229us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5638 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5250
Epoch 23/100
640/640 [==============================] - 0s 234us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5572 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5173
Epoch 24/100
640/640 [==============================] - 0s 212us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5567 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5390
Epoch 25/100
640/640 [==============================] - 0s 233us/step - loss: 0.6183 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5576 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5372
Epoch 26/100
640/640 [==============================] - 0s 245us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5638 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5170
Epoch 27/100
640/640 [==============================] - 0s 232us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5624 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5166
Epoch 28/100
640/640 [==============================] - 0s 235us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5620 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5271
Epoch 29/100
640/640 [==============================] - 0s 246us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5464 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5334
Epoch 30/100
640/640 [==============================] - 0s 247us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5557 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5247
Epoch 31/100
640/640 [==============================] - 0s 246us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5511 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5148
Epoch 32/100
640/640 [==============================] - 0s 239us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5569 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5152
Epoch 33/100
640/640 [==============================] - 0s 229us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5597 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5133
Epoch 34/100
640/640 [==============================] - 0s 253us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5675 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5151
Epoch 35/100
640/640 [==============================] - 0s 264us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5616 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5172
Epoch 36/100
640/640 [==============================] - 0s 238us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5610 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5162
Epoch 37/100
640/640 [==============================] - 0s 234us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5528 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5149
Epoch 38/100
640/640 [==============================] - 0s 238us/step - loss: 0.6181 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5464 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5107
Epoch 39/100
640/640 [==============================] - 0s 239us/step - loss: 0.6193 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5567 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5122
Epoch 40/100
640/640 [==============================] - 0s 236us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5561 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5133
Epoch 41/100
640/640 [==============================] - 0s 238us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5608 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5106
Epoch 42/100
640/640 [==============================] - 0s 242us/step - loss: 0.6173 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5612 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5113
Epoch 43/100
640/640 [==============================] - 0s 222us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5506 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5120
Epoch 44/100
640/640 [==============================] - 0s 241us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5600 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5122
Epoch 45/100
640/640 [==============================] - 0s 243us/step - loss: 0.6178 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5687 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5134
Epoch 46/100
640/640 [==============================] - 0s 256us/step - loss: 0.6180 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5718 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5169
Epoch 47/100
640/640 [==============================] - 0s 240us/step - loss: 0.6179 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5640 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5122
Epoch 48/100
640/640 [==============================] - 0s 241us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5714 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5139
Epoch 49/100
640/640 [==============================] - 0s 240us/step - loss: 0.6175 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5727 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5149
Epoch 50/100
640/640 [==============================] - 0s 250us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5625 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5149
Epoch 51/100
640/640 [==============================] - 0s 224us/step - loss: 0.6174 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5741 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5181
Epoch 52/100
640/640 [==============================] - 0s 238us/step - loss: 0.6176 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5708 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5152
Epoch 53/100
640/640 [==============================] - 0s 229us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5684 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5137
Epoch 54/100
640/640 [==============================] - 0s 242us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5709 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5139
Epoch 55/100
640/640 [==============================] - 0s 251us/step - loss: 0.6172 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5631 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5149
Epoch 56/100
640/640 [==============================] - 0s 237us/step - loss: 0.6170 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5833 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5150
Epoch 57/100
640/640 [==============================] - 0s 253us/step - loss: 0.6171 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5739 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5126
Epoch 58/100
640/640 [==============================] - 0s 230us/step - loss: 0.6168 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5682 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5153
Epoch 59/100
640/640 [==============================] - 0s 245us/step - loss: 0.6168 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5761 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5123
Epoch 60/100
640/640 [==============================] - 0s 253us/step - loss: 0.6171 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5679 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5127
Epoch 61/100
640/640 [==============================] - 0s 223us/step - loss: 0.6169 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5757 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5143
Epoch 62/100
640/640 [==============================] - 0s 226us/step - loss: 0.6169 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5736 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5134
Epoch 63/100
640/640 [==============================] - 0s 252us/step - loss: 0.6167 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5776 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5096
Epoch 64/100
640/640 [==============================] - 0s 253us/step - loss: 0.6164 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5827 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5098
Epoch 65/100
640/640 [==============================] - 0s 242us/step - loss: 0.6163 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5727 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5130
Epoch 66/100
640/640 [==============================] - 0s 226us/step - loss: 0.6166 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5744 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5132
Epoch 67/100
640/640 [==============================] - 0s 261us/step - loss: 0.6161 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5689 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5120
Epoch 68/100
640/640 [==============================] - 0s 230us/step - loss: 0.6164 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5772 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5088
Epoch 69/100
640/640 [==============================] - 0s 223us/step - loss: 0.6161 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5889 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5130
Epoch 70/100
640/640 [==============================] - 0s 245us/step - loss: 0.6161 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5742 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5127
Epoch 71/100
640/640 [==============================] - 0s 230us/step - loss: 0.6157 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5715 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5237
Epoch 72/100
640/640 [==============================] - 0s 250us/step - loss: 0.6157 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5647 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5258
Epoch 73/100
640/640 [==============================] - 0s 258us/step - loss: 0.6156 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5733 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5290
Epoch 74/100
640/640 [==============================] - 0s 244us/step - loss: 0.6152 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5715 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5208
Epoch 75/100
640/640 [==============================] - 0s 236us/step - loss: 0.6149 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5864 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5339
Epoch 76/100
640/640 [==============================] - 0s 244us/step - loss: 0.6149 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5923 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5352
Epoch 77/100
640/640 [==============================] - 0s 240us/step - loss: 0.6146 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5997 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5377
Epoch 78/100
640/640 [==============================] - 0s 246us/step - loss: 0.6143 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5921 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5407
Epoch 79/100
640/640 [==============================] - 0s 242us/step - loss: 0.6143 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5825 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5411
Epoch 80/100
640/640 [==============================] - 0s 218us/step - loss: 0.6143 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5900 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5374
Epoch 81/100
640/640 [==============================] - 0s 236us/step - loss: 0.6150 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5846 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5490
Epoch 82/100
640/640 [==============================] - 0s 247us/step - loss: 0.6138 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5888 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5631
Epoch 83/100
640/640 [==============================] - 0s 231us/step - loss: 0.6137 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5967 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5491
Epoch 84/100
640/640 [==============================] - 0s 246us/step - loss: 0.6132 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5990 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5625
Epoch 85/100
640/640 [==============================] - 0s 266us/step - loss: 0.6130 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5885 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5632
Epoch 86/100
640/640 [==============================] - 0s 226us/step - loss: 0.6122 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5989 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5575
Epoch 87/100
640/640 [==============================] - 0s 225us/step - loss: 0.6124 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5934 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5601
Epoch 88/100
640/640 [==============================] - 0s 219us/step - loss: 0.6119 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5994 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5550
Epoch 89/100
640/640 [==============================] - 0s 218us/step - loss: 0.6120 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5974 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5570
Epoch 90/100
640/640 [==============================] - 0s 211us/step - loss: 0.6112 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6007 - val_loss: 0.6223 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5563
Epoch 91/100
640/640 [==============================] - 0s 220us/step - loss: 0.6113 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6079 - val_loss: 0.6223 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5561
Epoch 92/100
640/640 [==============================] - 0s 233us/step - loss: 0.6108 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5999 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5576
Epoch 93/100
640/640 [==============================] - 0s 227us/step - loss: 0.6105 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6055 - val_loss: 0.6221 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5607
Epoch 94/100
640/640 [==============================] - 0s 244us/step - loss: 0.6104 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5939 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5600
Epoch 95/100
640/640 [==============================] - 0s 260us/step - loss: 0.6100 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6040 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5568
Epoch 96/100
640/640 [==============================] - 0s 214us/step - loss: 0.6096 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6027 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5486
Epoch 97/100
640/640 [==============================] - 0s 234us/step - loss: 0.6094 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6063 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5604
Epoch 98/100
640/640 [==============================] - 0s 228us/step - loss: 0.6089 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6091 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5559
Epoch 99/100
640/640 [==============================] - 0s 243us/step - loss: 0.6084 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6164 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5426
Epoch 100/100
640/640 [==============================] - 0s 229us/step - loss: 0.6082 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6027 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5581
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 17.580644845962524!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.01749110221862793!
[root    |INFO|build_network.py:183] Evaluation: [0.6108499765396118, 0.6912500262260437, 1.0, 0.0, 0.0, 0.6003397107124329]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 29us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.013756275177001953!
[root    |INFO|build_network.py:183] Evaluation: [0.6328535079956055, 0.6800000071525574, 1.0, 0.0, 0.0, 0.48609834909439087]
[root    |INFO|deepbiome.py:179] Compute time : 19.31364417076111
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.49604529 0.76000001 0.96721311 0.2749004  0.28743754 0.71490618]
[root    |INFO|deepbiome.py:189]        std : [0.14546571 0.08348527 0.04636766 0.38876787 0.40649807 0.16211051]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.5561042  0.74076285 0.93525179 0.24731183 0.25772907 0.61097093]
[root    |INFO|deepbiome.py:196]        std : [0.072147   0.04466064 0.09156779 0.34975174 0.36448395 0.17351639]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">deepbiome_train</span></code> saves the trained model weights, evaluation results and history based on the path information from the configuration.</p>
<p>From the example above, we can check that <code class="docutils literal notranslate"><span class="pre">hist_*.json</span></code>, <code class="docutils literal notranslate"><span class="pre">weight_*.h5</span></code>, <code class="docutils literal notranslate"><span class="pre">test_eval.npy</span></code>, <code class="docutils literal notranslate"><span class="pre">train_eval.npy</span></code> files were saved.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[&#39;hist_0.json&#39;,
 &#39;weight_2.h5&#39;,
 &#39;test_eval.npy&#39;,
 &#39;weight_0.h5&#39;,
 &#39;train_eval.npy&#39;,
 &#39;hist_2.json&#39;,
 &#39;weight_1.h5&#39;,
 &#39;hist_1.json&#39;]
</pre></div>
</div>
</div>
<p>Lets check the history files.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_one_input_file_40_0.png" src="_images/example_with_one_input_file_40_0.png" />
</div>
</div>
<p>Test evauation and train evauation is the numpy array of the shape (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.45950633, 0.78606963, 0.80575538, 0.74193549, 0.77318722,
        0.8563472 ],
       [0.57595277, 0.75621891, 1.        , 0.        , 0.        ,
        0.49046725],
       [0.63285351, 0.68000001, 1.        , 0.        , 0.        ,
        0.48609835]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_evaluation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.29080749, 0.8775    , 0.90163934, 0.82470119, 0.86231261,
        0.94416505],
       [0.58647841, 0.71125001, 1.        , 0.        , 0.        ,
        0.60021377],
       [0.61084998, 0.69125003, 1.        , 0.        , 0.        ,
        0.60033971]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="5.-Load-the-pre-trained-network-for-training">
<h2>5. Load the pre-trained network for training<a class="headerlink" href="#5.-Load-the-pre-trained-network-for-training" title="Permalink to this headline">¶</a></h2>
<p>If you have a pre-trianed model, you warm_start next training using the pre-trained weights by setting the <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> option in <code class="docutils literal notranslate"><span class="pre">training_info</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>. The file path of the pre-trained weights passed in the <code class="docutils literal notranslate"><span class="pre">warm_start_model</span></code> option. Below is the example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">warm_start_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span><span class="s1">&#39;True&#39;</span><span class="p">,</span>
        <span class="s1">&#39;warm_start_model&#39;</span><span class="p">:</span><span class="s1">&#39;./example_result/weight.h5&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;200&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">warm_start_network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span>
                                                                       <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_0.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 759us/step - loss: 0.2672 - binary_accuracy: 0.8875 - sensitivity: 0.9295 - specificity: 0.7705 - gmeasure: 0.8456 - auc: 0.9500 - val_loss: 0.4331 - val_binary_accuracy: 0.8188 - val_sensitivity: 0.8571 - val_specificity: 0.7292 - val_gmeasure: 0.7906 - val_auc: 0.8825
Epoch 2/100
640/640 [==============================] - 0s 79us/step - loss: 0.2603 - binary_accuracy: 0.8844 - sensitivity: 0.9323 - specificity: 0.7828 - gmeasure: 0.8513 - auc: 0.9614 - val_loss: 0.4312 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9464 - val_specificity: 0.6250 - val_gmeasure: 0.7691 - val_auc: 0.8895
Epoch 3/100
640/640 [==============================] - 0s 95us/step - loss: 0.2568 - binary_accuracy: 0.8984 - sensitivity: 0.9403 - specificity: 0.7943 - gmeasure: 0.8628 - auc: 0.9480 - val_loss: 0.4400 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8929 - val_specificity: 0.6875 - val_gmeasure: 0.7835 - val_auc: 0.8812
Epoch 4/100
640/640 [==============================] - 0s 85us/step - loss: 0.2548 - binary_accuracy: 0.8859 - sensitivity: 0.9193 - specificity: 0.8130 - gmeasure: 0.8640 - auc: 0.9605 - val_loss: 0.4735 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.8795
Epoch 5/100
640/640 [==============================] - 0s 82us/step - loss: 0.2514 - binary_accuracy: 0.8953 - sensitivity: 0.9296 - specificity: 0.8256 - gmeasure: 0.8754 - auc: 0.9632 - val_loss: 0.4299 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8929 - val_specificity: 0.6667 - val_gmeasure: 0.7715 - val_auc: 0.8851
Epoch 6/100
640/640 [==============================] - 0s 90us/step - loss: 0.2478 - binary_accuracy: 0.9016 - sensitivity: 0.9417 - specificity: 0.7789 - gmeasure: 0.8531 - auc: 0.9617 - val_loss: 0.4269 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.9018 - val_specificity: 0.6667 - val_gmeasure: 0.7754 - val_auc: 0.8873
Epoch 7/100
640/640 [==============================] - 0s 84us/step - loss: 0.2543 - binary_accuracy: 0.8922 - sensitivity: 0.8937 - specificity: 0.8894 - gmeasure: 0.8898 - auc: 0.9645 - val_loss: 0.4491 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8929 - val_specificity: 0.6875 - val_gmeasure: 0.7835 - val_auc: 0.8845
Epoch 8/100
640/640 [==============================] - 0s 73us/step - loss: 0.2472 - binary_accuracy: 0.8938 - sensitivity: 0.9489 - specificity: 0.7935 - gmeasure: 0.8672 - auc: 0.9656 - val_loss: 0.4914 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.8856
Epoch 9/100
640/640 [==============================] - 0s 81us/step - loss: 0.2496 - binary_accuracy: 0.8938 - sensitivity: 0.9472 - specificity: 0.7808 - gmeasure: 0.8589 - auc: 0.9529 - val_loss: 0.4162 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8661 - val_specificity: 0.7500 - val_gmeasure: 0.8059 - val_auc: 0.8900
Epoch 10/100
640/640 [==============================] - 0s 77us/step - loss: 0.2514 - binary_accuracy: 0.8969 - sensitivity: 0.9125 - specificity: 0.9148 - gmeasure: 0.9133 - auc: 0.9695 - val_loss: 0.4181 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9196 - val_specificity: 0.6667 - val_gmeasure: 0.7830 - val_auc: 0.8899
Epoch 11/100
640/640 [==============================] - 0s 80us/step - loss: 0.2439 - binary_accuracy: 0.9062 - sensitivity: 0.9631 - specificity: 0.8273 - gmeasure: 0.8922 - auc: 0.9682 - val_loss: 0.4467 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.8898
Epoch 12/100
640/640 [==============================] - 0s 96us/step - loss: 0.2446 - binary_accuracy: 0.9000 - sensitivity: 0.9046 - specificity: 0.8590 - gmeasure: 0.8769 - auc: 0.9601 - val_loss: 0.4358 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9196 - val_specificity: 0.6667 - val_gmeasure: 0.7830 - val_auc: 0.8867
Epoch 13/100
640/640 [==============================] - 0s 95us/step - loss: 0.2413 - binary_accuracy: 0.9000 - sensitivity: 0.9540 - specificity: 0.7873 - gmeasure: 0.8664 - auc: 0.9620 - val_loss: 0.4711 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.8874
Epoch 14/100
640/640 [==============================] - 0s 88us/step - loss: 0.2348 - binary_accuracy: 0.8984 - sensitivity: 0.9367 - specificity: 0.7945 - gmeasure: 0.8625 - auc: 0.9653 - val_loss: 0.4377 - val_binary_accuracy: 0.8313 - val_sensitivity: 0.8661 - val_specificity: 0.7500 - val_gmeasure: 0.8059 - val_auc: 0.8907
Epoch 15/100
640/640 [==============================] - 0s 82us/step - loss: 0.2451 - binary_accuracy: 0.8938 - sensitivity: 0.9103 - specificity: 0.8723 - gmeasure: 0.8906 - auc: 0.9682 - val_loss: 0.4234 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9375 - val_specificity: 0.6667 - val_gmeasure: 0.7906 - val_auc: 0.8951
Epoch 16/100
640/640 [==============================] - 0s 77us/step - loss: 0.2456 - binary_accuracy: 0.9000 - sensitivity: 0.9708 - specificity: 0.7789 - gmeasure: 0.8681 - auc: 0.9672 - val_loss: 0.4335 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.8897
Epoch 17/100
640/640 [==============================] - 0s 81us/step - loss: 0.2511 - binary_accuracy: 0.9016 - sensitivity: 0.9172 - specificity: 0.9047 - gmeasure: 0.9092 - auc: 0.9651 - val_loss: 0.4685 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.8750 - val_specificity: 0.7500 - val_gmeasure: 0.8101 - val_auc: 0.8861
Epoch 18/100
640/640 [==============================] - 0s 88us/step - loss: 0.2389 - binary_accuracy: 0.8938 - sensitivity: 0.9236 - specificity: 0.7823 - gmeasure: 0.8469 - auc: 0.9573 - val_loss: 0.4732 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.8896
Epoch 19/100
640/640 [==============================] - 0s 100us/step - loss: 0.2348 - binary_accuracy: 0.9047 - sensitivity: 0.9515 - specificity: 0.8202 - gmeasure: 0.8814 - auc: 0.9707 - val_loss: 0.3965 - val_binary_accuracy: 0.8250 - val_sensitivity: 0.8661 - val_specificity: 0.7292 - val_gmeasure: 0.7947 - val_auc: 0.8977
Epoch 20/100
640/640 [==============================] - 0s 86us/step - loss: 0.2378 - binary_accuracy: 0.8984 - sensitivity: 0.9200 - specificity: 0.8546 - gmeasure: 0.8857 - auc: 0.9637 - val_loss: 0.4346 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9196 - val_specificity: 0.6667 - val_gmeasure: 0.7830 - val_auc: 0.8903
Epoch 21/100
640/640 [==============================] - 0s 87us/step - loss: 0.2270 - binary_accuracy: 0.9078 - sensitivity: 0.9425 - specificity: 0.8453 - gmeasure: 0.8921 - auc: 0.9699 - val_loss: 0.4541 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8880
Epoch 22/100
640/640 [==============================] - 0s 87us/step - loss: 0.2272 - binary_accuracy: 0.9047 - sensitivity: 0.9264 - specificity: 0.8220 - gmeasure: 0.8721 - auc: 0.9620 - val_loss: 0.4049 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.8974
Epoch 23/100
640/640 [==============================] - 0s 94us/step - loss: 0.2278 - binary_accuracy: 0.9047 - sensitivity: 0.9295 - specificity: 0.8603 - gmeasure: 0.8925 - auc: 0.9618 - val_loss: 0.4213 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8979
Epoch 24/100
640/640 [==============================] - 0s 92us/step - loss: 0.2269 - binary_accuracy: 0.9047 - sensitivity: 0.9359 - specificity: 0.8348 - gmeasure: 0.8832 - auc: 0.9649 - val_loss: 0.4481 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.8938
Epoch 25/100
640/640 [==============================] - 0s 92us/step - loss: 0.2239 - binary_accuracy: 0.9094 - sensitivity: 0.9534 - specificity: 0.8290 - gmeasure: 0.8888 - auc: 0.9692 - val_loss: 0.4560 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.8902
Epoch 26/100
640/640 [==============================] - 0s 93us/step - loss: 0.2241 - binary_accuracy: 0.9047 - sensitivity: 0.9291 - specificity: 0.8642 - gmeasure: 0.8959 - auc: 0.9735 - val_loss: 0.4382 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8956
Epoch 27/100
640/640 [==============================] - 0s 86us/step - loss: 0.2250 - binary_accuracy: 0.9125 - sensitivity: 0.9722 - specificity: 0.7647 - gmeasure: 0.8608 - auc: 0.9653 - val_loss: 0.4316 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.8962
Epoch 28/100
640/640 [==============================] - 0s 87us/step - loss: 0.2252 - binary_accuracy: 0.9062 - sensitivity: 0.9246 - specificity: 0.8834 - gmeasure: 0.9031 - auc: 0.9697 - val_loss: 0.4343 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9018 - val_specificity: 0.7292 - val_gmeasure: 0.8109 - val_auc: 0.8955
Epoch 29/100
640/640 [==============================] - 0s 87us/step - loss: 0.2185 - binary_accuracy: 0.9141 - sensitivity: 0.9473 - specificity: 0.8647 - gmeasure: 0.9050 - auc: 0.9700 - val_loss: 0.4625 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9732 - val_specificity: 0.6250 - val_gmeasure: 0.7799 - val_auc: 0.8987
Epoch 30/100
640/640 [==============================] - 0s 83us/step - loss: 0.2271 - binary_accuracy: 0.9109 - sensitivity: 0.9761 - specificity: 0.7969 - gmeasure: 0.8816 - auc: 0.9736 - val_loss: 0.4192 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9018 - val_specificity: 0.7083 - val_gmeasure: 0.7992 - val_auc: 0.8983
Epoch 31/100
640/640 [==============================] - 0s 90us/step - loss: 0.2200 - binary_accuracy: 0.9047 - sensitivity: 0.9006 - specificity: 0.8592 - gmeasure: 0.8796 - auc: 0.9608 - val_loss: 0.4497 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.8964
Epoch 32/100
640/640 [==============================] - 0s 89us/step - loss: 0.2204 - binary_accuracy: 0.9109 - sensitivity: 0.9659 - specificity: 0.8149 - gmeasure: 0.8865 - auc: 0.9672 - val_loss: 0.4482 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8968
Epoch 33/100
640/640 [==============================] - 0s 90us/step - loss: 0.2109 - binary_accuracy: 0.9141 - sensitivity: 0.9382 - specificity: 0.8237 - gmeasure: 0.8787 - auc: 0.9674 - val_loss: 0.4284 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9018 - val_specificity: 0.7292 - val_gmeasure: 0.8109 - val_auc: 0.8972
Epoch 34/100
640/640 [==============================] - 0s 89us/step - loss: 0.2158 - binary_accuracy: 0.9109 - sensitivity: 0.9149 - specificity: 0.8945 - gmeasure: 0.9045 - auc: 0.9615 - val_loss: 0.4472 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8973
Epoch 35/100
640/640 [==============================] - 0s 94us/step - loss: 0.2125 - binary_accuracy: 0.9125 - sensitivity: 0.9596 - specificity: 0.8352 - gmeasure: 0.8948 - auc: 0.9691 - val_loss: 0.4353 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.8983
Epoch 36/100
640/640 [==============================] - 0s 92us/step - loss: 0.2080 - binary_accuracy: 0.9125 - sensitivity: 0.9457 - specificity: 0.8540 - gmeasure: 0.8985 - auc: 0.9718 - val_loss: 0.4546 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.8949
Epoch 37/100
640/640 [==============================] - 0s 106us/step - loss: 0.2086 - binary_accuracy: 0.9094 - sensitivity: 0.9510 - specificity: 0.8203 - gmeasure: 0.8819 - auc: 0.9744 - val_loss: 0.4429 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.8964
Epoch 38/100
640/640 [==============================] - 0s 86us/step - loss: 0.2078 - binary_accuracy: 0.9094 - sensitivity: 0.8840 - specificity: 0.8648 - gmeasure: 0.8728 - auc: 0.9594 - val_loss: 0.4415 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9554 - val_specificity: 0.6875 - val_gmeasure: 0.8104 - val_auc: 0.9012
Epoch 39/100
640/640 [==============================] - 0s 92us/step - loss: 0.2155 - binary_accuracy: 0.9172 - sensitivity: 0.9686 - specificity: 0.8237 - gmeasure: 0.8923 - auc: 0.9709 - val_loss: 0.4293 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9014
Epoch 40/100
640/640 [==============================] - 0s 87us/step - loss: 0.2100 - binary_accuracy: 0.9094 - sensitivity: 0.9362 - specificity: 0.8627 - gmeasure: 0.8982 - auc: 0.9721 - val_loss: 0.4553 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.8954
Epoch 41/100
640/640 [==============================] - 0s 94us/step - loss: 0.2064 - binary_accuracy: 0.9156 - sensitivity: 0.9597 - specificity: 0.8278 - gmeasure: 0.8905 - auc: 0.9762 - val_loss: 0.4563 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.8981
Epoch 42/100
640/640 [==============================] - 0s 92us/step - loss: 0.2061 - binary_accuracy: 0.9109 - sensitivity: 0.9290 - specificity: 0.8988 - gmeasure: 0.9127 - auc: 0.9765 - val_loss: 0.4311 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.9012
Epoch 43/100
640/640 [==============================] - 0s 90us/step - loss: 0.2070 - binary_accuracy: 0.9141 - sensitivity: 0.9554 - specificity: 0.8394 - gmeasure: 0.8952 - auc: 0.9733 - val_loss: 0.4365 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9007
Epoch 44/100
640/640 [==============================] - 0s 86us/step - loss: 0.2022 - binary_accuracy: 0.9172 - sensitivity: 0.9292 - specificity: 0.8843 - gmeasure: 0.9062 - auc: 0.9756 - val_loss: 0.4539 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.8969
Epoch 45/100
640/640 [==============================] - 0s 91us/step - loss: 0.2000 - binary_accuracy: 0.9125 - sensitivity: 0.9438 - specificity: 0.8674 - gmeasure: 0.9046 - auc: 0.9723 - val_loss: 0.4587 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9375 - val_specificity: 0.6875 - val_gmeasure: 0.8028 - val_auc: 0.8997
Epoch 46/100
640/640 [==============================] - 0s 96us/step - loss: 0.2037 - binary_accuracy: 0.9094 - sensitivity: 0.9423 - specificity: 0.8665 - gmeasure: 0.9030 - auc: 0.9763 - val_loss: 0.4596 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.8997
Epoch 47/100
640/640 [==============================] - 0s 83us/step - loss: 0.2100 - binary_accuracy: 0.9141 - sensitivity: 0.9627 - specificity: 0.7953 - gmeasure: 0.8744 - auc: 0.9672 - val_loss: 0.4334 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9018 - val_specificity: 0.7083 - val_gmeasure: 0.7992 - val_auc: 0.9014
Epoch 48/100
640/640 [==============================] - 0s 87us/step - loss: 0.2147 - binary_accuracy: 0.9094 - sensitivity: 0.9140 - specificity: 0.8769 - gmeasure: 0.8931 - auc: 0.9769 - val_loss: 0.4242 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9018 - val_specificity: 0.7083 - val_gmeasure: 0.7992 - val_auc: 0.9036
Epoch 49/100
640/640 [==============================] - 0s 99us/step - loss: 0.1957 - binary_accuracy: 0.9156 - sensitivity: 0.9557 - specificity: 0.8238 - gmeasure: 0.8869 - auc: 0.9767 - val_loss: 0.4423 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9643 - val_specificity: 0.6667 - val_gmeasure: 0.8018 - val_auc: 0.9029
Epoch 50/100
640/640 [==============================] - 0s 97us/step - loss: 0.1947 - binary_accuracy: 0.9234 - sensitivity: 0.9380 - specificity: 0.8508 - gmeasure: 0.8928 - auc: 0.9669 - val_loss: 0.4204 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.9019
Epoch 51/100
640/640 [==============================] - 0s 91us/step - loss: 0.1947 - binary_accuracy: 0.9187 - sensitivity: 0.9471 - specificity: 0.8940 - gmeasure: 0.9200 - auc: 0.9797 - val_loss: 0.4426 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.9014
Epoch 52/100
640/640 [==============================] - 0s 91us/step - loss: 0.1930 - binary_accuracy: 0.9281 - sensitivity: 0.9705 - specificity: 0.8608 - gmeasure: 0.9137 - auc: 0.9781 - val_loss: 0.4278 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.9014
Epoch 53/100
640/640 [==============================] - 0s 91us/step - loss: 0.1937 - binary_accuracy: 0.9203 - sensitivity: 0.9463 - specificity: 0.9155 - gmeasure: 0.9305 - auc: 0.9793 - val_loss: 0.4204 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.9053
Epoch 54/100
640/640 [==============================] - 0s 77us/step - loss: 0.1913 - binary_accuracy: 0.9266 - sensitivity: 0.9643 - specificity: 0.8262 - gmeasure: 0.8922 - auc: 0.9695 - val_loss: 0.4256 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.9018
Epoch 55/100
640/640 [==============================] - 0s 86us/step - loss: 0.1897 - binary_accuracy: 0.9234 - sensitivity: 0.9422 - specificity: 0.8882 - gmeasure: 0.9147 - auc: 0.9778 - val_loss: 0.4378 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9107 - val_specificity: 0.7083 - val_gmeasure: 0.8032 - val_auc: 0.9042
Epoch 56/100
640/640 [==============================] - 0s 85us/step - loss: 0.1870 - binary_accuracy: 0.9266 - sensitivity: 0.9313 - specificity: 0.8977 - gmeasure: 0.9141 - auc: 0.9759 - val_loss: 0.4670 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9643 - val_specificity: 0.6667 - val_gmeasure: 0.8018 - val_auc: 0.9076
Epoch 57/100
640/640 [==============================] - 0s 83us/step - loss: 0.2106 - binary_accuracy: 0.9156 - sensitivity: 0.9745 - specificity: 0.7564 - gmeasure: 0.8573 - auc: 0.9693 - val_loss: 0.4064 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.8929 - val_specificity: 0.7917 - val_gmeasure: 0.8407 - val_auc: 0.9060
Epoch 58/100
640/640 [==============================] - 0s 75us/step - loss: 0.2102 - binary_accuracy: 0.9156 - sensitivity: 0.9082 - specificity: 0.9578 - gmeasure: 0.9326 - auc: 0.9762 - val_loss: 0.4628 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9554 - val_specificity: 0.6667 - val_gmeasure: 0.7981 - val_auc: 0.9053
Epoch 59/100
640/640 [==============================] - 0s 76us/step - loss: 0.2096 - binary_accuracy: 0.9141 - sensitivity: 0.9817 - specificity: 0.7762 - gmeasure: 0.8728 - auc: 0.9787 - val_loss: 0.4532 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9196 - val_specificity: 0.7083 - val_gmeasure: 0.8071 - val_auc: 0.9005
Epoch 60/100
640/640 [==============================] - 0s 75us/step - loss: 0.2050 - binary_accuracy: 0.9187 - sensitivity: 0.9281 - specificity: 0.9433 - gmeasure: 0.9349 - auc: 0.9801 - val_loss: 0.4387 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9018 - val_specificity: 0.7917 - val_gmeasure: 0.8449 - val_auc: 0.9014
Epoch 61/100
640/640 [==============================] - 0s 72us/step - loss: 0.1886 - binary_accuracy: 0.9297 - sensitivity: 0.9563 - specificity: 0.8705 - gmeasure: 0.9111 - auc: 0.9788 - val_loss: 0.4640 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9643 - val_specificity: 0.6667 - val_gmeasure: 0.8018 - val_auc: 0.9090
Epoch 62/100
640/640 [==============================] - 0s 71us/step - loss: 0.1925 - binary_accuracy: 0.9219 - sensitivity: 0.9591 - specificity: 0.8747 - gmeasure: 0.9145 - auc: 0.9804 - val_loss: 0.4002 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.8839 - val_specificity: 0.7500 - val_gmeasure: 0.8142 - val_auc: 0.9064
Epoch 63/100
640/640 [==============================] - 0s 85us/step - loss: 0.1864 - binary_accuracy: 0.9297 - sensitivity: 0.9370 - specificity: 0.8855 - gmeasure: 0.9104 - auc: 0.9728 - val_loss: 0.4516 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9068
Epoch 64/100
640/640 [==============================] - 0s 87us/step - loss: 0.1846 - binary_accuracy: 0.9297 - sensitivity: 0.9789 - specificity: 0.8412 - gmeasure: 0.9070 - auc: 0.9810 - val_loss: 0.4739 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9018 - val_specificity: 0.7708 - val_gmeasure: 0.8337 - val_auc: 0.8975
Epoch 65/100
640/640 [==============================] - 0s 82us/step - loss: 0.1918 - binary_accuracy: 0.9203 - sensitivity: 0.9101 - specificity: 0.9310 - gmeasure: 0.9203 - auc: 0.9778 - val_loss: 0.4750 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.8994
Epoch 66/100
640/640 [==============================] - 0s 77us/step - loss: 0.1820 - binary_accuracy: 0.9297 - sensitivity: 0.9699 - specificity: 0.8563 - gmeasure: 0.9110 - auc: 0.9753 - val_loss: 0.4013 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9061
Epoch 67/100
640/640 [==============================] - 0s 64us/step - loss: 0.1822 - binary_accuracy: 0.9281 - sensitivity: 0.9526 - specificity: 0.9073 - gmeasure: 0.9293 - auc: 0.9831 - val_loss: 0.4393 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9014
Epoch 68/100
640/640 [==============================] - 0s 76us/step - loss: 0.1815 - binary_accuracy: 0.9234 - sensitivity: 0.9687 - specificity: 0.8222 - gmeasure: 0.8916 - auc: 0.9823 - val_loss: 0.4808 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.8980
Epoch 69/100
640/640 [==============================] - 0s 71us/step - loss: 0.1765 - binary_accuracy: 0.9281 - sensitivity: 0.9481 - specificity: 0.8942 - gmeasure: 0.9205 - auc: 0.9803 - val_loss: 0.4377 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9014
Epoch 70/100
640/640 [==============================] - 0s 83us/step - loss: 0.1726 - binary_accuracy: 0.9344 - sensitivity: 0.9620 - specificity: 0.8611 - gmeasure: 0.9100 - auc: 0.9793 - val_loss: 0.4393 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.9102
Epoch 71/100
640/640 [==============================] - 0s 79us/step - loss: 0.1729 - binary_accuracy: 0.9375 - sensitivity: 0.9626 - specificity: 0.9049 - gmeasure: 0.9329 - auc: 0.9813 - val_loss: 0.4150 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9196 - val_specificity: 0.7083 - val_gmeasure: 0.8071 - val_auc: 0.9055
Epoch 72/100
640/640 [==============================] - 0s 81us/step - loss: 0.1745 - binary_accuracy: 0.9391 - sensitivity: 0.9347 - specificity: 0.9061 - gmeasure: 0.9202 - auc: 0.9684 - val_loss: 0.4163 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9464 - val_specificity: 0.6875 - val_gmeasure: 0.8066 - val_auc: 0.9129
Epoch 73/100
640/640 [==============================] - 0s 78us/step - loss: 0.1730 - binary_accuracy: 0.9344 - sensitivity: 0.9739 - specificity: 0.8681 - gmeasure: 0.9193 - auc: 0.9815 - val_loss: 0.4226 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9070
Epoch 74/100
640/640 [==============================] - 0s 91us/step - loss: 0.1699 - binary_accuracy: 0.9391 - sensitivity: 0.9541 - specificity: 0.9125 - gmeasure: 0.9324 - auc: 0.9819 - val_loss: 0.4588 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9107
Epoch 75/100
640/640 [==============================] - 0s 102us/step - loss: 0.1740 - binary_accuracy: 0.9328 - sensitivity: 0.9777 - specificity: 0.8736 - gmeasure: 0.9227 - auc: 0.9840 - val_loss: 0.4135 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9076
Epoch 76/100
640/640 [==============================] - 0s 98us/step - loss: 0.1691 - binary_accuracy: 0.9375 - sensitivity: 0.9551 - specificity: 0.8975 - gmeasure: 0.9257 - auc: 0.9828 - val_loss: 0.4235 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9079
Epoch 77/100
640/640 [==============================] - 0s 77us/step - loss: 0.1680 - binary_accuracy: 0.9359 - sensitivity: 0.9703 - specificity: 0.8994 - gmeasure: 0.9331 - auc: 0.9840 - val_loss: 0.4327 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9066
Epoch 78/100
640/640 [==============================] - 0s 86us/step - loss: 0.1667 - binary_accuracy: 0.9391 - sensitivity: 0.9668 - specificity: 0.8785 - gmeasure: 0.9207 - auc: 0.9839 - val_loss: 0.4528 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9196 - val_specificity: 0.6667 - val_gmeasure: 0.7830 - val_auc: 0.9038
Epoch 79/100
640/640 [==============================] - 0s 81us/step - loss: 0.1646 - binary_accuracy: 0.9406 - sensitivity: 0.9651 - specificity: 0.8627 - gmeasure: 0.9104 - auc: 0.9787 - val_loss: 0.4035 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9102
Epoch 80/100
640/640 [==============================] - 0s 63us/step - loss: 0.1682 - binary_accuracy: 0.9422 - sensitivity: 0.9547 - specificity: 0.9104 - gmeasure: 0.9318 - auc: 0.9774 - val_loss: 0.3605 - val_binary_accuracy: 0.8438 - val_sensitivity: 0.9107 - val_specificity: 0.6875 - val_gmeasure: 0.7913 - val_auc: 0.9213
Epoch 81/100
640/640 [==============================] - 0s 72us/step - loss: 0.1670 - binary_accuracy: 0.9406 - sensitivity: 0.9486 - specificity: 0.9287 - gmeasure: 0.9381 - auc: 0.9798 - val_loss: 0.4366 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9094
Epoch 82/100
640/640 [==============================] - 0s 95us/step - loss: 0.1645 - binary_accuracy: 0.9406 - sensitivity: 0.9778 - specificity: 0.8844 - gmeasure: 0.9298 - auc: 0.9858 - val_loss: 0.4520 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9196 - val_specificity: 0.7500 - val_gmeasure: 0.8305 - val_auc: 0.9036
Epoch 83/100
640/640 [==============================] - 0s 69us/step - loss: 0.1668 - binary_accuracy: 0.9344 - sensitivity: 0.9245 - specificity: 0.9481 - gmeasure: 0.9358 - auc: 0.9812 - val_loss: 0.4250 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9464 - val_specificity: 0.6667 - val_gmeasure: 0.7943 - val_auc: 0.9185
Epoch 84/100
640/640 [==============================] - 0s 67us/step - loss: 0.1733 - binary_accuracy: 0.9187 - sensitivity: 0.9746 - specificity: 0.7848 - gmeasure: 0.8744 - auc: 0.9820 - val_loss: 0.4227 - val_binary_accuracy: 0.8750 - val_sensitivity: 0.9107 - val_specificity: 0.7917 - val_gmeasure: 0.8491 - val_auc: 0.9081
Epoch 85/100
640/640 [==============================] - 0s 73us/step - loss: 0.1723 - binary_accuracy: 0.9344 - sensitivity: 0.9208 - specificity: 0.9612 - gmeasure: 0.9406 - auc: 0.9857 - val_loss: 0.5234 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9643 - val_specificity: 0.6250 - val_gmeasure: 0.7763 - val_auc: 0.9085
Epoch 86/100
640/640 [==============================] - 0s 65us/step - loss: 0.1939 - binary_accuracy: 0.9187 - sensitivity: 0.9852 - specificity: 0.8258 - gmeasure: 0.9006 - auc: 0.9847 - val_loss: 0.3876 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9163
Epoch 87/100
640/640 [==============================] - 0s 70us/step - loss: 0.1592 - binary_accuracy: 0.9469 - sensitivity: 0.9593 - specificity: 0.9154 - gmeasure: 0.9367 - auc: 0.9816 - val_loss: 0.3858 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9196 - val_specificity: 0.6875 - val_gmeasure: 0.7951 - val_auc: 0.9198
Epoch 88/100
640/640 [==============================] - 0s 104us/step - loss: 0.1602 - binary_accuracy: 0.9406 - sensitivity: 0.9740 - specificity: 0.8731 - gmeasure: 0.9216 - auc: 0.9863 - val_loss: 0.4457 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9076
Epoch 89/100
640/640 [==============================] - 0s 80us/step - loss: 0.1672 - binary_accuracy: 0.9391 - sensitivity: 0.9412 - specificity: 0.9416 - gmeasure: 0.9409 - auc: 0.9807 - val_loss: 0.4576 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9081
Epoch 90/100
640/640 [==============================] - 0s 82us/step - loss: 0.1583 - binary_accuracy: 0.9344 - sensitivity: 0.9727 - specificity: 0.8790 - gmeasure: 0.9238 - auc: 0.9806 - val_loss: 0.4122 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9142
Epoch 91/100
640/640 [==============================] - 0s 68us/step - loss: 0.1518 - binary_accuracy: 0.9469 - sensitivity: 0.9582 - specificity: 0.9204 - gmeasure: 0.9390 - auc: 0.9824 - val_loss: 0.4118 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9286 - val_specificity: 0.7292 - val_gmeasure: 0.8229 - val_auc: 0.9114
Epoch 92/100
640/640 [==============================] - 0s 93us/step - loss: 0.1540 - binary_accuracy: 0.9453 - sensitivity: 0.9609 - specificity: 0.9030 - gmeasure: 0.9314 - auc: 0.9840 - val_loss: 0.4410 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9107
Epoch 93/100
640/640 [==============================] - 0s 73us/step - loss: 0.1546 - binary_accuracy: 0.9453 - sensitivity: 0.9636 - specificity: 0.9056 - gmeasure: 0.9332 - auc: 0.9873 - val_loss: 0.4101 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9286 - val_specificity: 0.7083 - val_gmeasure: 0.8110 - val_auc: 0.9130
Epoch 94/100
640/640 [==============================] - 0s 66us/step - loss: 0.1518 - binary_accuracy: 0.9484 - sensitivity: 0.9626 - specificity: 0.9399 - gmeasure: 0.9510 - auc: 0.9878 - val_loss: 0.4506 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9554 - val_specificity: 0.6458 - val_gmeasure: 0.7855 - val_auc: 0.9161
Epoch 95/100
640/640 [==============================] - 0s 73us/step - loss: 0.1541 - binary_accuracy: 0.9375 - sensitivity: 0.9741 - specificity: 0.8872 - gmeasure: 0.9288 - auc: 0.9875 - val_loss: 0.4272 - val_binary_accuracy: 0.8562 - val_sensitivity: 0.9286 - val_specificity: 0.6875 - val_gmeasure: 0.7990 - val_auc: 0.9137
Epoch 96/100
640/640 [==============================] - 0s 71us/step - loss: 0.1469 - binary_accuracy: 0.9500 - sensitivity: 0.9624 - specificity: 0.9186 - gmeasure: 0.9401 - auc: 0.9865 - val_loss: 0.4687 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9081
Epoch 97/100
640/640 [==============================] - 0s 85us/step - loss: 0.1541 - binary_accuracy: 0.9469 - sensitivity: 0.9778 - specificity: 0.9156 - gmeasure: 0.9458 - auc: 0.9880 - val_loss: 0.4116 - val_binary_accuracy: 0.8500 - val_sensitivity: 0.9286 - val_specificity: 0.6667 - val_gmeasure: 0.7868 - val_auc: 0.9159
Epoch 98/100
640/640 [==============================] - 0s 73us/step - loss: 0.1481 - binary_accuracy: 0.9469 - sensitivity: 0.9747 - specificity: 0.8821 - gmeasure: 0.9267 - auc: 0.9882 - val_loss: 0.3561 - val_binary_accuracy: 0.8625 - val_sensitivity: 0.9107 - val_specificity: 0.7500 - val_gmeasure: 0.8265 - val_auc: 0.9276
Epoch 99/100
640/640 [==============================] - 0s 68us/step - loss: 0.1600 - binary_accuracy: 0.9469 - sensitivity: 0.9492 - specificity: 0.9313 - gmeasure: 0.9396 - auc: 0.9805 - val_loss: 0.3866 - val_binary_accuracy: 0.8375 - val_sensitivity: 0.9107 - val_specificity: 0.6667 - val_gmeasure: 0.7792 - val_auc: 0.9237
Epoch 100/100
640/640 [==============================] - 0s 66us/step - loss: 0.1463 - binary_accuracy: 0.9516 - sensitivity: 0.9717 - specificity: 0.9083 - gmeasure: 0.9393 - auc: 0.9865 - val_loss: 0.4739 - val_binary_accuracy: 0.8687 - val_sensitivity: 0.9286 - val_specificity: 0.7292 - val_gmeasure: 0.8229 - val_auc: 0.9062
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 7.7927467823028564!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_0.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 8us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.014286279678344727!
[root    |INFO|build_network.py:183] Evaluation: [0.211964413523674, 0.9350000023841858, 0.9526411890983582, 0.8964143395423889, 0.9241002202033997, 0.9699598550796509]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 58us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.020142793655395508!
[root    |INFO|build_network.py:183] Evaluation: [0.5571370124816895, 0.8457711338996887, 0.8705036044120789, 0.7903226017951965, 0.8294448256492615, 0.891274094581604]
[root    |INFO|deepbiome.py:179] Compute time : 9.707443475723267
[root    |INFO|deepbiome.py:180] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_1.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 0s 713us/step - loss: 0.5902 - binary_accuracy: 0.7078 - sensitivity: 0.9983 - specificity: 0.0231 - gmeasure: 0.1015 - auc: 0.6077 - val_loss: 0.5811 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4685
Epoch 2/100
640/640 [==============================] - 0s 75us/step - loss: 0.5876 - binary_accuracy: 0.7047 - sensitivity: 0.9982 - specificity: 0.0127 - gmeasure: 0.0564 - auc: 0.6332 - val_loss: 0.5816 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679
Epoch 3/100
640/640 [==============================] - 0s 71us/step - loss: 0.5871 - binary_accuracy: 0.7047 - sensitivity: 0.9983 - specificity: 0.0293 - gmeasure: 0.1369 - auc: 0.6228 - val_loss: 0.5806 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4675
Epoch 4/100
640/640 [==============================] - 0s 73us/step - loss: 0.5876 - binary_accuracy: 0.7047 - sensitivity: 1.0000 - specificity: 0.0085 - gmeasure: 0.0651 - auc: 0.6470 - val_loss: 0.5819 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4669
Epoch 5/100
640/640 [==============================] - 0s 85us/step - loss: 0.5870 - binary_accuracy: 0.7031 - sensitivity: 0.9917 - specificity: 0.0290 - gmeasure: 0.1092 - auc: 0.6423 - val_loss: 0.5829 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 6/100
640/640 [==============================] - 0s 81us/step - loss: 0.5865 - binary_accuracy: 0.7047 - sensitivity: 0.9982 - specificity: 0.0123 - gmeasure: 0.0773 - auc: 0.6445 - val_loss: 0.5833 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4669
Epoch 7/100
640/640 [==============================] - 0s 80us/step - loss: 0.5860 - binary_accuracy: 0.7047 - sensitivity: 0.9982 - specificity: 0.0126 - gmeasure: 0.0971 - auc: 0.6418 - val_loss: 0.5828 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4667
Epoch 8/100
640/640 [==============================] - 0s 79us/step - loss: 0.5874 - binary_accuracy: 0.7047 - sensitivity: 1.0000 - specificity: 0.0078 - gmeasure: 0.0623 - auc: 0.5998 - val_loss: 0.5832 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4660
Epoch 9/100
640/640 [==============================] - 0s 76us/step - loss: 0.5881 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0038 - gmeasure: 0.0308 - auc: 0.6415 - val_loss: 0.5838 - val_binary_accuracy: 0.7500 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 10/100
640/640 [==============================] - 0s 77us/step - loss: 0.5858 - binary_accuracy: 0.7031 - sensitivity: 0.9982 - specificity: 0.0086 - gmeasure: 0.0653 - auc: 0.6292 - val_loss: 0.5880 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4652
Epoch 11/100
640/640 [==============================] - 0s 78us/step - loss: 0.5866 - binary_accuracy: 0.7094 - sensitivity: 0.9968 - specificity: 0.0286 - gmeasure: 0.1442 - auc: 0.6451 - val_loss: 0.5906 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4646
Epoch 12/100
640/640 [==============================] - 0s 66us/step - loss: 0.5875 - binary_accuracy: 0.7125 - sensitivity: 0.9928 - specificity: 0.0461 - gmeasure: 0.1819 - auc: 0.6185 - val_loss: 0.5893 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4652
Epoch 13/100
640/640 [==============================] - 0s 67us/step - loss: 0.5861 - binary_accuracy: 0.7094 - sensitivity: 0.9965 - specificity: 0.0307 - gmeasure: 0.1390 - auc: 0.6200 - val_loss: 0.5860 - val_binary_accuracy: 0.7375 - val_sensitivity: 0.9833 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4658
Epoch 14/100
640/640 [==============================] - 0s 69us/step - loss: 0.5857 - binary_accuracy: 0.7094 - sensitivity: 0.9983 - specificity: 0.0253 - gmeasure: 0.1374 - auc: 0.6195 - val_loss: 0.5883 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4656
Epoch 15/100
640/640 [==============================] - 0s 77us/step - loss: 0.5849 - binary_accuracy: 0.7094 - sensitivity: 0.9982 - specificity: 0.0252 - gmeasure: 0.1340 - auc: 0.6351 - val_loss: 0.5877 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4658
Epoch 16/100
640/640 [==============================] - 0s 77us/step - loss: 0.5848 - binary_accuracy: 0.7094 - sensitivity: 0.9983 - specificity: 0.0247 - gmeasure: 0.1335 - auc: 0.5925 - val_loss: 0.5866 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4652
Epoch 17/100
640/640 [==============================] - 0s 74us/step - loss: 0.5850 - binary_accuracy: 0.7094 - sensitivity: 1.0000 - specificity: 0.0207 - gmeasure: 0.1239 - auc: 0.6309 - val_loss: 0.5869 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 18/100
640/640 [==============================] - 0s 77us/step - loss: 0.5846 - binary_accuracy: 0.7109 - sensitivity: 1.0000 - specificity: 0.0431 - gmeasure: 0.1770 - auc: 0.6227 - val_loss: 0.5893 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4648
Epoch 19/100
640/640 [==============================] - 0s 76us/step - loss: 0.5848 - binary_accuracy: 0.7109 - sensitivity: 0.9982 - specificity: 0.0292 - gmeasure: 0.1473 - auc: 0.6376 - val_loss: 0.5880 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4644
Epoch 20/100
640/640 [==============================] - 0s 72us/step - loss: 0.5840 - binary_accuracy: 0.7125 - sensitivity: 1.0000 - specificity: 0.0289 - gmeasure: 0.1409 - auc: 0.6337 - val_loss: 0.5867 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4629
Epoch 21/100
640/640 [==============================] - 0s 77us/step - loss: 0.5864 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0040 - gmeasure: 0.0318 - auc: 0.6583 - val_loss: 0.5877 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619
Epoch 22/100
640/640 [==============================] - 0s 83us/step - loss: 0.5893 - binary_accuracy: 0.7031 - sensitivity: 1.0000 - specificity: 0.0034 - gmeasure: 0.0291 - auc: 0.6302 - val_loss: 0.5875 - val_binary_accuracy: 0.7437 - val_sensitivity: 0.9917 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4631
Epoch 23/100
640/640 [==============================] - 0s 80us/step - loss: 0.5844 - binary_accuracy: 0.7078 - sensitivity: 1.0000 - specificity: 0.0168 - gmeasure: 0.1104 - auc: 0.6593 - val_loss: 0.5882 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4638
Epoch 24/100
640/640 [==============================] - 0s 76us/step - loss: 0.5853 - binary_accuracy: 0.7078 - sensitivity: 1.0000 - specificity: 0.0181 - gmeasure: 0.0947 - auc: 0.6200 - val_loss: 0.5886 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4640
Epoch 25/100
640/640 [==============================] - 0s 70us/step - loss: 0.5863 - binary_accuracy: 0.7125 - sensitivity: 1.0000 - specificity: 0.0315 - gmeasure: 0.1456 - auc: 0.6531 - val_loss: 0.5939 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4638
Epoch 26/100
640/640 [==============================] - 0s 81us/step - loss: 0.5855 - binary_accuracy: 0.7141 - sensitivity: 0.9946 - specificity: 0.0465 - gmeasure: 0.1841 - auc: 0.6124 - val_loss: 0.5908 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4633
Epoch 27/100
640/640 [==============================] - 0s 83us/step - loss: 0.5836 - binary_accuracy: 0.7125 - sensitivity: 0.9982 - specificity: 0.0331 - gmeasure: 0.1503 - auc: 0.6277 - val_loss: 0.5885 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4631
Epoch 28/100
640/640 [==============================] - 0s 85us/step - loss: 0.5840 - binary_accuracy: 0.7125 - sensitivity: 1.0000 - specificity: 0.0658 - gmeasure: 0.2019 - auc: 0.6534 - val_loss: 0.5889 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4646
Epoch 29/100
640/640 [==============================] - 0s 78us/step - loss: 0.5834 - binary_accuracy: 0.7125 - sensitivity: 0.9981 - specificity: 0.0341 - gmeasure: 0.1564 - auc: 0.6381 - val_loss: 0.5893 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4652
Epoch 30/100
640/640 [==============================] - 0s 83us/step - loss: 0.5833 - binary_accuracy: 0.7125 - sensitivity: 0.9983 - specificity: 0.0499 - gmeasure: 0.2194 - auc: 0.6573 - val_loss: 0.5893 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4663
Epoch 31/100
640/640 [==============================] - 0s 80us/step - loss: 0.5834 - binary_accuracy: 0.7109 - sensitivity: 0.9875 - specificity: 0.0710 - gmeasure: 0.2476 - auc: 0.6469 - val_loss: 0.5903 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4663
Epoch 32/100
640/640 [==============================] - 0s 81us/step - loss: 0.5829 - binary_accuracy: 0.7109 - sensitivity: 0.9945 - specificity: 0.0758 - gmeasure: 0.2521 - auc: 0.6790 - val_loss: 0.5904 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 33/100
640/640 [==============================] - 0s 78us/step - loss: 0.5830 - binary_accuracy: 0.7125 - sensitivity: 0.9898 - specificity: 0.0367 - gmeasure: 0.1650 - auc: 0.6420 - val_loss: 0.5901 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4650
Epoch 34/100
640/640 [==============================] - 0s 86us/step - loss: 0.5838 - binary_accuracy: 0.7125 - sensitivity: 0.9898 - specificity: 0.0366 - gmeasure: 0.1563 - auc: 0.6544 - val_loss: 0.5907 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4660
Epoch 35/100
640/640 [==============================] - 0s 84us/step - loss: 0.5830 - binary_accuracy: 0.7109 - sensitivity: 0.9948 - specificity: 0.0380 - gmeasure: 0.1646 - auc: 0.6513 - val_loss: 0.5916 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4663
Epoch 36/100
640/640 [==============================] - 0s 87us/step - loss: 0.5827 - binary_accuracy: 0.7125 - sensitivity: 0.9792 - specificity: 0.0822 - gmeasure: 0.2780 - auc: 0.6410 - val_loss: 0.5945 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4685
Epoch 37/100
640/640 [==============================] - 0s 84us/step - loss: 0.5830 - binary_accuracy: 0.7078 - sensitivity: 0.9786 - specificity: 0.0827 - gmeasure: 0.2790 - auc: 0.6254 - val_loss: 0.5932 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 38/100
640/640 [==============================] - 0s 87us/step - loss: 0.5823 - binary_accuracy: 0.7078 - sensitivity: 0.9787 - specificity: 0.0659 - gmeasure: 0.2135 - auc: 0.6574 - val_loss: 0.5931 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4642
Epoch 39/100
640/640 [==============================] - 0s 84us/step - loss: 0.5821 - binary_accuracy: 0.7141 - sensitivity: 0.9859 - specificity: 0.0945 - gmeasure: 0.3012 - auc: 0.6716 - val_loss: 0.5927 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4633
Epoch 40/100
640/640 [==============================] - 0s 85us/step - loss: 0.5825 - binary_accuracy: 0.7141 - sensitivity: 0.9871 - specificity: 0.0896 - gmeasure: 0.2933 - auc: 0.6707 - val_loss: 0.5928 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4623
Epoch 41/100
640/640 [==============================] - 0s 85us/step - loss: 0.5824 - binary_accuracy: 0.7141 - sensitivity: 0.9821 - specificity: 0.0756 - gmeasure: 0.2672 - auc: 0.6410 - val_loss: 0.5932 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4627
Epoch 42/100
640/640 [==============================] - 0s 82us/step - loss: 0.5822 - binary_accuracy: 0.7125 - sensitivity: 0.9914 - specificity: 0.0888 - gmeasure: 0.2796 - auc: 0.6720 - val_loss: 0.5943 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4644
Epoch 43/100
640/640 [==============================] - 0s 86us/step - loss: 0.5815 - binary_accuracy: 0.7125 - sensitivity: 0.9805 - specificity: 0.1138 - gmeasure: 0.3271 - auc: 0.6383 - val_loss: 0.5977 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4635
Epoch 44/100
640/640 [==============================] - 0s 82us/step - loss: 0.5845 - binary_accuracy: 0.7125 - sensitivity: 0.9769 - specificity: 0.1019 - gmeasure: 0.3151 - auc: 0.6514 - val_loss: 0.5969 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4633
Epoch 45/100
640/640 [==============================] - 0s 79us/step - loss: 0.5807 - binary_accuracy: 0.7141 - sensitivity: 0.9803 - specificity: 0.1148 - gmeasure: 0.3292 - auc: 0.6737 - val_loss: 0.5939 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4625
Epoch 46/100
640/640 [==============================] - 0s 75us/step - loss: 0.5840 - binary_accuracy: 0.7156 - sensitivity: 0.9946 - specificity: 0.0518 - gmeasure: 0.1956 - auc: 0.6670 - val_loss: 0.5943 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619
Epoch 47/100
640/640 [==============================] - 0s 85us/step - loss: 0.5814 - binary_accuracy: 0.7094 - sensitivity: 0.9616 - specificity: 0.0831 - gmeasure: 0.2791 - auc: 0.6037 - val_loss: 0.6023 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9417 - val_specificity: 0.0250 - val_gmeasure: 0.1534 - val_auc: 0.4629
Epoch 48/100
640/640 [==============================] - 0s 87us/step - loss: 0.5869 - binary_accuracy: 0.7234 - sensitivity: 0.9627 - specificity: 0.1612 - gmeasure: 0.3895 - auc: 0.6673 - val_loss: 0.6062 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9333 - val_specificity: 0.0250 - val_gmeasure: 0.1528 - val_auc: 0.4627
Epoch 49/100
640/640 [==============================] - 0s 86us/step - loss: 0.5879 - binary_accuracy: 0.7219 - sensitivity: 0.9631 - specificity: 0.1427 - gmeasure: 0.3662 - auc: 0.6220 - val_loss: 0.5981 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4585
Epoch 50/100
640/640 [==============================] - 0s 72us/step - loss: 0.5808 - binary_accuracy: 0.7109 - sensitivity: 0.9787 - specificity: 0.1306 - gmeasure: 0.3432 - auc: 0.6672 - val_loss: 0.5955 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4583
Epoch 51/100
640/640 [==============================] - 0s 73us/step - loss: 0.5830 - binary_accuracy: 0.7141 - sensitivity: 0.9828 - specificity: 0.0998 - gmeasure: 0.3020 - auc: 0.6286 - val_loss: 0.5961 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4588
Epoch 52/100
640/640 [==============================] - 0s 68us/step - loss: 0.5837 - binary_accuracy: 0.7141 - sensitivity: 0.9829 - specificity: 0.0569 - gmeasure: 0.2028 - auc: 0.6219 - val_loss: 0.5953 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4590
Epoch 53/100
640/640 [==============================] - 0s 71us/step - loss: 0.5816 - binary_accuracy: 0.7125 - sensitivity: 0.9755 - specificity: 0.0918 - gmeasure: 0.2955 - auc: 0.6434 - val_loss: 0.5961 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4604
Epoch 54/100
640/640 [==============================] - 0s 80us/step - loss: 0.5808 - binary_accuracy: 0.7094 - sensitivity: 0.9770 - specificity: 0.0884 - gmeasure: 0.2918 - auc: 0.6704 - val_loss: 0.5966 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619
Epoch 55/100
640/640 [==============================] - 0s 77us/step - loss: 0.5817 - binary_accuracy: 0.7125 - sensitivity: 0.9703 - specificity: 0.0825 - gmeasure: 0.2381 - auc: 0.6393 - val_loss: 0.5991 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4619
Epoch 56/100
640/640 [==============================] - 0s 76us/step - loss: 0.5813 - binary_accuracy: 0.7125 - sensitivity: 0.9765 - specificity: 0.1032 - gmeasure: 0.3170 - auc: 0.5926 - val_loss: 0.5949 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4617
Epoch 57/100
640/640 [==============================] - 0s 76us/step - loss: 0.5805 - binary_accuracy: 0.7141 - sensitivity: 0.9838 - specificity: 0.0866 - gmeasure: 0.2890 - auc: 0.6688 - val_loss: 0.5942 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4625
Epoch 58/100
640/640 [==============================] - 0s 79us/step - loss: 0.5815 - binary_accuracy: 0.7141 - sensitivity: 0.9750 - specificity: 0.1089 - gmeasure: 0.3001 - auc: 0.6332 - val_loss: 0.5945 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4635
Epoch 59/100
640/640 [==============================] - 0s 84us/step - loss: 0.5803 - binary_accuracy: 0.7125 - sensitivity: 0.9820 - specificity: 0.0712 - gmeasure: 0.2268 - auc: 0.6534 - val_loss: 0.5943 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4642
Epoch 60/100
640/640 [==============================] - 0s 87us/step - loss: 0.5804 - binary_accuracy: 0.7141 - sensitivity: 0.9877 - specificity: 0.0784 - gmeasure: 0.2734 - auc: 0.6529 - val_loss: 0.5941 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4638
Epoch 61/100
640/640 [==============================] - 0s 87us/step - loss: 0.5804 - binary_accuracy: 0.7188 - sensitivity: 0.9832 - specificity: 0.0862 - gmeasure: 0.2873 - auc: 0.6322 - val_loss: 0.5957 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4644
Epoch 62/100
640/640 [==============================] - 0s 87us/step - loss: 0.5802 - binary_accuracy: 0.7125 - sensitivity: 0.9789 - specificity: 0.0925 - gmeasure: 0.2981 - auc: 0.6340 - val_loss: 0.6009 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9417 - val_specificity: 0.0250 - val_gmeasure: 0.1534 - val_auc: 0.4633
Epoch 63/100
640/640 [==============================] - 0s 87us/step - loss: 0.5847 - binary_accuracy: 0.7203 - sensitivity: 0.9686 - specificity: 0.1261 - gmeasure: 0.3471 - auc: 0.6517 - val_loss: 0.6009 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9417 - val_specificity: 0.0250 - val_gmeasure: 0.1534 - val_auc: 0.4640
Epoch 64/100
640/640 [==============================] - 0s 84us/step - loss: 0.5817 - binary_accuracy: 0.7125 - sensitivity: 0.9769 - specificity: 0.1007 - gmeasure: 0.3122 - auc: 0.6287 - val_loss: 0.5944 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4617
Epoch 65/100
640/640 [==============================] - 0s 93us/step - loss: 0.5811 - binary_accuracy: 0.7188 - sensitivity: 0.9869 - specificity: 0.0733 - gmeasure: 0.2642 - auc: 0.6368 - val_loss: 0.5943 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4621
Epoch 66/100
640/640 [==============================] - 0s 86us/step - loss: 0.5802 - binary_accuracy: 0.7109 - sensitivity: 0.9855 - specificity: 0.0577 - gmeasure: 0.2058 - auc: 0.6487 - val_loss: 0.5960 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4631
Epoch 67/100
640/640 [==============================] - 0s 85us/step - loss: 0.5799 - binary_accuracy: 0.7125 - sensitivity: 0.9728 - specificity: 0.0751 - gmeasure: 0.2332 - auc: 0.6205 - val_loss: 0.5959 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4629
Epoch 68/100
640/640 [==============================] - 0s 82us/step - loss: 0.5795 - binary_accuracy: 0.7156 - sensitivity: 0.9824 - specificity: 0.0921 - gmeasure: 0.2940 - auc: 0.6581 - val_loss: 0.5949 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4629
Epoch 69/100
640/640 [==============================] - 0s 87us/step - loss: 0.5789 - binary_accuracy: 0.7141 - sensitivity: 0.9824 - specificity: 0.0760 - gmeasure: 0.2327 - auc: 0.6479 - val_loss: 0.5977 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4638
Epoch 70/100
640/640 [==============================] - 0s 93us/step - loss: 0.5822 - binary_accuracy: 0.7141 - sensitivity: 0.9663 - specificity: 0.0990 - gmeasure: 0.2498 - auc: 0.5938 - val_loss: 0.6022 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9333 - val_specificity: 0.0250 - val_gmeasure: 0.1528 - val_auc: 0.4627
Epoch 71/100
640/640 [==============================] - 0s 82us/step - loss: 0.5822 - binary_accuracy: 0.7141 - sensitivity: 0.9649 - specificity: 0.1372 - gmeasure: 0.3616 - auc: 0.6045 - val_loss: 0.5965 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4638
Epoch 72/100
640/640 [==============================] - 0s 83us/step - loss: 0.5786 - binary_accuracy: 0.7156 - sensitivity: 0.9780 - specificity: 0.0731 - gmeasure: 0.2286 - auc: 0.6601 - val_loss: 0.5931 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4635
Epoch 73/100
640/640 [==============================] - 0s 89us/step - loss: 0.5829 - binary_accuracy: 0.7141 - sensitivity: 0.9945 - specificity: 0.0460 - gmeasure: 0.1846 - auc: 0.6509 - val_loss: 0.5930 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4654
Epoch 74/100
640/640 [==============================] - 0s 83us/step - loss: 0.5810 - binary_accuracy: 0.7172 - sensitivity: 0.9946 - specificity: 0.0954 - gmeasure: 0.2944 - auc: 0.6331 - val_loss: 0.5933 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4665
Epoch 75/100
640/640 [==============================] - 0s 91us/step - loss: 0.5789 - binary_accuracy: 0.7172 - sensitivity: 0.9858 - specificity: 0.1007 - gmeasure: 0.3107 - auc: 0.6643 - val_loss: 0.5940 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4669
Epoch 76/100
640/640 [==============================] - 0s 84us/step - loss: 0.5793 - binary_accuracy: 0.7172 - sensitivity: 0.9860 - specificity: 0.1040 - gmeasure: 0.3160 - auc: 0.6688 - val_loss: 0.5923 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4681
Epoch 77/100
640/640 [==============================] - 0s 86us/step - loss: 0.5786 - binary_accuracy: 0.7188 - sensitivity: 0.9894 - specificity: 0.0704 - gmeasure: 0.2252 - auc: 0.6293 - val_loss: 0.5934 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4673
Epoch 78/100
640/640 [==============================] - 0s 95us/step - loss: 0.5787 - binary_accuracy: 0.7141 - sensitivity: 0.9553 - specificity: 0.0789 - gmeasure: 0.2407 - auc: 0.5903 - val_loss: 0.5954 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9500 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4673
Epoch 79/100
640/640 [==============================] - 0s 87us/step - loss: 0.5790 - binary_accuracy: 0.7172 - sensitivity: 0.9818 - specificity: 0.1031 - gmeasure: 0.3166 - auc: 0.6774 - val_loss: 0.5931 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679
Epoch 80/100
640/640 [==============================] - 0s 83us/step - loss: 0.5780 - binary_accuracy: 0.7172 - sensitivity: 0.9858 - specificity: 0.1109 - gmeasure: 0.3241 - auc: 0.6635 - val_loss: 0.5926 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679
Epoch 81/100
640/640 [==============================] - 0s 79us/step - loss: 0.5797 - binary_accuracy: 0.7203 - sensitivity: 0.9914 - specificity: 0.0921 - gmeasure: 0.3015 - auc: 0.6503 - val_loss: 0.5929 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4685
Epoch 82/100
640/640 [==============================] - 0s 84us/step - loss: 0.5780 - binary_accuracy: 0.7203 - sensitivity: 0.9911 - specificity: 0.1055 - gmeasure: 0.3165 - auc: 0.6484 - val_loss: 0.5949 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4677
Epoch 83/100
640/640 [==============================] - 0s 83us/step - loss: 0.5790 - binary_accuracy: 0.7141 - sensitivity: 0.9576 - specificity: 0.1116 - gmeasure: 0.3237 - auc: 0.6468 - val_loss: 0.6007 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9333 - val_specificity: 0.0250 - val_gmeasure: 0.1528 - val_auc: 0.4688
Epoch 84/100
640/640 [==============================] - 0s 86us/step - loss: 0.5813 - binary_accuracy: 0.7172 - sensitivity: 0.9699 - specificity: 0.1137 - gmeasure: 0.2839 - auc: 0.6238 - val_loss: 0.5989 - val_binary_accuracy: 0.7063 - val_sensitivity: 0.9417 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4679
Epoch 85/100
640/640 [==============================] - 0s 85us/step - loss: 0.5780 - binary_accuracy: 0.7156 - sensitivity: 0.9663 - specificity: 0.1007 - gmeasure: 0.2674 - auc: 0.6519 - val_loss: 0.5948 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4663
Epoch 86/100
640/640 [==============================] - 0s 89us/step - loss: 0.5790 - binary_accuracy: 0.7188 - sensitivity: 0.9892 - specificity: 0.1141 - gmeasure: 0.2870 - auc: 0.6418 - val_loss: 0.5954 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4646
Epoch 87/100
640/640 [==============================] - 0s 85us/step - loss: 0.5812 - binary_accuracy: 0.7188 - sensitivity: 0.9947 - specificity: 0.0586 - gmeasure: 0.2059 - auc: 0.6539 - val_loss: 0.5946 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4652
Epoch 88/100
640/640 [==============================] - 0s 83us/step - loss: 0.5783 - binary_accuracy: 0.7188 - sensitivity: 0.9741 - specificity: 0.1091 - gmeasure: 0.3240 - auc: 0.6402 - val_loss: 0.5975 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9500 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4656
Epoch 89/100
640/640 [==============================] - 0s 80us/step - loss: 0.5779 - binary_accuracy: 0.7172 - sensitivity: 0.9678 - specificity: 0.1224 - gmeasure: 0.3382 - auc: 0.6488 - val_loss: 0.5954 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4656
Epoch 90/100
640/640 [==============================] - 0s 81us/step - loss: 0.5777 - binary_accuracy: 0.7172 - sensitivity: 0.9781 - specificity: 0.1058 - gmeasure: 0.3178 - auc: 0.6330 - val_loss: 0.5946 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4660
Epoch 91/100
640/640 [==============================] - 0s 83us/step - loss: 0.5776 - binary_accuracy: 0.7172 - sensitivity: 0.9777 - specificity: 0.0909 - gmeasure: 0.2919 - auc: 0.6319 - val_loss: 0.5961 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9500 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4656
Epoch 92/100
640/640 [==============================] - 0s 89us/step - loss: 0.5802 - binary_accuracy: 0.7172 - sensitivity: 0.9673 - specificity: 0.1774 - gmeasure: 0.3983 - auc: 0.6618 - val_loss: 0.5985 - val_binary_accuracy: 0.7125 - val_sensitivity: 0.9500 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4658
Epoch 93/100
640/640 [==============================] - 0s 79us/step - loss: 0.5790 - binary_accuracy: 0.7172 - sensitivity: 0.9802 - specificity: 0.0895 - gmeasure: 0.2540 - auc: 0.6703 - val_loss: 0.5939 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4650
Epoch 94/100
640/640 [==============================] - 0s 72us/step - loss: 0.5795 - binary_accuracy: 0.7203 - sensitivity: 0.9965 - specificity: 0.1091 - gmeasure: 0.3107 - auc: 0.6609 - val_loss: 0.5944 - val_binary_accuracy: 0.7312 - val_sensitivity: 0.9750 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4646
Epoch 95/100
640/640 [==============================] - 0s 79us/step - loss: 0.5791 - binary_accuracy: 0.7188 - sensitivity: 0.9866 - specificity: 0.0618 - gmeasure: 0.2115 - auc: 0.6878 - val_loss: 0.5948 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4640
Epoch 96/100
640/640 [==============================] - 0s 79us/step - loss: 0.5768 - binary_accuracy: 0.7172 - sensitivity: 0.9839 - specificity: 0.1143 - gmeasure: 0.3159 - auc: 0.6576 - val_loss: 0.5962 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4642
Epoch 97/100
640/640 [==============================] - 0s 94us/step - loss: 0.5766 - binary_accuracy: 0.7172 - sensitivity: 0.9821 - specificity: 0.1030 - gmeasure: 0.3147 - auc: 0.6396 - val_loss: 0.5962 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4663
Epoch 98/100
640/640 [==============================] - 0s 82us/step - loss: 0.5766 - binary_accuracy: 0.7172 - sensitivity: 0.9823 - specificity: 0.1024 - gmeasure: 0.3132 - auc: 0.6479 - val_loss: 0.5949 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4681
Epoch 99/100
640/640 [==============================] - 0s 80us/step - loss: 0.5765 - binary_accuracy: 0.7156 - sensitivity: 0.9819 - specificity: 0.0978 - gmeasure: 0.3089 - auc: 0.6765 - val_loss: 0.5946 - val_binary_accuracy: 0.7250 - val_sensitivity: 0.9667 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4708
Epoch 100/100
640/640 [==============================] - 0s 83us/step - loss: 0.5765 - binary_accuracy: 0.7156 - sensitivity: 0.9820 - specificity: 0.1077 - gmeasure: 0.3238 - auc: 0.6714 - val_loss: 0.5953 - val_binary_accuracy: 0.7188 - val_sensitivity: 0.9583 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.4719
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 7.451347351074219!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_1.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 9us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.015420198440551758!
[root    |INFO|build_network.py:183] Evaluation: [0.5800250172615051, 0.7174999713897705, 0.9736379384994507, 0.08658009022474289, 0.2903406023979187, 0.6202877163887024]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 25us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.013490915298461914!
[root    |INFO|build_network.py:183] Evaluation: [0.5820791721343994, 0.7611940503120422, 0.9868420958518982, 0.06122449040412903, 0.24580256640911102, 0.5089957118034363]
[root    |INFO|deepbiome.py:179] Compute time : 9.264056921005249
[root    |INFO|deepbiome.py:180] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------3 simulation start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 3 simulation
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|build_network.py:83] Load trained model weight at ./example_result/weight_2.h5
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:141] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 640 samples, validate on 160 samples
Epoch 1/100
640/640 [==============================] - 1s 866us/step - loss: 0.6088 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6146 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5613
Epoch 2/100
640/640 [==============================] - 0s 86us/step - loss: 0.6074 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6026 - val_loss: 0.6239 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5595
Epoch 3/100
640/640 [==============================] - 0s 81us/step - loss: 0.6087 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5842 - val_loss: 0.6253 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5602
Epoch 4/100
640/640 [==============================] - 0s 82us/step - loss: 0.6086 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6008 - val_loss: 0.6237 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5604
Epoch 5/100
640/640 [==============================] - 0s 96us/step - loss: 0.6080 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6169 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5606
Epoch 6/100
640/640 [==============================] - 0s 103us/step - loss: 0.6072 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6106 - val_loss: 0.6222 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5600
Epoch 7/100
640/640 [==============================] - 0s 90us/step - loss: 0.6070 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6072 - val_loss: 0.6221 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5616
Epoch 8/100
640/640 [==============================] - 0s 78us/step - loss: 0.6068 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6155 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5625
Epoch 9/100
640/640 [==============================] - 0s 84us/step - loss: 0.6072 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6150 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5631
Epoch 10/100
640/640 [==============================] - 0s 87us/step - loss: 0.6067 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6135 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5625
Epoch 11/100
640/640 [==============================] - 0s 82us/step - loss: 0.6061 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5906 - val_loss: 0.6227 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5624
Epoch 12/100
640/640 [==============================] - 0s 84us/step - loss: 0.6060 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6068 - val_loss: 0.6235 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5616
Epoch 13/100
640/640 [==============================] - 0s 89us/step - loss: 0.6061 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6355 - val_loss: 0.6235 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5616
Epoch 14/100
640/640 [==============================] - 0s 83us/step - loss: 0.6058 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6313 - val_loss: 0.6230 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5615
Epoch 15/100
640/640 [==============================] - 0s 87us/step - loss: 0.6056 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6291 - val_loss: 0.6226 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5615
Epoch 16/100
640/640 [==============================] - 0s 87us/step - loss: 0.6054 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6279 - val_loss: 0.6228 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5600
Epoch 17/100
640/640 [==============================] - 0s 100us/step - loss: 0.6059 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5955 - val_loss: 0.6230 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5615
Epoch 18/100
640/640 [==============================] - 0s 86us/step - loss: 0.6054 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6271 - val_loss: 0.6231 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5622
Epoch 19/100
640/640 [==============================] - 0s 81us/step - loss: 0.6048 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6305 - val_loss: 0.6235 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5629
Epoch 20/100
640/640 [==============================] - 0s 97us/step - loss: 0.6043 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5743 - val_loss: 0.6237 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5642
Epoch 21/100
640/640 [==============================] - 0s 93us/step - loss: 0.6041 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6047 - val_loss: 0.6241 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5640
Epoch 22/100
640/640 [==============================] - 0s 82us/step - loss: 0.6041 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6517 - val_loss: 0.6252 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5629
Epoch 23/100
640/640 [==============================] - 0s 87us/step - loss: 0.6050 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5785 - val_loss: 0.6255 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5636
Epoch 24/100
640/640 [==============================] - 0s 87us/step - loss: 0.6040 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5885 - val_loss: 0.6233 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5640
Epoch 25/100
640/640 [==============================] - 0s 85us/step - loss: 0.6057 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6161 - val_loss: 0.6229 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5629
Epoch 26/100
640/640 [==============================] - 0s 80us/step - loss: 0.6039 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6143 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5647
Epoch 27/100
640/640 [==============================] - 0s 81us/step - loss: 0.6028 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6307 - val_loss: 0.6230 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5644
Epoch 28/100
640/640 [==============================] - 0s 93us/step - loss: 0.6034 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6509 - val_loss: 0.6239 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5664
Epoch 29/100
640/640 [==============================] - 0s 83us/step - loss: 0.6028 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6249 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5664
Epoch 30/100
640/640 [==============================] - 0s 88us/step - loss: 0.6033 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6348 - val_loss: 0.6232 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5656
Epoch 31/100
640/640 [==============================] - 0s 82us/step - loss: 0.6043 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6076 - val_loss: 0.6228 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5658
Epoch 32/100
640/640 [==============================] - 0s 89us/step - loss: 0.6035 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6284 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5660
Epoch 33/100
640/640 [==============================] - 0s 88us/step - loss: 0.6027 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6391 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5656
Epoch 34/100
640/640 [==============================] - 0s 82us/step - loss: 0.6020 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6509 - val_loss: 0.6226 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5667
Epoch 35/100
640/640 [==============================] - 0s 81us/step - loss: 0.6021 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5968 - val_loss: 0.6236 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5658
Epoch 36/100
640/640 [==============================] - 0s 78us/step - loss: 0.6016 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5880 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5658
Epoch 37/100
640/640 [==============================] - 0s 85us/step - loss: 0.6012 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6044 - val_loss: 0.6223 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5660
Epoch 38/100
640/640 [==============================] - 0s 77us/step - loss: 0.6012 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6060 - val_loss: 0.6224 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5665
Epoch 39/100
640/640 [==============================] - 0s 85us/step - loss: 0.6007 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5958 - val_loss: 0.6231 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5662
Epoch 40/100
640/640 [==============================] - 0s 88us/step - loss: 0.6007 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6159 - val_loss: 0.6253 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5660
Epoch 41/100
640/640 [==============================] - 0s 77us/step - loss: 0.6023 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6304 - val_loss: 0.6267 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5665
Epoch 42/100
640/640 [==============================] - 0s 77us/step - loss: 0.6022 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6076 - val_loss: 0.6245 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5662
Epoch 43/100
640/640 [==============================] - 0s 83us/step - loss: 0.6012 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6566 - val_loss: 0.6226 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5673
Epoch 44/100
640/640 [==============================] - 0s 75us/step - loss: 0.6000 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6040 - val_loss: 0.6222 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5685
Epoch 45/100
640/640 [==============================] - 0s 80us/step - loss: 0.5998 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6056 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5689
Epoch 46/100
640/640 [==============================] - 0s 80us/step - loss: 0.6003 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6311 - val_loss: 0.6221 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5682
Epoch 47/100
640/640 [==============================] - 0s 73us/step - loss: 0.6014 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6513 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5689
Epoch 48/100
640/640 [==============================] - 0s 90us/step - loss: 0.6001 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6249 - val_loss: 0.6222 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5696
Epoch 49/100
640/640 [==============================] - 0s 79us/step - loss: 0.5999 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6318 - val_loss: 0.6249 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5691
Epoch 50/100
640/640 [==============================] - 0s 83us/step - loss: 0.6003 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6371 - val_loss: 0.6235 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5689
Epoch 51/100
640/640 [==============================] - 0s 84us/step - loss: 0.5989 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6364 - val_loss: 0.6220 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5687
Epoch 52/100
640/640 [==============================] - 0s 84us/step - loss: 0.5985 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5990 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5685
Epoch 53/100
640/640 [==============================] - 0s 84us/step - loss: 0.5995 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6397 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5691
Epoch 54/100
640/640 [==============================] - 0s 83us/step - loss: 0.5983 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6269 - val_loss: 0.6225 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5700
Epoch 55/100
640/640 [==============================] - 0s 83us/step - loss: 0.5983 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6152 - val_loss: 0.6234 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5700
Epoch 56/100
640/640 [==============================] - 0s 85us/step - loss: 0.5986 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6146 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5705
Epoch 57/100
640/640 [==============================] - 0s 87us/step - loss: 0.5978 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6201 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5707
Epoch 58/100
640/640 [==============================] - 0s 85us/step - loss: 0.5980 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6452 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5715
Epoch 59/100
640/640 [==============================] - 0s 90us/step - loss: 0.5984 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.5892 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5716
Epoch 60/100
640/640 [==============================] - 0s 79us/step - loss: 0.5967 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6240 - val_loss: 0.6227 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5716
Epoch 61/100
640/640 [==============================] - 0s 101us/step - loss: 0.5976 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6205 - val_loss: 0.6230 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5716
Epoch 62/100
640/640 [==============================] - 0s 86us/step - loss: 0.5973 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6165 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5716
Epoch 63/100
640/640 [==============================] - 0s 86us/step - loss: 0.5966 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6548 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5715
Epoch 64/100
640/640 [==============================] - 0s 97us/step - loss: 0.5962 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6256 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5715
Epoch 65/100
640/640 [==============================] - 0s 82us/step - loss: 0.5961 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6173 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5727
Epoch 66/100
640/640 [==============================] - 0s 87us/step - loss: 0.5959 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6325 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5727
Epoch 67/100
640/640 [==============================] - 0s 88us/step - loss: 0.5957 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6364 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5736
Epoch 68/100
640/640 [==============================] - 0s 98us/step - loss: 0.5955 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6418 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5747
Epoch 69/100
640/640 [==============================] - 0s 88us/step - loss: 0.5953 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6653 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5760
Epoch 70/100
640/640 [==============================] - 0s 86us/step - loss: 0.5954 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6515 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5745
Epoch 71/100
640/640 [==============================] - 0s 92us/step - loss: 0.5950 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6281 - val_loss: 0.6208 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5760
Epoch 72/100
640/640 [==============================] - 0s 83us/step - loss: 0.5958 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0039 - gmeasure: 0.0312 - auc: 0.6393 - val_loss: 0.6216 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5756
Epoch 73/100
640/640 [==============================] - 0s 84us/step - loss: 0.5962 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0045 - gmeasure: 0.0334 - auc: 0.6520 - val_loss: 0.6206 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5762
Epoch 74/100
640/640 [==============================] - 0s 85us/step - loss: 0.5948 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0036 - gmeasure: 0.0299 - auc: 0.6280 - val_loss: 0.6207 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5773
Epoch 75/100
640/640 [==============================] - 0s 87us/step - loss: 0.5943 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0045 - gmeasure: 0.0334 - auc: 0.6129 - val_loss: 0.6239 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5791
Epoch 76/100
640/640 [==============================] - 0s 85us/step - loss: 0.5952 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6602 - val_loss: 0.6248 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5791
Epoch 77/100
640/640 [==============================] - 0s 88us/step - loss: 0.5959 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6481 - val_loss: 0.6238 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5784
Epoch 78/100
640/640 [==============================] - 0s 90us/step - loss: 0.5945 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6265 - val_loss: 0.6221 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 79/100
640/640 [==============================] - 0s 86us/step - loss: 0.5928 - binary_accuracy: 0.6922 - sensitivity: 1.0000 - specificity: 0.0000e+00 - gmeasure: 0.0000e+00 - auc: 0.6368 - val_loss: 0.6207 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5769
Epoch 80/100
640/640 [==============================] - 0s 84us/step - loss: 0.5951 - binary_accuracy: 0.6969 - sensitivity: 0.9983 - specificity: 0.0154 - gmeasure: 0.0873 - auc: 0.6679 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5760
Epoch 81/100
640/640 [==============================] - 0s 84us/step - loss: 0.5947 - binary_accuracy: 0.6984 - sensitivity: 1.0000 - specificity: 0.0172 - gmeasure: 0.0929 - auc: 0.6292 - val_loss: 0.6214 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5771
Epoch 82/100
640/640 [==============================] - 0s 84us/step - loss: 0.5927 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0040 - gmeasure: 0.0315 - auc: 0.6761 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 83/100
640/640 [==============================] - 0s 84us/step - loss: 0.5928 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0037 - gmeasure: 0.0303 - auc: 0.6181 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5778
Epoch 84/100
640/640 [==============================] - 0s 81us/step - loss: 0.5927 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0037 - gmeasure: 0.0303 - auc: 0.6205 - val_loss: 0.6218 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5780
Epoch 85/100
640/640 [==============================] - 0s 81us/step - loss: 0.5925 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0034 - gmeasure: 0.0293 - auc: 0.6495 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 86/100
640/640 [==============================] - 0s 81us/step - loss: 0.5919 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0156 - gmeasure: 0.0625 - auc: 0.6786 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5795
Epoch 87/100
640/640 [==============================] - 0s 85us/step - loss: 0.5916 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0040 - gmeasure: 0.0318 - auc: 0.6372 - val_loss: 0.6206 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 88/100
640/640 [==============================] - 0s 79us/step - loss: 0.5918 - binary_accuracy: 0.6984 - sensitivity: 0.9982 - specificity: 0.0341 - gmeasure: 0.1541 - auc: 0.6816 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5778
Epoch 89/100
640/640 [==============================] - 0s 83us/step - loss: 0.5919 - binary_accuracy: 0.6984 - sensitivity: 0.9964 - specificity: 0.0384 - gmeasure: 0.1892 - auc: 0.6451 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5780
Epoch 90/100
640/640 [==============================] - 0s 84us/step - loss: 0.5912 - binary_accuracy: 0.7000 - sensitivity: 0.9982 - specificity: 0.0249 - gmeasure: 0.1363 - auc: 0.6407 - val_loss: 0.6210 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5784
Epoch 91/100
640/640 [==============================] - 0s 97us/step - loss: 0.5907 - binary_accuracy: 0.7000 - sensitivity: 0.9981 - specificity: 0.0269 - gmeasure: 0.1132 - auc: 0.6622 - val_loss: 0.6212 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5787
Epoch 92/100
640/640 [==============================] - 0s 89us/step - loss: 0.5906 - binary_accuracy: 0.6984 - sensitivity: 1.0000 - specificity: 0.0306 - gmeasure: 0.1451 - auc: 0.6477 - val_loss: 0.6219 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5798
Epoch 93/100
640/640 [==============================] - 0s 87us/step - loss: 0.5907 - binary_accuracy: 0.6938 - sensitivity: 1.0000 - specificity: 0.0042 - gmeasure: 0.0323 - auc: 0.6276 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5800
Epoch 94/100
640/640 [==============================] - 0s 86us/step - loss: 0.5901 - binary_accuracy: 0.6984 - sensitivity: 0.9964 - specificity: 0.0245 - gmeasure: 0.1103 - auc: 0.6475 - val_loss: 0.6210 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9909 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5791
Epoch 95/100
640/640 [==============================] - 0s 92us/step - loss: 0.5908 - binary_accuracy: 0.6984 - sensitivity: 0.9945 - specificity: 0.0290 - gmeasure: 0.1407 - auc: 0.6167 - val_loss: 0.6209 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9909 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5800
Epoch 96/100
640/640 [==============================] - 0s 85us/step - loss: 0.5902 - binary_accuracy: 0.6984 - sensitivity: 0.9962 - specificity: 0.0235 - gmeasure: 0.1264 - auc: 0.6253 - val_loss: 0.6213 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5813
Epoch 97/100
640/640 [==============================] - 0s 86us/step - loss: 0.5894 - binary_accuracy: 0.7000 - sensitivity: 0.9982 - specificity: 0.0489 - gmeasure: 0.1819 - auc: 0.6906 - val_loss: 0.6209 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5795
Epoch 98/100
640/640 [==============================] - 0s 84us/step - loss: 0.5895 - binary_accuracy: 0.6984 - sensitivity: 0.9885 - specificity: 0.0250 - gmeasure: 0.1365 - auc: 0.6220 - val_loss: 0.6211 - val_binary_accuracy: 0.6875 - val_sensitivity: 0.9909 - val_specificity: 0.0200 - val_gmeasure: 0.1408 - val_auc: 0.5785
Epoch 99/100
640/640 [==============================] - 0s 86us/step - loss: 0.5897 - binary_accuracy: 0.6984 - sensitivity: 0.9947 - specificity: 0.0595 - gmeasure: 0.1995 - auc: 0.6882 - val_loss: 0.6211 - val_binary_accuracy: 0.6812 - val_sensitivity: 0.9909 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5782
Epoch 100/100
640/640 [==============================] - 0s 87us/step - loss: 0.5888 - binary_accuracy: 0.6984 - sensitivity: 0.9964 - specificity: 0.0382 - gmeasure: 0.1858 - auc: 0.6698 - val_loss: 0.6215 - val_binary_accuracy: 0.6875 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00 - val_gmeasure: 0.0000e+00 - val_auc: 0.5785
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:151] Training end with time 7.964810848236084!
[root    |INFO|build_network.py:79] Saved trained model weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./example_result/weight_2.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./example_result/hist_2.json
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
800/800 [==============================] - 0s 10us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.017737150192260742!
[root    |INFO|build_network.py:183] Evaluation: [0.5949158668518066, 0.6974999904632568, 0.9981916546821594, 0.024291498586535454, 0.15571631491184235, 0.6360375285148621]
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 25us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.011327505111694336!
[root    |INFO|build_network.py:183] Evaluation: [0.6639898419380188, 0.6700000166893005, 0.9852941036224365, 0.0, 0.0, 0.47277113795280457]
[root    |INFO|deepbiome.py:179] Compute time : 9.810555696487427
[root    |INFO|deepbiome.py:180] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:183] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:185] Train Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:188]       mean : [0.46230177 0.78333332 0.97482359 0.33576198 0.45671905 0.74209503]
[root    |INFO|deepbiome.py:189]        std : [0.1771196  0.10755491 0.01861479 0.39725581 0.33502716 0.161253  ]
[root    |INFO|deepbiome.py:190] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:192] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:195]       mean : [0.60106868 0.7589884  0.9475466  0.28384903 0.3584158  0.62434698]
[root    |INFO|deepbiome.py:196]        std : [0.04564232 0.07177521 0.05448129 0.35900206 0.34785628 0.18932444]
[root    |INFO|deepbiome.py:197] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:206] Total Computing Ended
[root    |INFO|deepbiome.py:207] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>Let’s check the history plot again.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">%s</span><span class="s1">/hist_0.json&#39;</span> <span class="o">%</span> <span class="n">path_info</span><span class="p">[</span><span class="s1">&#39;model_info&#39;</span><span class="p">][</span><span class="s1">&#39;model_dir&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/example_with_one_input_file_48_0.png" src="_images/example_with_one_input_file_48_0.png" />
</div>
</div>
</div>
<div class="section" id="6.-Load-the-pre-trained-network-for-testing">
<h2>6. Load the pre-trained network for testing<a class="headerlink" href="#6.-Load-the-pre-trained-network-for-testing" title="Permalink to this headline">¶</a></h2>
<p>To test the trained model, we can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_test</span></code> function. If you use the index file, this function provides the evaluation using test index (index set not included in the index file) for each fold. If not, this function provides the evaluation using the whole samples. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is set to <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will test the model only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;idx_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/onefile_idx.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_test</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">test_network_info</span><span class="p">,</span> <span class="n">test_path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:262] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:294] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:296] -------1 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 1 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 486us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.267392635345459!
[root    |INFO|build_network.py:183] Evaluation: [0.5571370124816895, 0.8457711338996887, 0.8705036044120789, 0.7903226017951965, 0.8294448256492615, 0.891274094581604]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 1.864792823791504
[root    |INFO|deepbiome.py:323] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------2 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 2 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
201/201 [==============================] - 0s 466us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.2770264148712158!
[root    |INFO|build_network.py:183] Evaluation: [0.5820791721343994, 0.7611940503120422, 0.9868420958518982, 0.06122449040412903, 0.24580256640911102, 0.5089957118034363]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 2.0720319747924805
[root    |INFO|deepbiome.py:323] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:296] -------3 fold test start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:306] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:307] Build network for 3 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:316] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:317] 3 fold computing start!----------------------------------
[root    |INFO|build_network.py:177] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
200/200 [==============================] - 0s 538us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:182] Evaluation end with time 0.28798818588256836!
[root    |INFO|build_network.py:183] Evaluation: [0.6639898419380188, 0.6700000166893005, 0.9852941036224365, 0.0, 0.0, 0.47277113795280457]
[root    |INFO|deepbiome.py:320]
[root    |INFO|deepbiome.py:322] Compute time : 2.053978443145752
[root    |INFO|deepbiome.py:323] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:326] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:328] Test Evaluation : [&#39;loss&#39; &#39;binary_accuracy&#39; &#39;sensitivity&#39; &#39;specificity&#39; &#39;gmeasure&#39; &#39;auc&#39;]
[root    |INFO|deepbiome.py:331]       mean : [0.60106868 0.7589884  0.9475466  0.28384903 0.3584158  0.62434698]
[root    |INFO|deepbiome.py:332]        std : [0.04564232 0.07177521 0.05448129 0.35900206 0.34785628 0.18932444]
[root    |INFO|deepbiome.py:333] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:336] Total Computing Ended
[root    |INFO|deepbiome.py:337] -----------------------------------------------------------------
</pre></div></div>
</div>
<p>This function provide the evaluation result as a numpy array with a shape of (number of fold, number of evaluation measures).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">+</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%16s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">s</span>.strip() for s in network_info[&#39;model_info&#39;][&#39;metrics&#39;].split(&#39;,&#39;)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.mean(evaluation, axis=0)]))
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Std : </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%16.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">v</span> for v in np.std(evaluation, axis=0)]))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                  loss binary_accuracy     sensitivity     specificity        gmeasure             auc
Mean:           0.6011          0.7590          0.9475          0.2838          0.3584          0.6243
Std :           0.0456          0.0718          0.0545          0.3590          0.3479          0.1893
</pre></div></div>
</div>
</div>
<div class="section" id="7.-Load-the-pre-trained-network-for-prediction">
<h2>7. Load the pre-trained network for prediction<a class="headerlink" href="#7.-Load-the-pre-trained-network-for-prediction" title="Permalink to this headline">¶</a></h2>
<p>If you want to predict using the pre-trained model, you can use the <code class="docutils literal notranslate"><span class="pre">deepbiome_prediction</span></code> function. If <code class="docutils literal notranslate"><span class="pre">number_of_fold</span></code> is setted as <code class="docutils literal notranslate"><span class="pre">k</span></code>, the function will predict only with first <code class="docutils literal notranslate"><span class="pre">k</span></code> folds sample’s outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_l1_penalty&#39;</span><span class="p">:</span><span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;binary_accuracy, sensitivity, specificity, gmeasure, auc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeClassificationReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;texa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;accuracy, sensitivity, specificity, gmeasure&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction_path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data&#39;</span><span class="p">),</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;deepbiome&#39;</span><span class="p">,</span> <span class="s1">&#39;tests/data/genus48_dic.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;onefile_x.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;classification_y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./example_result/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight_0.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_prediction</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">prediction_network_info</span><span class="p">,</span> <span class="n">prediction_path_info</span><span class="p">,</span>
                                            <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:393] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:420] -------1 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 1 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 31us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.03356122970581055!
[root    |INFO|deepbiome.py:444] Compute time : 1.3081865310668945
[root    |INFO|deepbiome.py:445] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------2 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 2 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 44us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.04675102233886719!
[root    |INFO|deepbiome.py:444] Compute time : 1.3035345077514648
[root    |INFO|deepbiome.py:445] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:420] -------3 th repeatition prediction start!----------------------------------
[root    |INFO|readers.py:58] -----------------------------------------------------------------------
[root    |INFO|readers.py:59] Construct Dataset
[root    |INFO|readers.py:60] -----------------------------------------------------------------------
[root    |INFO|readers.py:61] Load data
[root    |INFO|deepbiome.py:429] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:430] Build network for 3 fold testing
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:514] Read phylogenetic tree information from /DATA/home/muha/github_repos/deepbiome/deepbiome/tests/data/genus48_dic.csv
[root    |INFO|build_network.py:518] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:519] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:526]      Genus: 48
[root    |INFO|build_network.py:526]     Family: 40
[root    |INFO|build_network.py:526]      Order: 23
[root    |INFO|build_network.py:526]      Class: 17
[root    |INFO|build_network.py:526]     Phylum: 9
[root    |INFO|build_network.py:529] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:530] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:531] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:541] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:541] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:541] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:541] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:554] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:570] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:571] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:572] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:648] ------------------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = binary_crossentropy
[root    |INFO|build_network.py:60] Metrics = binary_accuracy, sensitivity, specificity, gmeasure, auc
[root    |INFO|deepbiome.py:440] -----------------------------------------------------------------
[root    |INFO|build_network.py:197] Prediction start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1000/1000 [==============================] - 0s 50us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:202] Prediction end with time 0.05387568473815918!
[root    |INFO|deepbiome.py:444] Compute time : 1.3053226470947266
[root    |INFO|deepbiome.py:445] 3 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:449] Total Computing Ended
[root    |INFO|deepbiome.py:450] -----------------------------------------------------------------
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(3, 1000, 1)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.72311175],
       [0.9747908 ],
       [0.07443932],
       [0.07443932],
       [1.        ],
       [1.        ],
       [0.1007489 ],
       [0.07443932],
       [0.9979558 ],
       [0.999997  ]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="release-history.html" class="btn btn-neutral float-right" title="Release History" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="example_with_the_list_of_inputs.html" class="btn btn-neutral float-left" title="Example : k times repetition with the list of k input files" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Youngwon Choi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>