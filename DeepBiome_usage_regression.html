

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Getting start with the regression problem. &mdash; deepbiome 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="Getting start with the classification problem." href="DeepBiome_usage_classification.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deepbiome
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeepBiome_usage_classification.html">Getting start with the classification problem.</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting start with the regression problem.</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_with_the_list_of_inputs.html">Example : k times repetition with the list of k input files</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_with_one_input_file.html">Example : k fold cross-validation with an input file</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-history.html">Release History</a></li>
<li class="toctree-l1"><a class="reference internal" href="min_versions.html">Minimum Version of Python and NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepbiome</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Getting start with the regression problem.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/DeepBiome_usage_regression.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Getting-start-with-the-regression-problem.">
<h1>Getting start with the regression problem.<a class="headerlink" href="#Getting-start-with-the-regression-problem." title="Permalink to this headline">¶</a></h1>
<p>Let’s start with the baby step example for classification problem. Below is the basic example of the configuration for regression problem. For more detailed configuration, please check the detailed information about each option in the <a class="reference external" href="https://young-won.github.io/deepbiome/prerequisites.html#configuration">documantation</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;network_class&#39;</span><span class="p">:</span> <span class="s1">&#39;DeepBiomeNetwork&#39;</span><span class="p">,</span>
        <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="s1">&#39;0.01&#39;</span><span class="p">,</span>
        <span class="s1">&#39;decay&#39;</span><span class="p">:</span> <span class="s1">&#39;0.0001&#39;</span><span class="p">,</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;correlation_coefficient&#39;</span><span class="p">,</span>
        <span class="s1">&#39;taxa_selection_metrics&#39;</span><span class="p">:</span> <span class="s1">&#39;sensitivity, specificity, gmeasure, accuracy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reader_class&#39;</span><span class="p">:</span> <span class="s1">&#39;MicroBiomeRegressionReader&#39;</span><span class="p">,</span>
        <span class="s1">&#39;normalizer&#39;</span><span class="p">:</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;architecture_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;weight_initial&#39;</span><span class="p">:</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="s1">&#39;phylogenetic_tree&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_normalization&#39;</span><span class="p">:</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span>
        <span class="s1">&#39;drop_out&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;training_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="s1">&#39;100&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;30&#39;</span><span class="p">,</span>
        <span class="s1">&#39;callbacks&#39;</span><span class="p">:</span> <span class="s1">&#39;ModelCheckpoint&#39;</span><span class="p">,</span>
        <span class="s1">&#39;monitor&#39;</span><span class="p">:</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="s1">&#39;mode&#39;</span> <span class="p">:</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span>
        <span class="s1">&#39;min_delta&#39;</span><span class="p">:</span> <span class="s1">&#39;1e-7&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;validation_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;validation_size&#39;</span><span class="p">:</span> <span class="s1">&#39;0.2&#39;</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">&#39;test_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="s1">&#39;None&#39;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">path_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;data_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="s1">&#39;data/pulmonary/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;tree_info_path&#39;</span><span class="p">:</span> <span class="s1">&#39;data/genus48/genus48_dic.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;x_path&#39;</span><span class="p">:</span> <span class="s1">&#39;X.csv&#39;</span><span class="p">,</span>
        <span class="s1">&#39;y_path&#39;</span><span class="p">:</span> <span class="s1">&#39;y.csv&#39;</span>
    <span class="p">},</span>
    <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;./realdata_fev1/fev1_deepbiome&#39;</span><span class="p">,</span>
        <span class="s1">&#39;evaluation&#39;</span><span class="p">:</span> <span class="s1">&#39;eval.npy&#39;</span><span class="p">,</span>
        <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;history/hist.json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="s1">&#39;weight/weight.h5&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>For logging, we used the python logging library.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;[</span><span class="si">%(name)-8s</span><span class="s1">|</span><span class="si">%(levelname)s</span><span class="s1">|</span><span class="si">%(filename)s</span><span class="s1">:</span><span class="si">%(lineno)s</span><span class="s1">] </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Here is the <code class="docutils literal notranslate"><span class="pre">deepbiome.deepbiome_train</span></code> function for training:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">deepbiome</span> <span class="kn">import</span> <span class="n">deepbiome</span>

<span class="n">test_evaluation</span><span class="p">,</span> <span class="n">train_evaluation</span><span class="p">,</span> <span class="n">network</span> <span class="o">=</span> <span class="n">deepbiome</span><span class="o">.</span><span class="n">deepbiome_train</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">network_info</span><span class="p">,</span> <span class="n">path_info</span><span class="p">,</span> <span class="n">number_of_fold</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
[root    |INFO|deepbiome.py:100] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:137] -------1 simulation start!----------------------------------
[root    |INFO|readers.py:57] -----------------------------------------------------------------------
[root    |INFO|readers.py:58] Construct Dataset
[root    |INFO|readers.py:59] -----------------------------------------------------------------------
[root    |INFO|readers.py:60] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 1 simulation
[root    |INFO|build_network.py:506] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:507] Read phylogenetic tree information from data/genus48/genus48_dic.csv
[root    |INFO|build_network.py:512] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:520]      Genus: 48
[root    |INFO|build_network.py:520]     Family: 40
[root    |INFO|build_network.py:520]      Order: 23
[root    |INFO|build_network.py:520]      Class: 17
[root    |INFO|build_network.py:520]     Phylum: 9
[root    |INFO|build_network.py:524] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:525] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:526] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:536] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:536] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:536] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:536] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:549] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:557] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:558] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:559] ------------------------------------------------------------------------------------------
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[root    |INFO|build_network.py:636] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = mean_squared_error
[root    |INFO|build_network.py:60] Metrics = correlation_coefficient
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 1 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 12 samples, validate on 3 samples
Epoch 1/100
12/12 [==============================] - 1s 50ms/step - loss: 1.0048 - correlation_coefficient: -0.1126 - val_loss: 0.7376 - val_correlation_coefficient: -0.5486
Epoch 2/100
12/12 [==============================] - 0s 933us/step - loss: 0.9706 - correlation_coefficient: -0.1471 - val_loss: 0.6957 - val_correlation_coefficient: 0.1781
Epoch 3/100
12/12 [==============================] - 0s 940us/step - loss: 0.9235 - correlation_coefficient: -0.1054 - val_loss: 0.6541 - val_correlation_coefficient: 0.8798
Epoch 4/100
12/12 [==============================] - 0s 1ms/step - loss: 0.8764 - correlation_coefficient: -0.1026 - val_loss: 0.6105 - val_correlation_coefficient: 0.7807
Epoch 5/100
12/12 [==============================] - 0s 999us/step - loss: 0.8269 - correlation_coefficient: -0.1013 - val_loss: 0.5656 - val_correlation_coefficient: 0.5889
Epoch 6/100
12/12 [==============================] - 0s 1ms/step - loss: 0.7755 - correlation_coefficient: -0.1144 - val_loss: 0.5198 - val_correlation_coefficient: 0.2807
Epoch 7/100
12/12 [==============================] - 0s 967us/step - loss: 0.7229 - correlation_coefficient: -0.1259 - val_loss: 0.4734 - val_correlation_coefficient: -0.1526
Epoch 8/100
12/12 [==============================] - 0s 1ms/step - loss: 0.6692 - correlation_coefficient: -0.1370 - val_loss: 0.4266 - val_correlation_coefficient: -0.5200
Epoch 9/100
12/12 [==============================] - 0s 902us/step - loss: 0.6149 - correlation_coefficient: -0.1440 - val_loss: 0.3800 - val_correlation_coefficient: -0.7176
Epoch 10/100
12/12 [==============================] - 0s 891us/step - loss: 0.5602 - correlation_coefficient: -0.1469 - val_loss: 0.3337 - val_correlation_coefficient: 0.2796
Epoch 11/100
12/12 [==============================] - 0s 879us/step - loss: 0.5055 - correlation_coefficient: -0.1481 - val_loss: 0.2883 - val_correlation_coefficient: 0.8371
Epoch 12/100
12/12 [==============================] - 0s 883us/step - loss: 0.4511 - correlation_coefficient: -0.1498 - val_loss: 0.2441 - val_correlation_coefficient: 0.8362
Epoch 13/100
12/12 [==============================] - 0s 984us/step - loss: 0.3975 - correlation_coefficient: -0.1488 - val_loss: 0.2016 - val_correlation_coefficient: 0.7405
Epoch 14/100
12/12 [==============================] - 0s 933us/step - loss: 0.3451 - correlation_coefficient: -0.1490 - val_loss: 0.1614 - val_correlation_coefficient: 0.6448
Epoch 15/100
12/12 [==============================] - 0s 863us/step - loss: 0.2945 - correlation_coefficient: -0.1498 - val_loss: 0.1242 - val_correlation_coefficient: 0.5353
Epoch 16/100
12/12 [==============================] - 0s 897us/step - loss: 0.2463 - correlation_coefficient: -0.1507 - val_loss: 0.0906 - val_correlation_coefficient: 0.4308
Epoch 17/100
12/12 [==============================] - 0s 973us/step - loss: 0.2013 - correlation_coefficient: -0.1516 - val_loss: 0.0614 - val_correlation_coefficient: 0.3367
Epoch 18/100
12/12 [==============================] - 0s 872us/step - loss: 0.1602 - correlation_coefficient: -0.1524 - val_loss: 0.0375 - val_correlation_coefficient: 0.2558
Epoch 19/100
12/12 [==============================] - 0s 937us/step - loss: 0.1239 - correlation_coefficient: -0.1534 - val_loss: 0.0197 - val_correlation_coefficient: 0.1886
Epoch 20/100
12/12 [==============================] - 0s 962us/step - loss: 0.0933 - correlation_coefficient: -0.1544 - val_loss: 0.0088 - val_correlation_coefficient: 0.0671
Epoch 21/100
12/12 [==============================] - 0s 932us/step - loss: 0.0691 - correlation_coefficient: -0.1554 - val_loss: 0.0054 - val_correlation_coefficient: -0.1090
Epoch 22/100
12/12 [==============================] - 0s 920us/step - loss: 0.0523 - correlation_coefficient: -0.1562 - val_loss: 0.0098 - val_correlation_coefficient: -0.2414
Epoch 23/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0433 - correlation_coefficient: -0.1566 - val_loss: 0.0216 - val_correlation_coefficient: -0.3370
Epoch 24/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0420 - correlation_coefficient: -0.1566 - val_loss: 0.0395 - val_correlation_coefficient: -0.4068
Epoch 25/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0476 - correlation_coefficient: -0.1559 - val_loss: 0.0608 - val_correlation_coefficient: -0.4570
Epoch 26/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0580 - correlation_coefficient: -0.1546 - val_loss: 0.0819 - val_correlation_coefficient: -0.4900
Epoch 27/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0703 - correlation_coefficient: -0.1525 - val_loss: 0.0991 - val_correlation_coefficient: -0.5029
Epoch 28/100
12/12 [==============================] - 0s 877us/step - loss: 0.0811 - correlation_coefficient: -0.1502 - val_loss: 0.1100 - val_correlation_coefficient: -0.4942
Epoch 29/100
12/12 [==============================] - 0s 887us/step - loss: 0.0882 - correlation_coefficient: -0.1475 - val_loss: 0.1136 - val_correlation_coefficient: -0.4679
Epoch 30/100
12/12 [==============================] - 0s 961us/step - loss: 0.0906 - correlation_coefficient: -0.1446 - val_loss: 0.1107 - val_correlation_coefficient: -0.4251
Epoch 31/100
12/12 [==============================] - 0s 825us/step - loss: 0.0886 - correlation_coefficient: -0.1415 - val_loss: 0.1026 - val_correlation_coefficient: -0.3651
Epoch 32/100
12/12 [==============================] - 0s 932us/step - loss: 0.0832 - correlation_coefficient: -0.1383 - val_loss: 0.0911 - val_correlation_coefficient: -0.2872
Epoch 33/100
12/12 [==============================] - 0s 973us/step - loss: 0.0758 - correlation_coefficient: -0.1349 - val_loss: 0.0780 - val_correlation_coefficient: -0.1901
Epoch 34/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0677 - correlation_coefficient: -0.1313 - val_loss: 0.0647 - val_correlation_coefficient: -0.0745
Epoch 35/100
12/12 [==============================] - 0s 893us/step - loss: 0.0599 - correlation_coefficient: -0.1276 - val_loss: 0.0521 - val_correlation_coefficient: 0.0546
Epoch 36/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0532 - correlation_coefficient: -0.1237 - val_loss: 0.0411 - val_correlation_coefficient: 0.1895
Epoch 37/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0480 - correlation_coefficient: -0.1197 - val_loss: 0.0318 - val_correlation_coefficient: 0.3208
Epoch 38/100
12/12 [==============================] - 0s 960us/step - loss: 0.0444 - correlation_coefficient: -0.1156 - val_loss: 0.0243 - val_correlation_coefficient: 0.4388
Epoch 39/100
12/12 [==============================] - 0s 939us/step - loss: 0.0423 - correlation_coefficient: -0.1113 - val_loss: 0.0185 - val_correlation_coefficient: 0.5384
Epoch 40/100
12/12 [==============================] - 0s 817us/step - loss: 0.0414 - correlation_coefficient: -0.1070 - val_loss: 0.0143 - val_correlation_coefficient: 0.6071
Epoch 41/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0415 - correlation_coefficient: -0.1027 - val_loss: 0.0113 - val_correlation_coefficient: 0.6455
Epoch 42/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0423 - correlation_coefficient: -0.0983 - val_loss: 0.0092 - val_correlation_coefficient: 0.6784
Epoch 43/100
12/12 [==============================] - 0s 971us/step - loss: 0.0434 - correlation_coefficient: -0.0940 - val_loss: 0.0078 - val_correlation_coefficient: 0.7047
Epoch 44/100
12/12 [==============================] - 0s 862us/step - loss: 0.0447 - correlation_coefficient: -0.0896 - val_loss: 0.0070 - val_correlation_coefficient: 0.7261
Epoch 45/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0459 - correlation_coefficient: -0.0854 - val_loss: 0.0065 - val_correlation_coefficient: 0.7438
Epoch 46/100
12/12 [==============================] - 0s 870us/step - loss: 0.0468 - correlation_coefficient: -0.0811 - val_loss: 0.0062 - val_correlation_coefficient: 0.7584
Epoch 47/100
12/12 [==============================] - 0s 877us/step - loss: 0.0475 - correlation_coefficient: -0.0769 - val_loss: 0.0061 - val_correlation_coefficient: 0.7695
Epoch 48/100
12/12 [==============================] - 0s 993us/step - loss: 0.0478 - correlation_coefficient: -0.0728 - val_loss: 0.0061 - val_correlation_coefficient: 0.7781
Epoch 49/100
12/12 [==============================] - 0s 818us/step - loss: 0.0477 - correlation_coefficient: -0.0688 - val_loss: 0.0062 - val_correlation_coefficient: 0.7841
Epoch 50/100
12/12 [==============================] - 0s 903us/step - loss: 0.0474 - correlation_coefficient: -0.0648 - val_loss: 0.0065 - val_correlation_coefficient: 0.7885
Epoch 51/100
12/12 [==============================] - 0s 933us/step - loss: 0.0468 - correlation_coefficient: -0.0609 - val_loss: 0.0069 - val_correlation_coefficient: 0.7914
Epoch 52/100
12/12 [==============================] - 0s 976us/step - loss: 0.0460 - correlation_coefficient: -0.0570 - val_loss: 0.0074 - val_correlation_coefficient: 0.7934
Epoch 53/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0452 - correlation_coefficient: -0.0533 - val_loss: 0.0082 - val_correlation_coefficient: 0.7939
Epoch 54/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0443 - correlation_coefficient: -0.0497 - val_loss: 0.0091 - val_correlation_coefficient: 0.7942
Epoch 55/100
12/12 [==============================] - 0s 958us/step - loss: 0.0434 - correlation_coefficient: -0.0461 - val_loss: 0.0103 - val_correlation_coefficient: 0.7940
Epoch 56/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0427 - correlation_coefficient: -0.0425 - val_loss: 0.0117 - val_correlation_coefficient: 0.7935
Epoch 57/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0421 - correlation_coefficient: -0.0389 - val_loss: 0.0132 - val_correlation_coefficient: 0.7929
Epoch 58/100
12/12 [==============================] - 0s 984us/step - loss: 0.0416 - correlation_coefficient: -0.0352 - val_loss: 0.0149 - val_correlation_coefficient: 0.7924
Epoch 59/100
12/12 [==============================] - 0s 931us/step - loss: 0.0414 - correlation_coefficient: -0.0315 - val_loss: 0.0166 - val_correlation_coefficient: 0.7921
Epoch 60/100
12/12 [==============================] - 0s 966us/step - loss: 0.0413 - correlation_coefficient: -0.0278 - val_loss: 0.0183 - val_correlation_coefficient: 0.7923
Epoch 61/100
12/12 [==============================] - 0s 916us/step - loss: 0.0413 - correlation_coefficient: -0.0239 - val_loss: 0.0199 - val_correlation_coefficient: 0.7928
Epoch 62/100
12/12 [==============================] - 0s 959us/step - loss: 0.0414 - correlation_coefficient: -0.0200 - val_loss: 0.0214 - val_correlation_coefficient: 0.7937
Epoch 63/100
12/12 [==============================] - 0s 860us/step - loss: 0.0416 - correlation_coefficient: -0.0159 - val_loss: 0.0226 - val_correlation_coefficient: 0.7950
Epoch 64/100
12/12 [==============================] - 0s 839us/step - loss: 0.0418 - correlation_coefficient: -0.0117 - val_loss: 0.0236 - val_correlation_coefficient: 0.7969
Epoch 65/100
12/12 [==============================] - 0s 964us/step - loss: 0.0420 - correlation_coefficient: -0.0074 - val_loss: 0.0242 - val_correlation_coefficient: 0.7989
Epoch 66/100
12/12 [==============================] - 0s 976us/step - loss: 0.0421 - correlation_coefficient: -0.0029 - val_loss: 0.0246 - val_correlation_coefficient: 0.8015
Epoch 67/100
12/12 [==============================] - 0s 872us/step - loss: 0.0422 - correlation_coefficient: 0.0017 - val_loss: 0.0246 - val_correlation_coefficient: 0.8043
Epoch 68/100
12/12 [==============================] - 0s 895us/step - loss: 0.0422 - correlation_coefficient: 0.0065 - val_loss: 0.0243 - val_correlation_coefficient: 0.8073
Epoch 69/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0421 - correlation_coefficient: 0.0115 - val_loss: 0.0238 - val_correlation_coefficient: 0.8104
Epoch 70/100
12/12 [==============================] - 0s 959us/step - loss: 0.0420 - correlation_coefficient: 0.0166 - val_loss: 0.0231 - val_correlation_coefficient: 0.8136
Epoch 71/100
12/12 [==============================] - 0s 863us/step - loss: 0.0419 - correlation_coefficient: 0.0219 - val_loss: 0.0223 - val_correlation_coefficient: 0.8168
Epoch 72/100
12/12 [==============================] - 0s 873us/step - loss: 0.0417 - correlation_coefficient: 0.0274 - val_loss: 0.0213 - val_correlation_coefficient: 0.8197
Epoch 73/100
12/12 [==============================] - 0s 979us/step - loss: 0.0416 - correlation_coefficient: 0.0330 - val_loss: 0.0204 - val_correlation_coefficient: 0.8225
Epoch 74/100
12/12 [==============================] - 0s 939us/step - loss: 0.0414 - correlation_coefficient: 0.0387 - val_loss: 0.0194 - val_correlation_coefficient: 0.8252
Epoch 75/100
12/12 [==============================] - 0s 955us/step - loss: 0.0413 - correlation_coefficient: 0.0446 - val_loss: 0.0185 - val_correlation_coefficient: 0.8275
Epoch 76/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.0506 - val_loss: 0.0176 - val_correlation_coefficient: 0.8297
Epoch 77/100
12/12 [==============================] - 0s 954us/step - loss: 0.0412 - correlation_coefficient: 0.0568 - val_loss: 0.0168 - val_correlation_coefficient: 0.8316
Epoch 78/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.0630 - val_loss: 0.0162 - val_correlation_coefficient: 0.8330
Epoch 79/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.0694 - val_loss: 0.0156 - val_correlation_coefficient: 0.8342
Epoch 80/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.0759 - val_loss: 0.0152 - val_correlation_coefficient: 0.8351
Epoch 81/100
12/12 [==============================] - 0s 987us/step - loss: 0.0413 - correlation_coefficient: 0.0825 - val_loss: 0.0148 - val_correlation_coefficient: 0.8357
Epoch 82/100
12/12 [==============================] - 0s 986us/step - loss: 0.0413 - correlation_coefficient: 0.0892 - val_loss: 0.0146 - val_correlation_coefficient: 0.8361
Epoch 83/100
12/12 [==============================] - 0s 996us/step - loss: 0.0413 - correlation_coefficient: 0.0959 - val_loss: 0.0145 - val_correlation_coefficient: 0.8362
Epoch 84/100
12/12 [==============================] - 0s 988us/step - loss: 0.0413 - correlation_coefficient: 0.1028 - val_loss: 0.0144 - val_correlation_coefficient: 0.8361
Epoch 85/100
12/12 [==============================] - 0s 981us/step - loss: 0.0413 - correlation_coefficient: 0.1096 - val_loss: 0.0145 - val_correlation_coefficient: 0.8358
Epoch 86/100
12/12 [==============================] - 0s 968us/step - loss: 0.0413 - correlation_coefficient: 0.1166 - val_loss: 0.0146 - val_correlation_coefficient: 0.8353
Epoch 87/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0413 - correlation_coefficient: 0.1236 - val_loss: 0.0148 - val_correlation_coefficient: 0.8347
Epoch 88/100
12/12 [==============================] - 0s 967us/step - loss: 0.0413 - correlation_coefficient: 0.1306 - val_loss: 0.0151 - val_correlation_coefficient: 0.8340
Epoch 89/100
12/12 [==============================] - 0s 980us/step - loss: 0.0413 - correlation_coefficient: 0.1378 - val_loss: 0.0154 - val_correlation_coefficient: 0.8332
Epoch 90/100
12/12 [==============================] - 0s 944us/step - loss: 0.0412 - correlation_coefficient: 0.1450 - val_loss: 0.0157 - val_correlation_coefficient: 0.8323
Epoch 91/100
12/12 [==============================] - 0s 935us/step - loss: 0.0412 - correlation_coefficient: 0.1523 - val_loss: 0.0161 - val_correlation_coefficient: 0.8314
Epoch 92/100
12/12 [==============================] - 0s 880us/step - loss: 0.0412 - correlation_coefficient: 0.1597 - val_loss: 0.0164 - val_correlation_coefficient: 0.8304
Epoch 93/100
12/12 [==============================] - 0s 986us/step - loss: 0.0412 - correlation_coefficient: 0.1671 - val_loss: 0.0168 - val_correlation_coefficient: 0.8293
Epoch 94/100
12/12 [==============================] - 0s 933us/step - loss: 0.0412 - correlation_coefficient: 0.1746 - val_loss: 0.0171 - val_correlation_coefficient: 0.8283
Epoch 95/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0411 - correlation_coefficient: 0.1823 - val_loss: 0.0174 - val_correlation_coefficient: 0.8272
Epoch 96/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0411 - correlation_coefficient: 0.1900 - val_loss: 0.0177 - val_correlation_coefficient: 0.8262
Epoch 97/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0411 - correlation_coefficient: 0.1978 - val_loss: 0.0179 - val_correlation_coefficient: 0.8251
Epoch 98/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.2059 - val_loss: 0.0181 - val_correlation_coefficient: 0.8240
Epoch 99/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.2140 - val_loss: 0.0182 - val_correlation_coefficient: 0.8230
Epoch 100/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0412 - correlation_coefficient: 0.2222 - val_loss: 0.0182 - val_correlation_coefficient: 0.8220
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:83] Load trained model weight at ./realdata_fev1/fev1_deepbiome/weight/weight_0.h5
[root    |INFO|build_network.py:143] Training end with time 4.5308990478515625!
[root    |INFO|build_network.py:79] Saved trained model weight at ./realdata_fev1/fev1_deepbiome/weight/weight_0.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./realdata_fev1/fev1_deepbiome/weight/weight_0.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./realdata_fev1/fev1_deepbiome/history/hist_0.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
15/15 [==============================] - 0s 274us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.007390499114990234!
[root    |INFO|build_network.py:175] Evaluation: [0.042929645627737045, -0.13775882124900818]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
15/15 [==============================] - 0s 233us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.007122039794921875!
[root    |INFO|build_network.py:175] Evaluation: [0.02973029948771, -0.31848886609077454]
[root    |INFO|deepbiome.py:180] Compute time : 5.849995851516724
[root    |INFO|deepbiome.py:181] 1 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:137] -------2 simulation start!----------------------------------
[root    |INFO|readers.py:57] -----------------------------------------------------------------------
[root    |INFO|readers.py:58] Construct Dataset
[root    |INFO|readers.py:59] -----------------------------------------------------------------------
[root    |INFO|readers.py:60] Load data
[root    |INFO|deepbiome.py:147] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:148] Build network for 2 simulation
[root    |INFO|build_network.py:506] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:507] Read phylogenetic tree information from data/genus48/genus48_dic.csv
[root    |INFO|build_network.py:512] Phylogenetic tree level list: [&#39;Genus&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Class&#39;, &#39;Phylum&#39;]
[root    |INFO|build_network.py:513] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:520]      Genus: 48
[root    |INFO|build_network.py:520]     Family: 40
[root    |INFO|build_network.py:520]      Order: 23
[root    |INFO|build_network.py:520]      Class: 17
[root    |INFO|build_network.py:520]     Phylum: 9
[root    |INFO|build_network.py:524] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:525] Phylogenetic_tree_dict info: [&#39;Class&#39;, &#39;Phylum&#39;, &#39;Family&#39;, &#39;Order&#39;, &#39;Genus&#39;, &#39;Number&#39;]
[root    |INFO|build_network.py:526] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:536] Build edge weights between [ Genus, Family]
[root    |INFO|build_network.py:536] Build edge weights between [Family,  Order]
[root    |INFO|build_network.py:536] Build edge weights between [ Order,  Class]
[root    |INFO|build_network.py:536] Build edge weights between [ Class, Phylum]
[root    |INFO|build_network.py:549] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:557] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:558] Build network based on phylogenetic tree information
[root    |INFO|build_network.py:559] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:636] ------------------------------------------------------------------------------------------
[root    |INFO|build_network.py:57] Build Network
[root    |INFO|build_network.py:58] Optimizer = adam
[root    |INFO|build_network.py:59] Loss = mean_squared_error
[root    |INFO|build_network.py:60] Metrics = correlation_coefficient
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input (InputLayer)           (None, 48)                0
_________________________________________________________________
l1_dense (Dense_with_tree)   (None, 40)                1960
_________________________________________________________________
l1_activation (Activation)   (None, 40)                0
_________________________________________________________________
l2_dense (Dense_with_tree)   (None, 23)                943
_________________________________________________________________
l2_activation (Activation)   (None, 23)                0
_________________________________________________________________
l3_dense (Dense_with_tree)   (None, 17)                408
_________________________________________________________________
l3_activation (Activation)   (None, 17)                0
_________________________________________________________________
l4_dense (Dense_with_tree)   (None, 9)                 162
_________________________________________________________________
l4_activation (Activation)   (None, 9)                 0
_________________________________________________________________
last_dense_h (Dense)         (None, 1)                 10
_________________________________________________________________
p_hat (Activation)           (None, 1)                 0
=================================================================
Total params: 3,483
Trainable params: 3,483
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|deepbiome.py:157] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:158] 2 fold computing start!----------------------------------
[root    |INFO|build_network.py:133] Training start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train on 12 samples, validate on 3 samples
Epoch 1/100
12/12 [==============================] - 0s 22ms/step - loss: 0.9817 - correlation_coefficient: -0.0662 - val_loss: 0.7865 - val_correlation_coefficient: -0.6405
Epoch 2/100
12/12 [==============================] - 0s 998us/step - loss: 0.9237 - correlation_coefficient: 0.1474 - val_loss: 0.7323 - val_correlation_coefficient: -0.3348
Epoch 3/100
12/12 [==============================] - 0s 983us/step - loss: 0.8654 - correlation_coefficient: 0.2690 - val_loss: 0.6778 - val_correlation_coefficient: -0.3750
Epoch 4/100
12/12 [==============================] - 0s 879us/step - loss: 0.8067 - correlation_coefficient: 0.3854 - val_loss: 0.6234 - val_correlation_coefficient: -0.3945
Epoch 5/100
12/12 [==============================] - 0s 958us/step - loss: 0.7478 - correlation_coefficient: 0.3848 - val_loss: 0.5691 - val_correlation_coefficient: -0.3869
Epoch 6/100
12/12 [==============================] - 0s 910us/step - loss: 0.6889 - correlation_coefficient: 0.3392 - val_loss: 0.5150 - val_correlation_coefficient: -0.3780
Epoch 7/100
12/12 [==============================] - 0s 931us/step - loss: 0.6301 - correlation_coefficient: 0.2641 - val_loss: 0.4616 - val_correlation_coefficient: -0.3653
Epoch 8/100
12/12 [==============================] - 0s 992us/step - loss: 0.5716 - correlation_coefficient: 0.1793 - val_loss: 0.4091 - val_correlation_coefficient: -0.3486
Epoch 9/100
12/12 [==============================] - 0s 986us/step - loss: 0.5139 - correlation_coefficient: 0.1213 - val_loss: 0.3578 - val_correlation_coefficient: -0.3230
Epoch 10/100
12/12 [==============================] - 0s 993us/step - loss: 0.4572 - correlation_coefficient: 0.0742 - val_loss: 0.3081 - val_correlation_coefficient: -0.2833
Epoch 11/100
12/12 [==============================] - 0s 978us/step - loss: 0.4018 - correlation_coefficient: 0.0268 - val_loss: 0.2604 - val_correlation_coefficient: -0.2259
Epoch 12/100
12/12 [==============================] - 0s 964us/step - loss: 0.3482 - correlation_coefficient: -0.0271 - val_loss: 0.2151 - val_correlation_coefficient: -0.1448
Epoch 13/100
12/12 [==============================] - 0s 996us/step - loss: 0.2968 - correlation_coefficient: -0.0768 - val_loss: 0.1729 - val_correlation_coefficient: 0.0047
Epoch 14/100
12/12 [==============================] - 0s 926us/step - loss: 0.2482 - correlation_coefficient: -0.1226 - val_loss: 0.1341 - val_correlation_coefficient: 0.2891
Epoch 15/100
12/12 [==============================] - 0s 1ms/step - loss: 0.2028 - correlation_coefficient: -0.1580 - val_loss: 0.0994 - val_correlation_coefficient: 0.7902
Epoch 16/100
12/12 [==============================] - 0s 1ms/step - loss: 0.1613 - correlation_coefficient: -0.1915 - val_loss: 0.0694 - val_correlation_coefficient: 0.9845
Epoch 17/100
12/12 [==============================] - 0s 1ms/step - loss: 0.1243 - correlation_coefficient: -0.1996 - val_loss: 0.0447 - val_correlation_coefficient: 0.8285
Epoch 18/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0924 - correlation_coefficient: -0.2058 - val_loss: 0.0258 - val_correlation_coefficient: 0.7155
Epoch 19/100
12/12 [==============================] - 0s 964us/step - loss: 0.0662 - correlation_coefficient: -0.2094 - val_loss: 0.0132 - val_correlation_coefficient: 0.6484
Epoch 20/100
12/12 [==============================] - 0s 948us/step - loss: 0.0461 - correlation_coefficient: -0.2101 - val_loss: 0.0071 - val_correlation_coefficient: 0.6041
Epoch 21/100
12/12 [==============================] - 0s 868us/step - loss: 0.0326 - correlation_coefficient: -0.2070 - val_loss: 0.0075 - val_correlation_coefficient: 0.5772
Epoch 22/100
12/12 [==============================] - 0s 837us/step - loss: 0.0257 - correlation_coefficient: -0.1995 - val_loss: 0.0138 - val_correlation_coefficient: 0.5600
Epoch 23/100
12/12 [==============================] - 0s 914us/step - loss: 0.0250 - correlation_coefficient: -0.1875 - val_loss: 0.0250 - val_correlation_coefficient: 0.5499
Epoch 24/100
12/12 [==============================] - 0s 974us/step - loss: 0.0297 - correlation_coefficient: -0.1716 - val_loss: 0.0391 - val_correlation_coefficient: 0.5464
Epoch 25/100
12/12 [==============================] - 0s 939us/step - loss: 0.0380 - correlation_coefficient: -0.1519 - val_loss: 0.0538 - val_correlation_coefficient: 0.5475
Epoch 26/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0479 - correlation_coefficient: -0.1287 - val_loss: 0.0666 - val_correlation_coefficient: 0.5544
Epoch 27/100
12/12 [==============================] - 0s 927us/step - loss: 0.0572 - correlation_coefficient: -0.1019 - val_loss: 0.0758 - val_correlation_coefficient: 0.5660
Epoch 28/100
12/12 [==============================] - 0s 954us/step - loss: 0.0640 - correlation_coefficient: -0.0712 - val_loss: 0.0805 - val_correlation_coefficient: 0.5836
Epoch 29/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0675 - correlation_coefficient: -0.0362 - val_loss: 0.0805 - val_correlation_coefficient: 0.6095
Epoch 30/100
12/12 [==============================] - 0s 993us/step - loss: 0.0676 - correlation_coefficient: 0.0033 - val_loss: 0.0766 - val_correlation_coefficient: 0.6488
Epoch 31/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0646 - correlation_coefficient: 0.0473 - val_loss: 0.0698 - val_correlation_coefficient: 0.7112
Epoch 32/100
12/12 [==============================] - 0s 868us/step - loss: 0.0595 - correlation_coefficient: 0.0948 - val_loss: 0.0612 - val_correlation_coefficient: 0.8163
Epoch 33/100
12/12 [==============================] - 0s 972us/step - loss: 0.0531 - correlation_coefficient: 0.1441 - val_loss: 0.0519 - val_correlation_coefficient: 0.9721
Epoch 34/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0465 - correlation_coefficient: 0.1936 - val_loss: 0.0426 - val_correlation_coefficient: 0.8275
Epoch 35/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0402 - correlation_coefficient: 0.2410 - val_loss: 0.0341 - val_correlation_coefficient: 0.3025
Epoch 36/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0348 - correlation_coefficient: 0.2846 - val_loss: 0.0267 - val_correlation_coefficient: 0.0300
Epoch 37/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0305 - correlation_coefficient: 0.3237 - val_loss: 0.0206 - val_correlation_coefficient: -0.0985
Epoch 38/100
12/12 [==============================] - 0s 949us/step - loss: 0.0274 - correlation_coefficient: 0.3583 - val_loss: 0.0158 - val_correlation_coefficient: -0.1667
Epoch 39/100
12/12 [==============================] - 0s 992us/step - loss: 0.0255 - correlation_coefficient: 0.3885 - val_loss: 0.0123 - val_correlation_coefficient: -0.2086
Epoch 40/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0247 - correlation_coefficient: 0.4150 - val_loss: 0.0098 - val_correlation_coefficient: -0.2400
Epoch 41/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0246 - correlation_coefficient: 0.4324 - val_loss: 0.0082 - val_correlation_coefficient: -0.2587
Epoch 42/100
12/12 [==============================] - 0s 961us/step - loss: 0.0251 - correlation_coefficient: 0.4471 - val_loss: 0.0072 - val_correlation_coefficient: -0.2749
Epoch 43/100
12/12 [==============================] - 0s 957us/step - loss: 0.0260 - correlation_coefficient: 0.4608 - val_loss: 0.0067 - val_correlation_coefficient: -0.2852
Epoch 44/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0270 - correlation_coefficient: 0.4737 - val_loss: 0.0065 - val_correlation_coefficient: -0.2934
Epoch 45/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0280 - correlation_coefficient: 0.4859 - val_loss: 0.0065 - val_correlation_coefficient: -0.3014
Epoch 46/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0288 - correlation_coefficient: 0.4971 - val_loss: 0.0065 - val_correlation_coefficient: -0.3065
Epoch 47/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0294 - correlation_coefficient: 0.5084 - val_loss: 0.0066 - val_correlation_coefficient: -0.3110
Epoch 48/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0298 - correlation_coefficient: 0.5193 - val_loss: 0.0066 - val_correlation_coefficient: -0.3151
Epoch 49/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0299 - correlation_coefficient: 0.5297 - val_loss: 0.0065 - val_correlation_coefficient: -0.3181
Epoch 50/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0298 - correlation_coefficient: 0.5397 - val_loss: 0.0065 - val_correlation_coefficient: -0.3205
Epoch 51/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0294 - correlation_coefficient: 0.5494 - val_loss: 0.0065 - val_correlation_coefficient: -0.3231
Epoch 52/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0288 - correlation_coefficient: 0.5588 - val_loss: 0.0065 - val_correlation_coefficient: -0.3235
Epoch 53/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0281 - correlation_coefficient: 0.5680 - val_loss: 0.0066 - val_correlation_coefficient: -0.3263
Epoch 54/100
12/12 [==============================] - 0s 919us/step - loss: 0.0274 - correlation_coefficient: 0.5767 - val_loss: 0.0068 - val_correlation_coefficient: -0.3270
Epoch 55/100
12/12 [==============================] - 0s 980us/step - loss: 0.0267 - correlation_coefficient: 0.5851 - val_loss: 0.0072 - val_correlation_coefficient: -0.3289
Epoch 56/100
12/12 [==============================] - 0s 919us/step - loss: 0.0261 - correlation_coefficient: 0.5933 - val_loss: 0.0076 - val_correlation_coefficient: -0.3296
Epoch 57/100
12/12 [==============================] - 0s 994us/step - loss: 0.0255 - correlation_coefficient: 0.6013 - val_loss: 0.0083 - val_correlation_coefficient: -0.3305
Epoch 58/100
12/12 [==============================] - 0s 990us/step - loss: 0.0250 - correlation_coefficient: 0.6091 - val_loss: 0.0090 - val_correlation_coefficient: -0.3324
Epoch 59/100
12/12 [==============================] - 0s 968us/step - loss: 0.0247 - correlation_coefficient: 0.6165 - val_loss: 0.0098 - val_correlation_coefficient: -0.3331
Epoch 60/100
12/12 [==============================] - 0s 939us/step - loss: 0.0246 - correlation_coefficient: 0.6238 - val_loss: 0.0107 - val_correlation_coefficient: -0.3333
Epoch 61/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - correlation_coefficient: 0.6309 - val_loss: 0.0116 - val_correlation_coefficient: -0.3344
Epoch 62/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0246 - correlation_coefficient: 0.6378 - val_loss: 0.0125 - val_correlation_coefficient: -0.3354
Epoch 63/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0247 - correlation_coefficient: 0.6446 - val_loss: 0.0133 - val_correlation_coefficient: -0.3364
Epoch 64/100
12/12 [==============================] - 0s 944us/step - loss: 0.0248 - correlation_coefficient: 0.6511 - val_loss: 0.0140 - val_correlation_coefficient: -0.3376
Epoch 65/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0250 - correlation_coefficient: 0.6574 - val_loss: 0.0145 - val_correlation_coefficient: -0.3387
Epoch 66/100
12/12 [==============================] - 0s 938us/step - loss: 0.0251 - correlation_coefficient: 0.6636 - val_loss: 0.0148 - val_correlation_coefficient: -0.3397
Epoch 67/100
12/12 [==============================] - 0s 857us/step - loss: 0.0252 - correlation_coefficient: 0.6697 - val_loss: 0.0150 - val_correlation_coefficient: -0.3413
Epoch 68/100
12/12 [==============================] - 0s 986us/step - loss: 0.0253 - correlation_coefficient: 0.6756 - val_loss: 0.0150 - val_correlation_coefficient: -0.3421
Epoch 69/100
12/12 [==============================] - 0s 952us/step - loss: 0.0253 - correlation_coefficient: 0.6812 - val_loss: 0.0149 - val_correlation_coefficient: -0.3426
Epoch 70/100
12/12 [==============================] - 0s 922us/step - loss: 0.0252 - correlation_coefficient: 0.6868 - val_loss: 0.0146 - val_correlation_coefficient: -0.3448
Epoch 71/100
12/12 [==============================] - 0s 946us/step - loss: 0.0251 - correlation_coefficient: 0.6922 - val_loss: 0.0142 - val_correlation_coefficient: -0.3460
Epoch 72/100
12/12 [==============================] - 0s 930us/step - loss: 0.0250 - correlation_coefficient: 0.6975 - val_loss: 0.0137 - val_correlation_coefficient: -0.3477
Epoch 73/100
12/12 [==============================] - 0s 844us/step - loss: 0.0249 - correlation_coefficient: 0.7027 - val_loss: 0.0132 - val_correlation_coefficient: -0.3492
Epoch 74/100
12/12 [==============================] - 0s 903us/step - loss: 0.0248 - correlation_coefficient: 0.7077 - val_loss: 0.0126 - val_correlation_coefficient: -0.3503
Epoch 75/100
12/12 [==============================] - 0s 883us/step - loss: 0.0247 - correlation_coefficient: 0.7125 - val_loss: 0.0121 - val_correlation_coefficient: -0.3522
Epoch 76/100
12/12 [==============================] - 0s 862us/step - loss: 0.0246 - correlation_coefficient: 0.7173 - val_loss: 0.0116 - val_correlation_coefficient: -0.3525
Epoch 77/100
12/12 [==============================] - 0s 836us/step - loss: 0.0245 - correlation_coefficient: 0.7219 - val_loss: 0.0111 - val_correlation_coefficient: -0.3544
Epoch 78/100
12/12 [==============================] - 0s 947us/step - loss: 0.0245 - correlation_coefficient: 0.7264 - val_loss: 0.0107 - val_correlation_coefficient: -0.3554
Epoch 79/100
12/12 [==============================] - 0s 951us/step - loss: 0.0245 - correlation_coefficient: 0.7308 - val_loss: 0.0104 - val_correlation_coefficient: -0.3569
Epoch 80/100
12/12 [==============================] - 0s 933us/step - loss: 0.0245 - correlation_coefficient: 0.7350 - val_loss: 0.0101 - val_correlation_coefficient: -0.3569
Epoch 81/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - correlation_coefficient: 0.7395 - val_loss: 0.0098 - val_correlation_coefficient: -0.3588
Epoch 82/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - correlation_coefficient: 0.7443 - val_loss: 0.0096 - val_correlation_coefficient: -0.3596
Epoch 83/100
12/12 [==============================] - 0s 971us/step - loss: 0.0246 - correlation_coefficient: 0.7489 - val_loss: 0.0095 - val_correlation_coefficient: -0.3608
Epoch 84/100
12/12 [==============================] - 0s 941us/step - loss: 0.0246 - correlation_coefficient: 0.7533 - val_loss: 0.0094 - val_correlation_coefficient: -0.3616
Epoch 85/100
12/12 [==============================] - 0s 874us/step - loss: 0.0246 - correlation_coefficient: 0.7574 - val_loss: 0.0094 - val_correlation_coefficient: -0.3628
Epoch 86/100
12/12 [==============================] - 0s 920us/step - loss: 0.0246 - correlation_coefficient: 0.7613 - val_loss: 0.0094 - val_correlation_coefficient: -0.3633
Epoch 87/100
12/12 [==============================] - 0s 975us/step - loss: 0.0246 - correlation_coefficient: 0.7649 - val_loss: 0.0095 - val_correlation_coefficient: -0.3650
Epoch 88/100
12/12 [==============================] - 0s 936us/step - loss: 0.0246 - correlation_coefficient: 0.7684 - val_loss: 0.0095 - val_correlation_coefficient: -0.3659
Epoch 89/100
12/12 [==============================] - 0s 892us/step - loss: 0.0246 - correlation_coefficient: 0.7717 - val_loss: 0.0097 - val_correlation_coefficient: -0.3657
Epoch 90/100
12/12 [==============================] - 0s 919us/step - loss: 0.0245 - correlation_coefficient: 0.7749 - val_loss: 0.0098 - val_correlation_coefficient: -0.3669
Epoch 91/100
12/12 [==============================] - 0s 998us/step - loss: 0.0245 - correlation_coefficient: 0.7778 - val_loss: 0.0100 - val_correlation_coefficient: -0.3682
Epoch 92/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - correlation_coefficient: 0.7806 - val_loss: 0.0101 - val_correlation_coefficient: -0.3687
Epoch 93/100
12/12 [==============================] - 0s 2ms/step - loss: 0.0245 - correlation_coefficient: 0.7832 - val_loss: 0.0103 - val_correlation_coefficient: -0.3696
Epoch 94/100
12/12 [==============================] - 0s 938us/step - loss: 0.0245 - correlation_coefficient: 0.7857 - val_loss: 0.0105 - val_correlation_coefficient: -0.3698
Epoch 95/100
12/12 [==============================] - 0s 1ms/step - loss: 0.0245 - correlation_coefficient: 0.7880 - val_loss: 0.0107 - val_correlation_coefficient: -0.3713
Epoch 96/100
12/12 [==============================] - 0s 981us/step - loss: 0.0245 - correlation_coefficient: 0.7901 - val_loss: 0.0108 - val_correlation_coefficient: -0.3715
Epoch 97/100
12/12 [==============================] - 0s 947us/step - loss: 0.0244 - correlation_coefficient: 0.7922 - val_loss: 0.0110 - val_correlation_coefficient: -0.3729
Epoch 98/100
12/12 [==============================] - 0s 826us/step - loss: 0.0244 - correlation_coefficient: 0.7941 - val_loss: 0.0111 - val_correlation_coefficient: -0.3744
Epoch 99/100
12/12 [==============================] - 0s 922us/step - loss: 0.0244 - correlation_coefficient: 0.7959 - val_loss: 0.0112 - val_correlation_coefficient: -0.3748
Epoch 100/100
12/12 [==============================] - 0s 933us/step - loss: 0.0244 - correlation_coefficient: 0.7975 - val_loss: 0.0113 - val_correlation_coefficient: -0.3758
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:83] Load trained model weight at ./realdata_fev1/fev1_deepbiome/weight/weight_1.h5
[root    |INFO|build_network.py:143] Training end with time 3.820185422897339!
[root    |INFO|build_network.py:79] Saved trained model weight at ./realdata_fev1/fev1_deepbiome/weight/weight_1.h5
[root    |DEBUG|deepbiome.py:166] Save weight at ./realdata_fev1/fev1_deepbiome/weight/weight_1.h5
[root    |DEBUG|deepbiome.py:169] Save history at ./realdata_fev1/fev1_deepbiome/history/hist_1.json
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
15/15 [==============================] - 0s 236us/step
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.005889415740966797!
[root    |INFO|build_network.py:175] Evaluation: [0.02434637024998665, 0.46849143505096436]
[root    |INFO|build_network.py:169] Evaluation start!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
15/15 [==============================] - 0s 230us/step
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[root    |INFO|build_network.py:174] Evaluation end with time 0.006192207336425781!
[root    |INFO|build_network.py:175] Evaluation: [0.03814231604337692, 0.09145616739988327]
[root    |INFO|deepbiome.py:180] Compute time : 4.624242067337036
[root    |INFO|deepbiome.py:181] 2 fold computing end!---------------------------------------------
[root    |INFO|deepbiome.py:184] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:186] Train Evaluation : [&#39;loss&#39; &#39;correlation_coefficient&#39;]
[root    |INFO|deepbiome.py:189]       mean : [0.03363801 0.16536631]
[root    |INFO|deepbiome.py:190]        std : [0.00929164 0.30312513]
[root    |INFO|deepbiome.py:191] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:193] Test Evaluation : [&#39;loss&#39; &#39;correlation_coefficient&#39;]
[root    |INFO|deepbiome.py:196]       mean : [ 0.03393631 -0.11351635]
[root    |INFO|deepbiome.py:197]        std : [0.00420601 0.20497252]
[root    |INFO|deepbiome.py:198] -----------------------------------------------------------------
[root    |INFO|deepbiome.py:207] Total Computing Ended
[root    |INFO|deepbiome.py:208] -----------------------------------------------------------------
</pre></div></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="DeepBiome_usage_classification.html" class="btn btn-neutral float-left" title="Getting start with the classification problem." accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Youngwon Choi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>